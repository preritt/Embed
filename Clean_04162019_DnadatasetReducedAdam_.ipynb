{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean 04162019 DnadatasetReducedAdam-.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/Clean_04162019_DnadatasetReducedAdam_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "0d1aa85b-65fb-4fda-f517-651737b094e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.677234</td>\n",
              "      <td>-0.205123</td>\n",
              "      <td>-0.482950</td>\n",
              "      <td>-0.491417</td>\n",
              "      <td>0.074036</td>\n",
              "      <td>0.120849</td>\n",
              "      <td>-0.106411</td>\n",
              "      <td>-0.854025</td>\n",
              "      <td>0.235618</td>\n",
              "      <td>-0.724818</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.452475</td>\n",
              "      <td>-0.076587</td>\n",
              "      <td>0.065689</td>\n",
              "      <td>-0.204755</td>\n",
              "      <td>0.719114</td>\n",
              "      <td>-0.415737</td>\n",
              "      <td>0.151107</td>\n",
              "      <td>-0.278909</td>\n",
              "      <td>-0.022437</td>\n",
              "      <td>0.116028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.968325</td>\n",
              "      <td>-0.901980</td>\n",
              "      <td>-0.612648</td>\n",
              "      <td>-0.320269</td>\n",
              "      <td>0.900248</td>\n",
              "      <td>-1.070258</td>\n",
              "      <td>-0.276023</td>\n",
              "      <td>-1.350481</td>\n",
              "      <td>-0.307156</td>\n",
              "      <td>0.873546</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.312353</td>\n",
              "      <td>-0.154037</td>\n",
              "      <td>-0.097274</td>\n",
              "      <td>-0.028025</td>\n",
              "      <td>-0.198132</td>\n",
              "      <td>-0.364496</td>\n",
              "      <td>0.373894</td>\n",
              "      <td>-0.262713</td>\n",
              "      <td>-0.031868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.144510</td>\n",
              "      <td>-0.639640</td>\n",
              "      <td>0.094091</td>\n",
              "      <td>0.736130</td>\n",
              "      <td>-0.741035</td>\n",
              "      <td>1.317996</td>\n",
              "      <td>-0.332095</td>\n",
              "      <td>1.514341</td>\n",
              "      <td>-0.697174</td>\n",
              "      <td>0.793378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052664</td>\n",
              "      <td>0.234666</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.379384</td>\n",
              "      <td>-0.415597</td>\n",
              "      <td>-0.251387</td>\n",
              "      <td>-0.249521</td>\n",
              "      <td>-0.048087</td>\n",
              "      <td>0.846899</td>\n",
              "      <td>-0.228373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.011300</td>\n",
              "      <td>-0.753063</td>\n",
              "      <td>1.140482</td>\n",
              "      <td>-1.568935</td>\n",
              "      <td>0.673132</td>\n",
              "      <td>0.256885</td>\n",
              "      <td>-1.308196</td>\n",
              "      <td>-0.929054</td>\n",
              "      <td>-1.467942</td>\n",
              "      <td>0.812135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>0.306471</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.238929</td>\n",
              "      <td>-0.382544</td>\n",
              "      <td>0.214989</td>\n",
              "      <td>-0.098546</td>\n",
              "      <td>0.089057</td>\n",
              "      <td>0.111130</td>\n",
              "      <td>-0.350712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.019436</td>\n",
              "      <td>0.294622</td>\n",
              "      <td>1.569688</td>\n",
              "      <td>0.488142</td>\n",
              "      <td>-0.463129</td>\n",
              "      <td>-0.929467</td>\n",
              "      <td>-1.738224</td>\n",
              "      <td>-0.145351</td>\n",
              "      <td>0.004826</td>\n",
              "      <td>-1.081979</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014322</td>\n",
              "      <td>0.062022</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.140120</td>\n",
              "      <td>-0.348128</td>\n",
              "      <td>-0.529818</td>\n",
              "      <td>-0.252468</td>\n",
              "      <td>-0.330608</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>0.567040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.677234 -0.205123 -0.482950 -0.491417  0.074036  0.120849 -0.106411   \n",
              "1 -0.968325 -0.901980 -0.612648 -0.320269  0.900248 -1.070258 -0.276023   \n",
              "2 -1.144510 -0.639640  0.094091  0.736130 -0.741035  1.317996 -0.332095   \n",
              "3  1.011300 -0.753063  1.140482 -1.568935  0.673132  0.256885 -1.308196   \n",
              "4 -0.019436  0.294622  1.569688  0.488142 -0.463129 -0.929467 -1.738224   \n",
              "\n",
              "        7         8         9      ...          128       129       130  \\\n",
              "0 -0.854025  0.235618 -0.724818    ...    -0.452475 -0.076587  0.065689   \n",
              "1 -1.350481 -0.307156  0.873546    ...    -0.062500  0.312353 -0.154037   \n",
              "2  1.514341 -0.697174  0.793378    ...    -0.052664  0.234666  0.514637   \n",
              "3 -0.929054 -1.467942  0.812135    ...     0.005383  0.306471  0.055101   \n",
              "4 -0.145351  0.004826 -1.081979    ...     0.014322  0.062022  0.049797   \n",
              "\n",
              "        131       132       133       134       135       136       137  \n",
              "0 -0.204755  0.719114 -0.415737  0.151107 -0.278909 -0.022437  0.116028  \n",
              "1 -0.097274 -0.028025 -0.198132 -0.364496  0.373894 -0.262713 -0.031868  \n",
              "2  0.379384 -0.415597 -0.251387 -0.249521 -0.048087  0.846899 -0.228373  \n",
              "3  0.238929 -0.382544  0.214989 -0.098546  0.089057  0.111130 -0.350712  \n",
              "4 -0.140120 -0.348128 -0.529818 -0.252468 -0.330608 -0.000366  0.567040  \n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "19402d96-ff93-4cd1-875f-97039b3fb228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  1\n",
              "1  1\n",
              "2  1\n",
              "3  2\n",
              "4  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "7bb143e8-33bd-4b8d-ff96-62a08ee6901a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "acd7e62b-5781-47b5-cf05-4d9ed0a636f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "a04c70cd-50aa-4e40-8f47-d7e26cb08ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pDOMf8vCQFNW"
      },
      "cell_type": "markdown",
      "source": [
        "## without using vaidation data for fitting"
      ]
    },
    {
      "metadata": {
        "id": "P2OQDaKv_x0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_label.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "5dc1341d-1d32-4880-d70a-4f40b49b05dc",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1683
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(138, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.97153027\n",
            "Iteration 2, loss = 0.38995267\n",
            "Iteration 3, loss = 0.16863707\n",
            "Iteration 4, loss = 0.08644866\n",
            "Iteration 5, loss = 0.04790676\n",
            "Iteration 6, loss = 0.02766120\n",
            "Iteration 7, loss = 0.01804213\n",
            "Iteration 8, loss = 0.01303306\n",
            "Iteration 9, loss = 0.01017363\n",
            "Iteration 10, loss = 0.00846074\n",
            "Iteration 11, loss = 0.00731784\n",
            "Iteration 12, loss = 0.00642295\n",
            "Iteration 13, loss = 0.00578566\n",
            "Iteration 14, loss = 0.00524263\n",
            "Iteration 15, loss = 0.00482185\n",
            "Iteration 16, loss = 0.00445585\n",
            "Iteration 17, loss = 0.00415009\n",
            "Iteration 18, loss = 0.00387484\n",
            "Iteration 19, loss = 0.00363059\n",
            "Iteration 20, loss = 0.00342359\n",
            "Iteration 21, loss = 0.00324253\n",
            "Iteration 22, loss = 0.00306885\n",
            "Iteration 23, loss = 0.00291664\n",
            "Iteration 24, loss = 0.00277493\n",
            "Iteration 25, loss = 0.00265069\n",
            "Iteration 26, loss = 0.00253650\n",
            "Iteration 27, loss = 0.00242954\n",
            "Iteration 28, loss = 0.00233327\n",
            "Iteration 29, loss = 0.00224341\n",
            "Iteration 30, loss = 0.00215908\n",
            "Iteration 31, loss = 0.00208097\n",
            "Iteration 32, loss = 0.00200870\n",
            "Iteration 33, loss = 0.00194052\n",
            "Iteration 34, loss = 0.00187660\n",
            "Iteration 35, loss = 0.00181774\n",
            "Iteration 36, loss = 0.00176193\n",
            "Iteration 37, loss = 0.00170941\n",
            "Iteration 38, loss = 0.00166006\n",
            "Iteration 39, loss = 0.00161241\n",
            "Iteration 40, loss = 0.00156818\n",
            "Iteration 41, loss = 0.00152616\n",
            "Iteration 42, loss = 0.00148629\n",
            "Iteration 43, loss = 0.00144797\n",
            "Iteration 44, loss = 0.00141247\n",
            "Iteration 45, loss = 0.00137653\n",
            "Iteration 46, loss = 0.00134514\n",
            "Iteration 47, loss = 0.00131347\n",
            "Iteration 48, loss = 0.00128475\n",
            "Iteration 49, loss = 0.00125555\n",
            "Iteration 50, loss = 0.00122770\n",
            "Iteration 51, loss = 0.00120178\n",
            "Iteration 52, loss = 0.00117708\n",
            "Iteration 53, loss = 0.00115253\n",
            "Iteration 54, loss = 0.00112934\n",
            "Iteration 55, loss = 0.00110742\n",
            "Iteration 56, loss = 0.00108600\n",
            "Iteration 57, loss = 0.00106536\n",
            "Iteration 58, loss = 0.00104544\n",
            "Iteration 59, loss = 0.00102592\n",
            "Iteration 60, loss = 0.00100787\n",
            "Iteration 61, loss = 0.00099042\n",
            "Iteration 62, loss = 0.00097298\n",
            "Iteration 63, loss = 0.00095668\n",
            "Iteration 64, loss = 0.00094005\n",
            "Iteration 65, loss = 0.00092519\n",
            "Iteration 66, loss = 0.00090977\n",
            "Iteration 67, loss = 0.00089595\n",
            "Iteration 68, loss = 0.00088126\n",
            "Iteration 69, loss = 0.00086789\n",
            "Iteration 70, loss = 0.00085454\n",
            "Iteration 71, loss = 0.00084165\n",
            "Iteration 72, loss = 0.00082940\n",
            "Iteration 73, loss = 0.00081723\n",
            "Iteration 74, loss = 0.00080550\n",
            "Iteration 75, loss = 0.00079436\n",
            "Iteration 76, loss = 0.00078317\n",
            "Iteration 77, loss = 0.00077216\n",
            "Iteration 78, loss = 0.00076203\n",
            "Iteration 79, loss = 0.00075179\n",
            "Iteration 80, loss = 0.00074184\n",
            "Iteration 81, loss = 0.00073234\n",
            "Iteration 82, loss = 0.00072312\n",
            "Iteration 83, loss = 0.00071394\n",
            "Iteration 84, loss = 0.00070467\n",
            "Iteration 85, loss = 0.00069620\n",
            "Iteration 86, loss = 0.00068783\n",
            "Iteration 87, loss = 0.00067950\n",
            "Iteration 88, loss = 0.00067140\n",
            "Iteration 89, loss = 0.00066344\n",
            "Iteration 90, loss = 0.00065580\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(138,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "e611bf84-9dff-4e3a-e062-25c78a5011b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "b849a09d-4aab-4cee-ed44-2e43d8295de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9483333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "390f8150-f068-4df7-e458-8ba66b9ce3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9258010118043845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7rvpGmMDTKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1JsxsNc_922",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "52403e50-90f1-49e0-e783-321de9df90a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 16 -> 104 -> 26"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "4edf04d9-2ac7-4505-94e0-c625e272073c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_H2ratU_fFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# np.float32(clf.intercepts_ [1]).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "e6d2e7e7-02f7-4e7d-bb1f-2c4ad64f4bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Rerun the same thing in tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "b14467c5-8ecb-4d48-edcf-8020216bb651",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter44')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-f3d689514a20>:19: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.00044579685, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1000, training loss= 1.891845e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2000, training loss= 5.352492e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3000, training loss= 1.5914436e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4000, training loss= 9.357928e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 5000, training loss= 5.0067896e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 6000, training loss= 2.6822088e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 7000, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 8000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 9000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 11000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 12000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 13000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 14000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 15000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 16000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Test acc= 93.33895 %\n",
            "Valid acc= 94.833336 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UpCtcB9hQFPI",
        "outputId": "0ebd2a6f-ebb9-45a3-c645-a6c04f6a3839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mT7SryMuQFPO"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "metadata": {
        "id": "KsWd-9SdAe5M",
        "colab_type": "code",
        "outputId": "27152ff9-a602-4df1-b954-c250f27c844c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "XK_NlYiqAmBT",
        "colab_type": "code",
        "outputId": "d1d3ef0a-8ce0-43ee-9e8a-e2f0c613f8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K-zBUEuGwV98",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:550,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:550,:]\n",
        "valid_test_data = validation_data[550:,:]\n",
        "valid_test_data_label = validation_label_one_hot[550:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E91ru7-owV5i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ykK7OjEnEnSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# num_hidden_neurons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 138\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 2, W2 =1, W3 =  0from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "id": "46Xf22zJ5gVA",
        "colab_type": "code",
        "outputId": "40a0f9ac-37a3-4c13-c26b-c0701b9185a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W5Fa3AIQ5n8N",
        "outputId": "e60bd4ec-e3aa-41d1-81fa-a08a240d4f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51136
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "num_steps = 50000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 2\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter44')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.011436516, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 50, training loss= 0.000562717, training acc= 100.0%\n",
            "Validation Accuracy 93.33333587646484 ...\n",
            "\n",
            "step 100, training loss= 0.0006226911, training acc= 100.0%\n",
            "Validation Accuracy 93.66666412353516 ...\n",
            "\n",
            "step 150, training loss= 0.0003201904, training acc= 100.0%\n",
            "Validation Accuracy 94.16666412353516 ...\n",
            "\n",
            "step 200, training loss= 0.0003113033, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 250, training loss= 0.00029998634, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 300, training loss= 0.00023336831, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 350, training loss= 0.00020245374, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 400, training loss= 0.00018713533, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 450, training loss= 0.0001720381, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 500, training loss= 0.00013138202, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "step 550, training loss= 0.00012358274, training acc= 100.0%\n",
            "Validation Accuracy 94.16666412353516 ...\n",
            "\n",
            "step 600, training loss= 0.0001389661, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 650, training loss= 0.0001222275, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 700, training loss= 8.979599e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 750, training loss= 9.526935e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 800, training loss= 9.024617e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 850, training loss= 8.972424e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 900, training loss= 7.193157e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 950, training loss= 8.078199e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1000, training loss= 7.631496e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1050, training loss= 6.3569576e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1100, training loss= 5.7338257e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1150, training loss= 5.865446e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1200, training loss= 4.695354e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1250, training loss= 4.6019457e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1300, training loss= 4.77758e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 1350, training loss= 4.192265e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1400, training loss= 4.5492845e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1450, training loss= 3.668273e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1500, training loss= 3.5319717e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1550, training loss= 3.8361166e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1600, training loss= 3.1319043e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1650, training loss= 3.2508236e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1700, training loss= 3.111188e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 1750, training loss= 3.5115063e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 1800, training loss= 2.719266e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 1850, training loss= 2.7402375e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1900, training loss= 2.4304183e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1950, training loss= 1.9936408e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2000, training loss= 2.1459866e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2050, training loss= 1.770768e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2100, training loss= 2.0061238e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2150, training loss= 1.9087629e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2200, training loss= 2.0434018e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2250, training loss= 1.6287453e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 2300, training loss= 1.9455865e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 2350, training loss= 1.5801776e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2400, training loss= 1.4743098e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 2450, training loss= 1.3532091e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2500, training loss= 1.3802021e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2550, training loss= 1.1874482e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2600, training loss= 1.2437637e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2650, training loss= 1.2666823e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2700, training loss= 1.2180841e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 2750, training loss= 1.09544335e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2800, training loss= 1.1372045e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 2850, training loss= 9.977981e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 2900, training loss= 1.0481579e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 2950, training loss= 1.0312131e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 3000, training loss= 9.712717e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 3050, training loss= 1.04905475e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3100, training loss= 9.235543e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3150, training loss= 9.783074e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3200, training loss= 7.982885e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3250, training loss= 7.0312444e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3300, training loss= 8.705429e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3350, training loss= 7.981503e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3400, training loss= 7.27661e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3450, training loss= 6.59456e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3500, training loss= 7.01873e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3550, training loss= 6.9322996e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3600, training loss= 6.5456766e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3650, training loss= 5.791905e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3700, training loss= 5.9550066e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3750, training loss= 4.8324873e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3800, training loss= 5.5308465e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3850, training loss= 5.4227567e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3900, training loss= 5.2105706e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 3950, training loss= 5.2475275e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4000, training loss= 5.246524e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4050, training loss= 5.525283e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4100, training loss= 4.2286983e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4150, training loss= 4.5952734e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4200, training loss= 4.2408265e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4250, training loss= 3.6729987e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4300, training loss= 3.5075063e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4350, training loss= 4.0683717e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4400, training loss= 3.546448e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4450, training loss= 2.8319942e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4500, training loss= 3.0020674e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4550, training loss= 2.6573562e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4600, training loss= 3.3628655e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4650, training loss= 3.4419431e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4700, training loss= 3.3074339e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 4750, training loss= 2.524836e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4800, training loss= 3.3678323e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4850, training loss= 2.7652366e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4900, training loss= 2.5105326e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 4950, training loss= 2.5635804e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5000, training loss= 2.5443073e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5050, training loss= 2.4302665e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5100, training loss= 1.8874714e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5150, training loss= 2.2498625e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5200, training loss= 2.264565e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5250, training loss= 1.970518e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5300, training loss= 2.0853577e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5350, training loss= 2.1030382e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5400, training loss= 1.6967392e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5450, training loss= 2.1149608e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5500, training loss= 1.7595214e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5550, training loss= 2.086948e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5600, training loss= 1.7521697e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5650, training loss= 1.5783246e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5700, training loss= 1.6643538e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5750, training loss= 1.6009739e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5800, training loss= 1.4881242e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5850, training loss= 1.5556755e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5900, training loss= 1.2763297e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 5950, training loss= 1.4607052e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6000, training loss= 1.3109004e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6050, training loss= 1.3216286e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6100, training loss= 1.2379847e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6150, training loss= 1.2826879e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6200, training loss= 1.4162017e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6250, training loss= 1.0939407e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6300, training loss= 9.876458e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6350, training loss= 1.1090406e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6400, training loss= 1.1455977e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6450, training loss= 1.2179182e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6500, training loss= 1.1618895e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6550, training loss= 1.0204291e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6600, training loss= 1.1088423e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6650, training loss= 1.2016266e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6700, training loss= 9.828781e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6750, training loss= 8.380397e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6800, training loss= 1.0482445e-06, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6850, training loss= 9.687719e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6900, training loss= 8.974448e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 6950, training loss= 8.173769e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7000, training loss= 7.1644666e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7050, training loss= 7.259832e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7100, training loss= 7.5181214e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7150, training loss= 8.2750955e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7200, training loss= 6.570408e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7250, training loss= 6.482986e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7300, training loss= 6.4015296e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7350, training loss= 6.095561e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7400, training loss= 6.5882904e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7450, training loss= 6.3995424e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7500, training loss= 5.813431e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7550, training loss= 5.896879e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7600, training loss= 5.185597e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 7650, training loss= 5.861117e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7700, training loss= 5.364411e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7750, training loss= 5.2809645e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7800, training loss= 4.3789487e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7850, training loss= 4.6193543e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7900, training loss= 3.7670097e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 7950, training loss= 4.919365e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8000, training loss= 4.4067656e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8050, training loss= 4.2915298e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8100, training loss= 5.219374e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8150, training loss= 4.4763038e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8200, training loss= 3.7749578e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8250, training loss= 4.319346e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8300, training loss= 3.884232e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8350, training loss= 2.769627e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8400, training loss= 4.14848e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8450, training loss= 3.6756168e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.33332824707031 ...\n",
            "\n",
            "step 8500, training loss= 3.6358807e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8550, training loss= 3.1153337e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8600, training loss= 3.363686e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8650, training loss= 2.9424805e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8700, training loss= 3.2742793e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8750, training loss= 3.0398348e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8800, training loss= 3.0040718e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8850, training loss= 2.5629984e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8900, training loss= 2.4974332e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 8950, training loss= 2.8173105e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9000, training loss= 2.9087045e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9050, training loss= 2.3682901e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9100, training loss= 2.521275e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9150, training loss= 2.555051e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9200, training loss= 1.8556906e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9250, training loss= 1.9152951e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9300, training loss= 2.8212847e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9350, training loss= 2.1020563e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9400, training loss= 1.970926e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9450, training loss= 1.8517169e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9500, training loss= 2.0583461e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9550, training loss= 1.9033743e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9600, training loss= 1.6093247e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9650, training loss= 2.1358322e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9700, training loss= 1.7364815e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9750, training loss= 1.6570084e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9800, training loss= 1.7682706e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9850, training loss= 2.1576875e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9900, training loss= 1.8000597e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 9950, training loss= 1.7146263e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10000, training loss= 1.3669327e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10050, training loss= 1.7563495e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10100, training loss= 1.3232227e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10150, training loss= 1.15235615e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10200, training loss= 1.3271965e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10250, training loss= 1.188119e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10300, training loss= 1.15632986e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10350, training loss= 1.2318291e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.16666412353516 ...\n",
            "\n",
            "step 10400, training loss= 1.2199082e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10450, training loss= 1.1603035e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10500, training loss= 1.1881189e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10550, training loss= 1.2477237e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10600, training loss= 1.0251997e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10650, training loss= 1.0887779e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10700, training loss= 1.00135786e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10750, training loss= 9.536742e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10800, training loss= 8.7817504e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10850, training loss= 9.814896e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10900, training loss= 1.0053315e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10950, training loss= 8.106231e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11000, training loss= 8.622804e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11050, training loss= 8.22544e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11100, training loss= 7.470449e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11150, training loss= 9.775161e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11200, training loss= 8.1459675e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11250, training loss= 6.715456e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11300, training loss= 9.059905e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11350, training loss= 7.2717654e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11400, training loss= 7.7088664e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11450, training loss= 6.397565e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11500, training loss= 7.669131e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11550, training loss= 7.2717654e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11600, training loss= 6.11941e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11650, training loss= 6.0002e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11700, training loss= 5.6425726e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11750, training loss= 5.9207277e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11800, training loss= 6.635983e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11850, training loss= 5.2054716e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11900, training loss= 4.8478437e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11950, training loss= 5.046526e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12000, training loss= 5.364418e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12050, training loss= 4.7286346e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12100, training loss= 5.6425726e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12150, training loss= 4.4902162e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12200, training loss= 3.8146972e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12250, training loss= 4.6491618e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12300, training loss= 4.251798e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12350, training loss= 3.4173326e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12400, training loss= 3.89417e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12450, training loss= 3.0199686e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12500, training loss= 3.9736424e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12550, training loss= 4.1723247e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12600, training loss= 3.7749608e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12650, training loss= 3.616015e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12700, training loss= 3.1789142e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12750, training loss= 3.0199686e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12800, training loss= 3.1391778e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12850, training loss= 2.78155e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12900, training loss= 3.2186506e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12950, training loss= 2.8610227e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13000, training loss= 2.5431316e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13050, training loss= 2.7020771e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13100, training loss= 2.8610227e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13150, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13200, training loss= 2.7418135e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13250, training loss= 2.5033948e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13300, training loss= 1.9868212e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13350, training loss= 1.9868214e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13400, training loss= 1.9868214e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13450, training loss= 2.1060305e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13500, training loss= 2.5033948e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13550, training loss= 1.947085e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13600, training loss= 1.8676122e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13650, training loss= 1.8676122e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13700, training loss= 1.5894571e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13750, training loss= 1.4702478e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13800, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13850, training loss= 1.9868214e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13900, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13950, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14000, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14050, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14100, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14150, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14250, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14300, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14350, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14400, training loss= 1.0331472e-08, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14450, training loss= 9.934107e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14500, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14550, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14600, training loss= 7.549922e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14650, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14700, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14750, training loss= 7.549922e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14800, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14850, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14900, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14950, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15000, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15050, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15150, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15250, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15350, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15450, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15550, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15650, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15700, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15750, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15850, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15950, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16050, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16150, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16750, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18550, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 18850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 28850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 29150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 29250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 41950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 42950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 43950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 44400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 44950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 45950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 46950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 47950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 48950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49050, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49150, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49250, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49350, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49450, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49550, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49650, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49750, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49850, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 49950, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Valid acc= 95.33333 %\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwY5Bt2EM3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kwd9EKfLM3Z9",
        "colab_type": "code",
        "outputId": "2a9abce2-34a7-4b26-b96f-4768b3dbe7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1YqFTZJUKxY2SVKtWNgkSbXy/wFcnNmvPwbKSQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MpHiEL6VM3aB",
        "colab_type": "code",
        "outputId": "2cc42e97-1e44-4e47-dd20-e177a578a7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.33333\n",
            "54\n",
            "2700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_l2RRE0M3aE",
        "colab_type": "code",
        "outputId": "654981f0-0bec-44a7-ef4e-f91a578eda6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10500, 26)\n",
            "(15000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HaKv7GnsM3aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 200\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvHlJT_H7aKb",
        "colab_type": "code",
        "outputId": "f493e08f-6f70-4b17-8b69-c4d75ac3ae81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "aside_valid_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "G1MSxJHkHXBa",
        "colab_type": "code",
        "outputId": "998fc583-df47-49d6-d6d2-bdc8bd0f19f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15436
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "num_steps = 300000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 1000\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 2\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter44')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.009674838, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00016782759, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 2000, training loss= 4.503897e-05, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 3000, training loss= 2.2373619e-05, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 4000, training loss= 1.1938162e-05, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 5000, training loss= 6.903675e-06, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 6000, training loss= 3.5833905e-06, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 7000, training loss= 2.0142277e-06, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 8000, training loss= 1.3887827e-06, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 9000, training loss= 6.369739e-07, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 10000, training loss= 4.442527e-07, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 11000, training loss= 2.0901352e-07, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 12000, training loss= 1.3232227e-07, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 13000, training loss= 8.5433314e-08, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 14000, training loss= 3.5564103e-08, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 15000, training loss= 1.9868214e-08, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 16000, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 17000, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 18000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 30000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 31000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 32000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 33000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 34000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 35000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 36000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 37000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 38000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 39000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 40000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 41000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 42000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 43000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 44000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 45000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 46000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 47000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 48000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 49000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.5 ...\n",
            "\n",
            "step 50000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 51000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 52000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 53000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 54000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 55000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 56000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 57000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 58000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 59000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 60000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 61000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 62000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 63000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 64000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 65000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 66000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 67000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 68000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 69000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 70000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 71000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 72000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 73000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 74000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 75000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 76000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 77000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 78000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 79000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 80000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 81000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 82000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 83000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 84000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 85000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 86000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 87000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 88000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 89000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 90000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 91000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 92000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 93000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 94000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 95000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 96000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 97000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 98000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 99000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 100000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 101000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 102000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 103000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 104000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 105000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 106000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 107000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 108000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 109000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 110000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 111000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 112000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 113000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 114000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 115000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 116000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 117000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 118000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 119000, training loss= 3.4283057e-06, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 120000, training loss= 9.993689e-08, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 121000, training loss= 1.4106328e-07, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 122000, training loss= 3.0417965e-07, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 123000, training loss= 2.2411209e-07, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 124000, training loss= 1.3430865e-07, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 125000, training loss= 1.0470522e-07, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 126000, training loss= 5.3246758e-08, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 127000, training loss= 4.629291e-08, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 128000, training loss= 2.1855028e-08, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 129000, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 130000, training loss= 8.543331e-09, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 131000, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 132000, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 133000, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 134000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 135000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 136000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 137000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 138000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 139000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 140000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 141000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 142000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 143000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 144000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 145000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 146000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 147000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 148000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 149000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 150000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 151000, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy 90.0 ...\n",
            "\n",
            "step 152000, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 153000, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 154000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 155000, training loss= 4.304961e-06, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 156000, training loss= 7.035154e-07, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 157000, training loss= 8.1260445e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 158000, training loss= 2.654366e-07, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 159000, training loss= 1.6589847e-07, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 160000, training loss= 2.3424514e-07, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 161000, training loss= 1.3550091e-07, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 162000, training loss= 8.245291e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 163000, training loss= 3.5564067e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 164000, training loss= 3.3974626e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 165000, training loss= 2.4040531e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 166000, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 167000, training loss= 1.1126199e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 168000, training loss= 1.4106432e-08, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 169000, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 170000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 171000, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 172000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 173000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 174000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 175000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 176000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 177000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 178000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 179000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 91.0 ...\n",
            "\n",
            "step 180000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 181000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 182000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 90.0 ...\n",
            "\n",
            "step 183000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 90.5 ...\n",
            "\n",
            "step 184000, training loss= 3.0776332e-06, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 185000, training loss= 4.6171527e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 186000, training loss= 1.0768514e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 187000, training loss= 2.9166242e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 188000, training loss= 4.057037e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 189000, training loss= 1.4285209e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 190000, training loss= 6.059788e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 191000, training loss= 6.318082e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 192000, training loss= 4.5498165e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 193000, training loss= 4.371003e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 194000, training loss= 2.125898e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 195000, training loss= 1.2715655e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 196000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 197000, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 198000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 199000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 200000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 201000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 202000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 203000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 204000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 205000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 206000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 207000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 208000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 209000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 210000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 211000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 212000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 213000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 214000, training loss= 3.9800307e-06, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 215000, training loss= 2.942407e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 216000, training loss= 4.019244e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 217000, training loss= 3.1629733e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 218000, training loss= 2.2391309e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 219000, training loss= 2.064292e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 220000, training loss= 1.263614e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 221000, training loss= 1.1086432e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 222000, training loss= 7.4505685e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 223000, training loss= 8.344648e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 224000, training loss= 2.0861618e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 225000, training loss= 2.5033941e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 226000, training loss= 5.7617813e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 227000, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 228000, training loss= 6.1591456e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 229000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 230000, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 231000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 232000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 233000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.0 ...\n",
            "\n",
            "step 234000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 235000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 236000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 237000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 238000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 239000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 240000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 241000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 242000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 243000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 244000, training loss= 2.957655e-06, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 245000, training loss= 3.7724953e-06, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 246000, training loss= 9.623498e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 247000, training loss= 4.736482e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 248000, training loss= 3.4629733e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 249000, training loss= 9.715517e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 250000, training loss= 2.209328e-07, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 251000, training loss= 6.5366265e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 252000, training loss= 9.0598796e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 253000, training loss= 2.8411517e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 254000, training loss= 3.85443e-08, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 255000, training loss= 5.5630984e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 256000, training loss= 4.5696886e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 257000, training loss= 6.3578276e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 258000, training loss= 3.3775964e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 259000, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 260000, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 261000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 262000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 263000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 264000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 265000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 266000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 267000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 268000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 269000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 270000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 271000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 272000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 273000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 274000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.0 ...\n",
            "\n",
            "step 275000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 276000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 89.5 ...\n",
            "\n",
            "step 277000, training loss= 9.40031e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 278000, training loss= 4.2893794e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 279000, training loss= 7.501867e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 280000, training loss= 6.020048e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 281000, training loss= 1.5496899e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 282000, training loss= 1.740439e-07, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 283000, training loss= 4.291521e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 284000, training loss= 1.6887972e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 285000, training loss= 8.344646e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 286000, training loss= 1.549719e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 287000, training loss= 1.2318287e-08, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 288000, training loss= 3.9736423e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 289000, training loss= 6.5565096e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 290000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 291000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 292000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 293000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 294000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 295000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 296000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 297000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 298000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "step 299000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 88.5 ...\n",
            "\n",
            "Valid acc= 93.5 %\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYl3LFP7IjVg",
        "colab_type": "code",
        "outputId": "9af2fc9f-7f70-4eff-e692-eafbbc4a18bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAEYCAYAAADbKGjtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X98XHWd7/HXp0matE2b9AcJhTYt\nUMBCFaQR6w8wpYiArLpc9eKugor0urJavFddXX/vY9erqPfqXncRuOBFH2gVC4K/FrDboKIWWn62\npdDyI2kLbVpoUpI2bdJ+7h/nTDMtk+RM5seZOfN+Ph7zmDNnznzn882kefec8z3fMXdHREQkCcbF\nXYCIiEi+KNRERCQxFGoiIpIYCjUREUkMhZqIiCSGQk1ERBJDoSYiIomhUBMRkcRQqImISGJUx11A\nLmbMmOFz587NqY2+vj4mTZqUn4JKmPqZLJXQz0roI6ifUa1du3aXux8z2nZlHWpz585lzZo1ObXR\n3t5OW1tbfgoqYepnslRCPyuhj6B+RmVmHVG20+FHERFJDIWaiIgkhkJNREQSQ6EmIiKJoVATEZHE\nUKiJiEhiFCzUzOxmM+sys3Vp66aZ2b1mtim8nxquNzP7VzPbbGaPmdlZhapLRESSq5B7av8PuPCo\ndZ8FVrr7ycDK8DHARcDJ4W0pcF0B6xIRkYQydy9c42ZzgV+5+4Lw8ZNAm7u/YGYzgXZ3P9XMrg+X\nf3L0diO139ra6rlcfP3VX67nTxs6aWxsHHMb5aK7u1v9TJBK6Gcl9BEqo5+nHTeFt0zemevF12vd\nvXW07Yo9o0hzWlBtB5rD5eOBLWnbbQ3XvSLUzGwpwd4czc3NtLe3j7mYrVv3c/DgQbq7u8fcRrlQ\nP5OlEvpZCX2Eyujn1kN76J09kNPf66himybL3d3Mst5NdPcbgBsg2FPLJfnb2jRFTdKon8lRCX0E\n9TPfij36cUd42JHwvitcvw2YnbbdrHCdiIhIZMUOtbuAK8LlK4A709ZfHo6CXAT0jHY+TURE5GgF\nO/xoZj8B2oAZZrYV+DLwdeBnZnYl0AG8N9z8N8DFwGZgL/ChQtUlIiLJVbBQc/f3DfPUkgzbOnB1\noWoREZHKoBlFREQkMRRqIiKSGAo1ERFJDIWaiIgkhkJNREQSQ6EmIiKJoVATEZHEUKiJiEhiKNRE\nRCQxFGoiIpIYCjUREUkMhZqIiCSGQk1ERBJDoSYiIomhUBMRkcRQqImISGIo1EREJDEUaiIikhgK\nNRERSQyFmoiIJIZCTUREEkOhJiIiiaFQExGRxFCoiYhIYijUREQkMRRqIiKSGAo1ERFJDIWaiIgk\nRiyhZmbLzGydma03s2vCdWea2V/M7BEzW2NmZ8dRm4iIlK+ih5qZLQCuAs4GzgAuMbN5wLXAV939\nTOBL4WMREZHIqmN4z/nAanffC2Bm9wGXAg5MCbdpAJ6PoTYRESlj5u7FfUOz+cCdwBuAfcBKYA3w\n78DdgBHsQb7R3TsyvH4psBSgubl54fLly3Oqp7e3l/r6+pzaKAfqZ7JUQj8roY+gfka1ePHite7e\nOtp2RQ81ADO7EvgY0AesB/YTBNl97r7CzN4LLHX380dqp7W11desWZNTLe3t7bS1teXURjlQP5Ol\nEvpZCX0E9TMqM4sUarEMFHH3m9x9obufC+wGngKuAG4PN7mN4JybiIhIZHGNfmwK71sIzqf9mOAc\n2lvCTc4DNsVRm4iIlK84BooArDCz6cAAcLW7d5vZVcB3zawa6Cc8byYiIhJVLKHm7udkWPdHYGEM\n5YiISEJoRhEREUkMhZqIiCSGQk1ERBJDoSYiIomhUBMRkcRQqImISGIo1EREJDEUaiIikhgKNRER\nSQyFmoiIJIZCTUREEkOhJiIiiaFQExGRxFCoiYhIYijUREQkMRRqIiKSGAo1ERFJDIWaiIgkhkJN\nREQSQ6EmIiKJoVATEZHEUKiJiEhiKNRERCQxFGoiIpIYCjUREUkMhZqIiCSGQk1ERBJDoSYiIokR\nS6iZ2TIzW2dm683smrT1HzezjeH6a+OoTUREyld1sd/QzBYAVwFnAweA/zCzXwGzgXcCZ7j7fjNr\nKnZtIiJS3ooeasB8YLW77wUws/uAS4FW4Ovuvh/A3btiqE1ERMpYHIcf1wHnmNl0M5sIXEywl3ZK\nuH61md1nZq+LoTYRESlj5u7Ff1OzK4GPAX3AemA/cD6wCvgE8Drgp8CJflSBZrYUWArQ3Ny8cPny\n5TnV0tvbS319fU5tlAP1M1kqoZ+V0EdQP6NavHjxWndvHXVDd4/1BnyNIOD+A1ictv5p4JiRXrtw\n4ULP1apVq3Juoxyon8lSCf2shD66q59RAWs8QqbEcU4NM2ty9y4zayE4n7YIOAQsBlaZ2SnAeGBX\nHPWJiEh5iiXUgBVmNh0YAK52924zuxm42czWEYyKvCJMZxERkUhiCTV3PyfDugPA+2MoR0REEkIz\nioiISGIo1EREJDEUaiIikhgKNRERSQyFmoiIJIZCTUREEkOhJiIiiaFQExGRxFCoiYhIYijUREQk\nMRRqIiKSGAo1ERFJjFFDzcw+bmZTi1GMiIhILqLsqTUDD5rZz8zsQjOzQhclIiIyFqOGmrt/ATgZ\nuAn4ILDJzL5mZicVuDYREZGsRDqnFn5Z5/bwNghMBX5uZtcWsDYREZGsjPoloWa2DLgc2AX8X+DT\n7j5gZuOATcBnCluiiIhINFG++XoacKm7d6SvdPdDZnZJYcoSERHJXpTDj78FXko9MLMpZvZ6AHd/\nolCFiYiIZCtKqF0H9KY97g3XiYiIlJQooWbhQBEgOOxItMOWIiIiRRUl1J4xs0+YWU14WwY8U+jC\nREREshUl1D4KvBHYBmwFXg8sLWRRIiIiYzHqYUR37wIuK0ItIiIiOYlynVodcCVwOlCXWu/uHy5g\nXSIiIlmLcvjxR8CxwNuA+4BZwMuFLEpERGQsooTaPHf/ItDn7rcAbyc4ryYiIlJSooTaQHjfbWYL\ngAagqXAliYiIjE2U681uCL9P7QvAXUA98MWCViUiIjIGI+6phZMW73H33e7+e3c/0d2b3P36XN7U\nzJaZ2TozW29m1xz13P8wMzezGbm8h4iIVJ4RQy2cPSSvs/CHhzCvAs4GzgAuMbN54XOzgQuAzny+\np4iIVIYo59R+Z2afMrPZZjYtdcvhPecDq919r7sPEoyovDR87n8ThKgP92IREZHhWNq0jpk3MHs2\nw2p39xPH9IZm84E7gTcA+4CVwBrgd8B57r7MzJ4DWt19V4bXLyWc0aS5uXnh8uXLx1LGYb29vdTX\n1+fURjlQP5OlEvpZCX0E9TOqxYsXr3X31tG2GzXUCsHMrgQ+BvQB64EqgkORF7h7z0ihlq61tdXX\nrFmTUy3t7e20tbXl1EY5UD+TpRL6WQl9BPUzKjOLFGpRZhS5PNN6d//hWAoLX3sTcFPY/teAHcC7\ngEfNDIILvB8ys7PdfftY30dERCpLlCH9r0tbrgOWAA8BYw41M2ty9y4zayE4n7bI3b+b9vxzRNhT\nExERSRdlQuOPpz82s0YgtxNZsMLMphNc2H21u3fn2J6IiMiYvuyzDzghlzd193NGeX5uLu2LiEhl\ninJO7ZcMDbEfB5wG/KyQRYmIiIxFlD21b6UtDwId7r61QPWIiIiMWZRQ6wRecPd+ADObYGZz3f25\nglYmgQduhK4ncmvjtHfkpxYRkRIXJdRuA96Y9vhguO51mTeXvBncD7/5NNRMhJoJY2ujvwd2boQT\n8jrbmYhISYoSatXufiD1wN0PmNn4AtYkKT1bAYe3fwvO/JuxtXH7Uuj4c17LEhEpVVHmftxpZoeP\nX5nZOwFdP1YM3eG8zo0tY2+jsQX2bMMOHcxPTSIiJSzKntpHgVvN7Hvh461AxllGJM/yFWp+kNr9\n+n+IiCRflIuvnwYWmVl9+Li34FVJoGcLWBVMPm7sbTTMBqB2/848FSUiUrpGPfxoZl8zs0Z373X3\nXjObamb/XIziKl53J0w5HqrGco18KNzLq+vvylNRIiKlK8o5tYvSp7Fy993AxYUrSQ7r7szt0CNA\nwyzAFGoiUhGihFqVmdWmHpjZBKB2hO0lX/IRatW1MHkmdf078lOTiEgJi3Jc61ZgpZn9ADDgg8At\nhSyqpPW9CNsfjbZt7RSYNcrX/+zYAL0Zvl3HD8HLL0Dj7OxrPFrjbOp3d8DT/5l7WyWuanBf3CWI\nSIyiDBT5hpk9CpxPMAfk3cCcQhdWsn75Cdj4q+jbf/R+OHZB5uf6e+D6c+DQ4PCvn3FKdvUN08bk\nLavhR3+de1sl7qSZb4Xz3x53GSISk6gjEHYQBNp7gGeBFQWrqNS9uBnmngPnfWHk7XZ3wB1L4cVN\nw4fa7ueCQFvyJZjzplc+X1UDM8/MuWQu/DoPcTpnvfa1ubdVyn77GSbu3RZ3FSISo2FDzcxOAd4X\n3nYBPwXM3RcXqbbS4x6c5zrpPGhZNPK2TfOD+9S1ZpmknjvpPDiugIFTW8+ehvmj11zumk6jbuO9\ncVchIjEaaU9tI/AH4BJ33wxgZp8sSlWlau9LMLD38LVfI6prCG5RQq0hx8EgEmiYTe3+l+DgQLCX\nKyIVZ6TRj5cCLwCrzOxGM1tCMFCkcnV3BPdRRyQ2tkD3lhHa2wI1k2DitNxrE2hswTgEe3QIUqRS\nDRtq7v4Ld78MeBWwCrgGaDKz68zsgmIVWFKynbaqcc7oe2qNLWCV/X+FvEmNFB3pZy4iiTbqdWru\n3ufuP3b3vwJmAQ8D/1DwykpRT7jXldWeWmdwLi6TfFyHJkNSP0uFmkjFinLx9WHuvtvdb3D3JYUq\nqKR1d0JtA0xojLZ9YwsM9AXn4oZrT6GWP1Nm4ZhCTaSCZRVqFa97S3YXQ6cGlPRk+CO7rxv29+Tn\n4moJVI/nwPhpI5/HFJFEy2Gm3GSo2/cCfHMeHOgbfeOBfXDqRdEbT+2F3fQ2GFcVLM//K2j9MNz6\n3iO3kbzor2ui9rHlsOEX0V5QXQvvvx2OPyu/hQwegO+/Kfyi1whOvQjefXN+axCpQBUfalP2bIK+\nnXDW5cEQ/NGcfmn0xpsXwPlfgb0vBo+f/T1sXglNpwV7aed+Gua9dSxlyzCeOfEDvHbiC9E2PjgA\nq78PWx/Mf6j17YRdT8FJS6D5tJG3fe6Pwe+FiOSs4kPt8Oz1b/ufUFuf38bHjYM3p13a94dvw8p/\ngp0bYcLU0Wclkaz1NJ4ObVdH29gd1t5SmHNw+/cE92d9AE4fZXqy+78L934pmDYtyn+sRGRYFX9O\nrXb/TpgwLf+BlkljOGVmx/067FgKzMIRqh35b7u/J7iPElKHR23qXKBIrio+1Or6u4oXMA1p11FF\nmZVECq9xdmHCJBVqtRFCLTWjTI9CTSRXCrVihlr6+zRW7hcdlJTUtYT5NqY9NV2KIJKryg419+KG\nWn0zVI0PlnX4sTQ0tsC+l2D/y/ltN5tQmzQDqico1ETyIJZQM7NlZrbOzNab2TXhum+a2UYze8zM\n7jCziFc456BvF1WHDhQvYMaNGzrsqFArDYU6n9XfHdzXTRl920Ke2xOpMEUPNTNbAFwFnA2cAVxi\nZvOAe4EF7v4a4CngcwUvJtu5HPMhdbG1LrouDYU6n9XfE+x9VddG275Q5/ZEKkwcQ/rnA6vdfS+A\nmd0HXOru16Zt8xfg3QWvJNtZ9/Mh9V4aKFIaUp/H778Jj//8lc9X1cC5n4JpJ2bXbrbD8xtb4Ln7\nYcVVUFMHS74Ck6Zn954iEkuorQP+xcymA/uAi4E1R23zYYIvJX0FM1sKLAVobm6mvb19zIU07Xic\nE8ZPZ83jHRx8YueY28nGtIE5NDedyxOrHynK+6X09vbm9LMqF1n3051XT1vIxF1bYNcr95Qm9G/n\nmR6jc857sqrjtC2bmXSomgcj1jJt//HMq5nKuKfaqdvfxRN7p7Pj2LZht6+Ez7MS+gjqZ965e9Fv\nwJXAWuD3wHXAd9Ke+zxwB8G3bI/YzsKFCz1Xq1atyrmNcqB+jtE3TnS/6xPZv+6Wd7jfeH72rzuw\n1/3LU9zvu3bEzSrh86yEPrqrn1EBazxCvsQyUMTdb3L3he5+LrCb4BwaZvZB4BLgb8NOiMRrrEP+\n+/eMbXaQmgkwqUkjIUXGKK7Rj03hfQvBN2z/2MwuBD4DvMPD820isRvrAI5cprzSoBGRMYvrOrUV\nZrYB+CVwtbt3A98DJgP3mtkjZvb9mGoTGdLYEoyMzPbAQX9PtOH8w72n9tRExiSWCY3d/ZwM6+bF\nUYvIiBrnwGA/9HbB5OZor3HPcU+tBTb+Gg4dCq5tFJHI9C9GZCRjmcJqYB8cGsgt1A4egN4dY3u9\nSAVTqImMZKRvLx9ONlNkZXxPTXAsMlYV/31qIiNKzfyy6V6wqlc+b+PgxLah82eD++HJ3wTLueyp\nAWy4E/Y8D8edCVPnjq0tkQqjUBMZSe3kYM/p0Z8Et0ze8g+w+B+D5XW3w6//e7A81lljGlugZiL8\n+XvB4zlvhg/9emxtiVQYhZrIaP7bffDy9szP3foeePHpoccvPR3svX18bfZTa6WMnwjLHoW+XXDP\n56Fn29jaEalACjWR0UycFtwymXbCkee+ujthyqyxB1pKfVNwa5gFOzbk1pZIBdFAEZFcHH1NWfeW\n/H4DQ+2UoYEnIjIqhZpILhpb4OUXggEiEARcPr/1oa4RBvcNtS8iI1KoieQiFWA9W2HwALz8fJ5D\nLRxB2b8nf22KJJjOqYnkIv3ibBsHfqhAodYD9cfkr12RhFKoieQiNWy/uxPGVR25Lh9SobZf59VE\nolCoieRiyvHBRdndHWAWrCvUnhoE80GKyLAUaiK5qKqGhuPhD98OHltVEHT5kh5qXRvhhrfAoUGm\nLvgi0Ja/98nW/d+FZ+6DD9weXw0iGSjURHL1jv8DWx4IlmecAtXj89d2eqg9/3DwjQHApL6Yv5rm\n2T/As/fBwcEg2EVKhH4bRXJ1YltwK4T0UBvoP7y6erCvMO8XVXcnHBoMLmfI53V5IjnSkH6RUjZ+\nUnBIs78n+KaA+mNh/OR4Q819aBYVfZOAlBiFmkgpMwu+AaC/Z+jC7rqGeENt74swsDdY1jd0S4lR\nqImUurqG4OLrUgm17o60ZYWalBaFmkipq2uAfS8Fs5aURKilz3XZMfx2IjFQqImUuroG2PlUMDCj\ncXYJhFp4Hm3GqUPLIiVCoSZS6uoagkEicHhPrepgzHtqtQ1w7AIdfpSSoyH9IqUuNawfoHFO5j21\nnm1w9+eKM5v/848E4drYAut/ASs+Apd8B/5yHZz8VjjuzMLXIDIMhZpIqTv1Yti+DibPhKlzw1Db\nG0yZNS482NJxP2y4E46Zn9+LvzOZ3AyvuQyOXwhP3Q2P3wbz3wGr/hkOvKxQk1gp1ERK3aveHtxS\n6qZgeBAgqb241BD7D9wOU44rXm1/81P4zquh409hHfuK994iGeicmki5OXqSY4ADYajVTChuLZOP\nCy4O7/jjkXWIxEShJlJuMoXaQHiOrWZScWupqg4mcN6+7sg6RGKiUBMpNxlDbV+wx1RVU/x6GlsA\nH6pDJEYKNZFyczjU9gytO7A3nCfSil9P+vfHHdCemsQrllAzs2Vmts7M1pvZNeG6aWZ2r5ltCu+n\nxlGbSMnLuKe2F2omxlNP+iz92lOTmBU91MxsAXAVcDZwBnCJmc0DPgusdPeTgZXhYxE5Wl1jcP+K\nUCvyIJGU9D21AQ0UkXjFsac2H1jt7nvdfRC4D7gUeCdwS7jNLcC7YqhNpPTVTgnujx79OL7Ig0RS\ndPhRSkgc16mtA/7FzKYD+4CLgTVAs7u/EG6zHWjO9GIzWwosBWhubqa9vT2nYnp7e3Nuoxyon8ny\npqoJ7Nj0KJtpB+A1XduoOjjAwzH0veZAN4vGjefA+GlU9fXwpzzVUCmfpfqZX0UPNXd/wsy+AdwD\n9AGPAAeP2sbNzId5/Q3ADQCtra3e1taWUz3t7e3k2kY5UD+TpffBJmbVO7NSfX26Fqob4uv7eRcz\n4Xdfhod+mLcaKuWzVD/zK5aBIu5+k7svdPdzgd3AU8AOM5sJEN53xVGbSDnor2s6cjLhOAeKQDA1\nV83EoA7P+P9RkaKIa/RjU3jfQnA+7cfAXcAV4SZXAHfGUZtIOQhCLe1rXw7shfExhhoE7++HijOp\nssgw4pr7cUV4Tm0AuNrdu83s68DPzOxKoAN4b0y1iZS8/rom2N8D+7phQmMwlD7OPTUYev+BvVBT\nF28tUrFiCTV3PyfDuheBJTGUI1J29tceEyx0d4ah1ldaoca0WEuRyqUZRUTKUH9dU7CQOq9WCocf\nU6GmSY0lRgo1kTLUXxde8dKzBQ4OwKGB+PfUxqfvqYnEQ6EmUoYGaiYHM/J3dw6FSNyhVqNQKwvu\nsPclGDwQdyUFoVATKUdmwUwe3Z1D8y3GNU1WSlyh9m+L4M//Xtz3zMaaH8B3zwy+qTwb934JfvjO\n/Nfzy2Vw7Qlw3Rvy33YJUKiJlKvG2dDdMTQ1VVzTZKWMj+GcWn8P7HwCtj5QvPfM1pYHYPez0Lcz\n+9dteSD/1/09/1Bw/+JmODiY37ZLgEJNpFw1tgTXqh3eUyuVw49FnKk/da1e+jV7paZny5H3UXVv\nCfZ6976U33rSf1b79wy/XZlSqImUq8YW6O+G3u3B45IJtSJOapwa/Zk+u0qp6e448j6KwQPw8vPZ\nv240/T3B78wx84ceJ4xCTaRcpWbH79oY3Mc9pD+Ow4+pMOvrKs3vcjs4CD3bguVsgnfPtmB2lmxf\nN5rUXtqxrw7uFWoiUjJSobYzDLWSGShSzMOPaX/wS/EQ5MvPg4fztWcTTkf0K5+hFralUBORktOQ\nCrUng/uamAeKVNXAuJriHn7s6cy8XCrSgzab0E0//5btubgo7R67ILhXqIlIyZg0A6onDIVa3Icf\nIZypv8h7ak2nDy2XmlRNTaePYU/N4JhX5X9PrXoCTDspeKyBIiJSMlLXqu0P/7cd90ARCIK1mN9+\n3d0Js18X7CGWcqjNeUOwHHV4fncnTDkuCJ+8hlpH8DtT1xA8TuCeWlyz9ItIPjS2wK7U4ccSCLWa\nifDkb+Hmi3Ju6syebnimcYQtHPbthqknQMMsePhW6FwdPDVhKvyXGwt/7d4DN8K626Hl9XD2Urjz\n74/cU33pGag/FmacAoP74Oa3gVUd0UTGfnZtgKb5wee76Z68/DwB2LEOZr8eaqcAplATkRLz2vfD\nYD/MOBmqa+OuBhZeAZvuzUtTblUwrmrkjU5aAqdcGPR946+Ddft2Q+efgsOyx5+Vl1qG9eBNwcXf\nzz8UHCp8eiXMOnvos5hxMsxbAvPOD24ZvmsuYz+PfXXw2U49IWj/0MH81DvzjKDdceOCYFOoiUhJ\nOf1dwa1UvGlZcMuDR9vbaWtri7Zx06tg0d8Fyx1/gh9cVPg/2O7BwItx1cF/LLatDdZfcVfmkajv\nX5GxmVH7eXmBvi+5riGRoaZzaiKSLMU6X7RvNxzohTlvCh4/90eY1BT/pRVRKdRERMpAsUItNdPH\n3PA7j7s2DF07WA7qGqBfox9FREpb0UItHJU4901D68oq1JJ5Tk2hJiLJMr4ebFwRQi28kLlpfjDa\nEoJvTigXOvwoIlIGzIrzB7u7E8ZPhrrGoT20stpTU6iJiJSHYoVaY8vQRfAAjXMK+575VNcQzCiS\n7ZeXljgN6ReR5Cl0qK2/A7Y/Bse+JnicCrNy21PD4f7vFP4ax+MKfL1gGoWaiCRPai+kEHq74LYP\nBssLPxTczz4b1h9fXqE241TAYOVXC/9eb/4kVLcV/n1QqIlIEtU1wItPF6bt3eFQ/vfcMnTh+2nv\nDG7l5OTz4R+3waHBwr9XVS3c/5fCvw8KNRFJotoCHn5MXZ92zKmFab+YCj03Zgw0UEREkqeQ59RS\n16c1lNHw/QqiUBOR5KlrCKawOliAQ2vdnTBxOtTW579tyZlCTUSSJzWrSCEGi3R3ai+thMUSamb2\nSTNbb2brzOwnZlZnZkvM7CEze8TM/mhm8+KoTUQS4PBUWd35b7tnS3mNcqwwRQ81Mzse+ATQ6u4L\ngCrgMuA64G/d/Uzgx8AXil2biCREoeZ/dB+66FpKUlyjH6uBCWY2AEwEngccmBI+3xCuExHJXirU\ndm0ampcxH/btDr47rZxmDqkwRQ81d99mZt8COoF9wD3ufo+ZfQT4jZntA/YAi4pdm4gkxKQZwf3t\nVxWm/WknFKZdyZm5e3Hf0GwqsAL4r0A3cBvwc+BS4BvuvtrMPg2c6u4fyfD6pcBSgObm5oXLly/P\nqZ7e3l7q65M/ikn9TJZK6GdOfXRn+osPUD3Yl9+igEPjatk1YxE+riov7VXCZwm593Px4sVr3b11\n1A3dvag34D3ATWmPLyc4n/Z02roWYMNobS1cuNBztWrVqpzbKAfqZ7JUQj8roY/u6mdUwBqPkDFx\njH7sBBaZ2UQzM2AJsAFoMLNTwm3eCjwRQ20iIlLG4jinttrMfg48BAwCDwM3AFuBFWZ2CNgNfLjY\ntYmISHmLZfSju38Z+PJRq+8IbyIiImOiGUVERCQxFGoiIpIYCjUREUkMhZqIiCSGQk1ERBJDoSYi\nIolR9Gmy8snMdgIdOTYzA9iVh3JKnfqZLJXQz0roI6ifUc1x92NG26isQy0fzGyNR5lPrMypn8lS\nCf2shD6C+plvOvwoIiKJoVATEZHEUKgF805WAvUzWSqhn5XQR1A/86riz6mJiEhyaE9NREQSQ6Em\nIiKJUdGhZmYXmtmTZrbZzD4bdz1RmNlzZva4mT1iZmvCddPM7F4z2xTeTw3Xm5n9a9i/x8zsrLR2\nrgi332RmV6StXxi2vzl8rRWpXzebWZeZrUtbV/B+DfceRe7nV8xsW/iZPmJmF6c997mw5ifN7G1p\n6zP+7prZCWa2Olz/UzMbH66vDR9vDp+fW8A+zjazVWa2wczWm9mycH2iPs8R+pm0z7POzB4ws0fD\nfn51rLXlq/8jivL12Em8AVXA08CJwHjgUeC0uOuKUPdzwIyj1l0LfDZc/izwjXD5YuC3gAGLgNXh\n+mnAM+H91HB5avjcA+G2Fr5eluoiAAADo0lEQVT2oiL161zgLGBdMfs13HsUuZ9fAT6VYdvTwt/L\nWuCE8Pe1aqTfXeBnwGXh8veBvwuXPwZ8P1y+DPhpAfs4EzgrXJ4MPBX2JVGf5wj9TNrnaUB9uFwD\nrA5/9lnVls/+j1hvoX4QpX4D3gDcnfb4c8Dn4q4rQt3P8cpQexKYGS7PBJ4Ml68H3nf0dsD7gOvT\n1l8frpsJbExbf8R2RejbXI78Y1/wfg33HkXu51fI/EfwiN9J4O7w9zbj7274x2cXUH3073jqteFy\ndbidFelzvRN4a1I/zwz9TOznCUwEHgJen21t+ez/SLdKPvx4PLAl7fHWcF2pc+AeM1trZkvDdc3u\n/kK4vB1oDpeH6+NI67dmWB+XYvRruPcotr8PD73dnHbILNt+Tge63X3wqPVHtBU+3xNuX1DhoafX\nEvzvPrGf51H9hIR9nmZWZWaPAF3AvQR7VtnWls/+D6uSQ61cvdndzwIuAq42s3PTn/TgvzSJu06j\nGP2K8Wd3HXAScCbwAvDtGGrIOzOrB1YA17j7nvTnkvR5Zuhn4j5Pdz/o7mcCs4CzgVfFXNKwKjnU\ntgGz0x7PCteVNHffFt53AXcQ/ILtMLOZAOF9V7j5cH0caf2sDOvjUox+DfceRePuO8I/GoeAGwk+\nU8i+ny8CjWZWfdT6I9oKn28Ity8IM6sh+EN/q7vfHq5O3OeZqZ9J/DxT3L0bWEVwKDDb2vLZ/2FV\ncqg9CJwcjq4ZT3BC866YaxqRmU0ys8mpZeACYB1B3amRYVcQHNsnXH95OLpsEdATHpq5G7jAzKaG\nh0YuIDhW/QKwx8wWhaPJLk9rKw7F6Ndw71E0qT/Cob8m+EwhqO2ycDTZCcDJBAMkMv7uhnsmq4B3\nh68/+meW6ue7gf8Mty9Efwy4CXjC3f9X2lOJ+jyH62cCP89jzKwxXJ5AcN7wiTHUls/+D6/QJxZL\n+UYw6uopguPDn4+7ngj1nkgwMuhRYH2qZoJjzyuBTcDvgGnhegP+Lezf40BrWlsfBjaHtw+lrW8l\n+Ef4NPA9ijeY4CcEh2oGCI6dX1mMfg33HkXu54/CfjwW/sOfmbb958OanyRtJOpwv7vh78gDYf9v\nA2rD9XXh483h8ycWsI9vJjjs9xjwSHi7OGmf5wj9TNrn+Rrg4bA/64AvjbW2fPV/pJumyRIRkcSo\n5MOPIiKSMAo1ERFJDIWaiIgkhkJNREQSQ6EmIiKJoVATEZHEUKiJiEhi/H8Fp4iYqRdjpQAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9cYJNXuvJFdv",
        "colab_type": "code",
        "outputId": "34d1433b-1830-4c9a-8db0-4b254291966d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.5\n",
            "35\n",
            "35000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRpkJTtqM3aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 100 steps"
      ]
    },
    {
      "metadata": {
        "id": "jAwX7RnJJb4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Uifa_UHiM3aK",
        "colab_type": "code",
        "outputId": "5d28e46d-7d07-4d7e-8ef0-c503b3b87630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12070
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 35000\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 100\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 2\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc1=\",str(validationTest_accuracy), \"%\")\n",
        "    \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 0.09546514, training acc total= 98.84210228919983%\n",
            "ValidTest acc1= 91.0 %\n",
            "step 100, training loss Total= 0.0017772395, training acc total= 100.0%\n",
            "ValidTest acc1= 93.0 %\n",
            "step 200, training loss Total= 0.0010503164, training acc total= 100.0%\n",
            "ValidTest acc1= 93.0 %\n",
            "step 300, training loss Total= 0.0007682197, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 400, training loss Total= 0.0006004941, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 500, training loss Total= 0.00048381425, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 600, training loss Total= 0.00040132581, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 700, training loss Total= 0.0003365717, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 800, training loss Total= 0.00028801398, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 900, training loss Total= 0.0002479779, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1000, training loss Total= 0.00021595386, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1100, training loss Total= 0.0001892568, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1200, training loss Total= 0.0001667552, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1300, training loss Total= 0.00014848083, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1400, training loss Total= 0.00013246693, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1500, training loss Total= 0.00011845851, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1600, training loss Total= 0.00010668241, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1700, training loss Total= 9.63958e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1800, training loss Total= 8.731749e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 1900, training loss Total= 7.944121e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2000, training loss Total= 7.260354e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2100, training loss Total= 6.628086e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2200, training loss Total= 6.0798302e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2300, training loss Total= 5.585227e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2400, training loss Total= 5.1422874e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2500, training loss Total= 4.744196e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2600, training loss Total= 4.377111e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2700, training loss Total= 4.0462135e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2800, training loss Total= 3.7437858e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 2900, training loss Total= 3.4736044e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3000, training loss Total= 3.2215576e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3100, training loss Total= 2.9923158e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3200, training loss Total= 2.7837836e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3300, training loss Total= 2.592367e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3400, training loss Total= 2.4127161e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3500, training loss Total= 2.2486847e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3600, training loss Total= 2.0981284e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3700, training loss Total= 1.9604484e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3800, training loss Total= 1.8322069e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 3900, training loss Total= 1.7152252e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4000, training loss Total= 1.6087979e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4100, training loss Total= 1.50730475e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4200, training loss Total= 1.4128326e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4300, training loss Total= 1.3265158e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4400, training loss Total= 1.245054e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4500, training loss Total= 1.1697589e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4600, training loss Total= 1.0989453e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4700, training loss Total= 1.0321068e-05, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4800, training loss Total= 9.708997e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 4900, training loss Total= 9.138059e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5000, training loss Total= 8.60407e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5100, training loss Total= 8.098146e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5200, training loss Total= 7.618093e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5300, training loss Total= 7.1629847e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5400, training loss Total= 6.749282e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5500, training loss Total= 6.3577277e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5600, training loss Total= 5.992604e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5700, training loss Total= 5.6486874e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5800, training loss Total= 5.3243234e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 5900, training loss Total= 5.0288604e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6000, training loss Total= 4.739986e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6100, training loss Total= 4.467193e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6200, training loss Total= 4.212677e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6300, training loss Total= 3.9783217e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6400, training loss Total= 3.7505956e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6500, training loss Total= 3.5382614e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6600, training loss Total= 3.3382237e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6700, training loss Total= 3.1498564e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6800, training loss Total= 2.9788253e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 6900, training loss Total= 2.8150514e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7000, training loss Total= 2.6625075e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7100, training loss Total= 2.51559e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7200, training loss Total= 2.379003e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7300, training loss Total= 2.2492131e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7400, training loss Total= 2.1271403e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7500, training loss Total= 2.0091036e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7600, training loss Total= 1.8969438e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7700, training loss Total= 1.7922289e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7800, training loss Total= 1.6943318e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 7900, training loss Total= 1.6021861e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8000, training loss Total= 1.515666e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8100, training loss Total= 1.4351065e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8200, training loss Total= 1.3568264e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8300, training loss Total= 1.2831472e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8400, training loss Total= 1.2147801e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8500, training loss Total= 1.1484626e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8600, training loss Total= 1.0881055e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8700, training loss Total= 1.030488e-06, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8800, training loss Total= 9.747318e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 8900, training loss Total= 9.2171535e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9000, training loss Total= 8.7206604e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9100, training loss Total= 8.2503084e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9200, training loss Total= 7.8031707e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9300, training loss Total= 7.372556e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9400, training loss Total= 6.9682926e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9500, training loss Total= 6.5945613e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9600, training loss Total= 6.2350534e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9700, training loss Total= 5.908797e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9800, training loss Total= 5.6030365e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 9900, training loss Total= 5.307734e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10000, training loss Total= 5.017031e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10100, training loss Total= 4.7376213e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10200, training loss Total= 4.488537e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10300, training loss Total= 4.251374e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10400, training loss Total= 4.0190216e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10500, training loss Total= 3.803609e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10600, training loss Total= 3.5978164e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10700, training loss Total= 3.4108461e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10800, training loss Total= 3.228059e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 10900, training loss Total= 3.058447e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11000, training loss Total= 2.895947e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11100, training loss Total= 2.734492e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11200, training loss Total= 2.591441e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11300, training loss Total= 2.4607291e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11400, training loss Total= 2.3337816e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11500, training loss Total= 2.2059976e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11600, training loss Total= 2.0915988e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11700, training loss Total= 1.9824283e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11800, training loss Total= 1.8759769e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 11900, training loss Total= 1.7766358e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12000, training loss Total= 1.6810594e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12100, training loss Total= 1.5915478e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12200, training loss Total= 1.5053826e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12300, training loss Total= 1.4229818e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12400, training loss Total= 1.3545935e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12500, training loss Total= 1.2820223e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12600, training loss Total= 1.2111242e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12700, training loss Total= 1.15131044e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12800, training loss Total= 1.08710466e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 12900, training loss Total= 1.0289642e-07, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13000, training loss Total= 9.8044396e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13100, training loss Total= 9.26277e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13200, training loss Total= 8.788024e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13300, training loss Total= 8.302822e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13400, training loss Total= 7.855264e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13500, training loss Total= 7.445351e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13600, training loss Total= 7.004068e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13700, training loss Total= 6.6652625e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13800, training loss Total= 6.246985e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 13900, training loss Total= 5.973013e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14000, training loss Total= 5.577739e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14100, training loss Total= 5.2410254e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14200, training loss Total= 4.9921496e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14300, training loss Total= 4.724452e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14400, training loss Total= 4.4860336e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14500, training loss Total= 4.258072e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14600, training loss Total= 4.065664e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14700, training loss Total= 3.835611e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14800, training loss Total= 3.5971922e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 14900, training loss Total= 3.41315e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15000, training loss Total= 3.2081935e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15100, training loss Total= 3.0053286e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15200, training loss Total= 2.8422e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15300, training loss Total= 2.7041684e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15400, training loss Total= 2.5326742e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15500, training loss Total= 2.3862771e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15600, training loss Total= 2.2231486e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15700, training loss Total= 2.0892996e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15800, training loss Total= 2.0098268e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 15900, training loss Total= 1.8717948e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16000, training loss Total= 1.7630425e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16100, training loss Total= 1.6291935e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16200, training loss Total= 1.4576994e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16300, training loss Total= 1.3824094e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16400, training loss Total= 1.273657e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16500, training loss Total= 1.2401948e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16600, training loss Total= 1.1293511e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16700, training loss Total= 1.0205987e-08, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16800, training loss Total= 9.285776e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 16900, training loss Total= 8.344649e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17000, training loss Total= 7.48718e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17100, training loss Total= 6.5251395e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17200, training loss Total= 5.7304113e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17300, training loss Total= 5.353961e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17400, training loss Total= 4.559232e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17500, training loss Total= 4.182782e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17600, training loss Total= 3.3880532e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17700, training loss Total= 3.0952587e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17800, training loss Total= 2.6769804e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 17900, training loss Total= 2.1332187e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18000, training loss Total= 1.9240796e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18100, training loss Total= 1.380318e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18200, training loss Total= 1.1711789e-09, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18300, training loss Total= 8.783842e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18400, training loss Total= 8.783842e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18500, training loss Total= 5.4376165e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18600, training loss Total= 4.3919207e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18700, training loss Total= 4.60106e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18800, training loss Total= 3.1370867e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 18900, training loss Total= 2.9279473e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19000, training loss Total= 2.5096691e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19100, training loss Total= 1.6731128e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19200, training loss Total= 1.2548346e-10, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19300, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19500, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19600, training loss Total= 8.365564e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19800, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 19900, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20000, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20100, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20200, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20300, training loss Total= 4.182782e-11, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 20900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 21900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 22900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 23900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 24900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 25900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 26900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 27900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 28900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 29900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 30900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 31900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 32900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 33900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34000, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34100, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34200, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34300, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34400, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34500, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34600, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34700, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34800, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "step 34900, training loss Total= 0.0, training acc total= 100.0%\n",
            "ValidTest acc1= 94.0 %\n",
            "ValidValid acc= 99.0 %\n",
            "ValidTest acc= 94.0 %\n",
            "==================================================\n",
            "W1\n",
            "2\n",
            "W2\n",
            "1\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ft97oy5cM3aN",
        "colab_type": "code",
        "outputId": "0f085ad6-670e-4e17-a4d5-e2e7b8e45b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./Pendigit\n",
            "ValidValid acc= 99.0 %\n",
            "Test acc= 94.77235 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWblrxpgM3aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihtQRjvnM3aV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LUJzvaHZ6B3v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "best_weights = {'G_W1': G_W1np, 'G_b1': G_b1np,'G_W2': G_W2np, 'G_b2': G_b2np}\n",
        "scipy.io.savemat('HarFullDataset03212019_sgd', best_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9WWYbkum6Kl4"
      },
      "cell_type": "markdown",
      "source": [
        "## Verify handover works"
      ]
    },
    {
      "metadata": {
        "id": "2BZiy1Lgx0b4",
        "colab_type": "code",
        "outputId": "c656a113-9e09-4fb4-9e66-74752fce8528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i-MLbTOJQFQJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "id": "4OUfN10LXAQC",
        "colab_type": "code",
        "outputId": "48387104-dc8d-4157-f0f1-6ec42991e9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "oGbmg23bXJc9",
        "colab_type": "code",
        "outputId": "303c8201-ba29-497e-d803-b1b427144f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "qNDRZHqKXQtg",
        "colab_type": "code",
        "outputId": "4265ba7d-045a-464c-a4b5-bd2fce9c4980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "qskzaaBJYSpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BkroR_XQFQK",
        "outputId": "efcad80a-9170-47a1-9adc-fe4d50fad3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308737
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,5):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter44')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.11390518, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0006654033, training acc= 100.0%\n",
            "Validation Accuracy valid 93.63636016845703 ...\n",
            "\n",
            "step 200, training loss= 0.00041993908, training acc= 100.0%\n",
            "Validation Accuracy valid 93.81818389892578 ...\n",
            "\n",
            "step 300, training loss= 0.00036581428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 400, training loss= 0.00024466272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.000278986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 600, training loss= 0.00020484207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 700, training loss= 0.00020485155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 0.00014808222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 900, training loss= 0.00013487799, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1000, training loss= 0.000106940555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1100, training loss= 0.000103332, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 9.3888244e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1300, training loss= 8.086527e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1400, training loss= 9.2915514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1500, training loss= 6.975275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1600, training loss= 6.401783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 6.6929795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 6.216315e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 5.5837132e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 4.686427e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 4.266685e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 4.8607235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 4.7294332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 3.1420946e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2500, training loss= 3.5632132e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 3.2360353e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 2.629098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 2.7925558e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 2.5017247e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 2.7315176e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 2.0837042e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 2.3134868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 2.3202507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 1.923506e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 1.9367237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 1.5310456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 1.2788014e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 1.4507647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 1.4361386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 1.0811581e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 1.3430769e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 1.18566295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 1.2169309e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 8.875139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 8.893318e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 9.777806e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 6.796568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 7.912614e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 8.301834e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 7.002195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 6.553108e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 6.9768776e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 4.473553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 4.914904e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 5.2004243e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 5.570846e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 5.71718e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 4.1150506e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 4.340052e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 3.4182874e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 2.9089729e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 3.5494174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 3.7315006e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 3.3217254e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 3.0612616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 2.9936139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 2.8145037e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 2.258103e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 2.5027775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 2.3913167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 2.2247277e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 1.9693218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 1.98512e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 1.873959e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 1.641502e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 1.6909732e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 1.5631246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 1.2931168e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 1.344079e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 1.19626e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 1.2409636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 1.129801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 1.0830129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 1.1011921e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 1.0734759e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 8.746956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 9.596316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 9.253596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 7.1078364e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 9.453273e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 7.7158046e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 6.8068357e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 5.930649e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 5.4806355e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 5.608787e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 6.252513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 5.620708e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 4.5150443e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 4.431599e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 3.6716415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 4.1097343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 3.9637035e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 3.8504558e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 4.0799324e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 3.3915e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 2.4974327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 3.0726164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 2.9534078e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 2.46465e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 3.0964583e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 2.6106815e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 2.2709354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 1.8149603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 1.8209208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 1.6629689e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 1.9490707e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 1.4603131e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 1.5676012e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 1.3917678e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 1.4275305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 1.4811746e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 1.2606377e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 1.433491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 1.11758666e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 1.174211e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 1.2576575e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 9.0301e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 9.089707e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 9.089705e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 8.642672e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 8.404253e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 6.377695e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 7.420776e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 5.8412542e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 5.8710565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 5.3048126e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 7.063149e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 5.453824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 5.364417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 4.5299522e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 3.7550922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 4.8577775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 4.6193595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 3.8743014e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 3.7848945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 3.3974644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 3.248453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14800, training loss= 3.0994414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14900, training loss= 2.6226042e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 3.188848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 2.6524065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 2.712011e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 2.3841856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 2.05636e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 2.4437902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 1.966953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 1.5497207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 1.46031365e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 1.5199184e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 1.4007091e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 1.13248815e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.090904 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.124974005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0006487706, training acc= 100.0%\n",
            "Validation Accuracy valid 93.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.00029034042, training acc= 100.0%\n",
            "Validation Accuracy valid 93.45454406738281 ...\n",
            "\n",
            "step 300, training loss= 0.00027997885, training acc= 100.0%\n",
            "Validation Accuracy valid 93.45454406738281 ...\n",
            "\n",
            "step 400, training loss= 0.0002405372, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 500, training loss= 0.00020365788, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 600, training loss= 0.00021898709, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 700, training loss= 0.00015888523, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 0.0001368153, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 900, training loss= 0.00012805063, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1000, training loss= 0.00014247664, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1100, training loss= 0.00012912118, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 0.000114168906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1300, training loss= 9.3211005e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1400, training loss= 0.00010277402, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1500, training loss= 8.683253e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1600, training loss= 0.00010611769, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1700, training loss= 8.456937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1800, training loss= 8.4126135e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1900, training loss= 6.434218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2000, training loss= 8.0653714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2100, training loss= 6.12634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 6.0909046e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 5.397779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 5.259072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 4.986961e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 5.2495594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 3.8755265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 3.6783145e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 4.0215375e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3000, training loss= 3.811175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3100, training loss= 4.3587766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3200, training loss= 3.7766895e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3300, training loss= 2.9513174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3400, training loss= 3.5686295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3500, training loss= 2.663198e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3600, training loss= 2.6482285e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3700, training loss= 2.229723e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3800, training loss= 2.1555947e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3900, training loss= 2.284874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4000, training loss= 1.905099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4100, training loss= 1.9262048e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4200, training loss= 2.1260345e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4300, training loss= 1.9544712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4400, training loss= 1.6596745e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4500, training loss= 1.4415027e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4600, training loss= 1.7221435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4700, training loss= 1.1971095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4800, training loss= 1.2691808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4900, training loss= 1.2234677e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5000, training loss= 1.21115545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5100, training loss= 1.33678805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5200, training loss= 1.23692735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5300, training loss= 1.1222684e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5400, training loss= 1.0511077e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5500, training loss= 7.6260767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5600, training loss= 1.0054668e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5700, training loss= 6.7176293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5800, training loss= 7.5727253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5900, training loss= 8.335966e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6000, training loss= 5.8569894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6100, training loss= 7.143964e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6200, training loss= 5.107378e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 5.5665287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 5.5752475e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6500, training loss= 6.2563317e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6600, training loss= 4.963952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6700, training loss= 5.1882635e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6800, training loss= 4.4923054e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6900, training loss= 4.8449574e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7000, training loss= 4.255899e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7100, training loss= 3.851384e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7200, training loss= 3.4117124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7300, training loss= 2.874291e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7400, training loss= 2.7066078e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7500, training loss= 3.0831015e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7600, training loss= 3.073366e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7700, training loss= 3.1035634e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7800, training loss= 2.7201245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7900, training loss= 2.3525572e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8000, training loss= 2.646413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8100, training loss= 2.1085912e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8200, training loss= 1.6548104e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8300, training loss= 2.2884e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8400, training loss= 1.7716342e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8500, training loss= 1.721565e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8600, training loss= 1.7448124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8700, training loss= 1.6567947e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8800, training loss= 1.1678471e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8900, training loss= 1.4249395e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9000, training loss= 1.1908937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9100, training loss= 1.2961946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 1.3337433e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9300, training loss= 1.0665204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 1.0259887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9500, training loss= 9.0598695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 9.783064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 8.8870127e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 8.843307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 8.7936354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 6.908155e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 6.4611226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 6.2107836e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 7.114784e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 6.163102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 5.9167377e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 6.06376e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 5.2610903e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 5.539245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 4.9432003e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 4.6471652e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 4.1842372e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 4.53193e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 4.0630422e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 3.5802452e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 3.4113665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 2.7100208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 2.9981092e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 3.274276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 2.8053884e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 2.3543802e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 2.7497572e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 2.4994188e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 2.3464332e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 2.3186179e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 2.3066974e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 2.0921209e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 1.6550212e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 1.5060095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 1.8517161e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 1.3987211e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 1.5338252e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 1.4901153e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 1.414616e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 1.3252091e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 1.2119605e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 1.0251994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 1.2437496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 8.7420105e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 9.3380564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 8.940693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 8.185702e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 8.503592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 7.351236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 6.794927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 6.477036e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 6.695587e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 4.6690296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 5.1061303e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 5.761781e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 5.563099e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 4.4107434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 4.4703476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 4.4107434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 4.2716657e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 3.2782552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 3.9537742e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 3.5961463e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 3.4968053e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 3.198782e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 3.3974644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 2.344449e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 2.6623404e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 2.2053717e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 2.0265578e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 2.4437902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 1.8080074e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 2.0066896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 2.2451081e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 1.45037955e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 1.45037955e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 1.5497207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 1.1523563e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 1.490116e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 9.338061e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 1.1523564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 7.351239e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 4.569689e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 6.159146e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 3.774961e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 4.569689e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 1.589457e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.013410567, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 100, training loss= 0.00043582695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 200, training loss= 0.00026491645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 300, training loss= 0.0002007989, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 400, training loss= 0.00018730949, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 500, training loss= 0.0001354338, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 600, training loss= 0.00010068025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 700, training loss= 9.6129974e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 9.810863e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 7.598096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 6.3438405e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 5.829819e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 3.679993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 3.797836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 4.1173927e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1500, training loss= 3.5278477e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1600, training loss= 3.162233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1700, training loss= 3.3088654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1800, training loss= 2.4710867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 2.5553782e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2000, training loss= 1.5952339e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2100, training loss= 2.0519772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2200, training loss= 1.5722115e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2300, training loss= 1.6063614e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2400, training loss= 1.2507295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2500, training loss= 1.1893151e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2600, training loss= 1.3693358e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2700, training loss= 9.150693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2800, training loss= 1.1445211e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2900, training loss= 8.45655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3000, training loss= 7.733161e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3100, training loss= 6.94343e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3200, training loss= 7.611377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3300, training loss= 7.638211e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3400, training loss= 6.8289933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3500, training loss= 7.252187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3600, training loss= 5.3238264e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3700, training loss= 6.9641023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3800, training loss= 4.8732195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3900, training loss= 4.4989038e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4000, training loss= 4.196124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4100, training loss= 4.1865896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4200, training loss= 3.3028646e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4300, training loss= 4.084075e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4400, training loss= 3.1107418e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4500, training loss= 3.4399561e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4600, training loss= 2.7104034e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4700, training loss= 2.7131853e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4800, training loss= 2.437817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4900, training loss= 2.6690793e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5000, training loss= 2.4791425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5100, training loss= 2.102444e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5200, training loss= 2.2868192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5300, training loss= 1.8699883e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5400, training loss= 1.9830372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5500, training loss= 1.8886648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5600, training loss= 1.7607151e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5700, training loss= 1.3716971e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5800, training loss= 1.2505018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5900, training loss= 1.2715618e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6000, training loss= 1.1988448e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6100, training loss= 1.2946092e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6200, training loss= 1.0442704e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 1.2632172e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 1.0206279e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 9.880442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 9.3420135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 8.7479566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 8.1439657e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 7.2677807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 8.114165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 5.4716986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 7.490305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 6.107482e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 5.1895717e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 5.392227e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 4.8239974e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 4.1643736e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 4.6332624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 4.4107398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 3.7709833e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 3.9497976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 3.4888555e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 4.287557e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 3.8981403e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 3.556408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 2.5272354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 2.9802305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 2.7616807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 2.7259176e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 2.4676308e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 2.3166328e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 1.8199276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 2.0444384e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 2.0305308e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 1.772244e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 1.7563497e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 1.5834962e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 1.5040234e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 1.4603134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 1.3848143e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 1.2795128e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 1.255671e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 1.1702376e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 1.0768569e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 7.987022e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 9.059905e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 9.417532e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 7.788339e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 7.549921e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 8.2651766e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 7.3909746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 6.079673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 6.9936114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 4.4504798e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 7.430711e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 5.7220454e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 6.318092e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 5.5233635e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 4.9670533e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 4.0928523e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 4.013379e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 4.0928523e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 3.8146972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 4.371007e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 3.0994414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 2.3047129e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 3.1391778e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 3.377596e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 2.2252399e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 2.3444493e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 1.9868212e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 1.8278756e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 1.2715658e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 13800, training loss= 1.1523564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14200, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14300, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14500, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14600, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14900, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15000, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15100, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15700, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.81818 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.079838954, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0006006289, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 200, training loss= 0.00036654464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 300, training loss= 0.00037037325, training acc= 100.0%\n",
            "Validation Accuracy valid 93.81818389892578 ...\n",
            "\n",
            "step 400, training loss= 0.00023391382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 500, training loss= 0.00024658296, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 600, training loss= 0.00020327987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 700, training loss= 0.00022367183, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 0.00018071692, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 0.00015629301, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 0.00014889114, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1100, training loss= 0.00011651526, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1200, training loss= 0.00010528101, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1300, training loss= 9.632038e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1400, training loss= 9.8332246e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1500, training loss= 8.859806e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1600, training loss= 7.823021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 8.2358456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1800, training loss= 6.859262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1900, training loss= 6.880913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 4.955522e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 5.3223357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 5.905311e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 4.1597003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 4.1253872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 3.299034e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 3.9504605e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 3.744955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 3.6459285e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 2.761442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 3.065281e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 2.464272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 2.5270552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 2.280874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 2.2868415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 1.9569845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 2.0629504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 2.0184054e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 1.8811003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 1.7727072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 1.5518446e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 1.3561836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 1.2054618e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 1.1488736e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 1.1769963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 1.07316e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 1.1950261e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 9.297113e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 9.312339e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 8.099182e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 9.593381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 7.470944e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 6.0631296e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 7.0930914e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 6.6421744e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 5.912808e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 5.4429775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 5.554302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 5.813587e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 4.6981177e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 4.361812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 4.3927976e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 4.2667357e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 3.1755512e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 4.0064187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 3.072588e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 3.2370883e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 3.1855368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 2.8538473e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 3.256318e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 2.8453512e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 2.7259916e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 2.4886237e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 2.2530387e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 2.1484361e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 2.1120761e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 1.6641525e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 1.6218345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 1.422756e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 1.640162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 1.5178249e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 1.4036823e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 1.2938611e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 1.4126246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 1.1780811e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 1.031753e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 1.0082089e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 1.0231106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 7.727721e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 7.44758e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 9.4115427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 9.596321e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 9.131409e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 8.0197805e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 7.3090024e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 5.939591e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 6.6801755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 6.876872e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 5.656471e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 5.5968627e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 5.3003333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 4.142517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10200, training loss= 4.5329259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10300, training loss= 4.0650318e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 3.8713168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 3.769989e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 3.3646785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 3.078577e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 3.2529198e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 2.9116845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 2.8580394e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 2.935526e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 2.3886537e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 2.3499113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 2.3230895e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 1.9371498e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 1.8954266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 1.8700946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 2.3469312e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 1.5974038e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 1.5169374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 1.4454119e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 1.4305107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 1.4290208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 1.1354681e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12500, training loss= 1.187622e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 1.356005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 1.4007085e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 9.566543e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 1.0132786e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 1.1652705e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 8.463857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 8.434056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 8.285044e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 9.14931e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 7.793305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 6.2286844e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 7.063149e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 6.5565104e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13900, training loss= 6.079673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 6.526707e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 5.8710565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 4.0531148e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 4.6193595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14400, training loss= 4.4405457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 3.7550922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 3.933906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 4.1425224e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 3.6358827e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 3.2186502e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 3.010034e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 2.8312202e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 2.6822088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 3.2186506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 2.7418134e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 2.235174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 2.235174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15700, training loss= 1.8179415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15800, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15900, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 1.6987322e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 1.5199184e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 1.3411044e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 1.2665986e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 1.4007091e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 1.13248815e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16700, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16800, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16900, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17000, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17100, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17200, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17300, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17400, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17500, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.025114233, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.00047474765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 200, training loss= 0.00026895822, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 300, training loss= 0.0002493309, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.00018392871, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.00016295408, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.0001612087, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.00013279523, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 8.384876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 8.167252e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 9.565604e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 6.282979e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 5.8958227e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 5.814611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 5.5288154e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 4.0723273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 4.0820734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 4.137647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1800, training loss= 3.366772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 3.4208864e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2000, training loss= 2.595521e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2100, training loss= 2.4631196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2200, training loss= 2.8661154e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2300, training loss= 2.516615e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2400, training loss= 1.8953688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2500, training loss= 1.6812111e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2600, training loss= 1.5980342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2700, training loss= 1.6134642e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2800, training loss= 1.5603127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2900, training loss= 1.4867505e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3000, training loss= 1.0772599e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3100, training loss= 1.1198696e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 1.258289e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 9.6413505e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3400, training loss= 9.759391e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3500, training loss= 7.492394e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3600, training loss= 8.862064e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3700, training loss= 7.448604e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 7.472165e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 5.613148e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 5.9689905e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 6.337337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 5.047241e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 4.796311e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 5.2197925e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 4.4902567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 3.873061e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 4.140976e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 4.534954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4900, training loss= 4.2625716e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 3.1190782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 3.2558712e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5200, training loss= 2.8449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5300, training loss= 3.0865951e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5400, training loss= 2.7391084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5500, training loss= 2.5009886e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5600, training loss= 2.7283759e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5700, training loss= 2.2190636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5800, training loss= 2.4089036e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 2.2840336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 1.6897807e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 1.82568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6200, training loss= 1.6093167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 1.7723345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 1.3554039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 1.2621233e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6600, training loss= 1.3571923e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6700, training loss= 1.2585465e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6800, training loss= 1.1157949e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 1.4728249e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7000, training loss= 1.1742069e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 9.018158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 1.111623e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 8.64265e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7400, training loss= 9.1612077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7500, training loss= 8.5353605e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 6.6697464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7700, training loss= 6.9677685e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7800, training loss= 6.4074857e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7900, training loss= 5.8621043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8000, training loss= 6.985649e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 6.2942377e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 6.005157e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 4.7177002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 4.2468244e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 4.690878e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 4.2229837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 4.7147213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 4.1931813e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 3.5881953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 3.8534353e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 3.2275886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 2.8938027e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 3.045795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 2.4378278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 2.3752436e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 2.1576865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 2.580879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 1.8239011e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 2.3633224e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 1.8209208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 1.8149603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 1.8447626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 1.665949e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 1.5079966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 1.5825026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 1.6093243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 1.4036888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 1.1801715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 1.3351436e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 1.1444088e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 1.1235472e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 1.0132787e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 1.1324879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 9.924172e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 9.0599045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 9.745356e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 8.3148464e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 7.539986e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 7.3015684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 6.3478936e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 6.020068e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 6.973742e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 4.4107434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 5.8412546e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 4.5895572e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 5.4240218e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 4.1425224e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 3.9041037e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 4.0531155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 3.4868712e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 3.933906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 3.2186506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 2.6524065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 3.010034e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 2.5928019e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 2.5629994e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 2.712011e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13800, training loss= 2.413988e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 2.05636e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 1.8179415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14200, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14300, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 1.966953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14500, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14600, training loss= 1.2516974e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 1.2218951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14800, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14900, training loss= 1.13248815e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15000, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15100, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15200, training loss= 6.8545334e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15300, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15400, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15500, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15600, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15900, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16000, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16300, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 16800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 16900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 17100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.010589338, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0003957802, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 200, training loss= 0.0003184139, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 300, training loss= 0.0002468881, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.00022685077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.00017511136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 600, training loss= 0.00014096992, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 700, training loss= 0.00010716891, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 800, training loss= 0.00010080135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 900, training loss= 9.463366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1000, training loss= 9.051653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1100, training loss= 9.557625e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 8.037246e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1300, training loss= 6.3640866e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 5.9975602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1500, training loss= 5.9255155e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 4.5429995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1700, training loss= 4.442269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1800, training loss= 3.618425e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 3.7662525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2000, training loss= 3.25028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2100, training loss= 3.5101475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 2.8965713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 2.5749094e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 2.6163052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 2.8097622e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 1.6907721e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2700, training loss= 1.5359381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2800, training loss= 1.4737273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2900, training loss= 1.553101e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3000, training loss= 1.3590706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3100, training loss= 1.3141577e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3200, training loss= 1.5472227e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3300, training loss= 1.6176276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3400, training loss= 1.1285206e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3500, training loss= 1.06511425e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3600, training loss= 1.0371192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3700, training loss= 8.3176665e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3800, training loss= 9.618967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3900, training loss= 9.1816255e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4000, training loss= 8.295135e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4100, training loss= 7.58789e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4200, training loss= 6.79285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4300, training loss= 6.4616747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4400, training loss= 5.6656354e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4500, training loss= 5.37836e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4600, training loss= 4.6872087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4700, training loss= 5.1777297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4800, training loss= 5.0532794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4900, training loss= 3.9970105e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5000, training loss= 4.407095e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5100, training loss= 3.8825765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5200, training loss= 3.5747878e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5300, training loss= 3.4131442e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5400, training loss= 3.858263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5500, training loss= 3.177841e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5600, training loss= 2.365442e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5700, training loss= 2.928343e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5800, training loss= 2.3157352e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5900, training loss= 2.4704648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6000, training loss= 2.5734612e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6100, training loss= 2.0592045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6200, training loss= 2.5741783e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 2.2122638e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 1.91997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 1.6643852e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6600, training loss= 1.6095528e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6700, training loss= 1.5580562e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6800, training loss= 1.4161994e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6900, training loss= 1.2285636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7000, training loss= 1.4433764e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7100, training loss= 1.2106826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7200, training loss= 1.2681413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7300, training loss= 1.1236615e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7400, training loss= 1.149887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7500, training loss= 9.069405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 7.667513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7700, training loss= 8.6092604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7800, training loss= 8.8071465e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7900, training loss= 7.755727e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8000, training loss= 7.2383676e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8100, training loss= 6.48735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8200, training loss= 6.4241675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8300, training loss= 6.9904115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8400, training loss= 7.3992993e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 6.706693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8600, training loss= 5.81263e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8700, training loss= 5.159367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8800, training loss= 3.8313803e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8900, training loss= 5.073536e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9000, training loss= 4.6443847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9100, training loss= 4.0435717e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 4.89711e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9300, training loss= 3.4356066e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 3.3998427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9500, training loss= 3.5405102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 3.2043403e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 3.2710992e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 3.221031e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 2.839562e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 2.4199457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 2.6798213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 2.2935846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 2.1910651e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 2.429483e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 1.9311891e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 1.8191322e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 1.8334376e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 1.7571438e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 1.449584e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 1.7046918e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 1.5306463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 1.4781945e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 1.16348225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 1.1944766e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 1.1444086e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 1.0514255e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 8.606907e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 9.417531e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 1.1420244e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 7.7962845e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 9.1791115e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 7.629392e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 6.8902956e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 6.127356e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12500, training loss= 6.413458e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 6.175039e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 6.17504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 5.483626e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 6.9856625e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 5.2213654e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 4.386901e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 4.434585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 4.601478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 3.5762778e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 3.433227e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 3.9815898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 3.480911e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 3.2901756e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 2.8848646e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 3.099441e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 2.789497e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 3.314018e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 2.646446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 2.2411346e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 2.31266e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 2.6702878e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 2.0503995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 2.1219252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 1.7166135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 1.5020369e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 1.02519975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 1.2159347e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 7.629395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 8.106231e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 9.059906e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 3.814697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 5.483627e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 5.483627e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 7.152557e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 7.152557e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 2.384186e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.0005975779, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 100, training loss= 0.00031879832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 200, training loss= 0.00015261162, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 300, training loss= 9.044607e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 400, training loss= 6.012889e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 500, training loss= 4.5261273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 600, training loss= 3.8672573e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 700, training loss= 3.7591388e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 2.589838e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 2.161707e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1000, training loss= 1.852582e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1100, training loss= 1.3370402e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 1.3619089e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 9.9141325e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1400, training loss= 1.1876047e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 7.689871e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 6.2338095e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 6.634777e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 5.8153805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 5.774278e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 3.5176845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 3.8927365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 4.276145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 3.2002954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 2.912412e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 2.6844277e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 2.4331957e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 2.392663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 1.9687307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 2.3370844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 1.9521926e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 1.5163364e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 1.5310893e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 1.4528568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 1.4050255e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 1.3352882e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 1.2454353e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 1.1104314e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 9.226783e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 1.1068553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 9.93756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 9.436887e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 8.234364e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 8.6322245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 8.793159e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 6.137776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 7.1123134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 6.155659e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 5.766742e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 5.047017e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 5.6326303e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 5.078311e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 5.038076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 4.757936e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 4.3109006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 3.4794166e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 3.290174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5700, training loss= 3.527102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 3.0711269e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 2.9370165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 2.5480972e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 2.6285633e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 2.2351733e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 1.9535412e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 2.1010626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 1.9669523e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 1.8417826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 1.9013873e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 1.7523757e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 1.7613164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 1.5690917e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 1.224875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 1.6853207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 1.430511e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 1.3023612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 1.0550019e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 1.14440894e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 9.566544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 1.1399386e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 8.940695e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 7.152557e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 9.164212e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 7.6442944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 7.1078524e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 6.3031905e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 7.465481e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 7.0184456e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 5.9455623e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 5.8114523e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 5.8561554e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 5.6773423e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 5.6326385e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 4.5597552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 3.3080575e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 4.1574232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 3.5762785e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 3.4421678e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 3.5315747e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 3.7103888e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 2.995133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 2.5033948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 2.1010635e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 1.9222496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 1.6987322e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 1.5646219e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 1.6540287e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 1.9222496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 1.3411045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 1.3858079e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 7.599592e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 9.387731e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 4.0233132e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "Valid acc= 95.090904 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.0059260004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 100, training loss= 0.0005729847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 200, training loss= 0.0003375591, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 300, training loss= 0.0003050768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.00027671672, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 500, training loss= 0.0002294079, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.0001888995, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.00016302678, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.00015075043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.00011726878, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.000118684606, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.00010135021, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 0.00010566308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 8.6682965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1400, training loss= 7.8384954e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1500, training loss= 7.163656e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 6.967527e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 5.3912456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 4.8344562e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 4.9325023e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 4.7750535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 4.2427168e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 3.8219918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 3.9580187e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 3.1067135e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 3.1744235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 3.113644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 2.6258882e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 2.3227758e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 2.221084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 2.2017664e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 2.0482314e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 1.829692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 1.7497452e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 1.2833007e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 1.6899727e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 1.3461489e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 1.446603e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 1.1413456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 1.1679746e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 8.869741e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 1.0269441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 8.342555e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 1.0761069e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 8.314634e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 8.634022e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 8.23121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 6.2907807e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4800, training loss= 6.4240653e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4900, training loss= 5.989095e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 4.657322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 5.9960025e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5200, training loss= 5.196975e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5300, training loss= 4.5623206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5400, training loss= 4.379575e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5500, training loss= 4.4971093e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5600, training loss= 4.0711907e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5700, training loss= 4.077858e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5800, training loss= 3.436291e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5900, training loss= 3.1389889e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6000, training loss= 3.3281722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6100, training loss= 3.073187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 2.8173727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 2.6256857e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 2.4229107e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 2.5309141e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 2.2420754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 2.332194e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 2.1514763e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 1.7244723e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 1.6306554e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 1.7388975e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 1.8699074e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 1.683943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 1.3914055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 1.2756542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 1.2428717e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 1.1888704e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 1.3507557e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 1.2273749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 1.1290279e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 1.0789602e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 8.2647614e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 8.200388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 8.0895245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 8.863189e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 6.759155e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 6.953464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 7.28129e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 7.0667124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 6.004562e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 5.7935637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 4.7314106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 4.6467713e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 5.5527613e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 4.37736e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 5.737534e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 4.456038e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 4.7683653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 4.466767e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 3.9231742e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 3.7944278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 3.6442245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 2.9373146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 2.5069698e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 2.9897663e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 2.388953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 2.599953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 2.3019302e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 1.9752967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 1.9288056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 1.8560878e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 1.6987318e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 1.9240368e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 1.4483923e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 1.5020365e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 1.4770025e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 1.1157987e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 1.4734263e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 1.5664095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 1.02281525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 1.2195106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 9.1552714e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 1.0335443e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 9.7990004e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 9.155271e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 8.678435e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 8.5115424e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 7.402896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 7.5101845e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 6.580352e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 6.7234026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 4.8995016e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 6.04391e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 5.650519e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 5.6266778e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 4.470348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 4.3988223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 3.7908553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 3.7908553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 4.3988223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 3.8266176e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 3.46899e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 3.0875203e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 2.0384787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 1.8954276e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 2.646446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 2.503395e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 2.3245809e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 2.503395e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 1.6808508e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 2.2530555e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 1.859665e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 1.6093253e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 1.6450882e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 1.2874603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 1.2516975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 1.2874603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 1.1444092e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 7.867813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 7.867813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.06748133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 100, training loss= 0.00046525887, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 200, training loss= 0.00022828537, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 300, training loss= 0.00023324566, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.00015989297, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.00015515082, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 600, training loss= 0.00015233502, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.00010647813, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 800, training loss= 9.507906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 900, training loss= 8.689483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 6.61213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 6.614451e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 4.8489124e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 4.6110694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 3.807031e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 3.497835e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 3.5749836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 3.0740182e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 2.5864121e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 2.7694403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 2.4483208e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 2.1542392e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2200, training loss= 2.1720594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2300, training loss= 1.6695993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 1.3970322e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 1.4578541e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 1.1111132e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 1.1690854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 1.2749937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 1.1827423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 1.0744837e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 9.606926e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 8.469536e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 8.188769e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 7.5273138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 7.883736e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 6.5901136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 6.1366623e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 4.862245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 5.389383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 5.2796986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 4.6026144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 4.0297086e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 4.2031447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 4.1779913e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 3.7601792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 4.0243476e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 3.0287244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 3.0443414e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 3.5695696e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 2.9207238e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 2.32981e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 2.3498374e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 1.8067275e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 2.1858075e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 2.1768678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 1.6622461e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 1.5850003e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 1.5460195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 1.4315781e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 1.4451679e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 1.4201354e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 1.507754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 1.3139198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 1.1572802e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 1.0625091e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 1.0360453e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 8.815506e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 9.20889e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 9.3447926e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 8.143168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 9.0765747e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 7.313477e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 7.088172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 7.7247495e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 7.2884427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 5.618325e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7700, training loss= 5.475274e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7800, training loss= 5.9807206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7900, training loss= 4.7540604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8000, training loss= 4.5633251e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8100, training loss= 4.602666e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8200, training loss= 3.998275e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8300, training loss= 4.0841056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8400, training loss= 3.9553598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 3.368851e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8600, training loss= 3.6299198e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8700, training loss= 2.7668457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8800, training loss= 3.6156146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8900, training loss= 2.8216817e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9000, training loss= 2.6500206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9100, training loss= 2.7430036e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 2.5033933e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9300, training loss= 1.9133081e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 2.0956982e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9500, training loss= 2.2280203e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 1.9240372e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 2.0098678e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 1.5377992e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 1.7023078e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 1.6450875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 1.2373921e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 1.4877315e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 1.237392e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 1.2946123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 1.0371206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 1.17659525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 1.2695784e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 9.727474e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 8.583066e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 1.0836123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 1.06573076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 7.367134e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 7.832049e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 6.4730635e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 7.4386584e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 7.975101e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 7.152556e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 6.330013e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 5.650519e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 6.04391e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 4.506111e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 4.220008e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 4.506111e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 4.2557712e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 4.506111e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 3.7908553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 3.3617017e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 3.647804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 3.1471252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 3.683567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 2.646446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 3.1113625e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 2.8967856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 2.2172927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 2.503395e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 2.5749205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 1.6808508e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13800, training loss= 1.9311903e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 1.7166135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 1.7166135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 1.323223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14200, training loss= 1.4305114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14300, training loss= 1.1086463e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 1.2516975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14500, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14600, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 7.5101845e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14800, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14900, training loss= 7.867813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15000, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15100, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15200, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15300, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15400, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15600, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15700, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15800, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15900, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16000, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16100, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16200, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16400, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16800, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.014631225, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0005192278, training acc= 100.0%\n",
            "Validation Accuracy valid 93.81818389892578 ...\n",
            "\n",
            "step 200, training loss= 0.00038033625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 300, training loss= 0.00028271723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.0002500986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.00025996272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.00021609267, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.00015741825, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.000116883064, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.00013994818, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 0.00010643104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 9.357001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 8.878761e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 7.731491e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 7.157521e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 5.9251233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 5.4035183e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 5.155161e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 5.3272022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 4.5226636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 4.9740134e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 4.0098428e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 4.0421262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 3.494934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 3.3666838e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 3.0383115e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 3.1787997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 2.7263586e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 2.215203e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 1.8853061e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 2.4241483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 2.3537272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 2.0469266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 1.932072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 1.8368948e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 1.6843687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 1.5675676e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 1.29248065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 1.2280252e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 1.1519768e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 1.0286909e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 1.2393276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 1.0680886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 9.634392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 8.980165e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 8.317411e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 8.591234e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 7.634842e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 8.676908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 7.715248e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 6.3543275e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 6.6697257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 5.3664025e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 5.547708e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 5.829509e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 4.0283235e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 4.216767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 4.442365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 4.289688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 4.0739205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 3.065435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 3.1377513e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 4.452212e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 3.5531943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 2.4877747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 2.9525895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 2.3994662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 2.6940095e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 2.260192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 2.121315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 2.060024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 1.7679624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 1.9299866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 1.81068e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 1.4907052e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 1.4142136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 1.5565673e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 1.4349753e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 1.3717943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 1.2022209e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 1.3315625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 1.1185766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 1.0299649e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 9.635057e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 7.513146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 9.4800924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 8.322771e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 8.492648e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 6.9220704e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 5.7816396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 5.8919085e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 6.980683e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 6.165094e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 5.9405863e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 5.1408927e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 5.4985185e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 4.8875734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 4.471335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 3.3765997e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 4.38789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 4.4137184e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 3.8733043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 3.889199e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 3.8951595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 2.6454506e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 2.5957803e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 2.8302244e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 2.7765807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 2.1656336e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 2.3504083e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 2.2560343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 1.9699324e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 1.9619851e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 1.8656243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 1.9003937e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 1.9888074e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 1.3818338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 1.758336e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 1.4096491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 1.3947482e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 1.0877844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 1.1404352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 1.3679261e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 9.834763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 9.7453565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 8.88109e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 9.4771366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 9.616214e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 8.612869e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 7.033346e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 6.6757195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 6.496906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 6.60618e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 6.705521e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 6.020069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 5.3048133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 5.6326382e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 3.993511e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 4.768371e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 4.0531148e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 6.109475e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 4.738569e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 3.72529e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 3.248453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 3.2782552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 2.8014178e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 2.9504296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 3.1888483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 2.9504296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 2.8908252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 2.4437902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 2.682209e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 2.3841855e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 1.9669532e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 1.847744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 1.2218951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 1.9371509e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 1.8179417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 1.3411045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 1.3411045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 1.013279e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 1.0430813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 8.642674e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 6.556511e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 1.013279e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 5.066395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 2.682209e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 2.682209e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 2.682209e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.034351435, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0005117945, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 200, training loss= 0.00032589157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 300, training loss= 0.00032964488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.00018334122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.00014614897, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 600, training loss= 0.00012202793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 700, training loss= 0.00011959124, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 0.000112267015, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 0.000104256935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1000, training loss= 8.06262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1100, training loss= 6.2045925e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1200, training loss= 8.0695325e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1300, training loss= 7.509276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1400, training loss= 5.9611288e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1500, training loss= 4.5223514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1600, training loss= 4.2638534e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1700, training loss= 4.3051725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1800, training loss= 3.5696034e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 3.6596317e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2000, training loss= 2.833084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2100, training loss= 3.0272862e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 2.6463156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2300, training loss= 2.4934401e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 2.017218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 2.071228e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 2.0423353e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 2.0299021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 1.3681923e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 1.750048e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 1.6461652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 1.2799251e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 1.2884728e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 1.2899982e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 1.2484045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 8.028215e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 9.114129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 8.019857e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 8.178468e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 8.362309e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 6.877323e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 6.8472286e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 6.936909e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 6.611796e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 6.0899824e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 5.7421908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 5.4811458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 4.7218105e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 4.3165087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 4.207132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 4.194623e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 3.5905455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 2.7462559e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 3.2064008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 3.209974e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 3.0970266e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 3.023419e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 2.4372155e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 2.6023179e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 2.4118813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 2.270921e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 1.9398187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 2.0271414e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 1.6733908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 1.7651806e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 1.3923581e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 1.513651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 1.7329953e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 1.3586825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 1.3017597e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 1.1944716e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 1.1664582e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 1.2665935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 1.0898669e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 9.4175084e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 1.0120833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 8.589006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 7.945281e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 8.1509125e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 7.471424e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 8.150915e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 6.073701e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 6.84856e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 5.936612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 5.263082e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 4.887571e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 6.1452266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 5.3167247e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 5.37335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 4.684918e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 4.30643e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 3.5822347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 3.2812324e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 3.3885198e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 3.4034213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 2.9355257e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 2.8669808e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 3.5107095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 2.7358507e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 2.503393e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 2.792475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 2.4169668e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 2.2232516e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 2.1219239e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 1.6897906e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 1.7285338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 1.6331666e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 1.600384e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 1.5854826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 1.2874598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 1.4722339e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 1.16825056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 1.096725e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 1.05202155e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 1.2338157e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 7.927416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 1.2129541e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 1.05798215e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 9.030101e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 7.748602e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 8.136032e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 7.241963e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 7.361173e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12300, training loss= 7.301568e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 6.16908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 6.6459165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 6.079672e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 6.318091e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 5.7816496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 4.5299526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 4.947185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 4.202127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 3.546476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 4.1723247e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 3.6656854e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 2.8014178e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 3.010034e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 2.4437902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 2.980232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 2.5928019e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 2.6822086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 2.3245809e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 1.966953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 2.5331971e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 1.758337e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 1.9371507e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 1.7285346e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 1.13248815e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 1.2218951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 6.8545334e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15700, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16000, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16100, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16200, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16400, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 16800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 16900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17000, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 17900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.010653011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 100, training loss= 0.00047002273, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 200, training loss= 0.0003977256, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 300, training loss= 0.00021294488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.00021140033, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.00019690568, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.0001783183, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 700, training loss= 0.00010360997, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 800, training loss= 0.0001539513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 900, training loss= 9.891984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 0.0001101089, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 0.000114093484, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 7.9581834e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 5.997516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 7.5241376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 6.240282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 6.55449e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 4.6163965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 4.8668524e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 5.060459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 4.2503896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 3.6365156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 4.010515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 3.6065376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 2.577889e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 3.6661666e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2600, training loss= 2.3600134e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2700, training loss= 2.8867227e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2800, training loss= 2.836847e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2900, training loss= 2.1772177e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3000, training loss= 2.3312117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3100, training loss= 1.6186557e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3200, training loss= 1.8732879e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3300, training loss= 1.5459938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3400, training loss= 1.1518593e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3500, training loss= 1.7441937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3600, training loss= 1.3585331e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3700, training loss= 1.1155577e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3800, training loss= 1.2810201e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3900, training loss= 1.1752327e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4000, training loss= 9.756459e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4100, training loss= 1.0995941e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4200, training loss= 8.243034e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4300, training loss= 9.107929e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4400, training loss= 8.2098795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4500, training loss= 7.848694e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4600, training loss= 7.107638e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4700, training loss= 6.2171944e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4800, training loss= 5.7127663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4900, training loss= 7.6190677e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5000, training loss= 5.397248e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5100, training loss= 5.460352e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5200, training loss= 4.84118e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5300, training loss= 5.1421453e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5400, training loss= 4.6115306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5500, training loss= 3.9655197e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5600, training loss= 4.3494583e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5700, training loss= 3.925246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5800, training loss= 3.891454e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 5900, training loss= 3.7481332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6000, training loss= 3.4577115e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6100, training loss= 2.7424628e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6200, training loss= 2.7016747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 2.6883984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 2.9606188e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 2.5043073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6600, training loss= 2.1881501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6700, training loss= 2.2936542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6800, training loss= 1.8121382e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6900, training loss= 1.869613e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7000, training loss= 1.7411261e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7100, training loss= 1.9299e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7200, training loss= 1.6519746e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 1.4851697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 1.417306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 1.2974158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 1.3206624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 1.1719928e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 1.4032556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 1.2075847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 9.963302e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 1.014978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 1.1707157e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 8.3148217e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 9.540116e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 7.385846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 6.504551e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 7.688974e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 8.018502e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 6.6867744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 6.2661366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 5.8463525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 6.037086e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 5.203474e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 5.0067814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 4.6738478e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 4.4669346e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 3.8444938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 4.2498033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 3.428966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 3.2773994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 3.1939538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 2.9563867e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 3.082408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 3.0628235e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 3.1684095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 2.3501237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 2.079349e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 2.0589133e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 2.42165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 1.8434854e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 1.9924967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 1.5812253e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 1.4151836e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 1.6297604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 1.4228475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 1.3794212e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 1.4211443e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 1.3002322e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 1.1708051e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 1.2108252e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 1.2193401e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 1.0907647e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 1.0115756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 9.894368e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 8.233954e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 8.455342e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 7.612363e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 7.842265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 8.736336e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 5.5432313e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 6.8204734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 5.7986796e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 5.108969e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 5.6198655e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 5.0323344e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 5.1856027e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 3.678458e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13800, training loss= 5.0323344e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 3.6784577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 3.4740985e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 3.0909263e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14200, training loss= 3.193106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14300, training loss= 2.9121125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 3.5251887e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14500, training loss= 3.3208302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14600, training loss= 2.809933e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 2.7332987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14800, training loss= 2.4523052e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14900, training loss= 1.9414083e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15000, training loss= 2.1713118e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15100, training loss= 2.2734914e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15200, training loss= 1.839229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15300, training loss= 1.507146e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15400, training loss= 2.0180428e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15500, training loss= 1.7115047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15600, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15700, training loss= 1.2772423e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15800, training loss= 1.3538769e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15900, training loss= 1.4049665e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16000, training loss= 1.2772423e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16100, training loss= 1.1495181e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16200, training loss= 1.0984284e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16300, training loss= 9.707041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16400, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16500, training loss= 8.174352e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16600, training loss= 5.1089697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 5.6198664e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16800, training loss= 5.1089697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16900, training loss= 4.8535207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17000, training loss= 4.5980726e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17200, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17600, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17700, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17800, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17900, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18000, training loss= 1.021794e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18200, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18400, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18500, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18700, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18800, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.031794693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 100, training loss= 0.0004769412, training acc= 100.0%\n",
            "Validation Accuracy valid 93.81818389892578 ...\n",
            "\n",
            "step 200, training loss= 0.00023244506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 300, training loss= 0.00019325821, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 400, training loss= 0.00014254493, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.00011804325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.00010033458, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 700, training loss= 7.836788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 800, training loss= 6.277768e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 6.589226e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1000, training loss= 4.7709458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1100, training loss= 4.907874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1200, training loss= 4.436176e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1300, training loss= 2.8571856e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 3.2320164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1500, training loss= 3.1033353e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 2.2741913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 2.0688443e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1800, training loss= 1.9503024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 1.5622203e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2000, training loss= 1.4959965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 1.2530621e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2200, training loss= 1.3206604e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 1.3710845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 1.0762007e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2500, training loss= 1.0136398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 9.316375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 9.220918e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 8.567187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 7.141967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 6.481087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 6.168525e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 6.442458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 6.377623e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 4.5469583e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 4.7125345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 4.6224186e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 4.104577e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 3.521416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 3.474214e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 3.3721728e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 3.049356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 2.957208e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 2.3813118e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 2.5873062e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 2.1219173e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 2.1939181e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 1.8186493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 1.4576873e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 2.1436128e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 1.2659997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 1.4636472e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 1.5220601e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 1.7548745e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 1.3198818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 1.2464493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 1.3289422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 1.4324153e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 1.1024453e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 1.0375956e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 8.9406825e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 7.843957e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 8.745182e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 7.9679376e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 6.50405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 7.1763895e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 6.3800735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 5.9604577e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 6.12735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 5.0020174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 5.2833514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 4.8398937e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 4.9114186e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 5.3310345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 3.7431684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 3.4236885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 3.895757e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 3.118513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 3.495214e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 3.428457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 3.232954e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 2.9146653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 3.1709655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 2.270936e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 2.6035298e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 2.2220603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 2.3269642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 2.2459021e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 2.1076194e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 1.635551e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 1.8548958e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 1.8119808e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 1.6117092e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 1.7261502e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 1.1873242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 1.3971326e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 1.3208388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 1.1587141e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 1.0108946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 1.1062621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 1.05381005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 9.77516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 9.155272e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 7.534026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 9.822844e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 8.058547e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 8.0585465e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 6.961822e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 5.817413e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 7.2479246e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 6.29425e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 6.246566e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 4.5299526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 4.0531155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 3.8623806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 3.9100644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 4.2438504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 4.2915342e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 4.148483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 3.3378598e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 2.6226042e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 2.7656554e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 2.7179714e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 2.5272366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 1.8596648e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 2.0503995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 1.8119811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 1.3351439e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 1.0967254e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 1.2874603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 9.059906e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 3.8146974e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 8.106231e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14700, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14900, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15000, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15100, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15300, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.027596239, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 100, training loss= 0.0005094348, training acc= 100.0%\n",
            "Validation Accuracy valid 93.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.00038525386, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 300, training loss= 0.00024329829, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 400, training loss= 0.00025019073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 500, training loss= 0.00019764496, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.0001924925, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 700, training loss= 0.00015483832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.00014618372, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.00011973522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.000111442874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.00010343236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1200, training loss= 9.433616e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 7.552125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1400, training loss= 6.4711014e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1500, training loss= 5.1000927e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 5.571128e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 4.3048734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 4.661665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 3.509091e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 3.65526e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 3.6767655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 2.5027895e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 2.8193565e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 2.7167529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 2.3478757e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 2.052107e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 2.0547384e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 1.9760944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 1.6224218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 1.6885022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 1.6743634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 1.2863453e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 1.4359086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 1.3717052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 1.1930613e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 9.081576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 1.1570318e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 9.829847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 8.508954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 8.496267e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 8.347948e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 6.446233e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 6.612819e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 5.859253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 5.6748645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 5.3822278e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 6.0147117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 4.903808e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 5.0741783e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 4.067384e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 4.875307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 3.938736e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 3.5381968e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 3.738368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 2.964313e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 2.6539788e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 2.624574e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 2.521259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 3.3399187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 2.347217e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 2.7350413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 2.7281858e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 1.931281e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 1.6107092e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 1.593623e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 1.9759834e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 1.4940845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 1.9092274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 1.8256824e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 1.2696744e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 1.5218002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 1.0327468e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 1.3641469e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 1.2581509e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 1.1110274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 9.2545923e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7700, training loss= 8.069457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7800, training loss= 9.706595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7900, training loss= 8.8731275e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8000, training loss= 7.765477e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8100, training loss= 7.7366656e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8200, training loss= 7.1535385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8300, training loss= 6.035955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8400, training loss= 5.8889316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8500, training loss= 5.1220184e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8600, training loss= 5.3048075e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8700, training loss= 6.5684225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8800, training loss= 4.3690153e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8900, training loss= 5.129968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9000, training loss= 3.6120377e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9100, training loss= 4.2676876e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9200, training loss= 5.60879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9300, training loss= 3.8345613e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9400, training loss= 4.220005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9500, training loss= 3.075597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9600, training loss= 3.7282672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9700, training loss= 3.4133564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9800, training loss= 2.7179703e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9900, training loss= 2.5908133e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10000, training loss= 2.5858466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10100, training loss= 2.3841844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 2.3722637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 2.2133179e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 2.082188e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 2.2967644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 1.883506e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10700, training loss= 1.8000597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 1.9391369e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 1.7821782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 1.2715654e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 1.6172723e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 1.4265376e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 1.1285144e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 1.13646166e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 1.0410942e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 1.08083064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 1.2675918e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 1.11758695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 1.04904146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 7.11282e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 7.748603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 7.2717654e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 6.9141386e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 7.629394e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 5.682309e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 6.844599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 6.794929e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 6.079674e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 5.6028355e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 6.278355e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 5.245208e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 4.3312703e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 3.9736424e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 4.8478437e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 3.1391778e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 3.3378598e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 3.7749604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 3.268321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 3.377596e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 3.0199686e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 3.0994414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 2.78155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 2.5431312e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 2.0662943e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 1.7484028e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 1.8278756e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 1.5497207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 1.1523564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.007461497, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.00039507134, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.00027318634, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 300, training loss= 0.00017586912, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 400, training loss= 0.00016271751, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 500, training loss= 0.00012541757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 600, training loss= 0.00012462994, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 700, training loss= 8.354476e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 800, training loss= 5.961398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 900, training loss= 5.7286496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1000, training loss= 6.156311e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1100, training loss= 3.441702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 1200, training loss= 3.3904143e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1300, training loss= 3.0120918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 2.7452876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1500, training loss= 3.0223637e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 2.6628475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 2.0851037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1800, training loss= 2.209431e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 1.7821243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2000, training loss= 1.5789248e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2100, training loss= 1.3383467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2200, training loss= 1.1922935e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2300, training loss= 1.2523898e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2400, training loss= 1.0455566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2500, training loss= 1.0586271e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2600, training loss= 9.256775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2700, training loss= 8.209381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2800, training loss= 7.910772e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2900, training loss= 8.897571e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3000, training loss= 7.768926e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3100, training loss= 6.981356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3200, training loss= 6.2651484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3300, training loss= 4.450825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3400, training loss= 5.054808e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3500, training loss= 4.4754584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3600, training loss= 4.452413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3700, training loss= 4.1522107e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3800, training loss= 4.0026134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 3900, training loss= 3.6362496e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4000, training loss= 2.697685e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4100, training loss= 3.4697575e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4200, training loss= 3.0207425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4300, training loss= 2.930939e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4400, training loss= 2.2005897e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4500, training loss= 2.8236514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4600, training loss= 2.468413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4700, training loss= 2.1978112e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4800, training loss= 2.027938e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 4900, training loss= 1.6434922e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5000, training loss= 1.6542217e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5100, training loss= 1.7030957e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5200, training loss= 1.6726976e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5300, training loss= 1.9071425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5400, training loss= 1.4108375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5500, training loss= 1.291033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5600, training loss= 1.3021585e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5700, training loss= 1.347061e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5800, training loss= 1.1010939e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 5900, training loss= 1.2393751e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 6000, training loss= 1.0395024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 6100, training loss= 8.738022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 6200, training loss= 1.0085087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 9.2486334e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6400, training loss= 9.1314126e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 6500, training loss= 7.947269e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6600, training loss= 6.967771e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6700, training loss= 7.081022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6800, training loss= 6.9836653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6900, training loss= 5.896878e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7000, training loss= 5.6266714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7100, training loss= 5.6902496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7200, training loss= 5.2312924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7300, training loss= 4.3074232e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7400, training loss= 4.1842418e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7500, training loss= 4.986916e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 4.136558e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7700, training loss= 4.0054283e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7800, training loss= 3.8862194e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7900, training loss= 3.1312285e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 8000, training loss= 3.7550893e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 8100, training loss= 3.5007767e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8200, training loss= 3.0954658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 8300, training loss= 2.8928102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8400, training loss= 2.8570474e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8500, training loss= 2.4119998e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8600, training loss= 2.555051e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8700, training loss= 2.1219242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8800, training loss= 2.1735818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8900, training loss= 2.0265568e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9000, training loss= 2.0225835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9100, training loss= 1.9828472e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 1.6450875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9300, training loss= 1.5298521e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 1.3709064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9500, training loss= 1.28746e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9600, training loss= 1.4066691e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9700, training loss= 1.2675918e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 9.5764776e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.81817626953125 ...\n",
            "\n",
            "step 9900, training loss= 9.616214e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 1.2397763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 9.4970055e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 8.9009596e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 8.1857024e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 7.2717654e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 9.3777956e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 9.33806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 6.1591464e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 6.8744015e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 6.11941e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 6.198882e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 6.357828e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 5.4438907e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 5.6425726e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 11400, training loss= 5.1657352e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 4.0531155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 11600, training loss= 4.688898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 11700, training loss= 4.2517975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 11800, training loss= 3.6557513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 11900, training loss= 3.536542e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 3.6557513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 3.377596e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 3.1789142e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 2.980232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 2.8212863e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 2.7020771e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 2.5033948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 1.947085e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 2.0662943e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 2.2252399e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 1.5497207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 1.5894571e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 1.0728836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 1.11261995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 7.9472855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 1.11261995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.81818 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.019217385, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0006215408, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 200, training loss= 0.00035695627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 300, training loss= 0.0003266577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 400, training loss= 0.00029318995, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.00020719338, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.00016887227, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 700, training loss= 0.00016725805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 800, training loss= 0.00011956015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 900, training loss= 0.00012656643, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1000, training loss= 0.00010923681, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1100, training loss= 8.5687236e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1200, training loss= 8.8348876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1300, training loss= 8.0391386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 6.387487e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1500, training loss= 5.9083843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 6.6239314e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 4.475339e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 4.4620592e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 4.0356004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2000, training loss= 3.1892705e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2100, training loss= 3.4788172e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 3.5489724e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 2.3636578e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 2.4783685e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 2.3991124e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2600, training loss= 2.1309419e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 2.2350445e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 1.8502626e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 1.8996909e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 1.6263579e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 1.7562486e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 1.2477608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 1.2839174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 1.5272968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 1.2798368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 1.0722692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 1.1011213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 9.317826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 8.744951e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 9.303714e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 8.573306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 8.292576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 7.991944e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 6.689206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 7.635211e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 6.4811206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 5.739826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 4.9314467e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 5.0972235e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 4.6344576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 3.9938045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5200, training loss= 3.7475615e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 4.094114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 3.8112562e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 3.3626923e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 3.4732157e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 3.6072383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 3.111675e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 2.6167932e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 2.691727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 2.2465674e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 2.2349902e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 2.2172767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 2.3639038e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 1.8582929e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 1.8644236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 1.8023491e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 1.6437184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 1.9141507e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 1.3841847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 1.3695388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 1.3491037e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 1.3177686e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 1.1346987e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 1.1037044e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 9.931811e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 1.084461e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 1.0657279e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 8.194766e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 6.7131725e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 8.6137015e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 9.710425e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 7.77243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 6.4543184e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 6.570122e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 5.705007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 5.291181e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 6.5224407e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 4.778583e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 4.5980664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 4.625315e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 4.397115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 4.4975909e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 3.7346533e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 3.9986156e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 2.9121102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 3.893031e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 3.402571e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 3.0994389e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 3.2246083e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 2.7997132e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 2.247945e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 2.2377276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 2.4787002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 2.0538047e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 2.0469926e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 2.1014884e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 1.6714839e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 1.6314635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 1.559938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 1.6348697e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 1.3487674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 1.3990058e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 1.2900145e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 1.3802727e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 1.2627667e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 1.2363704e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 1.0950223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 8.6171276e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12000, training loss= 1.0558535e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12100, training loss= 9.7070405e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 7.799692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 7.833752e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 7.731573e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 7.5783035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 6.6757195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 5.415507e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 6.3351216e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 5.8923447e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 5.6539257e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 5.483627e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 6.139278e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 4.5980723e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 3.0313217e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 4.2915342e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 4.5299526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 3.610338e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 4.5640125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 3.6103383e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14000, training loss= 2.9376572e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14100, training loss= 2.7588431e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 2.656664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 2.520425e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 2.1117073e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14500, training loss= 1.839229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14600, training loss= 2.1798268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14700, training loss= 2.350126e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14800, training loss= 1.7370496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14900, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15000, training loss= 1.8051692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15100, training loss= 1.2602125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15200, training loss= 1.5667506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15300, training loss= 1.7711095e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15400, training loss= 1.1239732e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15500, training loss= 1.0558536e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15600, training loss= 1.0217939e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15700, training loss= 1.15803305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 6.130763e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 8.855547e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16000, training loss= 8.514949e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16100, training loss= 6.8119594e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16200, training loss= 5.1089697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16300, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16400, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16500, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16900, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17000, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17100, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17200, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17300, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17400, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17500, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17600, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.0007516131, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 100, training loss= 0.00044942176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 200, training loss= 0.0003136529, training acc= 100.0%\n",
            "Validation Accuracy valid 93.45454406738281 ...\n",
            "\n",
            "step 300, training loss= 0.00018288767, training acc= 100.0%\n",
            "Validation Accuracy valid 93.81818389892578 ...\n",
            "\n",
            "step 400, training loss= 0.00014933644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 500, training loss= 0.00010584792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 600, training loss= 7.168759e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 700, training loss= 5.9655496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 5.1656203e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 900, training loss= 5.137298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 5.6094443e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 4.6924026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 3.193736e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 3.042938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 2.3284754e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1500, training loss= 2.5674583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 1.9805751e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 2.0130929e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1800, training loss= 1.937533e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 1.5801299e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 1.4436951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 1.3097231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 1.2004251e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 1.0781646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 9.722344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 8.99622e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 8.354359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 8.331516e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 6.2446616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 6.116955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 4.98423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 4.7444637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 5.042812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 5.119014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 4.126976e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 4.3596833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 3.9083898e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 3.4219547e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3800, training loss= 3.692198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3900, training loss= 2.8211505e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4000, training loss= 2.7543872e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4100, training loss= 2.4720423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4200, training loss= 2.529945e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 2.8444767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 4400, training loss= 2.2394188e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 2.2086774e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 2.1093108e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 2.0044088e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 1.6787138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 1.7946022e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 1.9151698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 1.4815937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5200, training loss= 1.3637476e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 1.4683964e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 1.0047612e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 1.2786006e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 1.0824175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 1.2029881e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 8.596673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 8.2220174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 7.8439547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 7.9870034e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 7.7281516e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 7.815001e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 5.8446506e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 7.3151733e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 5.99792e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 5.7577967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 5.476807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 6.373426e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 5.887225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 4.8943866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 4.819454e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 5.2588234e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 3.893031e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 3.6988902e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 3.3080542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 3.5379574e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 3.1130628e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7900, training loss= 2.878051e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8000, training loss= 3.092627e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8100, training loss= 2.7545835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8200, training loss= 2.1832314e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8300, training loss= 2.292223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8400, training loss= 2.3944023e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 2.115112e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8600, training loss= 1.9380012e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8700, training loss= 1.8085744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 1.8290103e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 1.7813265e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 1.556532e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 1.5939978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 1.5531262e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 1.3828274e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 1.249994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 1.3964512e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 1.120567e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 1.1580327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 8.4468276e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 1.2057164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 8.3105895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 8.719307e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10200, training loss= 7.901871e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10300, training loss= 8.412767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 8.1743494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 6.880079e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 5.04085e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 5.858284e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 4.802431e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 4.7343114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 4.5299526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 5.3133277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 5.6879855e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 5.279268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 4.4958927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 3.8828166e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 4.461833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 2.963202e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 3.2697404e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 4.461833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 3.1675608e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 2.8610225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 2.5544846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 2.1117073e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 2.4523052e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 1.839229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 2.0435879e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 2.3841856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 2.3841856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 1.8051692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 1.498631e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 1.2602125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 1.2261526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 1.328332e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 1.15803305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 9.877342e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14000, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14100, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14200, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14400, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14500, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14600, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14700, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14800, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14900, training loss= 1.3623918e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15000, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15100, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15200, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15300, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15400, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15500, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16000, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16100, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16300, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16900, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17100, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.454544 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.01563594, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 100, training loss= 0.0004367173, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 200, training loss= 0.00023123011, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 300, training loss= 0.00018493847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.00016349963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 500, training loss= 0.00014041997, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 600, training loss= 9.949876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 700, training loss= 0.000101295955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 8.660893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 7.442916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1000, training loss= 5.7130306e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1100, training loss= 6.436836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 4.5301575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1300, training loss= 4.0963445e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1400, training loss= 4.0976876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1500, training loss= 4.3640644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1600, training loss= 3.590996e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1700, training loss= 3.2862343e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1800, training loss= 2.7607632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1900, training loss= 2.6453992e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2000, training loss= 2.147679e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2100, training loss= 2.623465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 1.8956978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2300, training loss= 1.7702587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 1.4994302e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 1.5097018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 1.2125379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 1.347346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 1.2909466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 1.1359773e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 1.0807238e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 1.228494e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 9.539122e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 9.475896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 9.747804e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 6.99147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 7.0731244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 7.777104e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 6.248308e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 6.186177e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 4.7539907e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 4.7638223e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 4.034729e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 4.5221423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 4.145748e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 4.0730315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 3.5374117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 3.9439888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 3.425145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 3.0824253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 2.702452e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 3.0798888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 2.3215061e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 2.3337282e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 2.5646211e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 2.339164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 2.0348896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 2.0234897e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 1.9365434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 1.5795142e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6000, training loss= 1.3957098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6100, training loss= 1.4685769e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6200, training loss= 1.4662672e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6300, training loss= 1.4554639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 1.2019226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 1.0997016e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6600, training loss= 9.4324e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6700, training loss= 1.0862908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6800, training loss= 7.638317e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6900, training loss= 9.4383677e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7000, training loss= 9.670822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7100, training loss= 8.386347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7200, training loss= 9.130659e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7300, training loss= 9.1790884e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7400, training loss= 6.020055e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7500, training loss= 6.1184045e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 7.8901456e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7700, training loss= 5.781641e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7800, training loss= 5.334607e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 7900, training loss= 4.8719266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8000, training loss= 5.0425444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8100, training loss= 5.5015005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8200, training loss= 4.166358e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8300, training loss= 3.692504e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8400, training loss= 4.455441e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 4.783267e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8600, training loss= 4.1425184e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8700, training loss= 3.5732947e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8800, training loss= 3.4153427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 8900, training loss= 3.230569e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9000, training loss= 3.150102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9100, training loss= 2.758947e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9200, training loss= 2.2441131e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 9300, training loss= 2.634523e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 2.530215e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 2.1688622e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 2.3335204e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 2.2292123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 1.8239011e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 1.4275304e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 1.7851582e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 1.7017115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 1.8388022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 1.3738864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 1.2814994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 1.3202424e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 1.2487168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 1.13248795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 1.1891121e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 1.1146066e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 1.0877846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 8.761881e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 8.49366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 8.583067e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 7.4803815e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 7.271765e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 8.016823e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 7.361173e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 7.927415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 6.318091e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 6.288289e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 5.1259985e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 6.288289e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 5.096196e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 5.0365916e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 5.6326382e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 4.4405457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 4.1723247e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 3.9041037e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 3.3378598e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 3.6060804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 3.188848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 2.980232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 2.5331971e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 2.2947786e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 2.5928019e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 2.533197e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 1.9371507e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13900, training loss= 1.6391276e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 1.9967553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 1.6987322e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 1.7881392e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14400, training loss= 1.579523e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 1.6093253e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14800, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14900, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15000, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.0122436965, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.0003526551, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.00021424373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 300, training loss= 0.00020487745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 400, training loss= 0.00014646485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 500, training loss= 0.0001271632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 600, training loss= 9.236681e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 700, training loss= 7.890345e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 800, training loss= 6.14886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 900, training loss= 5.7429283e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 1000, training loss= 4.4681623e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 1100, training loss= 3.7640344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1200, training loss= 3.722492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1300, training loss= 3.6189827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1400, training loss= 2.7763619e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1500, training loss= 2.9106326e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1600, training loss= 2.5110094e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1700, training loss= 1.6200001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1800, training loss= 2.052392e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 1.7677386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 2000, training loss= 1.7305503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2100, training loss= 1.2858075e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2200, training loss= 1.3710235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2300, training loss= 1.3354697e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 2400, training loss= 1.1611746e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 1.1775883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 8.728817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 7.65036e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 8.053257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 8.029742e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 7.5809257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 5.6301487e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 6.61359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 4.515866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 5.082682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 4.008057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 5.427204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 4.46254e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 4.624363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 4.029227e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 3.9144925e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 3.21266e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 2.3790972e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 3.0409965e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 2.967093e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 2.2488666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 2.4905617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 2.1853887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 1.8480291e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 1.9842234e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 1.5908394e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 1.7461077e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 1.5103728e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 1.3711975e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 1.4761007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 1.4775909e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 1.0585741e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 1.1613924e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 1.0046327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 1.2034136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 9.2237946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 8.6843744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 7.179361e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 9.1731255e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 8.76782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 8.2969456e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 6.19887e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 5.787601e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 5.3733487e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 6.675706e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 5.5849466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 4.640215e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 4.252784e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 4.130596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 4.726641e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 4.243845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 3.9130398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 3.6060763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 3.0845368e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 3.293153e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 3.1411616e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 2.8133363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 2.8908227e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 2.2977574e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 2.5838597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 2.0712598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 2.1934491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 2.0354973e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 1.9699324e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 1.889466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 1.8894661e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9100, training loss= 1.8209207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 1.689791e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 1.2695784e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 1.341104e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 1.7821782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 1.356005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 1.0639425e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 1.0222193e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 1.2010331e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 1.0043379e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 9.3579274e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 9.030101e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 9.089705e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 8.255242e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 7.808207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 7.83801e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 7.003544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 4.8875805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 5.6922428e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 6.616114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 4.947185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 5.0067893e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 4.9173824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 4.202127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 4.7385683e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 4.4405457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 4.4107434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 3.7848945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 2.9504294e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 4.11272e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 4.3809408e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 2.8312204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 3.188848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 2.9504294e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 2.5629994e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 2.8014181e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 1.9967553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 1.9967553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 2.0861624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 1.46031365e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 1.5497207e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 1.2516974e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13800, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14200, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14300, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14500, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14600, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14700, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 14800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 14900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15300, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 15900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.26626602, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 100, training loss= 0.00042063437, training acc= 100.0%\n",
            "Validation Accuracy valid 93.45454406738281 ...\n",
            "\n",
            "step 200, training loss= 0.00040804513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.0 ...\n",
            "\n",
            "step 300, training loss= 0.00024708582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 400, training loss= 0.00023846421, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 500, training loss= 0.00022226169, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 600, training loss= 0.00020544582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 700, training loss= 0.00016549608, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 0.00016647346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 0.00015225657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 0.000119693796, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1100, training loss= 0.00010358936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1200, training loss= 0.000117823445, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1300, training loss= 8.90475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1400, training loss= 8.560414e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1500, training loss= 8.329543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 7.877337e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 8.1318634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1800, training loss= 6.409342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 1900, training loss= 6.639591e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 5.318595e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 4.856587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 5.179098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 4.8611408e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 5.349212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 4.7729824e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 4.521074e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 2.7700376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 3.1943582e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 3.5383604e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3000, training loss= 2.935628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 3100, training loss= 2.7314734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3200, training loss= 2.6241594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3300, training loss= 2.3879216e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3400, training loss= 2.258342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3500, training loss= 2.4018098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3600, training loss= 2.0320125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3700, training loss= 2.0902125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3800, training loss= 1.97224e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 3900, training loss= 1.7710543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4000, training loss= 1.46665425e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4100, training loss= 1.3975121e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4200, training loss= 1.839161e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4300, training loss= 1.1073815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4400, training loss= 1.1803012e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4500, training loss= 1.1845738e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4600, training loss= 1.4348974e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4700, training loss= 1.1278359e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4800, training loss= 1.0407118e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 4900, training loss= 9.039676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5000, training loss= 7.981493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5100, training loss= 7.2530174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5200, training loss= 8.969638e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5300, training loss= 7.5426174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5400, training loss= 6.317269e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5500, training loss= 6.0111274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5600, training loss= 5.6072845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5700, training loss= 5.2509417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5800, training loss= 5.2830055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 5900, training loss= 5.000084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6000, training loss= 5.056506e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6100, training loss= 4.486692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6200, training loss= 3.7582092e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.63636016845703 ...\n",
            "\n",
            "step 6300, training loss= 4.153786e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6400, training loss= 4.0821983e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6500, training loss= 3.8726644e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6600, training loss= 3.6298084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6700, training loss= 3.9005376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6800, training loss= 2.8808581e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 6900, training loss= 3.302656e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7000, training loss= 2.4147573e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7100, training loss= 2.5441684e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7200, training loss= 2.883182e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7300, training loss= 2.8647057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7400, training loss= 2.5182064e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7500, training loss= 2.0665443e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7600, training loss= 2.1711796e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7700, training loss= 1.8434912e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7800, training loss= 1.5956726e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 7900, training loss= 1.576998e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8000, training loss= 1.9189906e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8100, training loss= 1.3263954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8200, training loss= 1.4000403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8300, training loss= 1.4013644e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8400, training loss= 1.3180509e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8500, training loss= 1.1274494e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8600, training loss= 1.2236773e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8700, training loss= 9.74201e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8800, training loss= 8.9611905e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 8900, training loss= 1.0257263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9000, training loss= 9.372461e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9100, training loss= 8.228063e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9200, training loss= 7.732683e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9300, training loss= 8.1916414e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9400, training loss= 6.4293397e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9500, training loss= 6.813457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9600, training loss= 6.824053e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9700, training loss= 6.614773e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9800, training loss= 6.9664407e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 9900, training loss= 5.4147415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10000, training loss= 5.6365997e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10100, training loss= 4.6385586e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10200, training loss= 4.9670444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10300, training loss= 4.31537e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10400, training loss= 3.9365503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10500, training loss= 4.3392103e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10600, training loss= 4.0054263e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10700, training loss= 3.8756212e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10800, training loss= 3.740518e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 10900, training loss= 3.168315e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11000, training loss= 3.2106996e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11100, training loss= 2.969633e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11200, training loss= 2.6464434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11300, training loss= 2.9298965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11400, training loss= 2.8504238e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11500, training loss= 2.6358475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11600, training loss= 2.4980946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11700, training loss= 2.6570402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11800, training loss= 2.1166254e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 11900, training loss= 1.8543656e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12000, training loss= 1.940461e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12100, training loss= 1.920593e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12200, training loss= 1.8040328e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12300, training loss= 1.804695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12400, training loss= 1.4623002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12500, training loss= 1.4629622e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12600, training loss= 1.4980625e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12700, training loss= 1.3569986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12800, training loss= 1.263618e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 12900, training loss= 8.6095575e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13000, training loss= 1.0940759e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13100, training loss= 1.0728833e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13200, training loss= 9.457267e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13300, training loss= 8.1327215e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13400, training loss= 9.563231e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13500, training loss= 9.642704e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13600, training loss= 8.424121e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13700, training loss= 8.3976296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13800, training loss= 6.1194086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 13900, training loss= 7.7883385e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14000, training loss= 7.655884e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14100, training loss= 5.2981896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 5.4571355e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 4.344516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 14400, training loss= 4.635916e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 5.218717e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 4.3710067e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 4.344516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 4.556443e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 4.2385516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 3.205405e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 3.152423e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 3.152423e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 2.6490948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 2.6490952e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15500, training loss= 2.8610225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15600, training loss= 2.7285681e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15700, training loss= 2.4371674e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15800, training loss= 2.7285678e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 15900, training loss= 2.1457671e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16000, training loss= 2.0398032e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16100, training loss= 1.9603304e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16200, training loss= 1.5629661e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16300, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16400, training loss= 1.6424389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16500, training loss= 1.6424389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16600, training loss= 1.5629661e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16700, training loss= 1.0066562e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16800, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 16900, training loss= 1.086129e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17000, training loss= 9.006923e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17100, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17200, training loss= 7.6823765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17300, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17400, training loss= 6.887648e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 17500, training loss= 5.033281e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 6.3578285e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 6.3578285e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 3.1789142e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 3.443824e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 4.238552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 3.1789142e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 2.6490952e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 1.5894571e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 1.3245476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 1.3245476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 1.5894571e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 18900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19000, training loss= 7.9472856e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19100, training loss= 1.0596382e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19200, training loss= 5.298191e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19300, training loss= 5.298191e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19400, training loss= 5.298191e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.45454406738281 ...\n",
            "\n",
            "step 19500, training loss= 5.298191e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19600, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 5.298191e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 2.6490954e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.63636 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BoQHpkHzQ0YO"
      },
      "cell_type": "markdown",
      "source": [
        "#### Valid acc= 98.799995 %\n",
        "#### Validation Accuracy Test 98.51380157470703 ...\n",
        "W1 = 4 ...\n",
        "W2 = 1 ...\n",
        "W3 = 0 ...\n",
        "Highest validation accuracy, to brake tie Validation test accuracy was used which is highest for this combination"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SeaxvipDvrKA"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "outputId": "04dc5a97-d43c-445e-aa7a-8cd32418289b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Test_track)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "WaOrJ6tu4YUl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# W_track[np.argmax((ValidAccuracy_Track))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCo_C_Nxs9wG",
        "colab_type": "code",
        "outputId": "d0fd6748-9491-4687-ffe7-90f7928d2304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.81818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "outputId": "34b23e6b-a3b8-42bd-d72b-3180da4c5099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZTLaSJQSimX+/8Je7gA1Faa4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "outputId": "e07e93b5-e89e-4061-cb4b-422971beb189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxP8AwB9qcsQd21sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SW9qZGWUQFQs",
        "outputId": "d35a6e8f-c23a-4f4c-d24f-4285e47f1824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD8CAYAAABdCyJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oWFUJtzdQFQx",
        "outputId": "c12688e0-8979-477b-9c9b-9247382ea113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEmNMwgkqXEGgSQ17n8BjdGJcphZZCEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5nSzdyLhJ3K-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNAReducedFullDatasetEpochBasedADAM0430_Test94p52.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/DNAReducedFullDatasetEpochBasedADAM0430_Test94p52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "4bb4bce1-0f9e-4fb2-c137-0bfd9906a302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.677234</td>\n",
              "      <td>-0.205123</td>\n",
              "      <td>-0.482950</td>\n",
              "      <td>-0.491417</td>\n",
              "      <td>0.074036</td>\n",
              "      <td>0.120849</td>\n",
              "      <td>-0.106411</td>\n",
              "      <td>-0.854025</td>\n",
              "      <td>0.235618</td>\n",
              "      <td>-0.724818</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.452475</td>\n",
              "      <td>-0.076587</td>\n",
              "      <td>0.065689</td>\n",
              "      <td>-0.204755</td>\n",
              "      <td>0.719114</td>\n",
              "      <td>-0.415737</td>\n",
              "      <td>0.151107</td>\n",
              "      <td>-0.278909</td>\n",
              "      <td>-0.022437</td>\n",
              "      <td>0.116028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.968325</td>\n",
              "      <td>-0.901980</td>\n",
              "      <td>-0.612648</td>\n",
              "      <td>-0.320269</td>\n",
              "      <td>0.900248</td>\n",
              "      <td>-1.070258</td>\n",
              "      <td>-0.276023</td>\n",
              "      <td>-1.350481</td>\n",
              "      <td>-0.307156</td>\n",
              "      <td>0.873546</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.312353</td>\n",
              "      <td>-0.154037</td>\n",
              "      <td>-0.097274</td>\n",
              "      <td>-0.028025</td>\n",
              "      <td>-0.198132</td>\n",
              "      <td>-0.364496</td>\n",
              "      <td>0.373894</td>\n",
              "      <td>-0.262713</td>\n",
              "      <td>-0.031868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.144510</td>\n",
              "      <td>-0.639640</td>\n",
              "      <td>0.094091</td>\n",
              "      <td>0.736130</td>\n",
              "      <td>-0.741035</td>\n",
              "      <td>1.317996</td>\n",
              "      <td>-0.332095</td>\n",
              "      <td>1.514341</td>\n",
              "      <td>-0.697174</td>\n",
              "      <td>0.793378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052664</td>\n",
              "      <td>0.234666</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.379384</td>\n",
              "      <td>-0.415597</td>\n",
              "      <td>-0.251387</td>\n",
              "      <td>-0.249521</td>\n",
              "      <td>-0.048087</td>\n",
              "      <td>0.846899</td>\n",
              "      <td>-0.228373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.011300</td>\n",
              "      <td>-0.753063</td>\n",
              "      <td>1.140482</td>\n",
              "      <td>-1.568935</td>\n",
              "      <td>0.673132</td>\n",
              "      <td>0.256885</td>\n",
              "      <td>-1.308196</td>\n",
              "      <td>-0.929054</td>\n",
              "      <td>-1.467942</td>\n",
              "      <td>0.812135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>0.306471</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.238929</td>\n",
              "      <td>-0.382544</td>\n",
              "      <td>0.214989</td>\n",
              "      <td>-0.098546</td>\n",
              "      <td>0.089057</td>\n",
              "      <td>0.111130</td>\n",
              "      <td>-0.350712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.019436</td>\n",
              "      <td>0.294622</td>\n",
              "      <td>1.569688</td>\n",
              "      <td>0.488142</td>\n",
              "      <td>-0.463129</td>\n",
              "      <td>-0.929467</td>\n",
              "      <td>-1.738224</td>\n",
              "      <td>-0.145351</td>\n",
              "      <td>0.004826</td>\n",
              "      <td>-1.081979</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014322</td>\n",
              "      <td>0.062022</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.140120</td>\n",
              "      <td>-0.348128</td>\n",
              "      <td>-0.529818</td>\n",
              "      <td>-0.252468</td>\n",
              "      <td>-0.330608</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>0.567040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.677234 -0.205123 -0.482950 -0.491417  0.074036  0.120849 -0.106411   \n",
              "1 -0.968325 -0.901980 -0.612648 -0.320269  0.900248 -1.070258 -0.276023   \n",
              "2 -1.144510 -0.639640  0.094091  0.736130 -0.741035  1.317996 -0.332095   \n",
              "3  1.011300 -0.753063  1.140482 -1.568935  0.673132  0.256885 -1.308196   \n",
              "4 -0.019436  0.294622  1.569688  0.488142 -0.463129 -0.929467 -1.738224   \n",
              "\n",
              "        7         8         9    ...       128       129       130       131  \\\n",
              "0 -0.854025  0.235618 -0.724818  ... -0.452475 -0.076587  0.065689 -0.204755   \n",
              "1 -1.350481 -0.307156  0.873546  ... -0.062500  0.312353 -0.154037 -0.097274   \n",
              "2  1.514341 -0.697174  0.793378  ... -0.052664  0.234666  0.514637  0.379384   \n",
              "3 -0.929054 -1.467942  0.812135  ...  0.005383  0.306471  0.055101  0.238929   \n",
              "4 -0.145351  0.004826 -1.081979  ...  0.014322  0.062022  0.049797 -0.140120   \n",
              "\n",
              "        132       133       134       135       136       137  \n",
              "0  0.719114 -0.415737  0.151107 -0.278909 -0.022437  0.116028  \n",
              "1 -0.028025 -0.198132 -0.364496  0.373894 -0.262713 -0.031868  \n",
              "2 -0.415597 -0.251387 -0.249521 -0.048087  0.846899 -0.228373  \n",
              "3 -0.382544  0.214989 -0.098546  0.089057  0.111130 -0.350712  \n",
              "4 -0.348128 -0.529818 -0.252468 -0.330608 -0.000366  0.567040  \n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "be5c7f5e-5028-4e73-cc8a-05fe1132b229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  1\n",
              "1  1\n",
              "2  1\n",
              "3  2\n",
              "4  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "490957ef-5e8b-485b-cbe0-3c32cc3fe024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "6faa0c37-47c6-4ca5-e4a5-26fc3c3cfa12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "9f391efa-401c-446b-9419-1deca5d39485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pDOMf8vCQFNW"
      },
      "cell_type": "markdown",
      "source": [
        "## without using vaidation data for fitting"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "00a8b09e-b3a3-4600-b779-ba8bcde93cea",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1683
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(138, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.97153027\n",
            "Iteration 2, loss = 0.38995267\n",
            "Iteration 3, loss = 0.16863707\n",
            "Iteration 4, loss = 0.08644866\n",
            "Iteration 5, loss = 0.04790676\n",
            "Iteration 6, loss = 0.02766120\n",
            "Iteration 7, loss = 0.01804213\n",
            "Iteration 8, loss = 0.01303306\n",
            "Iteration 9, loss = 0.01017363\n",
            "Iteration 10, loss = 0.00846074\n",
            "Iteration 11, loss = 0.00731784\n",
            "Iteration 12, loss = 0.00642295\n",
            "Iteration 13, loss = 0.00578566\n",
            "Iteration 14, loss = 0.00524263\n",
            "Iteration 15, loss = 0.00482185\n",
            "Iteration 16, loss = 0.00445585\n",
            "Iteration 17, loss = 0.00415009\n",
            "Iteration 18, loss = 0.00387484\n",
            "Iteration 19, loss = 0.00363059\n",
            "Iteration 20, loss = 0.00342359\n",
            "Iteration 21, loss = 0.00324253\n",
            "Iteration 22, loss = 0.00306885\n",
            "Iteration 23, loss = 0.00291664\n",
            "Iteration 24, loss = 0.00277493\n",
            "Iteration 25, loss = 0.00265069\n",
            "Iteration 26, loss = 0.00253650\n",
            "Iteration 27, loss = 0.00242954\n",
            "Iteration 28, loss = 0.00233327\n",
            "Iteration 29, loss = 0.00224341\n",
            "Iteration 30, loss = 0.00215908\n",
            "Iteration 31, loss = 0.00208097\n",
            "Iteration 32, loss = 0.00200870\n",
            "Iteration 33, loss = 0.00194052\n",
            "Iteration 34, loss = 0.00187660\n",
            "Iteration 35, loss = 0.00181774\n",
            "Iteration 36, loss = 0.00176193\n",
            "Iteration 37, loss = 0.00170941\n",
            "Iteration 38, loss = 0.00166006\n",
            "Iteration 39, loss = 0.00161241\n",
            "Iteration 40, loss = 0.00156818\n",
            "Iteration 41, loss = 0.00152616\n",
            "Iteration 42, loss = 0.00148629\n",
            "Iteration 43, loss = 0.00144797\n",
            "Iteration 44, loss = 0.00141247\n",
            "Iteration 45, loss = 0.00137653\n",
            "Iteration 46, loss = 0.00134514\n",
            "Iteration 47, loss = 0.00131347\n",
            "Iteration 48, loss = 0.00128475\n",
            "Iteration 49, loss = 0.00125555\n",
            "Iteration 50, loss = 0.00122770\n",
            "Iteration 51, loss = 0.00120178\n",
            "Iteration 52, loss = 0.00117708\n",
            "Iteration 53, loss = 0.00115253\n",
            "Iteration 54, loss = 0.00112934\n",
            "Iteration 55, loss = 0.00110742\n",
            "Iteration 56, loss = 0.00108600\n",
            "Iteration 57, loss = 0.00106536\n",
            "Iteration 58, loss = 0.00104544\n",
            "Iteration 59, loss = 0.00102592\n",
            "Iteration 60, loss = 0.00100787\n",
            "Iteration 61, loss = 0.00099042\n",
            "Iteration 62, loss = 0.00097298\n",
            "Iteration 63, loss = 0.00095668\n",
            "Iteration 64, loss = 0.00094005\n",
            "Iteration 65, loss = 0.00092519\n",
            "Iteration 66, loss = 0.00090977\n",
            "Iteration 67, loss = 0.00089595\n",
            "Iteration 68, loss = 0.00088126\n",
            "Iteration 69, loss = 0.00086789\n",
            "Iteration 70, loss = 0.00085454\n",
            "Iteration 71, loss = 0.00084165\n",
            "Iteration 72, loss = 0.00082940\n",
            "Iteration 73, loss = 0.00081723\n",
            "Iteration 74, loss = 0.00080550\n",
            "Iteration 75, loss = 0.00079436\n",
            "Iteration 76, loss = 0.00078317\n",
            "Iteration 77, loss = 0.00077216\n",
            "Iteration 78, loss = 0.00076203\n",
            "Iteration 79, loss = 0.00075179\n",
            "Iteration 80, loss = 0.00074184\n",
            "Iteration 81, loss = 0.00073234\n",
            "Iteration 82, loss = 0.00072312\n",
            "Iteration 83, loss = 0.00071394\n",
            "Iteration 84, loss = 0.00070467\n",
            "Iteration 85, loss = 0.00069620\n",
            "Iteration 86, loss = 0.00068783\n",
            "Iteration 87, loss = 0.00067950\n",
            "Iteration 88, loss = 0.00067140\n",
            "Iteration 89, loss = 0.00066344\n",
            "Iteration 90, loss = 0.00065580\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(138,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "9cb5611d-86b6-4953-e31a-6634ad3506e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "6053257d-1c2f-4e89-e785-6ac0e66efe10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9483333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "af5a990b-8849-43a2-e3d7-a6ae0200f6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9258010118043845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "fbced040-aa7f-4134-d89c-53974fba48fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 561 -> 374 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "8214f9c3-c9b6-44e0-f507-51d3868034b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Rerun the same thing in tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ## Building the graph - Best!\n",
        "# saver = tf.train.Saver()\n",
        "# learning_rate = 0.001\n",
        "# hid_neuron = [374]\n",
        "# num_steps = 20000\n",
        "# batch_size = 200\n",
        "# train_losses = []\n",
        "# test_acc = []\n",
        "# X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "# Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "# def neural_net(x,train = True):\n",
        "#     layer_outputs = []\n",
        "#     layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "#     layer_1 = tf.nn.relu(layer_1)\n",
        "# #     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "# #     layer_2 = tf.nn.relu(layer_2)\n",
        "#     out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_outputs.append(out_layer)\n",
        "#     return out_layer\n",
        "\n",
        "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "# train_op = optimizer.minimize(loss)\n",
        "# correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "#   ### Initialization and running the model\n",
        "# with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     best_accuracy_valid = 0\n",
        "#     for step in range(0, num_steps):\n",
        "#         batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "#         if step % 1000 == 0:\n",
        "#             train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "#             train_losses.append(train_loss)\n",
        "#             validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "#             if step%1000 == 0:\n",
        "#               print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "#               print()\n",
        "#               if (validation_accuracy >= best_accuracy_valid):\n",
        "#                 best_accuracy_valid = validation_accuracy\n",
        "#                 saver.save(sess, './statlog_letter')\n",
        "#                 test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#     print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "#     print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "#     print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UpCtcB9hQFPI",
        "outputId": "f6f88345-3733-4a14-bfaf-5c302e835aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mT7SryMuQFPO"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K-zBUEuGwV98",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E91ru7-owV5i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 138\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T8GKhA_FJX8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "regularizers =  (tf.nn.l2_loss(G_W1) + tf.nn.l2_loss(G_W2) +\n",
        "                 tf.nn.l2_loss(GwLoop) + tf.nn.l2_loss(GwLoop2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlDkpoIzcLL3",
        "colab_type": "code",
        "outputId": "42424a68-076d-42e3-a146-defcd00c31f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Hqw9g6e-cL3l",
        "colab_type": "code",
        "outputId": "11cd7323-d497-4a25-f2d7-df1c91ebcba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "5881/200"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "GUH5tpXwcUdm",
        "colab_type": "code",
        "outputId": "0cd3013c-fbfb-43f4-d86b-6f93c30b6499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "100000/30"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3333.3333333333335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "1dqcFndAcZyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXzaScAbcaj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle  #train_data, train_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIJshIO5b1w6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train using epoch based methos"
      ]
    },
    {
      "metadata": {
        "id": "crEGEj10b4k_",
        "colab_type": "code",
        "outputId": "d1d5b5ca-b32c-4de5-d725-5e85d3c0b312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5253
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "lmd = .00001*0\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 1400\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 100\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = train_data.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.001\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 2\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3) #+ lmd*regularizers\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(train_data, train_label_one_hot)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "              saver.save(sess, './HarFull')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/10000, training loss= 0.0938497, training acc= 100.0%\n",
            "Validation Accuracy 94.33333587646484 ...\n",
            "\n",
            "Epoch 100/10000, training loss= 0.0002813643, training acc= 100.0%\n",
            "Validation Accuracy 94.16666412353516 ...\n",
            "\n",
            "Epoch 200/10000, training loss= 0.00016565807, training acc= 100.0%\n",
            "Validation Accuracy 94.0 ...\n",
            "\n",
            "Epoch 300/10000, training loss= 0.00011289314, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 400/10000, training loss= 8.2091545e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 500/10000, training loss= 6.221706e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 600/10000, training loss= 4.856207e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 700/10000, training loss= 3.878342e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 800/10000, training loss= 3.152958e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 900/10000, training loss= 2.600859e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1000/10000, training loss= 2.1702317e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 1100/10000, training loss= 1.8279517e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 1200/10000, training loss= 1.5526923e-05, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 1300/10000, training loss= 1.3284989e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1400/10000, training loss= 1.1433283e-05, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1500/10000, training loss= 9.8905875e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1600/10000, training loss= 8.594861e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1700/10000, training loss= 7.497748e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 1800/10000, training loss= 6.5632885e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 1900/10000, training loss= 5.7633583e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 2000/10000, training loss= 5.073267e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 2100/10000, training loss= 4.4761537e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 2200/10000, training loss= 3.957517e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 2300/10000, training loss= 3.5046703e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 2400/10000, training loss= 3.1096392e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 2500/10000, training loss= 2.761893e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 2600/10000, training loss= 2.4558976e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 2700/10000, training loss= 2.1868561e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 2800/10000, training loss= 1.9493762e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 2900/10000, training loss= 1.738349e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3000/10000, training loss= 1.5524688e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3100/10000, training loss= 1.3874218e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3200/10000, training loss= 1.2409655e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3300/10000, training loss= 1.1102334e-06, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3400/10000, training loss= 9.944304e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3500/10000, training loss= 8.888455e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3600/10000, training loss= 7.9682763e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3700/10000, training loss= 7.137221e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3800/10000, training loss= 6.4077744e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 3900/10000, training loss= 5.748719e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 4000/10000, training loss= 5.164879e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 4100/10000, training loss= 4.6380882e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 4200/10000, training loss= 4.1572787e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 4300/10000, training loss= 3.740331e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 4400/10000, training loss= 3.3492114e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 4500/10000, training loss= 3.019967e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 4600/10000, training loss= 2.7156995e-07, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Epoch 4700/10000, training loss= 2.4386802e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 4800/10000, training loss= 2.1835157e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 4900/10000, training loss= 1.9595728e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5000/10000, training loss= 1.766e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5100/10000, training loss= 1.5749814e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5200/10000, training loss= 1.415752e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5300/10000, training loss= 1.2857572e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5400/10000, training loss= 1.15235636e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5500/10000, training loss= 1.0243484e-07, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5600/10000, training loss= 9.2557485e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5700/10000, training loss= 8.321944e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5800/10000, training loss= 7.461934e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 5900/10000, training loss= 6.749516e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6000/10000, training loss= 6.011554e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6100/10000, training loss= 5.3559027e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6200/10000, training loss= 4.827976e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6300/10000, training loss= 4.3255945e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6400/10000, training loss= 3.8544336e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6500/10000, training loss= 3.4003026e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6600/10000, training loss= 3.0313217e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6700/10000, training loss= 2.6680173e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6800/10000, training loss= 2.3756709e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 6900/10000, training loss= 2.0833241e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7000/10000, training loss= 1.7909775e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7100/10000, training loss= 1.5326908e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7200/10000, training loss= 1.2829189e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7300/10000, training loss= 1.0445003e-08, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7400/10000, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7500/10000, training loss= 7.322855e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7600/10000, training loss= 6.0172307e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7700/10000, training loss= 4.3142405e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7800/10000, training loss= 3.292447e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 7900/10000, training loss= 1.930055e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8000/10000, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8100/10000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8200/10000, training loss= 6.2442956e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8300/10000, training loss= 1.1353265e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8400/10000, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8500/10000, training loss= 2.5544847e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8600/10000, training loss= 1.4191581e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 8700/10000, training loss= 1.4191581e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 8800/10000, training loss= 5.6766324e-11, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Epoch 8900/10000, training loss= 1.1353265e-10, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9000/10000, training loss= 5.6766324e-11, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9100/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9200/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9300/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9400/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9500/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9600/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9700/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9800/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "Epoch 9900/10000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "Valid acc= 95.0 %\n",
            "==================================================\n",
            "W1\n",
            "2\n",
            "W2\n",
            "1\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UtrGwyKuZQL4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# cont training"
      ]
    },
    {
      "metadata": {
        "id": "ctjgqv4OcnxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMzDOL06cnuP",
        "colab_type": "code",
        "outputId": "2d0565b3-f87b-4503-ae9b-6e03972a3ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, 10000, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),11,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),11,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oiak3L46dJA2",
        "colab_type": "code",
        "outputId": "95ad6ffa-d7cd-4147-a140-0b50664480cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, 10000, plot_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8FeXZ//HPxaIBwhZ4QJRiUGll\nDSQRQQUSUeqCUtQiiAtqxbq0LlVLa5+6PNWqP+tWLdZ9qQRUqtSVAhKl1SJBAdkUULQoKossIYCQ\nXL8/ZogBT8ghyclJJt/363VeOec+c2auczHkyszcc9/m7oiIiERFg2QHICIiUp1U2EREJFJU2ERE\nJFJU2EREJFJU2EREJFJU2EREJFJU2EREJFJU2EREJFJU2EREJFIaJTuAqmjbtq2np6dXaR1btmyh\nWbNm1RNQhCgvsSkvsSkvsSkvsVU2L3Pnzl3r7v9T0XJ1urClp6dTUFBQpXXk5+eTk5NTPQFFiPIS\nm/ISm/ISm/ISW2XzYmafxrOcTkWKiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikJKyw\nmdljZva1mS0s05ZmZtPMbFn4s3XYbmZ2n5ktN7MFZpaZqLhERCTaEnnE9gRwwh5t44AZ7t4FmBG+\nBjgR6BI+xgLjExiXiIhEWMJu0Hb3t8wsfY/mYUBO+PxJIB/4ddj+lLs78B8za2VmHdx9daLiA7jp\npUW8vXgr4z98J5GbqZM2bFBeYlFeYlNeYlNevtPtwBbccEr3GtlWTY880r5MsfoSaB8+Pwj4b5nl\nVoVt3ytsZjaW4KiO9u3bk5+fX+lgVq3aTnFxMRs2bKj0OqJKeYlNeYlNeYlNefnOqpJN5OevAaCw\nsLBKv7srkrQhtdzdzcwr8bmHgIcAsrOzvSrD1eTkaMib8igvsSkvsSkvsSkvsSU6LzXdK/IrM+sA\nEP78Omz/HPhBmeU6hm0iIiL7pKYL2z+A88Ln5wFTyrSfG/aO7AdsTPT1NRERiaaEnYo0szyCjiJt\nzWwVcANwG/CsmV0IfAqMCBd/FTgJWA4UAecnKi4REYm2RPaKHFXOW4NjLOvAZYmKRURE6g+NPCIi\nIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGi\nwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYi\nIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGiwiYiIpGS\nlMJmZleY2UIzW2RmV4ZtGWb2jpl9YGYvmVmLZMQmIiJ1W40XNjPrAVwE9AUygKFmdhjwCDDO3XsC\nLwDX1nRsIiJS9yXjiK0rMNvdi9x9J/AmcBrwQ+CtcJlpwOlJiE1EROo4c/ea3aBZV2AK0B/YCswA\nCoAs4A53f9HMrgZucvfmMT4/FhgL0L59+6yJEydWKZ7CwkJSU1OrtI4oUl5iU15iU15iU15iq2xe\ncnNz57p7dkXL1XhhAzCzC4FLgS3AImA78CBwH9AG+AfwS3dvs7f1ZGdne0FBQZViyc/PJycnp0rr\niCLlJTblJTblJTblJbbK5sXM4ipsSek84u6PunuWuw8EvgE+cvel7j7E3bOAPGBFMmITEZG6LVm9\nItuFPzsRXF+bUKatAfA7giM4ERGRfZKs+9gmm9li4CXgMnffAIwys4+ApcAXwONJik1EROqwRsnY\nqLsPiNF2L3BvEsIREZEI0cgjIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiIS\nKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSps\nIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiISKSpsIiIS\nKSpsIiISKSpsIiISKSpsIiISKSpsIiISKUkpbGZ2hZktNLNFZnZl2NbbzP5jZvPMrMDM+iYjNhER\nqdtqvLCZWQ/gIqAvkAEMNbPDgDuAm9y9N/D78LWIiMg+aZSEbXYFZrt7EYCZvQmcBjjQIlymJfBF\nEmITEZE6zty9Zjdo1hWYAvQHtgIzgALgL8BUwAiOJI9y909jfH4sMBagffv2WRMnTqxSPIWFhaSm\nplZpHVGkvMSmvMSmvMSmvMRW2bzk5ubOdffsipar8cIGYGYXApcCW4BFwHaCYvamu082sxHAWHc/\nbm/ryc7O9oKCgirFkp+fT05OTpXWEUXKS2zKS2zKS2zKS2yVzYuZxVXYktJ5xN0fdfcsdx8IfAN8\nBJwH/D1c5DmCa3AiIiL7JFm9ItuFPzsRXF+bQHBNbVC4yLHAsmTEJiIidVsyOo8ATDazNsAO4DJ3\n32BmFwH3mlkjYBvhdTQREZF9kZTC5u4DYrT9C8hKQjgiIhIhGnlEREQiRYVNREQiRYVNREQiRYVN\nREQiRYVNREQiRYVNREQiRYVNREQiRYVNREQiRYVNREQipcLCZma/MLPWNRGMiIhIVcVzxNYemGNm\nz5rZCWZmiQ5KRESksiosbO7+O6AL8CgwBlhmZrea2aEJjk1ERGSfxTUIsru7mX0JfAnsBFoDz5vZ\nNHe/LpEBikh07dixg1WrVrFt27Zkh5IQLVu2ZMmSJckOo9apKC8pKSl07NiRxo0bV2r9FRY2M7sC\nOBdYCzwCXOvuO8ysAcGcaSpsIlIpq1atonnz5qSnpxPFqxybN2+mefPmyQ6j1tlbXtyddevWsWrV\nKjp37lyp9cdzxJYGnObun+6x8RIzG1qprYqIANu2bYtsUZPKMTPatGnDmjVrKr2OeDqPvAasL7PR\nFmZ2JIC76xhbRKpERU32VNV9Ip7CNh4oLPO6MGwTERGpdeIpbObuvuuFu5eQpJm3RUSq07p16+jd\nuze9e/fmgAMO4KCDDip9/e2338a1jvPPP58PP/xwn7c9dOhQjjnmmH3+nFQsngL1sZn9ku+O0i4F\nPk5cSCIiNaNNmzbMmzcPgBtvvJHU1FSuueaa3ZZxd9ydBg1iHwc8/vjj+7zd9evXs2DBAlJSUvjs\ns8/o1KnTvgcfh507d9KoUf07DonniO3nwFHA58Aq4EhgbCKDEhFJpuXLl9OtWzdGjx5N9+7dWb16\nNWPHjiU7O5vu3btz8803ly57zDHHMG/ePHbu3EmrVq0YN24cGRkZ9O/fv9wOEM8//zw/+clPOPPM\nM5k4cWJp+5dffsmwYcPo1asXGRkZzJ49GwiK5662888/H4Czzz6bF198sfSzqampAEyfPp2cnByG\nDh1Kz549ATjllFPIysqie/fuPPLII6WfeeWVV8jMzCQjI4MhQ4ZQUlLCYYcdxvr1QbeK4uJiDjnk\nkNLXdUWFpdzdvwZG1kAsIlKP3fTSIhZ/sala19ntwBbccEr3Sn126dKlPPXUU2RnZwNw2223kZaW\nxs6dO8nNzeWMM86gW7duu31m48aNDBo0iNtuu42rr76ap59+mhtuuOF7687Ly+PWW2+lZcuWjB49\nmuuuC+6auuyyyzj++OO5/PLL2blzJ0VFRcyfP5/bb7+dt99+m7S0tLiKTEFBAYsXLy49EnzyySdJ\nS0ujqKiI7OxsTj/9dLZv384ll1zCrFmzOPjgg1m/fj0NGjRg1KhRTJgwgcsvv5ypU6dyxBFHkJaW\nVqkcJks8Y0WmmNllZvYXM3ts16MmghMRSZZDDz20tKhBUIwyMzPJzMxkyZIlLF68+HufadKkCSee\neCIAWVlZfPbZZ99b5osvvuCzzz6jf//+dOvWjZKSEpYuXQpAfn4+F198MQCNGjWiRYsWvPHGG5x5\n5pmlxSWeItO/f//dTm/efffdpUeRq1atYsWKFbzzzjvk5uZy8MEH77beCy+8kCeffBKAxx57rPQI\nsS6J5+Tr08BS4MfAzcBoQN38RaRaVfbIKlGaNWtW+nzZsmXce++9vPvuu7Rq1Yqzzz475mgp++23\nX+nzhg0bsnPnzu8tM2nSJNauXUt6ejoQHOXl5eVx0003AfF3dW/UqBElJSVAcMqw7LbKxj59+nTe\neust/vOf/9CkSROOOeaYvY70kp6eTuvWrZk5cybvv/8+Q4YMiSue2iSea2yHufv/Alvc/UngZILr\nbCIi9cKmTZto3rw5LVq0YPXq1UydOrXS68rLy2P69OmsXLmSlStX8u6775KXlwdAbm4uDz74IBAU\nq02bNnHssccyadKk0lOQu36mp6czd+5cAF544QWKi4tjbm/jxo2kpaXRpEkTFi1axJw5cwA46qij\nmDlzJp9++ulu64XgqG306NGMHDmy3E4ztVk8Ee8If24wsx5AS6Bd4kISEaldMjMz6datG4cffjjn\nnnsuRx99dKXWs2LFClavXr3bKc4uXbqQkpLC3Llzuf/++5k6dSo9e/YkOzubpUuXkpGRwXXXXcfA\ngQPp3bs31157LQAXX3wx06ZNIyMjg/fff5/9998/5jZPPvlkioqK6NatG7/73e848sjguKR9+/aM\nHz+eYcOGkZGRwejRo0s/M3z4cDZu3MiYMWMq9T2TbldX1vIewM8IBj0eSNDN/2vg4oo+VxOPrKws\nr6qZM2dWeR1RpLzEprzEVtm8LF68uHoDqWU2bdqU7BAq5Z133vGcnJyErT+evMTaN4ACj6M27PUa\nWzjQ8SZ3/wZ4CzgkoVVWRESS6pZbbuGhhx7a7TaEumavpyI9GGVEo/eLiNQT119/PZ9++in9+/dP\ndiiVFs81tulmdo2Z/cDM0nY9Eh6ZiIhIJcTT3f/M8OdlZdqcKpyWDOd4uwgw4GF3v8fMJgE/Chdp\nBWxw996V3YaIiNRP8Yw8UrmZ3soR9qy8COgLfAu8bmYvu/uZZZb5E7CxOrcrIiL1QzwzaJ8bq93d\nn6rkNrsCs929KFz/m8BpwB3hawNGAMdWcv0iIlKPxXMq8ogyz1OAwcB7QGUL20LgFjNrA2wFTgIK\nyrw/APjK3ZfF+rCZjSUchLl9+/bk5+dXMoxAYWFhldcRRcpLbMpLbJXNS8uWLdm8eXP1BxSnk08+\nmauuuorjjjuutO2BBx5g+fLl3H333eV+rkOHDqxevZrVq1dz3XXX8fTTT39vmZNOOombb755t3vW\n9vTAAw9w/vnn07RpUwBOP/10Hn30UVq1alWFb/Wdo48+mi5duvDEE09Uy/qqS3FxcYX/7tu2bav8\n/7V47gko+yC4/vX6vn5uj3VcCMwluIVgPHBPmffGA7+KZz26jy1xlJfYlJfY6up9bH/96199zJgx\nu7UdeeSR/uabb+71c82aNatw3YMGDfL8/Py9LnPwwQf7mjVrKg60EhYvXuw9evTwAw880AsLCxOy\nDXf3HTt27PNnEn0fW2XGStkCVOm6m7s/6u5Z7j4Q+Ab4CMDMGhGclpxUlfWLiMTjjDPO4JVXXimd\nVHTlypV88cUXDBgwgMLCQgYPHkxmZiY9e/ZkypQp3/v8ypUr6dGjBwBbt25l5MiRdO3aleHDh7N1\n69bS5S655JLSKW92jfZ/33338cUXX5Cbm0tubi4QDJO1du1aAO666y569OhBjx49uOeee0q317Vr\nVy666CK6d+/OkCFDdttOWXl5eZxzzjkMGTJkt9iXL1/OcccdR0ZGBpmZmaxYsQKA22+/nZ49e5KR\nkcG4ceMAyMnJoaAgOKFWdnzLJ554glNPPZVjjz2WwYMH7zVXTz31VOmUO+eccw6bN2+mZ8+e7NgR\nDGq1adMmOnfuXPq6OsRzje0lgl6QENwe0A14tiobNbN27v61mXUiKGT9wreOA5a6+6qqrF9E6qDX\nxsGXH1TvOg/oCSfeVu7baWlp9O3bl9dee41hw4YxceJERowYgZmRkpLCCy+8QIsWLVi7di39+vXj\n1FNPLXeQ4vHjx9O0aVOWLFnCggULyMzMLH3vlltuIS0tjeLiYgYPHsyCBQv45S9/yV133cXMmTNp\n27btbuuaO3cujz/+OLNnz8bdOfLIIxk0aBCtW7dm2bJl5OXl8fDDDzNixAgmT57M2Wef/b14Jk2a\nxLRp01i6dCl//vOfOeusswAYPXo048aNY/jw4Wzbto2SkhJee+01pkyZwuzZs2natGlcU+O89957\nLFiwoHQqn1i5Wrx4MX/4wx94++23adu2LevXr6d58+Ycc8wxvPLKK/zkJz9h4sSJnHbaaTRu3LjC\nbcYrniO2O4E/hY8/AgPdfVwVtzvZzBYDLwGXufuGsH0kkFfFdYuIxG3UqFGlo2xMnDiRUaNGAcFl\nmt/+9rf06tWL4447js8//5yvvvqq3PW89dZbpQWmV69e9OrVq/S9Z599lszMTPr06cOiRYtiTnlT\n1r/+9S+GDx9Os2bNSE1N5bTTTmPWrFkAdO7cmd69gzuhsrKyWLly5fc+X1BQQNu2benUqRODBw/m\n/fffZ/369WzevJnPP/+c4cOHA5CSkkLTpk2ZPn36btf64pka5/jjjy9drrxcvfHGG/z0pz8tLdy7\nlj/vvPNKZx5//PHHq31qnHg6j3wGrHb3bQBm1sTM0t19ZWU36u4DymkfU9l1ikgdt5cjq0QaNmwY\nV111Fe+99x5FRUVkZWUB8Mwzz7BmzRrmzp1L48aNSU9P3+t0L+X55JNPuPPOO5kzZw6tW7dmzJgx\nlVrPLmUHO27YsGHMU5F5eXksXbq09NThpk2bmDx5MiNH7tuc0WWnxtkz5rJT4+xrrvr168c111xD\nfn4+xcXFpadzq0s8R2zPASVlXheHbSIidV5qaiq5ublccMEFpUdrEEz30q5dOxo3brzb9C7lGThw\nIBMmTABg4cKFLFiwAAiKSrNmzWjZsiVfffUVr732WulnmjdvHrN34IABA3jxxRcpKipiy5YtvPDC\nCwwYEPN44HtKSkp49tln+eCDD0qnxpkyZQp5eXk0b96cjh078uKLLwKwfft2ioqKOP7443n88ccp\nKioCYk+N8/zzz5e7zfJydeyxx/Lcc8+xbt263dYLcO6553LWWWclZCLTeApbI3f/dteL8Pl+e1le\nRKROGTVqFPPnz9+tsI0ePZqCggJ69uzJU089xeGHH77XdVxyySUUFhbStWtXfv/735ce+WVkZNCn\nTx8OP/xwzjrrrN2mvBk7diwnnHBCaeeRXTIzMxkzZgx9+/blyCOP5Gc/+xl9+vSJ67vMmjWLgw46\niAMPPLC0beDAgSxevJjVq1fz9NNPc99999GrVy+OOuoovvzyS0444QROPfVUsrOz6d27N3feeScA\n11xzDePHj6dPnz6lnVpiKS9X3bt35/rrr2fQoEFkZGRw9dVX7/aZb775ZrecV5uKuk0C04BTy7we\nBsyIp8tloh/q7p84yktsyktsdbW7f6LV1WlrEm3Tpk3+3HPP+dlnn13uMgmbtib0c+AZM7s/fL0K\niDkaiYiISEWuueYaZsyYwauvvpqQ9cczVuQKoJ+ZpYavCxMSiYiI1At33nknzZs3T9j6K7zGZma3\nmlkrdy9090Iza21mf0hYRCJSrwRnmES+U9V9Ip7OIyf6d/eZ4cFs2idVaasiIgT3Ua1bt07FTUq5\nO+vWrSMlJaXS64jnGltDM9vf3bdDcB8bsH8FnxERqVDHjh1ZtWoVa9asSXYoCbFt27Yq/YKOqory\nkpKSQseOHSu9/ngK2zPADDN7nGBi0DHAk5XeoohIqHHjxnTuXK1TPtYq+fn5cXfTr08SnZd4Oo/c\nbmbzCcZxdGAqcHDCIhIREamCeEf3/4qgqP2UYALQJQmLSEREpArKPWIzsx8Co8LHWoKpZMzdc8v7\njIiISLLt7VTkUmAWMNTdlwOY2VU1EpWIiEgl7e1U5GnAamCmmT1sZoMJOo+IiIjUWuUWNnd/0d1H\nAocDM4ErgXZmNt7MhtRUgCIiIvuiws4j7r7F3Se4+ylAR+B94NcJj0xERKQS4u0VCQSjjrj7Q+4+\nOFEBiYiIVMU+FTYREZHaToVNREQiRYVNREQiRYVNREQiRYVNREQiRYVNREQiRYVNREQiRYVNREQi\nRYVNREQiRYVNREQiRYVNREQiRYVNREQiJSmFzcyuMLOFZrbIzK4s0/4LM1satt+RjNhERKRu29sM\n2glhZj2Ai4C+wLfA62b2MvADYBiQ4e7bzaxdTccmIiJ1X40XNqArMNvdiwDM7E2C2bqzgdvcfTuA\nu3+dhNhERKSOM3ev2Q2adQWmAP2BrcAMoAAYELafAGwDrnH3OTE+PxYYC9C+ffusiRMnVimewsJC\nUlNTq7SOKFJeYlNeYlNeYlNeYqtsXnJzc+e6e3ZFy9X4EZu7LzGz24F/AluAeUBxGEsa0A84AnjW\nzA7xPSqvuz8EPASQnZ3tOTk5VYonPz+fqq4jipSX2JSX2JSX2JSX2BKdl6R0HnH3R909y90HAt8A\nHwGrgL974F2gBGibjPhERKTuSsY1Nsysnbt/bWadCK6v9SMoZLnATDP7IbAfsDYZ8YmISN2VlMIG\nTDazNsAO4DJ332BmjwGPmdlCgt6S5+15GlJERKQiSSls7j4gRtu3wNlJCEdERCJEI4+IiEikqLCJ\niEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEik\nqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJ\niEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikqLCJiEikJKWwmdkV\nZrbQzBaZ2ZVh241m9rmZzQsfJyUjNhERqdsa1fQGzawHcBHQF/gWeN3MXg7fvtvd76zpmEREJDpq\nvLABXYHZ7l4EYGZvAqclIY7arXgnNGgIZsmORCqjeAd8uyX2e2awfwv924okSDIK20LgFjNrA2wF\nTgIKgHXA5WZ2bvj6V+7+TRLiSy53+OA5mHo9tOgAJ98NHbOSHZXEq6QE5v0Npt0AW9eXv1zHvnDy\nn6BDr5qLTaSeMHev+Y2aXQhcCmwBFgHbgT8CawEH/g/o4O4XxPjsWGAsQPv27bMmTpxYpVgKCwtJ\nTU2t0jqqS9Mtn9Fl2V9pvWEhm1MPZb9v17PftxtY3WEIHx9yDjsbN6+xWGpTXmqTveUldfPHdFn2\nIC03fciGlt1Y27Yf8P2jsobF2zjo85dpvGMznx90Mp90PoviRk0THHliaX+JTXmJrbJ5yc3Nnevu\n2RUu6O5JfQC3Apfu0ZYOLKzos1lZWV5VM2fOrPI6qsXCv7vflOb+x07ucx5zLy5237rR/bXfuN/Y\n2v32zu7v/S1orwG1Ji+1TMy8bN3o/uqv3W9s5X77Ie7vP+NeUrL3FRWtd3/pKvcbWrr/vx+6L3iu\n4s/UYtpfYlNeYqtsXoACj6OuJKtXZLvwZyeC62sTzKxDmUWGE5yyrB++eB9euAQOyoZfzIXs86FB\nA0hpASfcChe/BW0OgymXwhMnwVeLkh2xQHja+Hm4/wiY/SBkjYHL50Dvsyq+ftakNQy9Cy6aAc0P\ngMkXwlOnwpqPaiR0kShL1n1sk81sMfAScJm7bwDuMLMPzGwBkAtclaTYatbmr2DiaGjWFs78W/Bz\nTwf0gPNfh2EPwJoP4cEBwTW47ZtrPl4JrF0GTw0LClLzA4ICNfRuaJq2b+s5KAsueiO43vbFfBh/\nFMy4Gb4tSkzcIvVAMjqP4O4DYrSdk4xYkmrndpg0GrZ+AxdMhdT/KX/ZBg2gz9nwo5Ng+o3wzgOw\ncDL8+FboPlw97GpIg+LtQeH5933QuCmcdCdkXxD0YK30ShvCET+DrqfCtN/DrD/BgufgpDvgRydW\nX/Ai9URSCpuEXr0GVs2BEU/F3zuuaRqceh9kngsvXwXPnx8UuRYdYi+f0hKOvgraHlZ9ccejaD38\n62745pOa3W6C9f14Nmz/GjJGwfE3Q2q76lt5ajsY/iD0OQde+RXkjYRO/WMfxdcy3desha8eSXYY\ntU615MUawOGnQM8z9AdsnFTYkuW/c+C9p+DoK6DbsH3/fMdsGJsPcx6B9/8G61bEXm7DZ7DgWTj6\nShhwNTRuUpWoK1ZSAvPzYNr/wtYN0PaHkfrPuC2lHSmjnoD0oxO3kfSj4eez4D/jg3+7bRsTt61q\n0mTrFlhX++OsadWSl+2bYfEUeO/J4AxBu8OrJ7gIU2FLBvfgF3+zdjDw2sqvp0FDOPLi4FGezV/C\nP38Hb90BCybBSf8Pfvjjym9zb75aFBxpfPZOcJ/W0LvggJ6J2VaSzMvPJyeRRW2Xho3h6F8Gjzqg\nID+fnJycZIdR61RLXkqKg6I2/SZ48GjofzkMug72a1YtMUaRBkFOhg9fDX7554yD/RN8b1rzA+D0\nR+Dcf0Cj/WHCiKCzyob/Vt82tm8OOrM8OCDo3HLq/cE1w4gVNZGkaNAwuI77i7nQ60z49z1wf19Y\n8nLwR7J8jwpbTSveGYxK0aYLZJ5Xc9s9ZBD8/N8w+AZYPgMe6BtcA9v5beXX6Q6LXgi6u79zf9C5\n5RdzIfOcoLOLiFSfZm3hJ38JekintAg6nk0YAZu+SHZktY5++9S095+Cdcvg+JugYQ2fCW60X3Cd\n7fJ34ZDcoHflg8fAJ7P2fV3rVsDfTofnxgT/4S6cHnRq2dfu7iKybw7uH9zbOuQWWPlv+NsZsL0w\n2VHVKrrGVpO2F8LMPwY93X6UxFl5WnWCURPgw9fhtWvhyaHQc0TQ6yocAipt3QL4qJyjuVXvwr/v\nhUYpcOIdkH1hzRdpkfqsYWM46nJo1xWeOQNeuBhGPK0zJSH9Nqop7vDqtbDlaxg5oXb0FPzRCcEp\nyll3BeftP3i29K1eAB/s5bM9R8CQ/wuu4YlIchw2OLiX9fVxkP9HOPb6ZEcU2yez4KDMGuvwosJW\nGe6w/mMo2fldW+v0oHNGed55AOZPgJzfwA+OSHiIcWvcJPjPkH3Bbufq5743l6zMcmYVSGlZ8/fF\niUhsR/4cvloY9Hxu1xV61LJ1/M85AAAKxUlEQVRZwOblwZTLoN8l8ONbamSTKmyVMT8PXrxk97aW\nneDE2+HwGKcYl00Luvd3PRUGXlczMe6rFh12u8l78/LNmi5HpC4wg5PvCoZ5+/tFsHp+7bkd4O0/\nB7cbdR4U9AKvITohu6/cgxtn2/4QzngseAz7C+yfChNHwYQzg44VO7YFj6+XwPMXQrvuwagSOgcu\nItWt0f5w1iTIGFnmdoCXknc7gDv883+DotZ9OIx+LvG3NpWhI7Z99flc+HJBMAJAj9O/a+81Ihjh\nfeYf4c+Zu3+madugs0Zt+AtKRKKpSetgoPQ+58DLV8Oks6HLkKCDV1rnmotj/cdBf4Ll04MxUE+8\no2pjqVaCCtu+mvMoNG4W3ChZVsPGcNQvgr9OFr0AxTu+e+/woUFPRBGRROvUDy5+E2b/NehQ8pd+\nMOBXcNQvoXFK4ra7Y1twtDjrLmi4X1DQ+o5NSkc5FbZ9UbQeFv09mG8rpUXsZVp2DAqciEiy7Lod\noMdpMPW3MPOW4HpXIseK3bEVtm8KzmQNuaX8gdlrgArbvpg3AXZuC+7bEhGp7VocCD99IhjlaMk/\nwEsSty1rEHSQOzQ3cduIkwpbvEpKoOAx+MGRwcSfIiJ1xaG5taLg1BR10YvXJ2/C+hU6WhMRqeVU\n2OI15xFokla5udNERKTGqLDFY/V8WPpyMDpHInsViYhIldXvwrZ2OYcteziYSqY8u240bJJWZyZ9\nFBGpz+p3Yft6MR0/fxnmPVP+MstnBNfXBl0XjJEoIiK1Wv0ubF1PYWOLw2HmrfDtlu+/X1IM034f\nDHCsTiMiInVC/S5sZqw4dAwUfhmMvr+n+RPh60XBrNON9qvp6EREpBLqd2EDNrXsCl1PCSbOLPz6\nuze+LYI3/gAHZgbDZImISJ1Q7wsbAINvDIaDefP24PXKf8PDx8LmL2DIH2rHpKAiIhIXjTwCwaSZ\n2edDweOwZS0sfjGYX23UJEg/OtnRiYjIPtAR2y6Dfh0MELr0FRhwDVw2G350QrKjEhGRfaQjtl1S\n28GF/wyKW9ohyY5GREQqSYWtrPbdkx2BiIhUkU5FiohIpCSlsJnZFWa20MwWmdmVe7z3KzNzM2ub\njNhERKRuq/HCZmY9gIuAvkAGMNTMDgvf+wEwBPispuMSEZFoSMYRW1dgtrsXuftO4E3gtPC9u4Hr\nAE9CXCIiEgHmXrM1xMy6AlOA/sBWYAZQAEwHjnX3K8xsJZDt7mtjfH4sMBagffv2WRMnTqxSPIWF\nhaSmplZpHVGkvMSmvMSmvMSmvMRW2bzk5ubOdffsipar8cIGYGYXApcCW4BFQEOC05JD3H3j3gpb\nWdnZ2V5QUFClWPLz88nJyanSOqJIeYlNeYlNeYlNeYmtsnkxs7gKW1I6j7j7o+6e5e4DgW8Iiltn\nYH5Y1DoC75nZAcmIT0RE6q5k9YpsF/7sRHB97Ul3b+fu6e6eDqwCMt39y2TEJyIidVeybtCebGZt\ngB3AZe6+IUlxiIhIxCTlGlt1MbM1wKdVXE1bYK/X8uop5SU25SU25SU25SW2yublYHf/n4oWqtOF\nrTqYWUE8FyPrG+UlNuUlNuUlNuUltkTnRUNqiYhIpKiwiYhIpKiwwUPJDqCWUl5iU15iU15iU15i\nS2he6v01NhERiRYdsYmISKSosImISKTU68JmZieY2YdmttzMxiU7nkQzsx+Y2UwzWxzOhXdF2J5m\nZtPMbFn4s3XYbmZ2X5ifBWaWWWZd54XLLzOz85L1naqLmTU0s/fN7OXwdWczmx1+90lmtl/Yvn/4\nenn4fnqZdfwmbP/QzH6cnG9SfcyslZk9b2ZLzWyJmfXXvgJmdlX4/2ehmeWZWUp93V/M7DEz+9rM\nFpZpq7Z9xMyyzOyD8DP3mZnFFZi718sHwcDLK4BDgP2A+UC3ZMeV4O/cgWCoMoDmwEdAN+AOYFzY\nPg64PXx+EvAaYEA/gumGANKAj8OfrcPnrZP9/aqYm6uBCcDL4etngZHh8weBS8LnlwIPhs9HApPC\n593CfWh/gnFPVwANk/29qpiTJ4Gfhc/3A1rV930FOAj4BGhSZj8ZU1/3F2AgkAksLNNWbfsI8G64\nrIWfPTGuuJKdmCT+g/QHppZ5/RvgN8mOq4ZzMAU4HvgQ6BC2dQA+DJ//FRhVZvkPw/dHAX8t077b\ncnXtQTDo9gzgWODl8D/RWqDRnvsKMBXoHz5vFC5ne+4/ZZeriw+gZfgL3PZor+/7ykHAf8Nfwo3C\n/eXH9Xl/AdL3KGzVso+E7y0t077bcnt71OdTkbt20F1WhW31QnhKpA8wG2jv7qvDt74E2ofPy8tR\n1HJ3D8EEtyXh6zbABg8mwoXdv1/pdw/f3xguH7WcdAbWAI+Hp2gfMbNm1PN9xd0/B+4EPgNWE/z7\nz0X7S1nVtY8cFD7fs71C9bmw1VtmlgpMBq50901l3/PgT6N6cw+ImQ0Fvnb3ucmOpZZpRHCKaby7\n9yGYO3G369D1bV8BCK8XDSMo/AcCzYATkhpULZasfaQ+F7bPgR+Ued0xbIs0M2tMUNSecfe/h81f\nmVmH8P0OwNdhe3k5ilLujgZOtWAewIkEpyPvBVqZ2a7ZL8p+v9LvHr7fElhHtHICwV/Hq9x9dvj6\neYJCV5/3FYDjgE/cfY277wD+TrAP1ff9pazq2kc+D5/v2V6h+lzY5gBdwt5M+xFc2P1HkmNKqLBH\n0aPAEne/q8xb/wB29UQ6j+Da2672c8PeTP2AjeEphqnAEDNrHf4FOyRsq3Pc/Tfu3tGDeQBHAm+4\n+2hgJnBGuNieOdmVqzPC5T1sHxn2gusMdCG48F0neTAX4n/N7Edh02BgMfV4Xwl9BvQzs6bh/6dd\neanX+8seqmUfCd/bZGb9wlyfW2Zde5fsC49Jvuh5EkHPwBXA9cmOpwa+7zEEpwUWAPPCx0kE5/xn\nAMuA6UBauLwBD4T5+QDILrOuC4Dl4eP8ZH+3aspPDt/1ijyE4BfNcuA5YP+wPSV8vTx8/5Ayn78+\nzNWHxNl7qzY/gN5AQbi/vEjQY63e7yvATcBSYCHwNEHPxnq5vwB5BNcadxAc5V9YnfsIkB3meQVw\nP3t0ZirvoSG1REQkUurzqUgREYkgFTYREYkUFTYREYkUFTYREYkUFTYREYkUFTaRJDGzYjObV+ZR\nbTNMmFl62RHXReqTRhUvIiIJstXdeyc7CJGo0RGbSC1jZivN7I5wHqp3zeywsD3dzN4I57KaYWad\nwvb2ZvaCmc0PH0eFq2poZg+Hc4f908yaJO1LidQgFTaR5Gmyx6nIM8u8t9HdexKMtnBP2PZn4El3\n7wU8A9wXtt8HvOnuGQTjOS4K27sAD7h7d2ADcHqCv49IraCRR0SSxMwK3T01RvtK4Fh3/zgctPpL\nd29jZmsJ5rnaEbavdve2ZrYG6Oju28usIx2Y5u5dwte/Bhq7+x8S/81EkktHbCK1k5fzfF9sL/O8\nGF1Tl3pChU2kdjqzzM93wudvE8xAADAamBU+nwFcAmBmDc2sZU0FKVIb6S84keRpYmbzyrx+3d13\ndflvbWYLCI66RoVtvyCY0fpagtmtzw/brwAeMrMLCY7MLiEYcV2kXtI1NpFaJrzGlu3ua5Mdi0hd\npFORIiISKTpiExGRSNERm4iIRIoKm4iIRIoKm4iIRIoKm4iIRIoKm4iIRMr/BzZ1XqQyYDwdAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "i1CaNdeDc_9p",
        "colab_type": "code",
        "outputId": "b1c33404-5ab4-413f-fc03-a44f30fee63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.0\n",
            "10\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pQiZpMXVc_6P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "# print(max(valid_accuracy_filtered))\n",
        "# valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "# print(np.argmax(valid_accuracy_filtered))\n",
        "# print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AenHvoY8c_3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MY1cF8ZQb1l2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now retrain till 4500  epoch with complete data "
      ]
    },
    {
      "metadata": {
        "id": "tk4b9AoviHXG",
        "colab_type": "code",
        "outputId": "8bb07c9f-a288-407e-c613-9e5dd9cc8452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 3)\n",
            "(2000, 138)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iGeoQbuFiHTF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0dSoVofcifpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 4500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMrVBWxFiTse",
        "colab_type": "code",
        "outputId": "f4e507b1-36cc-4d3f-9704-68b055e4cd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4743
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 4112\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.0001\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 2\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(combined_train_valid, combined_train_valid_label)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "      if (train_acc>99.4):\n",
        "        break\n",
        "    saver.save(sess, './HArFullBest')\n",
        "    G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4500, training loss= 0.16427413, training acc= 98.44922423362732%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Epoch 50/4500, training loss= 0.04597503, training acc= 99.24962520599365%\n",
            "Validation Accuracy 97.5 ...\n",
            "\n",
            "Epoch 100/4500, training loss= 0.022919431, training acc= 99.59980249404907%\n",
            "Validation Accuracy 98.66667175292969 ...\n",
            "\n",
            "Epoch 150/4500, training loss= 0.012899454, training acc= 99.79990124702454%\n",
            "Validation Accuracy 99.33333587646484 ...\n",
            "\n",
            "Epoch 200/4500, training loss= 0.008432813, training acc= 99.89994764328003%\n",
            "Validation Accuracy 99.66666412353516 ...\n",
            "\n",
            "Epoch 250/4500, training loss= 0.004584978, training acc= 99.94997382164001%\n",
            "Validation Accuracy 99.83333587646484 ...\n",
            "\n",
            "Epoch 300/4500, training loss= 0.0034579653, training acc= 99.94997382164001%\n",
            "Validation Accuracy 99.83333587646484 ...\n",
            "\n",
            "Epoch 350/4500, training loss= 0.0029407851, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 400/4500, training loss= 0.0025924225, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 450/4500, training loss= 0.002333495, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 500/4500, training loss= 0.002132636, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 550/4500, training loss= 0.0019714641, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 600/4500, training loss= 0.0018368233, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 650/4500, training loss= 0.0017225267, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 700/4500, training loss= 0.0016228822, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 750/4500, training loss= 0.001534032, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 800/4500, training loss= 0.0014536524, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 850/4500, training loss= 0.0013756643, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 900/4500, training loss= 0.0012322033, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 950/4500, training loss= 0.0010131116, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1000/4500, training loss= 0.0009283893, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1050/4500, training loss= 0.00086460495, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1100/4500, training loss= 0.00081111747, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1150/4500, training loss= 0.0007646192, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1200/4500, training loss= 0.0007232616, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1250/4500, training loss= 0.00068612956, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1300/4500, training loss= 0.0006523143, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1350/4500, training loss= 0.00062131864, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1400/4500, training loss= 0.00059280766, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1450/4500, training loss= 0.00056637987, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1500/4500, training loss= 0.00054176577, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1550/4500, training loss= 0.00051879697, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1600/4500, training loss= 0.00049729354, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1650/4500, training loss= 0.00047710259, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1700/4500, training loss= 0.00045811824, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1750/4500, training loss= 0.0004402182, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1800/4500, training loss= 0.00042332473, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1850/4500, training loss= 0.00040733145, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1900/4500, training loss= 0.0003921536, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1950/4500, training loss= 0.00037776376, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2000/4500, training loss= 0.0003641114, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2050/4500, training loss= 0.00035113964, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2100/4500, training loss= 0.00033879775, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2150/4500, training loss= 0.00032701713, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2200/4500, training loss= 0.00031576867, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2250/4500, training loss= 0.00030501583, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2300/4500, training loss= 0.00029472663, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2350/4500, training loss= 0.0002848833, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2400/4500, training loss= 0.00027546124, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2450/4500, training loss= 0.00026642354, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2500/4500, training loss= 0.00025774934, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2550/4500, training loss= 0.0002494284, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2600/4500, training loss= 0.00024144782, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2650/4500, training loss= 0.00023378262, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2700/4500, training loss= 0.00022642419, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2750/4500, training loss= 0.00021934215, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2800/4500, training loss= 0.00021253111, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2850/4500, training loss= 0.00020597616, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2900/4500, training loss= 0.00019966088, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2950/4500, training loss= 0.00019358107, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3000/4500, training loss= 0.00018771511, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3050/4500, training loss= 0.00018205738, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3100/4500, training loss= 0.00017659873, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3150/4500, training loss= 0.00017133093, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3200/4500, training loss= 0.00016624318, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3250/4500, training loss= 0.00016133653, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3300/4500, training loss= 0.00015659595, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3350/4500, training loss= 0.00015201175, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3400/4500, training loss= 0.0001475793, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3450/4500, training loss= 0.00014329207, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3500/4500, training loss= 0.00013914201, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3550/4500, training loss= 0.00013512866, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3600/4500, training loss= 0.00013124236, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3650/4500, training loss= 0.00012748077, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3700/4500, training loss= 0.00012383708, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3750/4500, training loss= 0.00012030914, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3800/4500, training loss= 0.000116891504, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3850/4500, training loss= 0.00011357956, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3900/4500, training loss= 0.00011036957, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 3950/4500, training loss= 0.00010725669, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4000/4500, training loss= 0.00010423838, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4050/4500, training loss= 0.00010131352, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4100/4500, training loss= 9.847777e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4150/4500, training loss= 9.5726886e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4200/4500, training loss= 9.30596e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4250/4500, training loss= 9.04714e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4300/4500, training loss= 8.795725e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4350/4500, training loss= 8.551782e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4400/4500, training loss= 8.3149374e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 4450/4500, training loss= 8.085114e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Valid acc= 100.0 %\n",
            "==================================================\n",
            "W1\n",
            "2\n",
            "W2\n",
            "1\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2mxHqJHiTqL",
        "colab_type": "code",
        "outputId": "0107744d-c9d0-4fa4-c836-d671bf5802ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './HArFullBest')\n",
        "    train_accuracy = sess.run(accuracy*100, feed_dict={X: X_train,Y: y_train})\n",
        "    print(\"Train acc=\",str(train_accuracy), \"%\")\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./HArFullBest\n",
            "Train acc= 100.0 %\n",
            "ValidValid acc= 100.0 %\n",
            "Test acc= 94.519394 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gFeVzG-_iTnA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zbc1-WviiTkI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 4, W2 =2, W3 = 1 from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W5Fa3AIQ5n8N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [374]\n",
        "num_steps = 100000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwY5Bt2EM3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kwd9EKfLM3Z9",
        "colab_type": "code",
        "outputId": "82535c54-6378-4f17-f5b2-987d3de0fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEYCAYAAAA06gPTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MpHiEL6VM3aB",
        "colab_type": "code",
        "outputId": "2d03f9be-d0d6-4a16-aecf-a242575ce7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.64704\n",
            "485\n",
            "24250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_l2RRE0M3aE",
        "colab_type": "code",
        "outputId": "8ad5cca4-e098-4fa4-bd62-f5f537063401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 6)\n",
            "(7352, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HaKv7GnsM3aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRpkJTtqM3aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 24300 steps"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Uifa_UHiM3aK",
        "colab_type": "code",
        "outputId": "d8ba0e2b-73ee-415a-c457-940391c94d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8432
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 24300\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "    \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 0.45379114, training acc total= 93.14671754837036%\n",
            "step 50, training loss Total= 0.039833248, training acc total= 99.64147806167603%\n",
            "step 100, training loss Total= 0.045330588, training acc total= 99.3381142616272%\n",
            "step 150, training loss Total= 0.019238897, training acc total= 99.79315996170044%\n",
            "step 200, training loss Total= 0.013733287, training acc total= 99.86210465431213%\n",
            "step 250, training loss Total= 0.021557797, training acc total= 99.7380018234253%\n",
            "step 300, training loss Total= 0.15683196, training acc total= 98.17981123924255%\n",
            "step 350, training loss Total= 0.016487077, training acc total= 99.86210465431213%\n",
            "step 400, training loss Total= 0.04703603, training acc total= 99.32432174682617%\n",
            "step 450, training loss Total= 0.01743794, training acc total= 99.82073903083801%\n",
            "step 500, training loss Total= 0.009342014, training acc total= 99.91726279258728%\n",
            "step 550, training loss Total= 0.014104057, training acc total= 99.94484186172485%\n",
            "step 600, training loss Total= 0.056876045, training acc total= 99.46221709251404%\n",
            "step 650, training loss Total= 0.023242952, training acc total= 99.75179433822632%\n",
            "step 700, training loss Total= 0.039095264, training acc total= 99.64147806167603%\n",
            "step 750, training loss Total= 0.01313867, training acc total= 99.90347623825073%\n",
            "step 800, training loss Total= 0.0052991095, training acc total= 99.97242093086243%\n",
            "step 850, training loss Total= 0.0073110424, training acc total= 99.94484186172485%\n",
            "step 900, training loss Total= 0.0054948954, training acc total= 100.0%\n",
            "step 950, training loss Total= 0.0026818907, training acc total= 100.0%\n",
            "step 1000, training loss Total= 0.005416252, training acc total= 99.95863437652588%\n",
            "step 1050, training loss Total= 0.0029244383, training acc total= 99.98621344566345%\n",
            "step 1100, training loss Total= 0.009015584, training acc total= 99.91726279258728%\n",
            "step 1150, training loss Total= 0.0047110305, training acc total= 99.97242093086243%\n",
            "step 1200, training loss Total= 0.0025466764, training acc total= 100.0%\n",
            "step 1250, training loss Total= 0.011902557, training acc total= 99.90347623825073%\n",
            "step 1300, training loss Total= 0.0025260278, training acc total= 100.0%\n",
            "step 1350, training loss Total= 0.02453232, training acc total= 99.82073903083801%\n",
            "step 1400, training loss Total= 0.01409426, training acc total= 99.82073903083801%\n",
            "step 1450, training loss Total= 0.023859076, training acc total= 99.80695247650146%\n",
            "step 1500, training loss Total= 0.03329613, training acc total= 99.6690571308136%\n",
            "step 1550, training loss Total= 0.009649995, training acc total= 99.86210465431213%\n",
            "step 1600, training loss Total= 0.003689609, training acc total= 99.98621344566345%\n",
            "step 1650, training loss Total= 0.0005480611, training acc total= 100.0%\n",
            "step 1700, training loss Total= 0.0006046851, training acc total= 100.0%\n",
            "step 1750, training loss Total= 0.002250957, training acc total= 100.0%\n",
            "step 1800, training loss Total= 0.0011101604, training acc total= 99.98621344566345%\n",
            "step 1850, training loss Total= 0.000708361, training acc total= 99.98621344566345%\n",
            "step 1900, training loss Total= 0.00043114158, training acc total= 99.98621344566345%\n",
            "step 1950, training loss Total= 0.00029356795, training acc total= 99.98621344566345%\n",
            "step 2000, training loss Total= 0.0003990697, training acc total= 100.0%\n",
            "step 2050, training loss Total= 0.0002397307, training acc total= 100.0%\n",
            "step 2100, training loss Total= 0.0001829968, training acc total= 100.0%\n",
            "step 2150, training loss Total= 0.00016412513, training acc total= 100.0%\n",
            "step 2200, training loss Total= 0.00016021628, training acc total= 100.0%\n",
            "step 2250, training loss Total= 0.00015052022, training acc total= 100.0%\n",
            "step 2300, training loss Total= 0.00014221712, training acc total= 100.0%\n",
            "step 2350, training loss Total= 0.00013628391, training acc total= 100.0%\n",
            "step 2400, training loss Total= 0.0001313389, training acc total= 100.0%\n",
            "step 2450, training loss Total= 0.0001279928, training acc total= 100.0%\n",
            "step 2500, training loss Total= 0.00012342617, training acc total= 100.0%\n",
            "step 2550, training loss Total= 0.00011975322, training acc total= 100.0%\n",
            "step 2600, training loss Total= 0.00011516353, training acc total= 100.0%\n",
            "step 2650, training loss Total= 0.000115180126, training acc total= 100.0%\n",
            "step 2700, training loss Total= 0.00010938619, training acc total= 100.0%\n",
            "step 2750, training loss Total= 0.000107229935, training acc total= 100.0%\n",
            "step 2800, training loss Total= 0.00010414702, training acc total= 100.0%\n",
            "step 2850, training loss Total= 0.00010170599, training acc total= 100.0%\n",
            "step 2900, training loss Total= 9.9578305e-05, training acc total= 100.0%\n",
            "step 2950, training loss Total= 9.720049e-05, training acc total= 100.0%\n",
            "step 3000, training loss Total= 9.5185576e-05, training acc total= 100.0%\n",
            "step 3050, training loss Total= 9.3388655e-05, training acc total= 100.0%\n",
            "step 3100, training loss Total= 9.1292364e-05, training acc total= 100.0%\n",
            "step 3150, training loss Total= 9.0570175e-05, training acc total= 100.0%\n",
            "step 3200, training loss Total= 8.810865e-05, training acc total= 100.0%\n",
            "step 3250, training loss Total= 8.655106e-05, training acc total= 100.0%\n",
            "step 3300, training loss Total= 8.511055e-05, training acc total= 100.0%\n",
            "step 3350, training loss Total= 8.30821e-05, training acc total= 100.0%\n",
            "step 3400, training loss Total= 8.2190854e-05, training acc total= 100.0%\n",
            "step 3450, training loss Total= 7.991048e-05, training acc total= 100.0%\n",
            "step 3500, training loss Total= 7.9128265e-05, training acc total= 100.0%\n",
            "step 3550, training loss Total= 7.738369e-05, training acc total= 100.0%\n",
            "step 3600, training loss Total= 7.606571e-05, training acc total= 100.0%\n",
            "step 3650, training loss Total= 7.4599535e-05, training acc total= 100.0%\n",
            "step 3700, training loss Total= 7.394822e-05, training acc total= 100.0%\n",
            "step 3750, training loss Total= 7.243282e-05, training acc total= 100.0%\n",
            "step 3800, training loss Total= 7.1066104e-05, training acc total= 100.0%\n",
            "step 3850, training loss Total= 7.007496e-05, training acc total= 100.0%\n",
            "step 3900, training loss Total= 6.9149006e-05, training acc total= 100.0%\n",
            "step 3950, training loss Total= 6.789845e-05, training acc total= 100.0%\n",
            "step 4000, training loss Total= 6.752289e-05, training acc total= 100.0%\n",
            "step 4050, training loss Total= 6.586513e-05, training acc total= 100.0%\n",
            "step 4100, training loss Total= 6.472743e-05, training acc total= 100.0%\n",
            "step 4150, training loss Total= 6.4207445e-05, training acc total= 100.0%\n",
            "step 4200, training loss Total= 6.291922e-05, training acc total= 100.0%\n",
            "step 4250, training loss Total= 6.2562474e-05, training acc total= 100.0%\n",
            "step 4300, training loss Total= 6.151337e-05, training acc total= 100.0%\n",
            "step 4350, training loss Total= 6.0053877e-05, training acc total= 100.0%\n",
            "step 4400, training loss Total= 5.98447e-05, training acc total= 100.0%\n",
            "step 4450, training loss Total= 5.832744e-05, training acc total= 100.0%\n",
            "step 4500, training loss Total= 5.7690355e-05, training acc total= 100.0%\n",
            "step 4550, training loss Total= 5.6781522e-05, training acc total= 100.0%\n",
            "step 4600, training loss Total= 5.579446e-05, training acc total= 100.0%\n",
            "step 4650, training loss Total= 5.5062155e-05, training acc total= 100.0%\n",
            "step 4700, training loss Total= 5.510753e-05, training acc total= 100.0%\n",
            "step 4750, training loss Total= 5.3011812e-05, training acc total= 100.0%\n",
            "step 4800, training loss Total= 5.2269887e-05, training acc total= 100.0%\n",
            "step 4850, training loss Total= 5.1641724e-05, training acc total= 100.0%\n",
            "step 4900, training loss Total= 5.0703253e-05, training acc total= 100.0%\n",
            "step 4950, training loss Total= 5.019182e-05, training acc total= 100.0%\n",
            "step 5000, training loss Total= 5.0755316e-05, training acc total= 100.0%\n",
            "step 5050, training loss Total= 4.9589915e-05, training acc total= 100.0%\n",
            "step 5100, training loss Total= 4.7938887e-05, training acc total= 100.0%\n",
            "step 5150, training loss Total= 4.7407844e-05, training acc total= 100.0%\n",
            "step 5200, training loss Total= 4.6303157e-05, training acc total= 100.0%\n",
            "step 5250, training loss Total= 4.5708e-05, training acc total= 100.0%\n",
            "step 5300, training loss Total= 4.47868e-05, training acc total= 100.0%\n",
            "step 5350, training loss Total= 4.4157092e-05, training acc total= 100.0%\n",
            "step 5400, training loss Total= 4.3727534e-05, training acc total= 100.0%\n",
            "step 5450, training loss Total= 4.2848886e-05, training acc total= 100.0%\n",
            "step 5500, training loss Total= 4.2399846e-05, training acc total= 100.0%\n",
            "step 5550, training loss Total= 4.15261e-05, training acc total= 100.0%\n",
            "step 5600, training loss Total= 4.097614e-05, training acc total= 100.0%\n",
            "step 5650, training loss Total= 4.076816e-05, training acc total= 100.0%\n",
            "step 5700, training loss Total= 3.970181e-05, training acc total= 100.0%\n",
            "step 5750, training loss Total= 3.933144e-05, training acc total= 100.0%\n",
            "step 5800, training loss Total= 3.898717e-05, training acc total= 100.0%\n",
            "step 5850, training loss Total= 3.7689042e-05, training acc total= 100.0%\n",
            "step 5900, training loss Total= 3.6948193e-05, training acc total= 100.0%\n",
            "step 5950, training loss Total= 3.6885023e-05, training acc total= 100.0%\n",
            "step 6000, training loss Total= 3.5781293e-05, training acc total= 100.0%\n",
            "step 6050, training loss Total= 3.5292782e-05, training acc total= 100.0%\n",
            "step 6100, training loss Total= 3.5001445e-05, training acc total= 100.0%\n",
            "step 6150, training loss Total= 3.4707784e-05, training acc total= 100.0%\n",
            "step 6200, training loss Total= 3.333456e-05, training acc total= 100.0%\n",
            "step 6250, training loss Total= 3.2890694e-05, training acc total= 100.0%\n",
            "step 6300, training loss Total= 3.268921e-05, training acc total= 100.0%\n",
            "step 6350, training loss Total= 3.1813724e-05, training acc total= 100.0%\n",
            "step 6400, training loss Total= 3.1175947e-05, training acc total= 100.0%\n",
            "step 6450, training loss Total= 3.06217e-05, training acc total= 100.0%\n",
            "step 6500, training loss Total= 2.9924515e-05, training acc total= 100.0%\n",
            "step 6550, training loss Total= 2.9368362e-05, training acc total= 100.0%\n",
            "step 6600, training loss Total= 2.9557104e-05, training acc total= 100.0%\n",
            "step 6650, training loss Total= 2.8611234e-05, training acc total= 100.0%\n",
            "step 6700, training loss Total= 2.7806207e-05, training acc total= 100.0%\n",
            "step 6750, training loss Total= 2.8191218e-05, training acc total= 100.0%\n",
            "step 6800, training loss Total= 2.6764219e-05, training acc total= 100.0%\n",
            "step 6850, training loss Total= 2.6985621e-05, training acc total= 100.0%\n",
            "step 6900, training loss Total= 2.5748674e-05, training acc total= 100.0%\n",
            "step 6950, training loss Total= 2.5859163e-05, training acc total= 100.0%\n",
            "step 7000, training loss Total= 2.4881081e-05, training acc total= 100.0%\n",
            "step 7050, training loss Total= 2.4454004e-05, training acc total= 100.0%\n",
            "step 7100, training loss Total= 2.4397496e-05, training acc total= 100.0%\n",
            "step 7150, training loss Total= 2.3464538e-05, training acc total= 100.0%\n",
            "step 7200, training loss Total= 2.3243449e-05, training acc total= 100.0%\n",
            "step 7250, training loss Total= 2.2654332e-05, training acc total= 100.0%\n",
            "step 7300, training loss Total= 2.2294273e-05, training acc total= 100.0%\n",
            "step 7350, training loss Total= 2.1747077e-05, training acc total= 100.0%\n",
            "step 7400, training loss Total= 2.1405414e-05, training acc total= 100.0%\n",
            "step 7450, training loss Total= 2.1371805e-05, training acc total= 100.0%\n",
            "step 7500, training loss Total= 2.0714097e-05, training acc total= 100.0%\n",
            "step 7550, training loss Total= 2.0047093e-05, training acc total= 100.0%\n",
            "step 7600, training loss Total= 1.9721607e-05, training acc total= 100.0%\n",
            "step 7650, training loss Total= 1.9668209e-05, training acc total= 100.0%\n",
            "step 7700, training loss Total= 1.9357909e-05, training acc total= 100.0%\n",
            "step 7750, training loss Total= 1.8505072e-05, training acc total= 100.0%\n",
            "step 7800, training loss Total= 1.8325072e-05, training acc total= 100.0%\n",
            "step 7850, training loss Total= 1.7988601e-05, training acc total= 100.0%\n",
            "step 7900, training loss Total= 1.7382707e-05, training acc total= 100.0%\n",
            "step 7950, training loss Total= 1.7103308e-05, training acc total= 100.0%\n",
            "step 8000, training loss Total= 1.676944e-05, training acc total= 100.0%\n",
            "step 8050, training loss Total= 1.6405153e-05, training acc total= 100.0%\n",
            "step 8100, training loss Total= 1.6218299e-05, training acc total= 100.0%\n",
            "step 8150, training loss Total= 1.5685093e-05, training acc total= 100.0%\n",
            "step 8200, training loss Total= 1.5637701e-05, training acc total= 100.0%\n",
            "step 8250, training loss Total= 1.5384174e-05, training acc total= 100.0%\n",
            "step 8300, training loss Total= 1.5263153e-05, training acc total= 100.0%\n",
            "step 8350, training loss Total= 1.4749183e-05, training acc total= 100.0%\n",
            "step 8400, training loss Total= 1.4942148e-05, training acc total= 100.0%\n",
            "step 8450, training loss Total= 1.3973641e-05, training acc total= 100.0%\n",
            "step 8500, training loss Total= 1.5342941e-05, training acc total= 100.0%\n",
            "step 8550, training loss Total= 1.352159e-05, training acc total= 100.0%\n",
            "step 8600, training loss Total= 1.3141211e-05, training acc total= 100.0%\n",
            "step 8650, training loss Total= 1.2816561e-05, training acc total= 100.0%\n",
            "step 8700, training loss Total= 1.2515919e-05, training acc total= 100.0%\n",
            "step 8750, training loss Total= 1.2235865e-05, training acc total= 100.0%\n",
            "step 8800, training loss Total= 1.194812e-05, training acc total= 100.0%\n",
            "step 8850, training loss Total= 1.1650202e-05, training acc total= 100.0%\n",
            "step 8900, training loss Total= 1.18395465e-05, training acc total= 100.0%\n",
            "step 8950, training loss Total= 1.1626804e-05, training acc total= 100.0%\n",
            "step 9000, training loss Total= 1.09505445e-05, training acc total= 100.0%\n",
            "step 9050, training loss Total= 1.0693775e-05, training acc total= 100.0%\n",
            "step 9100, training loss Total= 1.0483288e-05, training acc total= 100.0%\n",
            "step 9150, training loss Total= 1.0218528e-05, training acc total= 100.0%\n",
            "step 9200, training loss Total= 1.0311115e-05, training acc total= 100.0%\n",
            "step 9250, training loss Total= 1.0391344e-05, training acc total= 100.0%\n",
            "step 9300, training loss Total= 9.610909e-06, training acc total= 100.0%\n",
            "step 9350, training loss Total= 9.3115705e-06, training acc total= 100.0%\n",
            "step 9400, training loss Total= 9.170817e-06, training acc total= 100.0%\n",
            "step 9450, training loss Total= 8.87041e-06, training acc total= 100.0%\n",
            "step 9500, training loss Total= 8.703654e-06, training acc total= 100.0%\n",
            "step 9550, training loss Total= 8.5080765e-06, training acc total= 100.0%\n",
            "step 9600, training loss Total= 8.317578e-06, training acc total= 100.0%\n",
            "step 9650, training loss Total= 8.11799e-06, training acc total= 100.0%\n",
            "step 9700, training loss Total= 7.88519e-06, training acc total= 100.0%\n",
            "step 9750, training loss Total= 7.749754e-06, training acc total= 100.0%\n",
            "step 9800, training loss Total= 7.5953894e-06, training acc total= 100.0%\n",
            "step 9850, training loss Total= 7.3588785e-06, training acc total= 100.0%\n",
            "step 9900, training loss Total= 7.3093056e-06, training acc total= 100.0%\n",
            "step 9950, training loss Total= 7.02444e-06, training acc total= 100.0%\n",
            "step 10000, training loss Total= 6.8462446e-06, training acc total= 100.0%\n",
            "step 10050, training loss Total= 6.649202e-06, training acc total= 100.0%\n",
            "step 10100, training loss Total= 6.5015815e-06, training acc total= 100.0%\n",
            "step 10150, training loss Total= 6.4178876e-06, training acc total= 100.0%\n",
            "step 10200, training loss Total= 6.4071637e-06, training acc total= 100.0%\n",
            "step 10250, training loss Total= 6.3303687e-06, training acc total= 100.0%\n",
            "step 10300, training loss Total= 5.9762883e-06, training acc total= 100.0%\n",
            "step 10350, training loss Total= 6.5979016e-06, training acc total= 100.0%\n",
            "step 10400, training loss Total= 6.0262655e-06, training acc total= 100.0%\n",
            "step 10450, training loss Total= 5.6011913e-06, training acc total= 100.0%\n",
            "step 10500, training loss Total= 5.4835136e-06, training acc total= 100.0%\n",
            "step 10550, training loss Total= 5.374652e-06, training acc total= 100.0%\n",
            "step 10600, training loss Total= 5.1238726e-06, training acc total= 100.0%\n",
            "step 10650, training loss Total= 4.988756e-06, training acc total= 100.0%\n",
            "step 10700, training loss Total= 5.152259e-06, training acc total= 100.0%\n",
            "step 10750, training loss Total= 4.868415e-06, training acc total= 100.0%\n",
            "step 10800, training loss Total= 4.6311525e-06, training acc total= 100.0%\n",
            "step 10850, training loss Total= 4.490116e-06, training acc total= 100.0%\n",
            "step 10900, training loss Total= 4.3844657e-06, training acc total= 100.0%\n",
            "step 10950, training loss Total= 4.347875e-06, training acc total= 100.0%\n",
            "step 11000, training loss Total= 4.3009345e-06, training acc total= 100.0%\n",
            "step 11050, training loss Total= 4.264303e-06, training acc total= 100.0%\n",
            "step 11100, training loss Total= 4.0137693e-06, training acc total= 100.0%\n",
            "step 11150, training loss Total= 3.863273e-06, training acc total= 100.0%\n",
            "step 11200, training loss Total= 3.8003948e-06, training acc total= 100.0%\n",
            "step 11250, training loss Total= 3.825282e-06, training acc total= 100.0%\n",
            "step 11300, training loss Total= 3.6556785e-06, training acc total= 100.0%\n",
            "step 11350, training loss Total= 3.543266e-06, training acc total= 100.0%\n",
            "step 11400, training loss Total= 3.4455707e-06, training acc total= 100.0%\n",
            "step 11450, training loss Total= 3.3386596e-06, training acc total= 100.0%\n",
            "step 11500, training loss Total= 3.3748452e-06, training acc total= 100.0%\n",
            "step 11550, training loss Total= 3.1914726e-06, training acc total= 100.0%\n",
            "step 11600, training loss Total= 3.084842e-06, training acc total= 100.0%\n",
            "step 11650, training loss Total= 2.993544e-06, training acc total= 100.0%\n",
            "step 11700, training loss Total= 2.931459e-06, training acc total= 100.0%\n",
            "step 11750, training loss Total= 2.865205e-06, training acc total= 100.0%\n",
            "step 11800, training loss Total= 2.795469e-06, training acc total= 100.0%\n",
            "step 11850, training loss Total= 2.874802e-06, training acc total= 100.0%\n",
            "step 11900, training loss Total= 1.0209057, training acc total= 94.60838437080383%\n",
            "step 11950, training loss Total= 0.07255421, training acc total= 99.37947988510132%\n",
            "step 12000, training loss Total= 0.0339027, training acc total= 99.86210465431213%\n",
            "step 12050, training loss Total= 0.014941098, training acc total= 99.97242093086243%\n",
            "step 12100, training loss Total= 0.021021731, training acc total= 99.94484186172485%\n",
            "step 12150, training loss Total= 0.0063558845, training acc total= 99.97242093086243%\n",
            "step 12200, training loss Total= 0.0075750193, training acc total= 100.0%\n",
            "step 12250, training loss Total= 0.005658201, training acc total= 99.98621344566345%\n",
            "step 12300, training loss Total= 0.0025600367, training acc total= 100.0%\n",
            "step 12350, training loss Total= 0.01002537, training acc total= 99.94484186172485%\n",
            "step 12400, training loss Total= 0.0026108145, training acc total= 100.0%\n",
            "step 12450, training loss Total= 0.0064419555, training acc total= 100.0%\n",
            "step 12500, training loss Total= 0.0029203158, training acc total= 100.0%\n",
            "step 12550, training loss Total= 0.002632146, training acc total= 100.0%\n",
            "step 12600, training loss Total= 0.00075261656, training acc total= 100.0%\n",
            "step 12650, training loss Total= 0.000614577, training acc total= 100.0%\n",
            "step 12700, training loss Total= 0.00038471568, training acc total= 100.0%\n",
            "step 12750, training loss Total= 0.0002161647, training acc total= 100.0%\n",
            "step 12800, training loss Total= 0.00012398882, training acc total= 100.0%\n",
            "step 12850, training loss Total= 0.000118790806, training acc total= 100.0%\n",
            "step 12900, training loss Total= 9.826971e-05, training acc total= 100.0%\n",
            "step 12950, training loss Total= 8.907376e-05, training acc total= 100.0%\n",
            "step 13000, training loss Total= 8.240566e-05, training acc total= 100.0%\n",
            "step 13050, training loss Total= 7.578769e-05, training acc total= 100.0%\n",
            "step 13100, training loss Total= 7.1960305e-05, training acc total= 100.0%\n",
            "step 13150, training loss Total= 6.774983e-05, training acc total= 100.0%\n",
            "step 13200, training loss Total= 6.53275e-05, training acc total= 100.0%\n",
            "step 13250, training loss Total= 6.2719664e-05, training acc total= 100.0%\n",
            "step 13300, training loss Total= 6.3502426e-05, training acc total= 100.0%\n",
            "step 13350, training loss Total= 5.8850674e-05, training acc total= 100.0%\n",
            "step 13400, training loss Total= 5.8054902e-05, training acc total= 100.0%\n",
            "step 13450, training loss Total= 5.750559e-05, training acc total= 100.0%\n",
            "step 13500, training loss Total= 6.4130785e-05, training acc total= 100.0%\n",
            "step 13550, training loss Total= 5.6682693e-05, training acc total= 100.0%\n",
            "step 13600, training loss Total= 5.308215e-05, training acc total= 100.0%\n",
            "step 13650, training loss Total= 5.2863226e-05, training acc total= 100.0%\n",
            "step 13700, training loss Total= 4.9961112e-05, training acc total= 100.0%\n",
            "step 13750, training loss Total= 4.8936126e-05, training acc total= 100.0%\n",
            "step 13800, training loss Total= 4.7082147e-05, training acc total= 100.0%\n",
            "step 13850, training loss Total= 4.624399e-05, training acc total= 100.0%\n",
            "step 13900, training loss Total= 4.534407e-05, training acc total= 100.0%\n",
            "step 13950, training loss Total= 4.3765842e-05, training acc total= 100.0%\n",
            "step 14000, training loss Total= 4.3111228e-05, training acc total= 100.0%\n",
            "step 14050, training loss Total= 4.7520767e-05, training acc total= 100.0%\n",
            "step 14100, training loss Total= 4.28178e-05, training acc total= 100.0%\n",
            "step 14150, training loss Total= 4.1930125e-05, training acc total= 100.0%\n",
            "step 14200, training loss Total= 4.179911e-05, training acc total= 100.0%\n",
            "step 14250, training loss Total= 4.1090072e-05, training acc total= 100.0%\n",
            "step 14300, training loss Total= 3.924191e-05, training acc total= 100.0%\n",
            "step 14350, training loss Total= 3.9495477e-05, training acc total= 100.0%\n",
            "step 14400, training loss Total= 3.9067312e-05, training acc total= 100.0%\n",
            "step 14450, training loss Total= 3.712748e-05, training acc total= 100.0%\n",
            "step 14500, training loss Total= 3.9845294e-05, training acc total= 100.0%\n",
            "step 14550, training loss Total= 3.5955298e-05, training acc total= 100.0%\n",
            "step 14600, training loss Total= 3.5604637e-05, training acc total= 100.0%\n",
            "step 14650, training loss Total= 3.8322854e-05, training acc total= 100.0%\n",
            "step 14700, training loss Total= 3.435951e-05, training acc total= 100.0%\n",
            "step 14750, training loss Total= 3.4393794e-05, training acc total= 100.0%\n",
            "step 14800, training loss Total= 3.3091106e-05, training acc total= 100.0%\n",
            "step 14850, training loss Total= 3.2454176e-05, training acc total= 100.0%\n",
            "step 14900, training loss Total= 3.198538e-05, training acc total= 100.0%\n",
            "step 14950, training loss Total= 3.2053125e-05, training acc total= 100.0%\n",
            "step 15000, training loss Total= 3.1777246e-05, training acc total= 100.0%\n",
            "step 15050, training loss Total= 3.0407202e-05, training acc total= 100.0%\n",
            "step 15100, training loss Total= 2.995752e-05, training acc total= 100.0%\n",
            "step 15150, training loss Total= 3.0806186e-05, training acc total= 100.0%\n",
            "step 15200, training loss Total= 2.9611158e-05, training acc total= 100.0%\n",
            "step 15250, training loss Total= 2.8551924e-05, training acc total= 100.0%\n",
            "step 15300, training loss Total= 2.8678187e-05, training acc total= 100.0%\n",
            "step 15350, training loss Total= 2.8250133e-05, training acc total= 100.0%\n",
            "step 15400, training loss Total= 2.7691269e-05, training acc total= 100.0%\n",
            "step 15450, training loss Total= 2.7365511e-05, training acc total= 100.0%\n",
            "step 15500, training loss Total= 2.687747e-05, training acc total= 100.0%\n",
            "step 15550, training loss Total= 2.6238273e-05, training acc total= 100.0%\n",
            "step 15600, training loss Total= 2.5903539e-05, training acc total= 100.0%\n",
            "step 15650, training loss Total= 2.5482948e-05, training acc total= 100.0%\n",
            "step 15700, training loss Total= 2.487454e-05, training acc total= 100.0%\n",
            "step 15750, training loss Total= 2.4458062e-05, training acc total= 100.0%\n",
            "step 15800, training loss Total= 2.473055e-05, training acc total= 100.0%\n",
            "step 15850, training loss Total= 2.3969742e-05, training acc total= 100.0%\n",
            "step 15900, training loss Total= 2.6466554e-05, training acc total= 100.0%\n",
            "step 15950, training loss Total= 2.834014e-05, training acc total= 100.0%\n",
            "step 16000, training loss Total= 2.6482347e-05, training acc total= 100.0%\n",
            "step 16050, training loss Total= 2.4651712e-05, training acc total= 100.0%\n",
            "step 16100, training loss Total= 2.3973747e-05, training acc total= 100.0%\n",
            "step 16150, training loss Total= 2.3076702e-05, training acc total= 100.0%\n",
            "step 16200, training loss Total= 2.2449334e-05, training acc total= 100.0%\n",
            "step 16250, training loss Total= 2.2098344e-05, training acc total= 100.0%\n",
            "step 16300, training loss Total= 2.1766302e-05, training acc total= 100.0%\n",
            "step 16350, training loss Total= 2.1222e-05, training acc total= 100.0%\n",
            "step 16400, training loss Total= 2.080561e-05, training acc total= 100.0%\n",
            "step 16450, training loss Total= 2.090354e-05, training acc total= 100.0%\n",
            "step 16500, training loss Total= 2.0370742e-05, training acc total= 100.0%\n",
            "step 16550, training loss Total= 2.0760885e-05, training acc total= 100.0%\n",
            "step 16600, training loss Total= 1.9534786e-05, training acc total= 100.0%\n",
            "step 16650, training loss Total= 1.9427054e-05, training acc total= 100.0%\n",
            "step 16700, training loss Total= 1.87044e-05, training acc total= 100.0%\n",
            "step 16750, training loss Total= 1.8716624e-05, training acc total= 100.0%\n",
            "step 16800, training loss Total= 2.2635626e-05, training acc total= 100.0%\n",
            "step 16850, training loss Total= 1.8225313e-05, training acc total= 100.0%\n",
            "step 16900, training loss Total= 1.7550552e-05, training acc total= 100.0%\n",
            "step 16950, training loss Total= 1.7222199e-05, training acc total= 100.0%\n",
            "step 17000, training loss Total= 1.697274e-05, training acc total= 100.0%\n",
            "step 17050, training loss Total= 1.6750691e-05, training acc total= 100.0%\n",
            "step 17100, training loss Total= 1.6436534e-05, training acc total= 100.0%\n",
            "step 17150, training loss Total= 1.598548e-05, training acc total= 100.0%\n",
            "step 17200, training loss Total= 1.5796219e-05, training acc total= 100.0%\n",
            "step 17250, training loss Total= 1.5340629e-05, training acc total= 100.0%\n",
            "step 17300, training loss Total= 1.565426e-05, training acc total= 100.0%\n",
            "step 17350, training loss Total= 1.46872935e-05, training acc total= 100.0%\n",
            "step 17400, training loss Total= 1.4296611e-05, training acc total= 100.0%\n",
            "step 17450, training loss Total= 1.5036277e-05, training acc total= 100.0%\n",
            "step 17500, training loss Total= 1.508462e-05, training acc total= 100.0%\n",
            "step 17550, training loss Total= 1.4147187e-05, training acc total= 100.0%\n",
            "step 17600, training loss Total= 1.3512053e-05, training acc total= 100.0%\n",
            "step 17650, training loss Total= 1.4053218e-05, training acc total= 100.0%\n",
            "step 17700, training loss Total= 1.3120511e-05, training acc total= 100.0%\n",
            "step 17750, training loss Total= 1.3031911e-05, training acc total= 100.0%\n",
            "step 17800, training loss Total= 1.3263974e-05, training acc total= 100.0%\n",
            "step 17850, training loss Total= 1.2188266e-05, training acc total= 100.0%\n",
            "step 17900, training loss Total= 1.2318173e-05, training acc total= 100.0%\n",
            "step 17950, training loss Total= 1.1965285e-05, training acc total= 100.0%\n",
            "step 18000, training loss Total= 1.1512229e-05, training acc total= 100.0%\n",
            "step 18050, training loss Total= 1.1250276e-05, training acc total= 100.0%\n",
            "step 18100, training loss Total= 1.1044826e-05, training acc total= 100.0%\n",
            "step 18150, training loss Total= 1.2330011e-05, training acc total= 100.0%\n",
            "step 18200, training loss Total= 1.0683701e-05, training acc total= 100.0%\n",
            "step 18250, training loss Total= 1.0797374e-05, training acc total= 100.0%\n",
            "step 18300, training loss Total= 1.0438748e-05, training acc total= 100.0%\n",
            "step 18350, training loss Total= 1.00635125e-05, training acc total= 100.0%\n",
            "step 18400, training loss Total= 9.913598e-06, training acc total= 100.0%\n",
            "step 18450, training loss Total= 1.0549147e-05, training acc total= 100.0%\n",
            "step 18500, training loss Total= 1.0018655e-05, training acc total= 100.0%\n",
            "step 18550, training loss Total= 1.0534897e-05, training acc total= 100.0%\n",
            "step 18600, training loss Total= 9.481535e-06, training acc total= 100.0%\n",
            "step 18650, training loss Total= 9.153038e-06, training acc total= 100.0%\n",
            "step 18700, training loss Total= 8.9223395e-06, training acc total= 100.0%\n",
            "step 18750, training loss Total= 8.7094795e-06, training acc total= 100.0%\n",
            "step 18800, training loss Total= 8.681695e-06, training acc total= 100.0%\n",
            "step 18850, training loss Total= 8.363177e-06, training acc total= 100.0%\n",
            "step 18900, training loss Total= 8.277223e-06, training acc total= 100.0%\n",
            "step 18950, training loss Total= 8.2033885e-06, training acc total= 100.0%\n",
            "step 19000, training loss Total= 7.806901e-06, training acc total= 100.0%\n",
            "step 19050, training loss Total= 7.658677e-06, training acc total= 100.0%\n",
            "step 19100, training loss Total= 7.775378e-06, training acc total= 100.0%\n",
            "step 19150, training loss Total= 7.3148403e-06, training acc total= 100.0%\n",
            "step 19200, training loss Total= 7.185485e-06, training acc total= 100.0%\n",
            "step 19250, training loss Total= 7.5392913e-06, training acc total= 100.0%\n",
            "step 19300, training loss Total= 7.0234905e-06, training acc total= 100.0%\n",
            "step 19350, training loss Total= 6.9441194e-06, training acc total= 100.0%\n",
            "step 19400, training loss Total= 6.727451e-06, training acc total= 100.0%\n",
            "step 19450, training loss Total= 6.7591345e-06, training acc total= 100.0%\n",
            "step 19500, training loss Total= 6.681769e-06, training acc total= 100.0%\n",
            "step 19550, training loss Total= 6.309461e-06, training acc total= 100.0%\n",
            "step 19600, training loss Total= 6.2060367e-06, training acc total= 100.0%\n",
            "step 19650, training loss Total= 6.0697666e-06, training acc total= 100.0%\n",
            "step 19700, training loss Total= 5.915979e-06, training acc total= 100.0%\n",
            "step 19750, training loss Total= 5.7332577e-06, training acc total= 100.0%\n",
            "step 19800, training loss Total= 5.637579e-06, training acc total= 100.0%\n",
            "step 19850, training loss Total= 5.9968793e-06, training acc total= 100.0%\n",
            "step 19900, training loss Total= 5.424773e-06, training acc total= 100.0%\n",
            "step 19950, training loss Total= 5.447223e-06, training acc total= 100.0%\n",
            "step 20000, training loss Total= 5.1735146e-06, training acc total= 100.0%\n",
            "step 20050, training loss Total= 5.4999823e-06, training acc total= 100.0%\n",
            "step 20100, training loss Total= 5.0290687e-06, training acc total= 100.0%\n",
            "step 20150, training loss Total= 4.842328e-06, training acc total= 100.0%\n",
            "step 20200, training loss Total= 4.793106e-06, training acc total= 100.0%\n",
            "step 20250, training loss Total= 4.73369e-06, training acc total= 100.0%\n",
            "step 20300, training loss Total= 4.645777e-06, training acc total= 100.0%\n",
            "step 20350, training loss Total= 4.8547076e-06, training acc total= 100.0%\n",
            "step 20400, training loss Total= 4.9739415e-06, training acc total= 100.0%\n",
            "step 20450, training loss Total= 3.5053017, training acc total= 89.68560099601746%\n",
            "step 20500, training loss Total= 0.10172338, training acc total= 99.25537705421448%\n",
            "step 20550, training loss Total= 0.037739296, training acc total= 99.86210465431213%\n",
            "step 20600, training loss Total= 0.018938145, training acc total= 99.94484186172485%\n",
            "step 20650, training loss Total= 0.020598738, training acc total= 99.8896837234497%\n",
            "step 20700, training loss Total= 0.03055688, training acc total= 99.79315996170044%\n",
            "step 20750, training loss Total= 0.007804987, training acc total= 99.95863437652588%\n",
            "step 20800, training loss Total= 0.008381491, training acc total= 99.98621344566345%\n",
            "step 20850, training loss Total= 0.0035855577, training acc total= 100.0%\n",
            "step 20900, training loss Total= 0.0026489256, training acc total= 100.0%\n",
            "step 20950, training loss Total= 0.002648671, training acc total= 100.0%\n",
            "step 21000, training loss Total= 0.0011988437, training acc total= 100.0%\n",
            "step 21050, training loss Total= 0.0006779384, training acc total= 100.0%\n",
            "step 21100, training loss Total= 0.0006692555, training acc total= 100.0%\n",
            "step 21150, training loss Total= 0.00031337776, training acc total= 100.0%\n",
            "step 21200, training loss Total= 0.00023146188, training acc total= 100.0%\n",
            "step 21250, training loss Total= 0.00017637269, training acc total= 100.0%\n",
            "step 21300, training loss Total= 0.00017985937, training acc total= 100.0%\n",
            "step 21350, training loss Total= 0.00014176367, training acc total= 100.0%\n",
            "step 21400, training loss Total= 0.00013669221, training acc total= 100.0%\n",
            "step 21450, training loss Total= 0.00012420192, training acc total= 100.0%\n",
            "step 21500, training loss Total= 0.00012334884, training acc total= 100.0%\n",
            "step 21550, training loss Total= 0.00011904327, training acc total= 100.0%\n",
            "step 21600, training loss Total= 0.00011099148, training acc total= 100.0%\n",
            "step 21650, training loss Total= 0.00010931609, training acc total= 100.0%\n",
            "step 21700, training loss Total= 9.824542e-05, training acc total= 100.0%\n",
            "step 21750, training loss Total= 9.387492e-05, training acc total= 100.0%\n",
            "step 21800, training loss Total= 9.347381e-05, training acc total= 100.0%\n",
            "step 21850, training loss Total= 8.649283e-05, training acc total= 100.0%\n",
            "step 21900, training loss Total= 8.3630344e-05, training acc total= 100.0%\n",
            "step 21950, training loss Total= 8.3775325e-05, training acc total= 100.0%\n",
            "step 22000, training loss Total= 8.0197606e-05, training acc total= 100.0%\n",
            "step 22050, training loss Total= 7.768636e-05, training acc total= 100.0%\n",
            "step 22100, training loss Total= 7.589365e-05, training acc total= 100.0%\n",
            "step 22150, training loss Total= 7.506433e-05, training acc total= 100.0%\n",
            "step 22200, training loss Total= 7.6290264e-05, training acc total= 100.0%\n",
            "step 22250, training loss Total= 7.0420145e-05, training acc total= 100.0%\n",
            "step 22300, training loss Total= 7.1476854e-05, training acc total= 100.0%\n",
            "step 22350, training loss Total= 6.6403634e-05, training acc total= 100.0%\n",
            "step 22400, training loss Total= 6.638282e-05, training acc total= 100.0%\n",
            "step 22450, training loss Total= 6.378655e-05, training acc total= 100.0%\n",
            "step 22500, training loss Total= 6.2599196e-05, training acc total= 100.0%\n",
            "step 22550, training loss Total= 6.110889e-05, training acc total= 100.0%\n",
            "step 22600, training loss Total= 6.026148e-05, training acc total= 100.0%\n",
            "step 22650, training loss Total= 5.981463e-05, training acc total= 100.0%\n",
            "step 22700, training loss Total= 5.8371283e-05, training acc total= 100.0%\n",
            "step 22750, training loss Total= 5.8286798e-05, training acc total= 100.0%\n",
            "step 22800, training loss Total= 5.529193e-05, training acc total= 100.0%\n",
            "step 22850, training loss Total= 5.9883594e-05, training acc total= 100.0%\n",
            "step 22900, training loss Total= 5.393805e-05, training acc total= 100.0%\n",
            "step 22950, training loss Total= 5.3223517e-05, training acc total= 100.0%\n",
            "step 23000, training loss Total= 5.308398e-05, training acc total= 100.0%\n",
            "step 23050, training loss Total= 5.040383e-05, training acc total= 100.0%\n",
            "step 23100, training loss Total= 4.928916e-05, training acc total= 100.0%\n",
            "step 23150, training loss Total= 4.815358e-05, training acc total= 100.0%\n",
            "step 23200, training loss Total= 4.786538e-05, training acc total= 100.0%\n",
            "step 23250, training loss Total= 4.7190108e-05, training acc total= 100.0%\n",
            "step 23300, training loss Total= 4.5908808e-05, training acc total= 100.0%\n",
            "step 23350, training loss Total= 4.485738e-05, training acc total= 100.0%\n",
            "step 23400, training loss Total= 4.4378958e-05, training acc total= 100.0%\n",
            "step 23450, training loss Total= 4.341851e-05, training acc total= 100.0%\n",
            "step 23500, training loss Total= 4.2810032e-05, training acc total= 100.0%\n",
            "step 23550, training loss Total= 4.1852305e-05, training acc total= 100.0%\n",
            "step 23600, training loss Total= 4.5016805e-05, training acc total= 100.0%\n",
            "step 23650, training loss Total= 4.016359e-05, training acc total= 100.0%\n",
            "step 23700, training loss Total= 3.920151e-05, training acc total= 100.0%\n",
            "step 23750, training loss Total= 3.94171e-05, training acc total= 100.0%\n",
            "step 23800, training loss Total= 3.7841815e-05, training acc total= 100.0%\n",
            "step 23850, training loss Total= 3.707498e-05, training acc total= 100.0%\n",
            "step 23900, training loss Total= 3.61458e-05, training acc total= 100.0%\n",
            "step 23950, training loss Total= 3.5822e-05, training acc total= 100.0%\n",
            "step 24000, training loss Total= 4.2347845e-05, training acc total= 100.0%\n",
            "step 24050, training loss Total= 3.7062808e-05, training acc total= 100.0%\n",
            "step 24100, training loss Total= 3.4290773e-05, training acc total= 100.0%\n",
            "step 24150, training loss Total= 3.290595e-05, training acc total= 100.0%\n",
            "step 24200, training loss Total= 3.183751e-05, training acc total= 100.0%\n",
            "step 24250, training loss Total= 3.128255e-05, training acc total= 100.0%\n",
            "ValidValid acc= 99.93202 %\n",
            "ValidTest acc= 99.0 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ft97oy5cM3aN",
        "colab_type": "code",
        "outputId": "c0b2db3c-1b5b-463d-c3ec-ba640046fa73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./Pendigit\n",
            "ValidValid acc= 99.93202 %\n",
            "Test acc= 94.876144 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWblrxpgM3aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihtQRjvnM3aV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LUJzvaHZ6B3v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "best_weights = {'G_W1': G_W1np, 'G_b1': G_b1np,'G_W2': G_W2np, 'G_b2': G_b2np}\n",
        "scipy.io.savemat('HarFullDataset03212019_Adam', best_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9WWYbkum6Kl4"
      },
      "cell_type": "markdown",
      "source": [
        "## Verify handover works"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-2ER5pNw6JCz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "x = loadmat('HarFullDataset03212019_Adam.mat')\n",
        "G_W1np, G_b1np, G_W2np, G_b2np= x['G_W1'],x['G_b1'], x['G_W2'],x['G_b2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n1lIoTcq6N43",
        "outputId": "752fc367-a7c3-4399-af51-abc1718ffe58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1np), G_b1np)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2np) + G_b2np\n",
        "    layer_outputs.append(out_layer)\n",
        "    return layer_outputs\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"Valid acc=\",str(validation_accuracy), \"%\")\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid acc= 98.64038 %\n",
            "Test acc= 95.38514 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2BZiy1Lgx0b4",
        "colab_type": "code",
        "outputId": "c50c4a28-0265-45ac-d260-812a62ee940a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i-MLbTOJQFQJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BkroR_XQFQK",
        "outputId": "d0e538bd-2766-47d7-bebb-c4691f6506c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278830
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,5):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 1.9857837, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 87.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.008144151, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.0006294729, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0005400359, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 400, training loss= 0.1527065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 500, training loss= 0.0013683734, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00021194252, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00032862485, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00025341622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.00028031622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00020475077, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0003020033, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00024354778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00014706065, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00029177137, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.0001350425, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00016606697, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00018623672, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00015216254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 0.00011072023, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 0.00014188612, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00023836568, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.0001355805, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001233557, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00016521299, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.00019633351, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.00010483772, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2700, training loss= 0.00014303994, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.586293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.609259e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 9.8155026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 3.3604018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 9.2597256e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 6.721567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 7.687432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.780202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 8.004801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.1782518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.9696853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 6.810024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.636981e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5683905e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.8620117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.8458773e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 5.265702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 8.7179935e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.327066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 5.9413127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.1775235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 1.39963295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.2185797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.6216587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 2.6288237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.5653866e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.2123731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3709934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 1.8652794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.2361822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.9032594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.2012822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.6528496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.1033039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.5385518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5541144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 2.489545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 9.935381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.3722548e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.4826099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3191649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.5937192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.5124231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.579236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0794279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2980037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1881518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0636356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 4.5980264e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.622366e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 1.09407665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.1238885e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.4111827e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.7718606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.1832344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 2.6180458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.5346616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 6.9588204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 6.3365137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 6.0044563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.809996e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 2.5300678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.2133055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.3530669e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1355425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.349093e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 3.9301335e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.0649427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.6249492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.645543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 2.8087782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.811128e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.698381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.818887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 2.8230727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.6247938e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.3677005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.494359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.8569029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 2.545933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 1.9594595e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.4409051e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.8693646e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.000875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.2531683e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0448554e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 1.5181027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 1.1676285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 9.0001987e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 9.393475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 8.669367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 5.629609e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 9.915129e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 6.344809e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 8.430959e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 7.560755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.3955247e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 5.1885485e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 2.8520526e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 7.706814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 5.3196766e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.519351e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.3104553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.1064213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 2.6166344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 3.2424703e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 4.398789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.7252724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 2.2113223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 4.348137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.085874e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.302084e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.1202762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.3454369e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.3543713e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.8954229e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 2.3066919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.632889e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.8328382e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.0132776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.5331883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 2.3394738e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.9802197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.4156079e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7911132e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 1.5228956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.8358172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.2308327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 9.477127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.296399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 7.7187906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.5169358e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 8.493651e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 5.394215e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.5963244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.463851e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.2904381e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.1980514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 4.172321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.1557972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.387722e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.755089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.9935088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.169074e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 6.228681e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2750053e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 4.79817e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 4.2617295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 4.023311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.0829136e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 3.308056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 4.2021256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.3378583e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 4.053114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.2351736e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.264975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.2218949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1590442e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 2.1457668e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.3113018e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.609325e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.0132787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.1026856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.1324881e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.1622901e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.2814996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.344648e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1026857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.8545334e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.278255e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23800, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24100, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24500, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.08719349, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 28000, training loss= 0.025652321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28100, training loss= 0.04324808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28200, training loss= 0.0004310665, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.643979e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 1.3230393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.007661752, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 6.094262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 8.180307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 2.5535144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.176015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 1.8676748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.7169636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 7.167124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 8.642062e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 2.030267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1825708e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.7748385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 5.291539e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.22399315e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 1.7870418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.7662272, training acc= 81.99999928474426%\n",
            "Validation Accuracy valid 86.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.008894306, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.001817639, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.01971873, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.010990087, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0014096084, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.0018062931, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00828336, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 800, training loss= 0.00034360992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0011482139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.0004452518, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00033666857, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 7.3411196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00016483082, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.00013365646, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00012015406, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.989801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014627678, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 9.896378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00013707647, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 9.413417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.0002904884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.071585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.000113107744, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 6.5728214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 7.467509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 7.47882e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00014493043, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 4.986713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 8.715366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 8.345896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3100, training loss= 8.374644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 9.8462915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.850093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.7121793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.1049865e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 6.073701e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 4.474434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.698458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 4.537524e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.7783116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 2.1114298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.4028376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 7.428725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 4.9455317e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 6.0670907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 3.9265742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.3787823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 2.222307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 2.7888911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.6384652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 4.268808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 1.8342535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 3.640592e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.675147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.0683655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 5.7309517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 5.3059237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1050517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 2.9001272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 2.1682825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 2.4490568e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.6777477e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 1.206457e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.8631803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 2.8394177e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 2.064755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 1.9105793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3473336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.6770351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 3.8086808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.083156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 2.8561692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.1495483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 2.2305263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7590653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.8775003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7700, training loss= 1.7969975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.1573217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3541719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.2924986e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.8286872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 2.0161868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.9373725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 8.702997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1870059e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 2.1714874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 8.531334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3683234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 6.9569533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 1.028602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 1.446362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 4.9309697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2126831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 1.1932704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.1256293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 9.782787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.105736e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 4.566323e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 7.683178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 6.630302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.8557586e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.638747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 7.2090293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 3.390549e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 7.0846722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.3014383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 5.559007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 3.6495085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 4.144894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11000, training loss= 3.8692833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 5.5646865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 2.6532234e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 1.5492373e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.8420288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.52481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.1986982e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 1.4946331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 3.4738641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.394339e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 4.213718e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 2.7818019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.381144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.0114609e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.7353825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.762105e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.6738297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 2.8655863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12900, training loss= 2.7352635e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.059733e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.0988865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.3960894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.2538417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13400, training loss= 8.654316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 1.0774263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.4088228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 5.956388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13800, training loss= 8.853005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.6378345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.4510845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 5.1637033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.2424226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.027154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 7.955074e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14500, training loss= 8.4458196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.847785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 4.841795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 7.291442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.635848e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15000, training loss= 5.25106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 8.404123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.2722545e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15300, training loss= 3.5067077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 3.798765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 4.0987763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 2.0086694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 3.762983e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15800, training loss= 2.8808694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15900, training loss= 2.2212514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16000, training loss= 3.1888223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 2.1119722e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16200, training loss= 3.977578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3801812e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.8927866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 3.0517435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.6152802e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.3523779e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16800, training loss= 1.7642911e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16900, training loss= 1.9152844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 3.4709578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 9.1790945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 8.821453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17300, training loss= 2.3503938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.5795172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.5830486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.8744806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.0907608e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 1.13049815e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 9.457251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.5755424e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.59624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 9.735403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 1.007316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18400, training loss= 1.140433e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 8.0664805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.4108236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 6.3975506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18800, training loss= 8.920804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.410739e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 2.6027344e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 9.6161976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 4.0928494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 19300, training loss= 4.649158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 3.2981205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 6.099537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 4.9670483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 4.4902137e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.655749e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.801416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.3577265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 4.549816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.9140343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 3.4769357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20500, training loss= 2.3841842e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 3.2186488e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20900, training loss= 1.7881387e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.529852e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21100, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.854431e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21300, training loss= 2.423921e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21400, training loss= 1.76827e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21500, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21700, training loss= 1.8278751e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.8874797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 22100, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 1.2914334e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 1.17222445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 7.351239e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.2318289e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 6.159146e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.9736423e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 7.9472855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 2.5828677e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.9802318e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 4.569689e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.3775964e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7636182, training acc= 89.49999809265137%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0014524448, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.002393889, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.13864827, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 400, training loss= 0.0029713945, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0051878896, training acc= 100.0%\n",
            "Validation Accuracy valid 96.5 ...\n",
            "\n",
            "step 600, training loss= 0.00075327273, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.006071425, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0008636887, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00034359877, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00020992127, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017444276, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 8.93537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00022914476, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 8.4610336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00015365804, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 4.266093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00011484732, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 0.00010020897, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 8.292834e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.0001145257, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00012196603, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 8.1921855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.842964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 4.8611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 8.0116275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 5.582913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.1031668e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 7.064959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 7.517244e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.7207286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 4.1879233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.4186698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.4159504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.5968543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 5.0703657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.340508e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.7673002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.251103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.7012665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 4.6962698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.385241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 3.4974462e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.0854018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.690291e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 2.8908937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 1.7610624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.1664196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.5627796e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.0464651e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.517009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.759404e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 1.9673145e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 8.960804e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9765514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.2240092e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.668813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.8317649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.8910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.2009532e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.2012475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.0280283e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8704028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.3285839e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.5801768e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.552519e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 9.762813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.0695344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 8.8103625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2685976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 8.348381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.0402509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.683439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 5.94079e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.603427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.2821643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 8.822334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 6.4213345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 4.3542923e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 9.515376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.848005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.077483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 5.8962605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 7.2099474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 4.577006e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.092034e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.700421e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.8339763e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.2160867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 6.3622447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.250631e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.6400797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 4.893738e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.439866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 3.4113343e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.594419e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.8299346e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.3984117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.6114793e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.7841119e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.3087333e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.2500294e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.2367042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8166952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.9553854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.6409862e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.9424567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.595777e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.4432038e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.4477749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.4052541e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7197599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8244617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.4058462e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.3106868e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.1147757e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.229424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0220067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.4116162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.997535e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 9.590278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 6.083603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.042517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 8.2849544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 4.5060912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 5.114039e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.9815674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.0842294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.445209e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 2.5073595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.2061374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.1391636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 4.6511127e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.153072e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 3.576264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 3.7729563e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.797439e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13700, training loss= 4.525961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.9470808e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 4.7206638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 2.4855063e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 3.4570587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.1934457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.7596883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.8331965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 1.7603206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.9192649e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.4557033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.9669483e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 1.1920912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.331169e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8993967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7444259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.1761971e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 2.1656297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 9.675813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.4781924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.1344734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.6053491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 7.6691165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0391059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 7.232023e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1404347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.00334404e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.563096e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.0068816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.2516956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 4.7286328e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 8.583061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 4.4703462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.0133777e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.7352223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 9.179109e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2054688e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.6160138e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.3246787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 3.6557505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.7815496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 3.8345647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 3.2981234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.741813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.66234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6291928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.5033946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.8080073e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.5099841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.6623402e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.9073484e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.88748e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.2516974e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.11261995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.735425e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 4.3710067e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.7617817e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.12636083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 1.5009055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 4.5446195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 0.00019335095, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 2.0004713e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28000, training loss= 0.00024587451, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 5.17878e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.8015188e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2475813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.16426875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.2762443e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 2.4796489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.874821e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.9667257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 1.3271837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.1669373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 5.0436165e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 3.8146922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 2.386263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 8.116291e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.4715047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 3.1947408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.6322995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 8.512951e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 6.2739383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7304913, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.024764434, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.00072215847, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0033973714, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.0005037752, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0030435477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.0022072683, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.0008827405, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00044512466, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0021594528, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0021753563, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.000990368, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1200, training loss= 0.0021206276, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00036779614, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.0037439256, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.00082475785, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1600, training loss= 0.00024784182, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.000190548, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.000101983955, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00021216992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 0.00011386407, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 0.00011138018, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 8.63583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 5.57357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 5.417957e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000108176755, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.0001890949, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.0819992e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 6.838632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 5.6099372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 5.2011772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 2.472774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 6.274405e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.713733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 9.317016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.7877868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 2.8687671e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 5.5696095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.441774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.780889e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.309848e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5136407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.2342344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.198066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 4.228693e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 4.623733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 5.259833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.8154747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 2.9219354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 4.8661506e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.720072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.737663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 3.3301876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 1.9597674e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.303492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.149919e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.0326766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 3.693348e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.0893876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.4200576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.0393646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.36700555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 2.2173379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 2.4110748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 2.927052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 2.1804688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 3.3416698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 1.1375284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 3.0013467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.5185645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 1.9262208e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 7.24648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.9320647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.0112638e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.3421217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.6355956e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 2.1810254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 9.434999e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3208644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3258212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.6602802e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.3406531e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 8.6087675e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.1284631e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.3691073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1275537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 1.0726529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 5.316216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3310492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 7.1013837e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 7.122497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.4317516e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 5.995298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 6.4786645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 8.058474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 4.1793282e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 5.9965755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.325073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 5.3627527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 8.09692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 3.2421524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 7.312679e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.890297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.465615e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 3.6471156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 3.6296326e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.547755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 3.7599389e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 3.9908955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.801147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.700158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.3630324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 5.625648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 5.4111997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.9192797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 4.2606243e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.0359045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.8398329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 2.0259854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 3.4805132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 1.8117825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.1677497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 2.0436332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 2.1751746e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8606397e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.8549617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.8841043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.5198765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.0305584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.3752001e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 1.1393081e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.4402093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 13200, training loss= 1.4075287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.7976179e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 1.3381026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.8223251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 7.575585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.0067002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 1.0707812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.2458647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 14000, training loss= 5.9276107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.170657e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 4.3049062e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 8.118035e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.939553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 6.636888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 5.1080553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.84716e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 4.2199778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.5060816e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 4.944158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.769806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 7.1345886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 6.8634006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.6373513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 2.7134763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.5032457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.5778866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.583847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.2739103e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.7374686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 4.950135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.00433624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3543706e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 3.3408233e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16500, training loss= 2.539148e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 3.71484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 2.3931165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 3.0442934e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 2.3037137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.3798397e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.6525345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.548226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.136021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.15632865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1725819e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 1.2189115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.6591824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.6128566e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 9.909255e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.18911075e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 8.0764195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.3362352e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 9.626133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.2442453e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.09672335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 8.314835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 7.8976015e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 8.821478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 5.6624362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.6656832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 7.733698e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 4.529949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 4.202125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 4.1723204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 5.2303033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.7699913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 4.4256414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 4.52995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 3.4272656e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 2.8610216e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 2.9057254e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 3.2782513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 3.5762767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 2.473592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.9371504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 3.576277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21200, training loss= 1.8477435e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 2.7716155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 2.4139867e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.130865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.4901157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.9837765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.2814995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748602e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 9.089707e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 7.0035444e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.6391276e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 5.960464e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28100, training loss= 0.14615121, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 0.16133761, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 0.00042809127, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 0.02816139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 5.3594245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 6.424133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 8.930463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0064306515, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 0.0013593932, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 0.00028876038, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 2.99408e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 3.9986888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 1.6156795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 2.3464807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29500, training loss= 7.012028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 1.301896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 8.8096385e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3575656e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.338141e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.5094995, training acc= 87.99999952316284%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.039435677, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0029222893, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0010214503, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.00034394336, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0002726078, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0003874169, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00024444636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 800, training loss= 7.78137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0002793996, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0002509097, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00022534527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.0002431607, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00015126858, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00026668172, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00020671163, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011088938, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0002102695, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00024402318, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00014018922, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.000118058495, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 0.000169405, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 9.5967356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00018843854, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.619639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00017519623, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010826914, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 6.3557294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 5.8655984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 0.000116522075, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.6885975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 6.175657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.320747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.7774046e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.00010348646, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.05501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 7.633815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 5.044512e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 5.3543514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 7.600165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 3.658233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 7.516591e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 3.8953043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 5.268231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.604312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 5.693039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 4.1753025e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 5.882939e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 4.570583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 5.954526e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.8352653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.220578e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 4.9572915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 1.7886814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.347068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.200028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6758515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.4645338e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.7491753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.890632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.0029758e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 9.767324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.4392694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9938734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1649712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.1366663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 1.15115445e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.627149e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 9.4102315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.18667695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 7.315959e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 9.4693305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.999106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.817514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.0087821e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 1.0298888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.0137086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.0302095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 7.774598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.379647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 8.708265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 4.684891e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 5.9717368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 4.1632193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 4.3086106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 8.625295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8600, training loss= 9.096246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.021494e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8800, training loss= 3.964501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2560058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9000, training loss= 5.396032e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9100, training loss= 4.86689e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9200, training loss= 2.7238436e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 4.746905e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 2.6210175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.1935015e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.127882e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 1.8012137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 1.9081392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.85567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.2672803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9290576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.8781066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.990749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3388204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.5172055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.0706204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 1.0570711e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.8903185e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10900, training loss= 1.1977398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.3911481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1804457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.5905444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.422006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.308879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.456476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 1.1220336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0493231e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 7.1763264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.869385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 7.119715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 8.287952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.593852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 6.6249885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 4.0590544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 7.5786664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.2961245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 7.1971675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.3836154e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 4.0024162e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.42427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.3289052e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.1872093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.1083673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 4.392842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 4.8160257e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.007029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.453785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8119763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.086158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.9265803e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.5570313e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1980515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.9341665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 2.306693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.596335e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.4036873e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.3977251e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 1.9669494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.14142715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.5944207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.0728818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.6629673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 9.775151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.5914415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.4960735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.3351398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.09672364e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 1.0997041e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 7.331364e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.4871326e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.1682496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1116253e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.84125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 9.685743e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 8.791676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.1557983e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.9008553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.6028327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 8.136025e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.172323e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 5.0365898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.245204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 4.7683695e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.5464744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.9935095e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 3.039836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 2.026557e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.2649758e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7716151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.3709066e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.3245805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 2.1159643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.400709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.0430811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 9.238718e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.49011585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.025566172, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 95.5 ...\n",
            "\n",
            "step 26400, training loss= 0.0034496982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26500, training loss= 0.0040100445, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26600, training loss= 0.00511861, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26700, training loss= 4.1705647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.0001831693, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 5.6671648e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27000, training loss= 0.0001770996, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 4.699156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.5728401e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 7.700904e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 7.4260447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 5.681718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 7.393381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.2465034e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.3613008e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 3.1198968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 2.7861872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.3089022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 3.7146718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.1053833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 3.186115e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.283511e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.856783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3570617e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 1.779635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 2.4203371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 7.957782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 1.8808056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.6190117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.5169241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.2388602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 2.2471556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.6563006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.2319857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.8784289e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.952098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7491051, training acc= 91.00000262260437%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 100, training loss= 0.034846384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0027968925, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.00047345422, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.00033690428, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0034412623, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 600, training loss= 0.0007994493, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.06041136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.031878598, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 900, training loss= 0.00096669135, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0003687142, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.00053446105, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00048036771, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00012743808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0001659477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001688339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00016108585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 8.44349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 7.4442396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00014246671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.0271857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 8.8449226e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 6.683565e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 9.433382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 3.48266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 9.452199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 3.536197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.962503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.5803066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 5.3583466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 0.00011115102, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 4.639947e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 8.055888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3300, training loss= 2.217185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 7.468372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3500, training loss= 5.611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3600, training loss= 7.5111566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3700, training loss= 5.248479e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.4966724e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3900, training loss= 3.2931985e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 3.0140853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 5.587737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4200, training loss= 4.4394117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 2.7067463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 5.3845055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4500, training loss= 4.7568883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 2.760794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4700, training loss= 2.4561949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 3.833233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4900, training loss= 2.414298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5000, training loss= 3.2821878e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.6419088e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 3.0928026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5300, training loss= 3.172096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5400, training loss= 2.9084766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.960324e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 1.702319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5700, training loss= 3.1217234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1078644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 1.9665416e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.102241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.3703633e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.190164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.925997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.682143e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.8846249e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.1859872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 2.855706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5393258e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 2.198239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.3099368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.3651934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 3.332225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2504407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.4693432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1715385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.0993313e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.3868442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.0447887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.3118067e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.5397375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.0527187e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.1633114e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0775805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.407657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 8.719276e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.2441643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 9.942413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8800, training loss= 9.356401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.113451e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.2375984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0537907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 3.4513328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 3.542377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 4.840788e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 7.922656e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 4.8024226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 3.311136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 6.2441645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.7440457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.286357e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 4.602099e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 3.6908616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 5.3517865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 4.891503e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10500, training loss= 3.3034005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10600, training loss= 5.554033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 4.325919e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.3685297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 3.9670913e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.1605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.5436977e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.1449933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.311484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.1916028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5230588e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.415313e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 2.6025407e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 1.3350995e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 11900, training loss= 2.8675822e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12000, training loss= 1.9370934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.328794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12200, training loss= 1.3141361e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.3128187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2933568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 2.231692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.8400432e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 9.240939e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12800, training loss= 7.4671203e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.9659087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 8.5793647e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13100, training loss= 1.4408387e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 5.378687e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 5.118801e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.263327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.0149259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.2730089e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 7.9726226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 6.0366494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.989159e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14000, training loss= 7.107143e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14100, training loss= 8.423157e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14200, training loss= 5.671921e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 7.487463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 4.2795787e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 8.196721e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.985288e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 6.4455566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.2506367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 4.1126978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 4.2056612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 3.104176e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15200, training loss= 4.6896585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.0877617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 4.868468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 5.917487e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 4.039961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15700, training loss= 2.9337158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.3078768e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.5497163e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 2.0933044e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 3.00406e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.6331612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.1290678e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.7954385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.1362237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.7249492e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.0170113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 1.561638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 7.200231e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 1.635547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.4829605e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.1563275e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.0514238e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1396386e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 1.01327714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17600, training loss= 1.04665524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 5.8412436e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.7962746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 1.5044178e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.022774e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 8.65458e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 6.9379645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 5.3286477e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 5.078311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 8.225427e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.747238e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.6014744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 3.838537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 5.292885e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 5.531306e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 7.414811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8610183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 3.0517565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.8875773e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 4.756447e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8610211e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 4.3392152e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 1.740455e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 3.0517562e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 2.431868e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.454353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 2.7179704e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.0027157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.0980828e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 3.6001182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.7404552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 2.5629987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 2.1457662e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.9311898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.704692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 9.53674e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1444089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.1444088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 1.3709062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 9.77516e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.821486e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 7.867811e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.4373005e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.814697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 7.3909754e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 7.629394e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.0994411e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.7418137e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.112007275, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.11103656, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 0.0005116432, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 9.75468e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 0.008496265, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 5.7019173e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27600, training loss= 0.0004373042, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27700, training loss= 1.1850859e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 2.3806272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 2.7104883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28000, training loss= 9.759002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 2.3935432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28300, training loss= 2.4006331e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 2.4710875e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 6.238008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 3.3717086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28700, training loss= 1.6770267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28800, training loss= 1.710619e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28900, training loss= 1.4606363e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 2.031028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 8.3561845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29200, training loss= 1.5126936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 3.6813908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 1.4453636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 2.6563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 1.6650685e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 1.752893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6865813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 5.1087663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.14847247, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 94.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.0007601454, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0062709516, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00041410883, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.018620707, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00094815134, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.00047243008, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.00019986519, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 800, training loss= 0.0002234125, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00031657013, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00017952269, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00015443658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00014692658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00018098918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00023744153, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.000103558945, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00012654845, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0001302577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 9.935229e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 9.933386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 9.201987e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 9.5115174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 0.00012162826, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 8.828254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 0.00011542862, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 9.615535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 7.242731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 3.2542845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.252827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 2.7502243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 7.2430645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.4835316e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 8.825268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 5.4219643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 3.3850585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.0782274e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 5.4826043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.1017585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.276399e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.4302393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 3.2332002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.6150792e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.4243556e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 1.4400564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.9570925e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 3.4416033e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 2.4489924e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.7464997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 1.7821938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.6904687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.1947513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.062126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 1.6229103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 2.0709907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.3617691e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 1.1845765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.5679694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.5038126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 7.5704993e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.5022351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.8019406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.6936581e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.232541e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.18999815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 1.0497903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.4213764e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7636456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 4.6242885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.18226235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 6.5555055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 4.8518627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 7.4627187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 8.263121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 7.917012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 5.2882624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 5.1350253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.0090554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 9.185651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.505415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.2839044e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.9021405e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 3.8857816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 3.6776676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 6.341853e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.4922955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 5.8767273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 4.4723574e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 3.2225844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.149103e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 1.452396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.3337114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 2.3051564e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 1.9564932e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2847678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.717753e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.6361012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 1.6295547e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 1.9295053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 1.1090625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.2548023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1157888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.5792895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 1.6151013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.0733162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.2195002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 7.308938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.4850286e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.0086438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 9.4815323e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.3936844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.3254976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 7.3089427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.5289888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0713821e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 9.028518e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 6.645876e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 7.389442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 4.5358885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 5.552135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 4.231914e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 6.581788e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 4.9665243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 6.696544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 4.8502847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.1958747e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 4.793684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 4.1261177e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.39121e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 2.6509105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 6.4640886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 1.6719059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.591442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.792468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 1.3768653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.3379826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.829859e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.710514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.8118396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8522104e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.6525361e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.384181e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.0950999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1667598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.799919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 1.5869719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.164205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.12354655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2963997e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.2278537e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 8.0913225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.00880754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 7.599584e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.374445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.230305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 5.677339e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 4.4256417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 6.7949244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 5.364415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 7.7933024e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 6.213781e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.7453466e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.1856006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 3.21865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 3.933906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 6.73532e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 6.7502235e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.409118e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.919003e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.7997946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.664061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 2.8610218e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 3.7103877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.096195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1010626e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 4.306434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.0116564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 1.5646217e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 2.0563599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 1.2665984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.0877846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.0563597e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.877546e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 1.02818e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.1622903e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 7.897615e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 8.791685e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 7.3015682e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20400, training loss= 1.2069938e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20700, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20900, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.9371509e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21100, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21400, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.0233132e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 2.8312204e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0430813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.1794868, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 91.19999694824219 ...\n",
            "\n",
            "step 24900, training loss= 0.05283235, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.024460968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 25100, training loss= 0.0011026246, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 0.0037383218, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25300, training loss= 0.007821645, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25400, training loss= 2.9168423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 0.00014622895, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 25600, training loss= 5.9074697e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25700, training loss= 4.7847083e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25800, training loss= 7.369522e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 2.8571852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26000, training loss= 3.942655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26100, training loss= 3.220571e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 3.3161654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26300, training loss= 2.0020156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26400, training loss= 8.432376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26500, training loss= 4.895209e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 4.6962043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 3.5029458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26800, training loss= 6.3240573e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 2.9128441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27000, training loss= 4.7755293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 2.4796074e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 7.1433337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27300, training loss= 2.4853827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 2.1829412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 2.6021942e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.898441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 1.9363055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.187242e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 1.2992667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 3.7369962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.6083064e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.2791265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2738248e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.0155272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 1.7903318e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 8.328605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 7.0235537e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 2.1747273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 6.9265398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 1.7684783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 8.7655435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.4506243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.0134418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 5.924403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.476949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.2289474e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 7.034543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 9.128639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 1.083224e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.4625556, training acc= 86.50000095367432%\n",
            "Validation Accuracy valid 84.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.009873457, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.009675698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.06272699, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.4000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.009281827, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0023525394, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.000796955, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.007612922, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.008417513, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.04200749, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0010823058, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.011957829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.005447494, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00016969378, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00025642803, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 0.00018994625, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00011148728, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 0.0001519523, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 5.1344472e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.000114705, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 0.00017647487, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.00016669072, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 7.0707545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 0.00014605207, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 0.00019520438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00012533748, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 9.3231065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00013419885, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 0.00015070809, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 6.698415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 7.4300464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 7.788869e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 6.204043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 6.954175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 0.000101137164, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 0.00014247942, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 3.9282517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 6.19493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 0.00012098811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 7.959501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 2.0376454e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.5651745e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.053907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 5.738453e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 6.5646214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 7.19845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 4.2279626e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.0300577e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.6554233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.9958282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 4.414931e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 8.059281e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 4.4121003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0030613e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.980649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.2697437e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 1.987078e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3039963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 2.044901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.324795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 3.006205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.0659782e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.8798682e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 3.736447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.926903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9375326e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.0508218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 3.2549677e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 4.4712488e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 2.3236962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 2.9457082e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 2.1961814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 2.5960593e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.216319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.39927015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7645887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.9442721e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.262071e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.6021906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.5504424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.5671989e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.2741196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.2926779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0557667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.09657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.4000293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.5243709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 1.6457901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 5.975668e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 6.3747534e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.679973e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 7.3154283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 6.9534776e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.8046176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 1.2720513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.6647705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 9600, training loss= 4.9250134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 7.0780306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 8.165239e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.324812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 5.124565e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.060113e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10200, training loss= 4.5891775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.454139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10400, training loss= 2.5667296e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 5.3375766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.954761e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 2.921967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10800, training loss= 3.5418911e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 1.7839251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 1.8321765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.414253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 2.3481068e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.809641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.2566621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 2.5879533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 6.2190503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.6484897e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.7702238e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11900, training loss= 1.532734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0999341e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.556374e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5289532e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.3946088e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.0038367e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.5996262e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.4872192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.2217483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3159212e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.6888064e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.1527846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.5043951e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.5712758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.8937896e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.5219156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 8.4899415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 5.999765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.1037449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 8.475642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 8.4673076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 5.1891465e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.828087e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.5517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 6.4861297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 6.718564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 5.9866505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.3917927e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 4.3785363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.6476286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 4.5418423e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 5.5074395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.99484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.7215384e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 5.357237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.60352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.181685e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.888267e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.650015e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.8192883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.7215398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.4734239e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.7739915e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.3446785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 2.1207283e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 2.4998124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.6214005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.3554077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 1.8143614e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 2.2244394e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 9.5844165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 2.2160962e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.2016282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.3518307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.1193731e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.6307804e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 9.798988e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 8.690347e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 6.830686e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.108645e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 8.904927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.878368e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 7.59362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.731249e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 7.009502e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 4.386899e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 9.310237e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.079671e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.8146947e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.9696673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.5537924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 4.684922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 5.3644158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 5.2809664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 4.6014765e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.7564487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.0279143e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.3603434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.2530552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2305703e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 2.2172927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.8596644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.7523764e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.7537338e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.28746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.4175325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.323223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.4662741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.2636183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.466274e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.602837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.106231e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.026558e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 1.6689301e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.2649764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 0.10768938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.008793372, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 0.012823711, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27000, training loss= 1.2324063e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.012677136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.3485197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 3.1230695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27400, training loss= 1.0392901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 2.1648111e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 2.415332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.8522265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 1.8608886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.7186818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 3.8044805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 7.1837685e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.2715481e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 1.637915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3154365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.0271192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 4.4160174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 1.5864213e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 7.2442067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.9943133e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.6809759e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 3.192872e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 4.392033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 7.865176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 2.9069377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 2.593819e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.3062578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.8372024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 3.7867183e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.836629e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.19013658, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 95.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00093026174, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0026277967, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.001492311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0024322432, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0055890502, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.00030306313, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.003100828, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0011220517, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0055018878, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0009811673, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.0002756448, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.00011071658, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00025124694, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00016421286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00011190099, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00010541811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 9.068278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1800, training loss= 0.00010285259, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.00011336279, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 9.543807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 6.598983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 0.0001048186, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 6.791052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 8.446564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 0.00012669193, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 5.7286346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 7.6599514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.583943e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 7.213351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3000, training loss= 8.483188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 0.0001235103, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 5.7044235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.213048e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3400, training loss= 8.943349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.9132086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.019669e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 5.190742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 7.3327596e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.2594657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 3.1536434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 6.0016704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.3755753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.8125934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.6538997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 3.681976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 5.190695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.0097595e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 4.829544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 2.4251223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 3.4608584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.0206395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.1829377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 2.141725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.593269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3686447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.7244552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 2.9091678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.3514032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.6609652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.596803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.2894791e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 1.3850272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.3748465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 9.598098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.5380698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.3717976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.531126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0051459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2853964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.0743887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.392279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 1.1115343e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 8.731065e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.3423013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 8.573937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 5.6051285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 8.959563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1156192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.093328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.699008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.97865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 6.377527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.442519e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 5.4422085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.3331244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 3.4193479e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.3501954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 3.2585556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 4.601866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.73484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 8.332201e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 2.6594612e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.3757423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.614429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.3148297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 2.994404e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.5207094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.716661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 4.0560403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.5897298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.4749584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 4.7529043e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 3.8448393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3756274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.9698388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.7610328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.5251676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.6350413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.833491e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 2.583909e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7254063e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.9528363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.3899358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.7905795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.4260626e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.2743261e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1824178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.1075607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 5.171254e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.1026717e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.1557121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.0965964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.4981807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.1550235e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.5883385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.0082405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 5.1855665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 8.489946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 7.6567466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 3.2830022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.02304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 5.7720746e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 4.4345572e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.407294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.266953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.4785123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.2138655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 3.6835488e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 1.8632356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 4.3189343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.278083e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.2780837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 4.6551006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 3.9064693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 2.9325346e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.4519667e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 2.8550505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.778759e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.5878642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 1.6975366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 2.5105408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.7237619e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.3150396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.052776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.5532946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.3518297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.9955564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.4519672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.7869435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 8.475768e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.0335435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.976452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 8.618823e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.3113002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.0228137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 6.866446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.5061068e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 4.8637357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 9.822834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 9.691693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 4.2080853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 5.8174063e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.8293296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 3.5762763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 5.7101204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 4.935263e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.5180297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 6.759163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 4.577633e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 5.340574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.2530555e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 3.1828865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.7656545e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.8252591e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.4318684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.076955e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 4.25577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.5047517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.8715854e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.9431107e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.7523762e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 2.3126592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 9.298322e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.0967251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.823902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.1086461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.1086463e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 7.0333472e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.4570693e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.3113021e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 0.00049628475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.0487039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.0063560284, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27400, training loss= 6.09169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27500, training loss= 1.2766516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 4.756465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 2.0138152e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 1.1392219e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 3.7247166e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 6.1270885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 2.4826218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.4615197e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.3096518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 8.548321e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 1.4721978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28600, training loss= 8.3002915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 1.2625357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 1.3777887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28900, training loss= 7.742751e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 3.521224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.1625331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.0342712e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 2.7950875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 4.9842947e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 7.2881144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29600, training loss= 4.0344307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29700, training loss= 4.7630215e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29800, training loss= 1.17057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 8.4733865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7141365, training acc= 90.49999713897705%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0074453596, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0009144604, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0011556392, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0052687093, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0003429781, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.00025804708, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.049575698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 800, training loss= 0.0019488088, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.051701337, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.030002326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.0077472776, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00019876577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 9.024233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 8.974371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 8.9546375e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00014210286, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.00018890618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 9.702795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00010099527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00014198791, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 8.03155e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 9.9710735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00011535117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 8.077585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 9.9031706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 6.20196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.8977676e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 0.00010070081, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.108279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.5106906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.9841175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 5.907393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.209719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 6.7312016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 2.7272741e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 7.707601e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3700, training loss= 7.978093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.3837307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.3424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 5.4274147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 4.5890218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.3613356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 4.9521983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.7869322e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 6.9451555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.733818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.57006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.3307286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 6.0959308e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 6.312785e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.731221e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.9706269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 6.433572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.619432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 4.91137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.5674917e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.2786286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.6947797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.9430896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 2.134277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.6391627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.103963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 2.3596955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 3.065319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9957584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 3.1795567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 2.6485766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 2.0281239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 3.579099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.2436634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.4378545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.882001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.7350767e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1065293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1154377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 8.33703e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2613851e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3134572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.0364819e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 1.6570779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 9.424848e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.5135257e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 1.4990833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 1.2265535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.0599004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0820388e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 7.829222e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 1.0707916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.348662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 1.2290646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0312282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 1.2390558e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 9.838934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 6.499245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 5.473657e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 5.8741857e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.9230167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 3.375192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.2452206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.903218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.590292e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.589014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 6.082514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.6260811e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.906372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 2.5236131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 3.7562318e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.0008514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 4.632992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.2223502e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.8740915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.948306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 3.1749946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.0445693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.8900785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 3.6731817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 5.078464e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 2.6606458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.9680439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0738598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.815725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5706449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.1089242e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8578164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.6621826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 1.0975984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 9.974736e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3866722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.7796442e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 5.230249e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 9.995538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 1.6169129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.1837301e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 8.383242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.2278381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 1.0618398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.879924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.5805797e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.61637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 7.9690517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 7.887602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 4.4285986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 4.8756146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.196464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 3.2712842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 3.811684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 3.6259286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.9279186e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 3.4153206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 5.820335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 3.9487844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.1500858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.0563522e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.0374756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 4.0828968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.0149823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.42292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.0503948e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.316978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.189471e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 2.6851794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.1248985e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.6341573e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.4384551e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.0281785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.7871415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.1056644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.56653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.04307986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.1553338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.3261976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.0838093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.493643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.987011e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.0758597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.3023586e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 1.23282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.8975078e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 7.957209e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.82472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 7.8181316e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.695486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 9.248642e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 7.450572e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.2518944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.6358806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 5.9604613e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.619353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.947182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.010033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 4.3511363e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.9603624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.904102e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 2.831219e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8908236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.4437892e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 4.410741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.8676117e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 3.5862115e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.8908243e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.0398354e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.9206262e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.1258987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 1.4603133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.976887e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.834764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.238717e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 6.854533e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 7.4505797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.854534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 6.2584866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.066395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.021732664, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.0 ...\n",
            "\n",
            "step 26000, training loss= 4.065458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 0.010269502, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.6831855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00021952903, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 3.9125225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 1.5004598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.082927e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.876794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 4.683961e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.6893438e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 5.7578727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 3.5213143e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 3.8073863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27300, training loss= 9.285785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 7.257216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27500, training loss= 1.18348635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.3288599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 3.6785648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27800, training loss= 5.0734984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27900, training loss= 2.892303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28000, training loss= 5.3037293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.8159358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28200, training loss= 4.5573865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.9036553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 7.1590184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.5684889e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 1.2261452e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 2.853986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 6.2794925e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 7.1493105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 6.7924702e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 2.631013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 6.1907673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.7757769e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 2.6626967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.6199251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 2.8669488e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.0942198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 1.1702637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 2.7612755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.240357, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 87.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00072087307, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.010604541, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0005547491, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00061997864, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.00030061085, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.0002527497, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 700, training loss= 0.00042292374, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.000133779, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00021847297, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0001858882, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0002035335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00022087155, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00020502399, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.000119573524, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00016135925, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00023241036, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00013802794, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00020564668, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00017970696, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00012806633, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2100, training loss= 0.00013740644, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.000104741404, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00010557528, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.0001370245, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 9.642969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010056618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 0.000101965255, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012939224, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00010101048, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.3418385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 0.00011470896, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 4.7746402e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.00010684254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 6.681612e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.1465045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 6.3796884e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.478265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.8874266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.422483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 6.0372688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 8.1153245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 8.310058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4300, training loss= 2.6912525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 3.9985393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 4.7254805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4600, training loss= 2.5460518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4700, training loss= 4.8057296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.1858537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 3.2272234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 4.7587422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.9853529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.3146597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.8194277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 4.5807366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 2.5900312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6406013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.2266395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 4.1245698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5900, training loss= 4.01718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.9558687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.2121938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8255998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9564624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.4104778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.2817856e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 7.790083e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.7202658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.4445213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.091918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7000, training loss= 7.1219297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7100, training loss= 1.0965941e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0558951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6640362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7400, training loss= 7.5274647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 9.91309e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7600, training loss= 1.48251465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.1687644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1087876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 8.414353e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 7.6496835e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.232028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 8.863616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8300, training loss= 9.999422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 5.7980305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.5095164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.231801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.1509533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.6448375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2739158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.7755434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 5.1879542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.6441028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.9093198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.9708538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 2.632359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.777344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 3.3987578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9800, training loss= 3.0161123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9900, training loss= 2.442489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.0720563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9975748e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 2.16029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 2.178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10400, training loss= 1.8458895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.4912632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 1.4972244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.0454469e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.9919305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.8130879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.2424379e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 8.29984e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8092544e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 5.6533764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.5353871e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.0657184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 9.366682e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0514067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 8.5352207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 7.1584344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0949204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.008199e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 1.1461756e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 8.240231e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 5.2094146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.6521106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 7.8498266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 6.6428674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 5.0902077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 5.0663544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 6.5355965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.9981007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 6.991501e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.0427992e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 4.7891893e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 2.7358405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 4.3451462e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.6494146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.7954454e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 2.616635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 1.388782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.2023836e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 2.056353e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 2.7328596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 1.5824993e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.6583552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 2.226224e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.81333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 2.3543718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 2.3126496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 2.0772136e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.7583338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.096723e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.3619629e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.2516955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.4811727e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 8.2552326e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 1.0311588e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0460595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.2516952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 7.927403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.05798065e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.1557933e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.344645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 5.7816422e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 5.602831e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.261727e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 4.3213337e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 7.301559e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 5.2750064e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 6.25848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.9769824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.0365866e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 3.665684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 2.801417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 3.457067e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.1888472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.5629989e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 1.639127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.682208e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.8179412e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 2.6822077e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.2947784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.341104e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.2516973e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 8.3446485e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 0.07618469, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 0.079483144, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.7620423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 0.0008994444, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3940243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 3.0558513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 6.925167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 8.874664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 4.0461928e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.7967077e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 3.2079129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 9.0263875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 8.843295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 6.6778966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 8.88847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.1153843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.066351e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.5637835, training acc= 88.49999904632568%\n",
            "Validation Accuracy valid 83.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.009219123, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.028671242, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0339968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.000744403, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0017800194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0066021285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0035789192, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0008883609, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0006055735, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00017274884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00033500823, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0002683743, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.0001676285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00014868894, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00016313572, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00017124631, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 9.40735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1800, training loss= 5.2675383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00015923165, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00010941772, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2100, training loss= 5.985739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.000118150616, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001165792, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00013586287, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2500, training loss= 4.287825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2600, training loss= 3.3790533e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2700, training loss= 7.964137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2800, training loss= 5.701467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2900, training loss= 9.243786e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3000, training loss= 7.799166e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3100, training loss= 9.340639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3200, training loss= 3.677304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 3300, training loss= 8.6567816e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3400, training loss= 6.0278806e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3500, training loss= 7.397346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3600, training loss= 6.843914e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3700, training loss= 8.776783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3800, training loss= 5.9543127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3900, training loss= 9.175373e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4000, training loss= 4.402351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4100, training loss= 2.2397937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4200, training loss= 3.2885026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4300, training loss= 4.080262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4400, training loss= 4.5756886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4500, training loss= 5.9554888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4600, training loss= 2.0483687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4700, training loss= 4.8015147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4800, training loss= 1.8999515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4900, training loss= 5.000678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5000, training loss= 3.1390948e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5100, training loss= 4.341062e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5200, training loss= 3.5542293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5300, training loss= 3.29073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 5400, training loss= 3.0748364e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 2.1142372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 3.6396024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5700, training loss= 1.8799263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5800, training loss= 5.672108e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5900, training loss= 2.0149058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.615231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6100, training loss= 1.8298879e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.1910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.066327e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.1439587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.9743922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.909969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6700, training loss= 9.895275e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6800, training loss= 1.8217193e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.8964653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.850747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7100, training loss= 1.2582383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 1.5819525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.94874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.5780653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.0326659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.5469042e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.6382518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.649186e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.1612133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.3358386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.200997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 9.97935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.5963342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.4736417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.2384781e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0966139e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 1.2153874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 6.3762327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 1.3212799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.370498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.599305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 7.3170618e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 7.3944047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 5.7985617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 1.0688096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 7.312641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 4.737663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.357037e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 4.169524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.464946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 2.616641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 7.613475e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.946591e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 6.5175204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 4.156245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.4063607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 2.643734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 4.840908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.0164205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.8086952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.1595501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 3.9890697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.7695444e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.1670805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4616354e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.8973368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 2.654517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.6394304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 1.4092485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.1499834e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.6281841e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.0322422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.531545e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12400, training loss= 2.2337817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12500, training loss= 1.1781003e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.0956027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.8034227e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.0394018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.2493897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 7.139658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.3696742e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 8.603279e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.1339162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.2074739e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 7.863428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 6.8152826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.515626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 7.3005623e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 5.674273e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 8.7864754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 6.411636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 5.2187596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 6.15794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 4.2395635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.7564095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 4.6976615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.61982e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.1113345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.4260295e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.5621335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.2506082e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.933879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 3.5430352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.1496637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.7755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 2.9478602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.725621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.6285505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.405113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.2377196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.8060149e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.0120724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 1.6859549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.0725307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 1.901383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9184115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.6476366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 1.1980512e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.7140543e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 9.340883e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.9873822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.7029862e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.1546246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1111979e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.148793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 8.685232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.1355174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.276517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.1818729e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.16228854e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.3463742e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 6.616106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18400, training loss= 5.7475837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 5.6964954e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.2148958e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.734308e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 2.2479462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 3.474097e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.371918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0994396e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 2.0691315e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.8572693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7370493e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.0142907e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 2.6311184e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.4778494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.627366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 2.3671552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.8647734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 1.5326908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.9924979e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.0435873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.3538767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1495181e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.592295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.8818033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 7.4080053e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 9.451592e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 7.663454e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.619866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 3.5762788e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.8099332e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.172325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.087176e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.150531e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.11982353, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 5.7371297e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 0.002606958, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 0.0016902818, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 0.00011953538, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.005635671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 0.0002883323, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.0006777974, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 0.00031814972, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 3.1952416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 1.09939165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.8625235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 2.4129022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3158775e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 1.640398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.3519716, training acc= 87.00000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.0009528943, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.003006239, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.014029461, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 400, training loss= 0.0015689554, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 500, training loss= 0.0003099327, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00030536676, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.03523389, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00039316947, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00039418964, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0010337114, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.00062609004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00021209747, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1300, training loss= 0.0001306783, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1400, training loss= 4.746507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 9.367379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.05381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 4.580253e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 4.2583804e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 5.3734188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 7.2573726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 5.3641164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 3.843553e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 4.4612098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 6.1662984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000104323626, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.348726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.2048243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 3.371978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.642993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 2.5509988e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 6.684009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3200, training loss= 2.5878713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 3.7779122e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.2883649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 4.758754e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 3.0657113e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 2.8887041e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3800, training loss= 3.2864176e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 3.732585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 5.088799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.419403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 2.3272509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 2.7392243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.9352435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 2.3834718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 2.0721232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.4677913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.049585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 1.9331095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.1888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.3766056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 2.1681566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.500228e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.5583608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 1.6841575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.7202525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.7157108e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.0916995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.6099933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.2681335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 9.948798e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 7.475171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5907854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 9.327078e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.026643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 6.4742485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 6.6350053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 3.7976392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 6.5302593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 6.3062303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 7.660167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.4459723e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 9.755237e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 5.9006593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.1660866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 7.315005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.629828e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.098802e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 4.431427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.212194e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.3657767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.108661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 4.8544553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 2.3476496e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 3.904682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 5.2775117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 2.5992967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.197542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.4326245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.1559794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 2.4537435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.9838131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.6144287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1462056e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.8924104e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9600, training loss= 2.1578867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 1.3227204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 1.8188492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.0837114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.441226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 1.2795639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 9.5056566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.4546888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.684517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 8.5973164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.1005285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.1821861e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.025697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.3952018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 5.631402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.1376029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 9.2362524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.362464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.1725314e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.162041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.846139e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 5.8638676e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 5.9258434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 6.313289e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 7.460071e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 3.0612864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.589695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 3.8528333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.052225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 6.7758185e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 6.645871e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 4.2009188e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.8301724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.587864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.4558644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.4926575e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.5513897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13300, training loss= 3.0469775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 2.2900056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 1.9466829e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8812818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.3269595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.0170174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 2.499814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 2.6416683e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.950421e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 1.5592553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.0108937e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.776216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 1.5032272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.6486621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.6164756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.3364976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.1205658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 8.583062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.3136845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.10268495e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 15300, training loss= 9.810914e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 1.1301029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 7.092948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 8.726113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 9.21487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 5.781647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.388256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 7.748599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 7.450577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 5.14984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 8.058544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 4.1961655e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 4.3153747e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 3.671645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 5.6743563e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 6.580348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.6597246e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.8756586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.3365017e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 3.0040734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 3.5166725e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.099441e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 2.8252595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.6702873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.3841855e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.4199483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.0623204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6212462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.7762183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.5258788e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0251998e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 9.655952e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.503395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 4.8875806e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.1988827e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 4.4107433e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 1.0728836e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.1729553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 95.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.0031946634, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 0.00025052714, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25200, training loss= 0.0047556064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25300, training loss= 0.00039012992, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0019254637, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25500, training loss= 0.0009243777, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25600, training loss= 0.0037950636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 25700, training loss= 0.0002131526, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25800, training loss= 0.00033333493, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 9.50662e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26000, training loss= 5.5164932e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26100, training loss= 6.2116036e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 0.00012879116, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00013183773, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26400, training loss= 6.066161e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26500, training loss= 5.828503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26600, training loss= 0.00014434585, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26700, training loss= 6.5723725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.00013109639, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26900, training loss= 5.679692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.4003347e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27100, training loss= 5.0567993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27200, training loss= 5.742894e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27300, training loss= 3.3297933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27400, training loss= 4.2237552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27500, training loss= 4.8522703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27600, training loss= 2.9742963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 2.129703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27800, training loss= 2.1666032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27900, training loss= 2.1551958e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28000, training loss= 2.329084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28100, training loss= 2.5134379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28200, training loss= 4.9698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28300, training loss= 2.1453234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.6060341e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28500, training loss= 3.4785953e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28600, training loss= 4.0305527e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 1.1208098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28800, training loss= 1.6175867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28900, training loss= 2.3721153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29000, training loss= 1.4099831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29100, training loss= 2.7127657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29200, training loss= 1.2386997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29300, training loss= 1.923202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29400, training loss= 9.747781e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29500, training loss= 8.271617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29600, training loss= 1.8319597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29700, training loss= 1.1474658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29800, training loss= 7.541031e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29900, training loss= 1.7230459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.08917236328125 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.4353279, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.0023052054, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.00817067, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0012017189, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.0019304784, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0011654797, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0024550452, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.0019152034, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00040729338, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0037700261, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00527143, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00017237726, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0004813281, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.0001397225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00024952108, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1500, training loss= 8.417386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1600, training loss= 0.0001752477, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1700, training loss= 7.580368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1800, training loss= 7.096267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1900, training loss= 7.655546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00012819025, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2100, training loss= 0.00011084802, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2200, training loss= 6.95028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00013003117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2400, training loss= 7.066823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 6.038435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 4.9352657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2700, training loss= 5.35837e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 9.045679e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 6.712659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 4.825196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.356384e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 3.754795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.1368664e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.7147125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 6.498417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 2.2050423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.576332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 6.4594205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 4.001712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 2.3424298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 5.2356507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 5.2146053e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.7952497e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 2.306709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 3.150861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 3.2143907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 2.27654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.046918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 4.7465153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 3.2441218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 2.1702464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.487742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.9062137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9037901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.4690544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 4.4863158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3629243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.814534e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.1962673e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.4901772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.1438396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.518539e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 2.2726628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1718959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 9.16725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.37141205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 2.3904355e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.6641432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.3209275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.00211855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 2.0758102e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.8091861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6848642e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 7.1548e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 8.754681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.1048828e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.08617705e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.0820899e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.431282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 6.1394758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.1510084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 1.0234857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 5.8081164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 1.210195e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.71322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 7.745655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 8.386487e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 1.3572065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.234663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.9971045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.239033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 5.749447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.9238816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 5.477398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 7.675773e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 6.401778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.8150787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.910181e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.831391e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 5.557418e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.475434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.9240425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 2.0966415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.087136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.2135805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.9673515e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.2271935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.4433057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.468637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.3491589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 3.3168315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 1.9718705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.0837392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.718139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4965427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.7829245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1739949e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.3384041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.0300517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.5389562e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.0319427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.730026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 9.278356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2689695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 1.2989624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 7.994861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.5140245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.133902e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.0366132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 6.3339417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.1051603e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 6.069677e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.9170665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.586867e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.9775966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 6.5167114e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.963399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 7.6730606e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.405814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 4.330259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 4.85476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.5947725e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 3.2663172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 3.8742775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.190822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.8888243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.634515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.8530624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.2852564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2017493e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8715814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.912668e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 2.6186208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.499417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 1.6887945e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.6967428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.8517133e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.3609709e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.3788525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 1.8993961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.581865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.622237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.13646045e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 7.480377e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.056988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9192672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 1.2000373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 9.53673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 7.3909696e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 7.867805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.0995376e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 7.192287e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.4041514e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.1603026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 7.867807e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.427454e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.1155994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.5101795e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 5.6425677e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.622797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 3.496804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.688897e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.708666e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 4.4504784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 4.837909e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 3.9736413e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.4570675e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 5.0663935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 2.622604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.2981227e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 1.8278755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 1.986821e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.1822574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.536541e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.9868212e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.9470848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.4305112e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20700, training loss= 2.1855035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.2020268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.2318291e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21900, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 2.8808909e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.9670534e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.4835267e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 0.13311927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.046874475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 0.05061221, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.0041597537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27100, training loss= 0.014204321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 27200, training loss= 0.001146232, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.021358844, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 0.0018947971, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 0.0047540064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 0.0003114235, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27700, training loss= 3.8776663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 6.4117994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 5.7206264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 1.6581589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.1862379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.3297419e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 6.852968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.608867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.1707627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 4.0452374e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.984698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 3.1582522e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.5353715e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 6.449117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.8671493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 5.4049688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 1.6709346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 1.3321171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.6156073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 9.45316e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 3.602549e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 7.384754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 1.2332417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.0955105, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0028113748, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.020106887, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0075765625, training acc= 100.0%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.0030207026, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.02076395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0071594287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00045671416, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00037344565, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0012458521, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00021473918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00014760095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00013677847, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00013461121, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00021795194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001313438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011562832, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014888095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013140295, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00010066957, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.000112738475, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 7.613995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 5.3595628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 7.152121e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.671476e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 0.00010096761, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 3.564369e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.1420422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 6.614269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.349897e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 5.164496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.2876585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 6.37733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 6.556921e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.9869544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.2773994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.1103998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 5.787611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.1437328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 2.4311628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 1.4565001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4100, training loss= 4.5023902e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 1.8875788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 4.076463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 4.7788562e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 3.184429e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.972469e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.776609e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 2.9440813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 2.2038916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 1.7966004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5100, training loss= 2.8320275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.2405575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.2988037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.3130415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 1.32359055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.247483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 9.296824e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 2.4153762e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.7385415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.9255198e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.8501427e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6200, training loss= 2.1512398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.6649432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.2661908e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.1631276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.2810624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 9.034132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0652611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 9.76632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.1188107e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 8.573692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 7.988838e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.1142546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.05885265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0540736e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 5.203169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.0639708e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7800, training loss= 7.1809513e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 8.578989e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 7.4236045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.1001803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 7.1308214e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.7187563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 3.943845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.446505e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 7.254146e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8700, training loss= 2.8082854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.5589026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8900, training loss= 2.1234277e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 5.221008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.047283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.692058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9300, training loss= 2.9169641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9400, training loss= 3.8244416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.2935446e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.1042814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.504906e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.1706138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.9283163e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.862589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.6190272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 3.1757636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8427322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 9.73531e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10500, training loss= 2.3000148e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.8012147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.5653662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.2071681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.250008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11000, training loss= 1.4086252e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1070438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.923374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.9851818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 8.7855835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5202958e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.004134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.613352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 4.3312525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.9220255e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0176362e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 5.42e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.64523e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.833968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 2.9762452e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 6.8067965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 6.9895714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.9497866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.608102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 12900, training loss= 6.8504954e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 7.2200305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 4.1345547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.960347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 4.4723112e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 2.8510783e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 3.1669754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 4.6769503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.496794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 1.8318434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 3.3060525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.6530316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.7219292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 1.5536901e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.0980772e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.1537078e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.3643126e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.1497372e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 1.4861402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.345076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.0609617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.6947558e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15100, training loss= 1.8358199e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.1603023e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 1.18414334e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 1.7444272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15500, training loss= 9.695676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 7.311496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 8.6227956e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.4563365e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 1.0728823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.0609615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16100, training loss= 6.119405e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.0689081e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 8.9009504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 8.066485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 6.715452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 9.83476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 6.7154524e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16800, training loss= 6.735318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 5.205467e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 5.5829645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 6.635977e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 5.5034924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.2716643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.1657317e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 2.9206268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 3.5365403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.715453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 4.8279738e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 4.5895558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 5.7021744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 4.450478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 3.337859e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 2.8411542e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 1.4305108e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.3047125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18700, training loss= 2.2053715e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.5894567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 2.8212858e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.589457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.1060302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 3.283803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27600, training loss= 8.750192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27700, training loss= 0.00017802311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 2.1196429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.8985592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 7.8763205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 3.546847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.6731125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 7.883992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3357021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.3983502e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 1.2783901e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 3.0526621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.755123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 8.7105955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 7.6139836e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 5.894734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 2.29254e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 9.097336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.9656381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 4.0238247e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.581168e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.5255363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 7.185875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.3462383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 97.87686157226562 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.043932762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.00346537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.0011190585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0012442004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.021783786, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.022612568, training acc= 100.0%\n",
            "Validation Accuracy valid 96.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.008526753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0036731793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0003066097, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00044239248, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.027541004, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.0022008778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00021435294, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1300, training loss= 0.05735776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0005141321, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.0004150997, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00011833411, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 4.3463686e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00013469311, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.000113486225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.763822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00010155505, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 0.00011534586, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2300, training loss= 7.263035e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 6.118358e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00011097876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.573861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 8.1907354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 4.1220737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 8.37911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 4.5873494e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.979296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 5.355815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.9706516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.9243054e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 3.6681795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.558105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 9.076852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 3.5366185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.0052702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 8.139999e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.2944783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.6386212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.4070846e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 2.7786818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 5.3323733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.0305944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.0987096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4800, training loss= 4.204507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 4.7204703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.7862954e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.3337867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 3.93738e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0123836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.8250397e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.340844e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.3037133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.379435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.8580007e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 4.6972276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.1531753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.5730778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.2070937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.26575305e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 1.646893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.3563857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.4728784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.9740706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.0944378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.7237191e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.6347589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.3372672e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.1593232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.873226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 8.970844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.86823e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.35795835e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2734335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 7.63589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.1472493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.64973e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.3011335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.2727216e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 8.41922e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 6.9051134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.3500094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 8.619766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 9.1507845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 9.704187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.358283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 7.530288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 7.376592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1223903e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 4.9204627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 7.2851317e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.7224943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 6.3660896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.853605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.0799845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.673084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.6151978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 5.018778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 4.3387704e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 5.035393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.0998478e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 4.3450655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 5.868524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 2.5312145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.5855664e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.039097e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 3.6719402e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11100, training loss= 1.6627401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 2.246681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 2.751994e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 4.0859622e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11500, training loss= 2.403876e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 2.1279636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 2.2112338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.9876795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.718517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 2.0409645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 1.9794986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12200, training loss= 2.0122852e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 1.121226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.3376744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 1.1521322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 1.9483273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 1.361175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 1.4165066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.2780766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 1.3518024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.2564403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 9.152626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 6.0864096e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13400, training loss= 4.3545228e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 9.839789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 9.414007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13700, training loss= 1.3303458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 6.7667764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 5.490398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 7.271686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 4.870499e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 4.795587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 7.9358546e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 4.965891e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14500, training loss= 8.1325726e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14600, training loss= 4.7334325e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.7792632e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 5.359276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14900, training loss= 3.4170236e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 2.9121003e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 3.382125e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.8153827e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15300, training loss= 3.7056924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 2.8235408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 2.861861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 1.743858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15700, training loss= 3.4749345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15800, training loss= 2.6021596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 2.9597865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.66552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.3998549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16200, training loss= 1.8221955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 1.5667482e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 1.963542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 1.7540755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16600, training loss= 3.3625395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 1.1035363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.2642516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 1.449242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 7.901864e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17100, training loss= 9.2131664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 1.3436569e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.2568047e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17400, training loss= 1.1886851e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 6.505416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 8.1743444e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 8.4127585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.03967366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 7.629383e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 8.21692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 5.1600544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 8.8385086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 4.8364875e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 6.7438336e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 7.322849e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 6.556505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 6.003037e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 2.997261e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18900, training loss= 3.3889485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 3.5081577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19100, training loss= 3.8487553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 3.0483513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.8269621e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 2.758841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 2.3501252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 2.929141e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 2.4182446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 2.4948793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 3.193105e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 2.7588428e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 1.7029896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 2.0095277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.452305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.6518996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20600, training loss= 1.958438e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 1.7370494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.5326904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21100, training loss= 1.4645709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 1.3623916e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 1.4986309e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1239731e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.328332e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 9.621892e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 1.2261526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 8.429799e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 6.8119594e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 8.8555465e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22400, training loss= 4.598072e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 6.130763e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 8.514948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22900, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 5.449567e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23300, training loss= 6.2159122e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23500, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23600, training loss= 4.0871755e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 4.5980726e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24000, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24100, training loss= 1.4475414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25200, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25300, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26400, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 2.2138869e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.08700258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28200, training loss= 0.0010462438, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 0.007788537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 0.0002787191, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.03819514, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 0.0005042283, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.009254003, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 0.00053602253, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 4.780922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.00015877286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 6.313633e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.1946026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 1.9100013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 3.2852473e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1920068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.3221739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 3.518542e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.7654147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.6732978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9243863, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0024209036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0068702064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00035379876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00045177506, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00038027472, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00036243335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00017564422, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.00029733498, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00027954616, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.000161541, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017748478, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00022369123, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.000344609, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00015815801, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00012104943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.0002594582, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.00018366707, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013618838, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 7.929951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00015742778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00018521569, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.00021373876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.9257304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.3261504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.000116200856, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 9.615918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 9.446045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012584943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00011829853, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.00011489536, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 8.699955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.80409e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.161969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 5.5696393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 3.2970627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 8.763576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.7847116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 6.593805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.6044188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 4.8277332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.8972863e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.126466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.9542392e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.5367608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 1.985223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 5.5880606e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 3.2430893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 3.910794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 2.018158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.5018284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.3676028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.0947302e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.6408117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 2.6051965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.1301573e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.367336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.049514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 9.990617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 8.0822365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.5722264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.2119383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.2337974e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 9.168887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.6381538e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.9810032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 7.81372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 8.688743e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.10711435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.0865252e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 5.9742338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 4.7527224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.2080694e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 8.884138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.293933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.51772e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 7.38424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 2.1105293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 6.9539697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 3.7264176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.755928e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.063937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 3.9288493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 3.2804019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 3.0751528e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.550676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 3.4777236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.084731e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 2.4777005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.0058607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 1.4986039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.1463794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.966666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 1.2074029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 1.7817259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 1.3650937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.261265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.7514195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.3318578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.5875698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1644014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.048308e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.4952833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 8.9976413e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.2329394e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.6770747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 8.1129633e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 4.567388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.5798327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 8.6085134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 9.19009e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 4.133988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.034042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 7.367038e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.0818939e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.5007466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 5.320095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.200197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 7.127799e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 8.553963e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.6966734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 6.839999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.735665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 3.3514695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 3.4425798e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.8849995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 5.039107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.1777643e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.136189e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 4.8475374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 2.1219216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 2.5544762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.1661975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.8921604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.0197416e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.7804719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8303603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.932538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.7200168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.0691259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.8562555e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 1.4168852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.4863567e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.7915418e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 9.84327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.809205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 8.617114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2568043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 8.6086054e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 7.4590886e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 6.914132e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 8.3786965e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.4979106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 6.335113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.04222835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 5.6539225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 7.833745e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 6.2669976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.006787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 4.4958913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.9982724e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 4.2489567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.8923415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 5.177086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 4.7939146e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.160056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 3.1335006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.2196604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.712516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.975468e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 2.7929026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 3.031321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 4.1552934e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 2.2138865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 1.9414083e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7247832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.1372518e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 2.656663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.29427224e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.2857571e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.4560561e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 1.5667505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.3027872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.8392285e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 8.855547e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.1239732e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.0813985e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 7.833753e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 9.196145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 4.4277733e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 3.32083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.3623918e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.24474247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 96.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.032282036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 5.73278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 0.00030204258, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 26700, training loss= 4.8327554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26800, training loss= 0.0003888717, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 8.557337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 1.0821099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27100, training loss= 9.114718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27200, training loss= 6.6440302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 2.1565978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 1.7132148e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27500, training loss= 1.2015865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 7.938417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 8.493593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 6.0402754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 1.7332968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28000, training loss= 5.8008377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 7.557258e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0585328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 3.2737814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.2189442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.4599065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 4.4164253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28700, training loss= 3.0639646e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 2.4838625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.8142007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 8.375978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.4958329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 2.5601869e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 7.4032455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 6.6567754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.7429356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 8.500388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 6.127682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6215455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29900, training loss= 1.1230701e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3563504, training acc= 89.99999761581421%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0013517543, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.046949483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.015602395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0010993601, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.00060543907, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.035742156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.02051982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 800, training loss= 0.0003255704, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.002698314, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.00090309983, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.0007421032, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00023186239, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.0002514339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.000115245464, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00015637734, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 8.212202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1700, training loss= 0.00014769404, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.00014291928, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 7.7071294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 8.413261e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 6.18306e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.244873e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 7.1835784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2400, training loss= 0.00014239793, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00011172854, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2600, training loss= 4.0016163e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 3.7728772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 4.3896995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 3.8974944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 4.320103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 6.5506516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.630137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 8.348236e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 4.6463654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 4.73913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.9050643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 3.443583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3800, training loss= 5.295749e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 2.9115756e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.7335463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.3563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 7.086432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.7008376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.1530515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 5.4621105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 3.8189406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.090024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.822282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.6192174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.9120765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.4396213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 4.3570755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.8151382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.6990412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.3288716e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.3502238e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 3.2518095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.6441714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.6492204e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.2933482e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 3.7795922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.8690403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.6910099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 4.06955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.0182362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7673021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.2118496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5177543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.828235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.4597936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.6470447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 2.1047e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.4996771e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.1297304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.5014371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.3697337e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.5776854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 2.1273268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.753624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.9416693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 1.307189e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.0839659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 7.0077126e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 7.5698817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.5104426e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.3171199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 4.5427187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.0951795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.323114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.55921e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0194833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.873782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 6.6927596e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1024396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 3.8785356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.2273388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 5.3128606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.273568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.140481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.284792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 5.9459653e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.5585815e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.6425023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 4.1130966e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 2.938506e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.3039228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 4.156696e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 2.800087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.8784414e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.6066193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.2186498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 4.17659e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 3.9410666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 3.8625662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11500, training loss= 2.8251538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 1.9006941e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.1492651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.2465964e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 9.211739e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.5813542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.2170963e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.289801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.2382616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.4377094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.1516122e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3979792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.3319154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12800, training loss= 7.256767e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.0221991e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 7.5279627e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 8.2810675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 9.0776246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 4.2489964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.548806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.855719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 8.304287e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 6.607124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 3.659695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.7520888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 6.347845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.280196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.4469117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 3.9212117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.0348688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.830923e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.755484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 2.9384975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 3.433214e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 3.611269e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2983607e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 2.479542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.9580064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 4.0672444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.3351415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 3.5554007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 3.6067885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.0205908e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.5637343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.573278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.5765391e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.2977463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.8179368e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.5884589e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 2.0980778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 9.9241525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 2.3901367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.630183e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.4473165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 1.1891107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 1.3142795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.364943e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 9.097145e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.4454085e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.8380026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.0490401e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.2606354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.884327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.039163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 7.27176e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 6.586307e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 6.288281e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 4.3287837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 8.493653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 5.692239e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.731114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 7.3760674e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 5.9306558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 3.4272652e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 3.09944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 3.6954862e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.6491586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 2.7418128e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.397464e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2186495e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 2.5033941e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.3841853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.795589e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.9744032e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 1.9147986e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 2.175569e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 1.9371505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.788139e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.4007088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.4454123e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 8.940692e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 4.2468304e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.5762782e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920928e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 1.0501016, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 94.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.00021391657, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 0.1540282, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 0.00055521145, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 3.4036017e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 0.001800267, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 0.0073885997, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0033072354, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 0.00026740984, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.0043647327, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 0.00016933345, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.00020177083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 0.0009964005, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 1.4938123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 9.6338714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.6149547e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.3622192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 0.00013764083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.4615026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9294039, training acc= 87.99999952316284%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1286d8755697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", training loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\", training acc= \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_validation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_validation_data_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mplot_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy valid {} ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BoQHpkHzQ0YO"
      },
      "cell_type": "markdown",
      "source": [
        "#### Valid acc= 98.799995 %\n",
        "#### Validation Accuracy Test 98.51380157470703 ...\n",
        "W1 = 4 ...\n",
        "W2 = 1 ...\n",
        "W3 = 0 ...\n",
        "Highest validation accuracy, to brake tie Validation test accuracy was used which is highest for this combination"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SeaxvipDvrKA"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SW9qZGWUQFQs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oWFUJtzdQFQx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5nSzdyLhJ3K-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
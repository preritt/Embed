{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V98p74T98p46_LeNEt300_100EpochBasedPRob_Decay1p0005.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/V98p74T98p46_LeNEt300_100EpochBasedPRob_Decay1p0005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qWL1XvRKt0EI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rTq2SzhyZgD",
        "colab_type": "code",
        "outputId": "81b20752-fc4a-421f-f1f3-b28f083ba0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
        "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
        "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
        "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
        "\n",
        "assert(len(X_train) == len(y_train))\n",
        "assert(len(X_validation) == len(y_validation))\n",
        "assert(len(X_test) == len(y_test))\n",
        "\n",
        "print()\n",
        "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
        "print()\n",
        "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
        "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
        "print(\"Test Set:       {} samples\".format(len(X_test)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-566519a95339>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            "Image Shape: (28, 28, 1)\n",
            "\n",
            "Training Set:   55000 samples\n",
            "Validation Set: 5000 samples\n",
            "Test Set:       10000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lopHk729ydu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = X_train.reshape(X_train.shape[0],-1)\n",
        "train_label = y_train\n",
        "validation_data = X_validation.reshape(X_validation.shape[0],-1)\n",
        "validation_label = y_validation\n",
        "test_data = X_test.reshape(X_test.shape[0],-1)\n",
        "test_label = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VloppGYRyrEX",
        "colab_type": "code",
        "outputId": "31709f30-6a7e-4758-ae51-50b0f9f2cf16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.27088284\n",
            "Iteration 2, loss = 0.09284897\n",
            "Iteration 3, loss = 0.06362837\n",
            "Iteration 4, loss = 0.04513577\n",
            "Iteration 5, loss = 0.03265040\n",
            "Iteration 6, loss = 0.02556718\n",
            "Iteration 7, loss = 0.01983507\n",
            "Iteration 8, loss = 0.01265771\n",
            "Iteration 9, loss = 0.00954815\n",
            "Iteration 10, loss = 0.00746641\n",
            "Iteration 11, loss = 0.00487287\n",
            "Iteration 12, loss = 0.00280570\n",
            "Iteration 13, loss = 0.00162220\n",
            "Iteration 14, loss = 0.00092841\n",
            "Iteration 15, loss = 0.00073810\n",
            "Iteration 16, loss = 0.00063660\n",
            "Iteration 17, loss = 0.00065059\n",
            "Iteration 18, loss = 0.00056893\n",
            "Iteration 19, loss = 0.00052885\n",
            "Iteration 20, loss = 0.00050482\n",
            "Iteration 21, loss = 0.00049094\n",
            "Iteration 22, loss = 0.00047780\n",
            "Iteration 23, loss = 0.00046712\n",
            "Iteration 24, loss = 0.00045812\n",
            "Iteration 25, loss = 0.00044891\n",
            "Iteration 26, loss = 0.00044162\n",
            "Iteration 27, loss = 0.00043538\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(300, 100), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "8m9_X9bUdZJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fo_lFxdIc85n",
        "colab_type": "code",
        "outputId": "628061bb-c704-47d2-91b2-16ec921f0ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf2 = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "clf2.fit(train_valid_combined, train_valid_label)\n",
        "# clf2.fit(train_data, train_label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.25907034\n",
            "Iteration 2, loss = 0.09239542\n",
            "Iteration 3, loss = 0.06153412\n",
            "Iteration 4, loss = 0.04633119\n",
            "Iteration 5, loss = 0.03438245\n",
            "Iteration 6, loss = 0.02314845\n",
            "Iteration 7, loss = 0.01970873\n",
            "Iteration 8, loss = 0.01600088\n",
            "Iteration 9, loss = 0.01225262\n",
            "Iteration 10, loss = 0.01059671\n",
            "Iteration 11, loss = 0.00743295\n",
            "Iteration 12, loss = 0.00342327\n",
            "Iteration 13, loss = 0.00159669\n",
            "Iteration 14, loss = 0.00100458\n",
            "Iteration 15, loss = 0.00071399\n",
            "Iteration 16, loss = 0.00058734\n",
            "Iteration 17, loss = 0.00055026\n",
            "Iteration 18, loss = 0.00052253\n",
            "Iteration 19, loss = 0.00050488\n",
            "Iteration 20, loss = 0.00048858\n",
            "Iteration 21, loss = 0.00047578\n",
            "Iteration 22, loss = 0.00046572\n",
            "Iteration 23, loss = 0.00045739\n",
            "Iteration 24, loss = 0.00044846\n",
            "Iteration 25, loss = 0.00044014\n",
            "Iteration 26, loss = 0.00043509\n",
            "Iteration 27, loss = 0.00042904\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(300, 100), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Wi_0y1C6e9Er",
        "colab_type": "code",
        "outputId": "bae62371-8fed-4f12-9e27-84e4c913a8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "oy5MNJqFys-H",
        "colab_type": "code",
        "outputId": "14ea866c-42a0-4b4f-c471-985e0d76ad7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "T0aiYNsdyuBR",
        "colab_type": "code",
        "outputId": "365b3aaa-6fd5-4aaa-e40f-2dfbe3f2004f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "w7DSKjQcyvL0",
        "colab_type": "code",
        "outputId": "898c6315-a8bd-4407-9181-f476223762fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "bOJLm3y6dkCs",
        "colab_type": "code",
        "outputId": "45ef6067-2f93-48ef-ddb2-923df16a1b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "hnUFUI4rdjwi",
        "colab_type": "code",
        "outputId": "343fcd99-1583-4bdd-d770-88c9c83d9c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "BtNN_G2Bdkpr",
        "colab_type": "code",
        "outputId": "5ddd8c83-8edc-4ace-eba5-f1e3b4d89680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "HFVqYNiRCy47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LeNet Lab\n",
        "![LeNet Architecture](https://github.com/sujaybabruwad/LeNet-in-Tensorflow/blob/master/lenet.png?raw=1)\n",
        "Source: Yan LeCun"
      ]
    },
    {
      "metadata": {
        "id": "oWv2YnX4IxqB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tensorboard.plugins import projector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7PXv7fjCy5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "\n",
        "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "t4iqynjrCy5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
        "# X_train, y_train           = mnist.train.images, mnist.train.labels\n",
        "# X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
        "# X_test, y_test             = mnist.test.images, mnist.test.labels\n",
        "\n",
        "# assert(len(X_train) == len(y_train))\n",
        "# assert(len(X_validation) == len(y_validation))\n",
        "# assert(len(X_test) == len(y_test))\n",
        "\n",
        "# print()\n",
        "# print(\"Image Shape: {}\".format(X_train[0].shape))\n",
        "# print()\n",
        "# print(\"Training Set:   {} samples\".format(len(X_train)))\n",
        "# print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
        "# print(\"Test Set:       {} samples\".format(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8LwdNZ5guEpy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Jm9y17KI5QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "logs_path = \"./logs/embedding/\"  # path to the folder that we want to save the logs for Tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pV8kvNmMCy5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
        "\n",
        "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
        "\n",
        "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QBcHY4jyzH5J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Pad images with 0s\n",
        "# X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "# X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "# X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "    \n",
        "# print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6o1m5ujwMvb",
        "colab_type": "code",
        "outputId": "b3f36a7a-7e4b-478f-e58b-31724300bf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fsvvfG8bwGOe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train_reshaped = np.reshape(X_train, newshape=(X_train.shape[0],-1))\n",
        "# X_validation_reshaped= np.reshape(X_validation, newshape=(X_validation.shape[0],-1))\n",
        "# X_test_reshaped= np.reshape(X_test, newshape=(X_test.shape[0],-1))\n",
        "\n",
        "# # X_train_reshaped.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eaMcBCNCvzWq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "# #                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "# #                     learning_rate_init=.1)\n",
        "# ### acc is 98.41\n",
        "# clf = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "# # Test set score: 0.950119\n",
        "\n",
        "# # clf.fit(train_valid_combined, train_valid_label)\n",
        "# clf.fit(X_train_reshaped, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzbhg-ryyhkD",
        "colab_type": "code",
        "outputId": "d5257df1-f349-494b-ca32-8b2f7aa4b2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5444., 6179., 5470., 5638., 5307., 4987., 5417., 5715., 5389.,\n",
              "        5454.]),\n",
              " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sfj08N7cwqqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_train_reshaped,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTE-oU9NwssQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_validation_reshaped,y_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBteDY2jwuF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_test_reshaped,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cW7cCH1xCy5c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize Data\n",
        "\n",
        "View a sample from the dataset.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "h7UbBX8RCy5e",
        "colab_type": "code",
        "outputId": "ff7f1f0d-edd9-475d-ad99-fabfcf37c5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "index = random.randint(0, len(X_train))\n",
        "image = X_train[index].squeeze()\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image, cmap=\"gray\")\n",
        "print(y_train[index])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABIBJREFUeJztnE9oHGUYxn+PtbILK0RXKIkpukgv\nJYcKIkJuaiEIoXoRe5DcYsCCYiAUTx57UG+hELHQg+AhylrIQUKRJYYgjaGoTYkNErAlCi4B/xwi\n3bwedjZuo+lO9s87u5PvB8vOzO5+38PDwzfzzb7zycwI+PBA0gIOE8FsR4LZjgSzHQlmOxLMdiSY\n7UhLZksakbQmaV3S+XaJSitqdlIj6QjwI3AauA1cA86a2Wr75KWLB1v47bPAupn9BCDpU+AMsK/Z\nklI7XTUzNfpOK8PI48DPdfu3o2P3IGlc0rKk5Rb6SgWtJDsWZjYDzEC6kx2HVpJ9Bzhetz8YHQvs\nQytmXwNOSCpIegh4DbjSHlnppOlhxMzuSjoHfAkcAS6Z2Y22KUshTV/6NdVZisfsTl+NBA5Ix69G\nkiCbzTI7OwvAzs4OAKOjo0lKAkKyXUllsicmJhgZGQFge3sbgOHhYQAWFxcT0xWS7UgqzR4bG9vd\nzmQyZDIZCoUChUIhQVUpNbtbSeWYXU+5XAZgbm4uYSUh2a6kPtlLS0sAbG1tJawkJNuVVCZbElL1\nVsXCwkLCav4lJNuRVCV7aGgIgMHBQWp3M7upSjck25FUJXtgYACAvr6+hJX8PyHZjgSzHQlmOxLM\ndiRVJ8gatQnN3u2kCcl2JJXJrp/IhEnNISWY7Ugw25FgtiPBbEeC2Y40NFvScUlfSVqVdEPSW9Hx\nRyXNS7oVvT/Sebm9TZxk3wUmzewk8BzwpqSTwHngqpmdAK5G+11B7W8xSeRyOXK5XNKSgBhmm9mm\nma1E238AN6k+qHQGuBx97TLwcqdEpoUDzSAlPQk8DXwDHDOzzeijX4BjbVXWAvWzxqmpKQDm5+eB\nZAsrY5stKQd8BrxtZr/X3+AxM9vvqQJJ48B4q0JTgZk1fAFHqT47807dsTWgP9ruB9ZitGOdfOXz\necvn87a+vm6VSsUqlYrVKBaLViwWO9Z3HB/jXI0I+Bi4aWYf1n10BaiVi44BXzRq67AT52pkGHgd\neF7S9ej1EnABOC3pFvBitJ8o5XKZcrnM9PT07rFaqkqlEqVSKUF1McZsM/sa2O8O/AvtlZNuUvlo\nXjabZWNjA4DV1eq6BZOTkwCsrKx0pM/waF6XkcpkJ0FIdpcRzHYkmO1IMNuRYLYjwWxHgtmOeFdE\n/Qb8Fb33Ko/xX/1PxPmh66QGQNKymT3j2mkbaUV/GEYcCWY7koTZMwn02U6a1u8+Zh9mwjDiiJvZ\nvbjW9n2qwd6TdGfP34SN2/MYRnp1rW1J/VQrCFYkPQx8S7UY6VXgTzN7/yDteSV7d61tM/sbqK21\n3dXcpxqsKbzMjrXWdjezpxoM4Jyk7yRdiltUGk6QMdhbDQZcBJ4CTgGbwAdx2vEyu2fX2pZ0lKrR\nn5jZ5wBm9quZVcxsB/iI6jDZEC+ze3Kt7f2qwaITZ41XgB/itOdy16+H19quVYN9L+l6dOxd4Kyk\nU1Tr/DaAN+I0FmaQjoQTpCPBbEeC2Y4Esx0JZjsSzHYkmO1IMNuRfwAyivnIJG/3pAAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1W6py5mlCy5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data\n",
        "\n",
        "Shuffle the training data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "UYJZs7GgCy5p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4WFIdiuCy53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup TensorFlow\n",
        "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "est-t83SCy55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWVHSK0pCy59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO: Implement LeNet-5\n",
        "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
        "\n",
        "This is the only cell you need to edit.\n",
        "### Input\n",
        "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
        "\n",
        "### Architecture\n",
        "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 14x14x6.\n",
        "\n",
        "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 5x5x16.\n",
        "\n",
        "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
        "\n",
        "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
        "\n",
        "### Output\n",
        "Return the result of the 2nd fully connected layer."
      ]
    },
    {
      "metadata": {
        "id": "Vgad6Ny0OjqN",
        "colab_type": "code",
        "outputId": "bbd7e267-cb9c-4ef7-9058-94080a867643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "connection_probability = tf.Variable(.9999)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YqIQlX7Rtqrz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Se2Hp4KQvCW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "G_W3 =  tf.Variable(np.float32(clf.coefs_[2]))\n",
        "G_b3 = tf.Variable(np.float32(clf.intercepts_ [2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iov1Mky-vohQ",
        "colab_type": "code",
        "outputId": "5c5481c7-a343-4a81-de9f-3bf59fc26040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.coefs_[2].shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "X1nJmcI7Cy5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "def LeNet(x, test_mode = False):    \n",
        "    # Hyperparameters\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    layer_depth = {\n",
        "        'layer_1' : 6,\n",
        "        'layer_2' : 16,\n",
        "        'layer_3' : 120,\n",
        "        'layer_f1' : 84\n",
        "    }\n",
        "\n",
        "\n",
        "    \n",
        "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
        "    x_flat = flatten(x)\n",
        "    fc1 = flatten(x)\n",
        "    fdense = fc1\n",
        "    \n",
        "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    fc1_w = G_W1# tf.Variable(tf.truncated_normal(shape = (X_train.shape[1]*X_train.shape[2],300), mean = mu, stddev = sigma))\n",
        "    fc1_b = G_b1# tf.Variable(tf.zeros(300))\n",
        "    fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
        "    \n",
        "    # TODO: Activation.\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "\n",
        "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "    fc2_w = G_W2# tf.Variable(tf.truncated_normal(shape = (300,100), mean = mu, stddev = sigma))\n",
        "    fc2_b = G_b2# tf.Variable(tf.zeros(100))\n",
        "    fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
        "    # TODO: Activation.\n",
        "    fc2 = tf.nn.relu(fc2)\n",
        "    \n",
        "    \n",
        "    #################\n",
        "    ##### Inset probability connection from x to conv2\n",
        "    fc2p_w = tf.Variable(tf.truncated_normal(shape = [X_train.shape[1]*X_train.shape[2],100], mean = mu, stddev = sigma))\n",
        "    fc2p_w = tf.Variable(xavier_init([X_train.shape[1]*X_train.shape[2],clf.coefs_[1].shape[1]]))\n",
        "\n",
        "#     fc2p_b = tf.Variable(tf.zeros(clf.coefs_[1].shape[1]))\n",
        "    fc2p_b = tf.Variable(xavier_init([clf.coefs_[1].shape[1]]))\n",
        "\n",
        "    fc2_2nd_input = tf.matmul(x_flat,fc2p_w) + fc2p_b\n",
        "    fc2_2nd_input = tf.nn.relu(fc2_2nd_input)\n",
        "    connect2 = tf.logical_and(tf.random.uniform(shape = tf.shape(connection_probability)) < connection_probability, tf.equal(test_mode,False))\n",
        "    fc2 = tf.cond(connect2,lambda: fc2 + fc2_2nd_input, lambda: fc2 )    \n",
        "    ################\n",
        "    \n",
        "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
        "#     fc3_w = tf.Variable(tf.truncated_normal(shape = (clf.coefs_[1].shape[1],10), mean = mu , stddev = sigma))\n",
        "#     fc3_w = tf.Variable(tf.truncated_normal(shape = (clf.coefs_[1].shape[1],10), mean = mu , stddev = sigma))\n",
        "\n",
        "#     fc3_b = tf.Variable(tf.zeros(10))\n",
        "    fc3_w = G_W3\n",
        "    fc3_b = G_b3\n",
        "    \n",
        "    logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2V3XEMaYvjDW",
        "colab_type": "code",
        "outputId": "1eb259dc-05aa-457f-8570-6149f1e5cb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "aCx837c9Cy6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Features and Labels\n",
        "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
        "\n",
        "`x` is a placeholder for a batch of input images.\n",
        "`y` is a placeholder for a batch of output labels.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "iafVK0DgLRTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mrb2FHFHCy6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('Input'):\n",
        "\n",
        "  x = tf.placeholder(tf.float32, (None, 28, 28, 1), name='X')\n",
        "  tf.summary.image('input_image', x, max_outputs=5)\n",
        "  y = tf.placeholder(tf.int32, (None), name = 'Y')\n",
        "one_hot_y = tf.one_hot(y, 10)\n",
        "is_testing= tf.placeholder(tf.bool) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uk0pcAjmCy6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Pipeline\n",
        "Create a training pipeline that uses the model to classify MNIST data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "BPo6q2KkpDVA",
        "colab_type": "code",
        "outputId": "a0e4de3a-fe39-45e5-91a7-4b8cf86f468f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape[0]/BATCH_SIZE"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.421875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "dvZ1AxLnoyr2",
        "colab_type": "code",
        "outputId": "a622fa3a-4d5c-4581-a799-419f480708b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(55000/512)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.421875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "37lsIW7Zo7bB",
        "colab_type": "code",
        "outputId": "0bde89b3-55e6-446d-facc-0fbe5a34ab76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "1.0002**107.421875"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0217146310875027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3oYy_Y3FCy6N",
        "colab_type": "code",
        "outputId": "eae258fd-9326-491d-96a8-a92016e8302d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rate = 0.001\n",
        "decay_rate = 1.0005**(X_train.shape[0]/BATCH_SIZE);\n",
        "print(decay_rate)\n",
        "logits = LeNet(x,is_testing)\n",
        "with tf.name_scope('Train'):\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "  loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "  tf.summary.scalar('loss', loss_operation)\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "# tf.train.natural_exp_decay()\n",
        "training_operation = optimizer.minimize(loss_operation)\n",
        "new_prob = connection_probability.assign(connection_probability/decay_rate)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0551653813751776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRw7tBqHvnh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0963484c-ed7c-425f-c4f5-3e6f056f6740"
      },
      "cell_type": "code",
      "source": [
        "(1/decay_rate)**200"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1671709710075617e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "KrMtHo6rCy6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "OMR9XsLBCy6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "def evaluate(X_data, y_data):\n",
        "    num_examples = len(X_data)\n",
        "    total_accuracy = 0\n",
        "    sess = tf.get_default_session()\n",
        "    for offset in range(0, num_examples, BATCH_SIZE):\n",
        "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, is_testing: True})\n",
        "        total_accuracy += (accuracy * len(batch_x))\n",
        "    tot_acc = total_accuracy / num_examples\n",
        "    with tf.name_scope('Accuracy'):\n",
        "      tf.summary.scalar('accuracy', tot_acc)\n",
        "    return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Jw7iox3Cy6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "Run the training data through the training pipeline to train the model.\n",
        "\n",
        "Before each epoch, shuffle the training set.\n",
        "\n",
        "After each epoch, measure the loss and accuracy of the validation set.\n",
        "\n",
        "Save the model after training.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "c98G07hDQG2g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QC1kt_DL1yU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment(images, labels,\n",
        "            resize=None, # (width, height) tuple or None\n",
        "            horizontal_flip=False,\n",
        "            vertical_flip=False,\n",
        "            rotate=0, # Maximum rotation angle in degrees\n",
        "            crop_probability=0, # How often we do crops\n",
        "            crop_min_percent=0.6, # Minimum linear dimension of a crop\n",
        "            crop_max_percent=1.,  # Maximum linear dimension of a crop\n",
        "            mixup=0):  # Mixup coeffecient, see https://arxiv.org/abs/1710.09412.pdf\n",
        "  if resize is not None:\n",
        "    images = tf.image.resize_bilinear(images, resize)\n",
        "  \n",
        "  # My experiments showed that casting on GPU improves training performance\n",
        "  if images.dtype != tf.float32:\n",
        "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n",
        "    images = tf.subtract(images, 0.5)\n",
        "    images = tf.multiply(images, 2.0)\n",
        "  labels = tf.to_float(labels)\n",
        "\n",
        "  with tf.name_scope('augmentation'):\n",
        "    shp = tf.shape(images)\n",
        "    batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "    width = tf.cast(width, tf.float32)\n",
        "    height = tf.cast(height, tf.float32)\n",
        "\n",
        "    # The list of affine transformations that our image will go under.\n",
        "    # Every element is Nx8 tensor, where N is a batch size.\n",
        "    transforms = []\n",
        "    identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n",
        "    if horizontal_flip:\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [-1., 0., width, 0., 1., 0., 0., 0.], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if vertical_flip:\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [1, 0, 0, 0, -1, height, 0, 0], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if rotate > 0:\n",
        "      angle_rad = rotate / 180 * math.pi\n",
        "      angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n",
        "      transforms.append(\n",
        "          tf.contrib.image.angles_to_projective_transforms(\n",
        "              angles, height, width))\n",
        "\n",
        "    if crop_probability > 0:\n",
        "      crop_pct = tf.random_uniform([batch_size], crop_min_percent,\n",
        "                                   crop_max_percent)\n",
        "      left = tf.random_uniform([batch_size], 0, width * (1 - crop_pct))\n",
        "      top = tf.random_uniform([batch_size], 0, height * (1 - crop_pct))\n",
        "      crop_transform = tf.stack([\n",
        "          crop_pct,\n",
        "          tf.zeros([batch_size]), top,\n",
        "          tf.zeros([batch_size]), crop_pct, left,\n",
        "          tf.zeros([batch_size]),\n",
        "          tf.zeros([batch_size])\n",
        "      ], 1)\n",
        "\n",
        "      coin = tf.less(\n",
        "          tf.random_uniform([batch_size], 0, 1.0), crop_probability)\n",
        "      transforms.append(\n",
        "          tf.where(coin, crop_transform,\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if transforms:\n",
        "      images = tf.contrib.image.transform(\n",
        "          images,\n",
        "          tf.contrib.image.compose_transforms(*transforms),\n",
        "          interpolation='BILINEAR') # or 'NEAREST'\n",
        "\n",
        "    def cshift(values): # Circular shift in batch dimension\n",
        "      return tf.concat([values[-1:, ...], values[:-1, ...]], 0)\n",
        "\n",
        "    if mixup > 0:\n",
        "      mixup = 1.0 * mixup # Convert to float, as tf.distributions.Beta requires floats.\n",
        "      beta = tf.distributions.Beta(mixup, mixup)\n",
        "      lam = beta.sample(batch_size)\n",
        "      ll = tf.expand_dims(tf.expand_dims(tf.expand_dims(lam, -1), -1), -1)\n",
        "      images = ll * images + (1 - ll) * cshift(images)\n",
        "      labels = lam * labels + (1 - lam) * cshift(labels)\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siI7jT2RUvYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_data(dataset, dataset_labels, augementation_factor=1, use_random_rotation=True, use_random_shear=True, use_random_shift=True, use_random_zoom=True):\n",
        "\taugmented_image = []\n",
        "\taugmented_image_labels = []\n",
        "\n",
        "\tfor num in range (0, dataset.shape[0]):\n",
        "\n",
        "\t\tfor i in range(0, augementation_factor):\n",
        "\t\t\t# original image:\n",
        "\t\t\taugmented_image.append(dataset[num])\n",
        "\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_rotation:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_rotation(dataset[num], 20, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_shear:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_shear(dataset[num], 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_shift:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_shift(dataset[num], 0.2, 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "# \t\t\tif use_random_zoom:\n",
        "# \t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_zoom(dataset[num], 0.9, row_axis=0, col_axis=1, channel_axis=2))\n",
        "# \t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\treturn np.array(augmented_image), np.array(augmented_image_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Of2PvjkIQikg",
        "colab_type": "code",
        "outputId": "1bc423c4-d79e-4a8c-f1fa-f26a77f6ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "Eb8X_yO6QDIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sw7vjTrPxBDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e8a1e2d-f684-41b4-ad98-63d0dac4f269"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "MbueMHwfEbi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "BATCH_SIZE= 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INEVMxw4R0Nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mnist.test.images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYoZ96svRxfO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the test set\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels\n",
        "\n",
        "# Initialize the embedding variable with the shape of our desired tensor\n",
        "tensor_shape = (x_test.shape[0] , logits.get_shape()[1].value) # [test_set , h1] = [10000 , 200]\n",
        "embedding_var = tf.Variable(tf.zeros(tensor_shape), \n",
        "                            name='logits_embedding')\n",
        "# assign the tensor that we want to visualize to the embedding variable\n",
        "embedding_assign = embedding_var.assign(logits) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QrvPzlGSN6S",
        "colab_type": "code",
        "outputId": "749f45b0-1022-49bd-cb7b-2d0b49f876ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# EPOCHS = 2\n",
        "X_train.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "t26ZbqMVoNRr",
        "colab_type": "code",
        "outputId": "0f3cdb7d-1acd-4fff-d6ad-2466291ce0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "bKU1MIyJCy6Y",
        "colab_type": "code",
        "outputId": "3c3a9e36-ce0c-491a-b6d0-ef1ffd668e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        }
      },
      "cell_type": "code",
      "source": [
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = X_train.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "\n",
        "print_every = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(X_train)\n",
        "    best_accuracy_valid = 0\n",
        "    train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
        "\n",
        "    print(\"Training...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        X_train, y_train = shuffle(X_train, y_train)\n",
        "        for step in range(0, total_steps_for_one_pass):        \n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:,:,:],y_train[step*BATCH_SIZE:]\n",
        "#             print(step,'Finishing',step*BATCH_SIZE )\n",
        "            step = 0\n",
        "\n",
        "          else:\n",
        "\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "#             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "            batch_x, batch_y = X_train[step:finish,:,:,:],y_train[step:finish]\n",
        "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "  \n",
        "  \n",
        "#         for offset in range(0, num_examples + BATCH_SIZE, BATCH_SIZE):\n",
        "#             end = offset + BATCH_SIZE\n",
        "#             if end>X_train.shape[0]:\n",
        "#               end = X_train.shape[0]\n",
        "#             print(offset,end)\n",
        "#             batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
        "            tr_op,summary_tr  = sess.run([training_operation,merged], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "            train_writer.add_summary(summary_tr, i)\n",
        "        prob = sess.run(new_prob)\n",
        "#         print(prob)\n",
        "        if i%print_every == 0:\n",
        "          tr_accuracy = evaluate(X_train, y_train)\n",
        "          print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "          validation_accuracy = evaluate(X_validation, y_validation)\n",
        "          validation_accuracy_track.append(validation_accuracy)\n",
        "          train_accuracy_track.append(tr_accuracy)\n",
        "          connection_probability_track.append(prob)\n",
        "          print(\"EPOCH {} ...\".format(i+1))\n",
        "          print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "          print(prob)\n",
        "          print()\n",
        "          if (validation_accuracy >= best_accuracy_valid):\n",
        "            best_accuracy_valid = validation_accuracy\n",
        "            saver.save(sess, './lenet')\n",
        "        \n",
        "#     saver.save(sess, './lenet')\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 1 ...\n",
            "Validation Accuracy = 0.98520\n",
            "0.9476239\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 11 ...\n",
            "Validation Accuracy = 0.98580\n",
            "0.5538988\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 21 ...\n",
            "Validation Accuracy = 0.98580\n",
            "0.32376122\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 31 ...\n",
            "Validation Accuracy = 0.98600\n",
            "0.18924274\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 41 ...\n",
            "Validation Accuracy = 0.98620\n",
            "0.110614896\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 51 ...\n",
            "Validation Accuracy = 0.98640\n",
            "0.06465587\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 61 ...\n",
            "Validation Accuracy = 0.98660\n",
            "0.03779221\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 71 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.022090051\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 81 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.012911929\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 91 ...\n",
            "Validation Accuracy = 0.98720\n",
            "0.0075471946\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 101 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.004411436\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 111 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.0025785433\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 121 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.0015071927\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 131 ...\n",
            "Validation Accuracy = 0.98720\n",
            "0.0008809743\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 141 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.0005149412\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 151 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.00030098998\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 161 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.00017593266\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 171 ...\n",
            "Validation Accuracy = 0.98740\n",
            "0.00010283497\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 181 ...\n",
            "Validation Accuracy = 0.98700\n",
            "6.010841e-05\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 191 ...\n",
            "Validation Accuracy = 0.98660\n",
            "3.513417e-05\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QOmTLbuCIaZJ",
        "colab_type": "code",
        "outputId": "8601f111-1fab-4c61-bd4b-1ca6a085c6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "best_accuracy_valid"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9873999964714051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "hUc5BqhdSVtq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_w = 28\n",
        "img_h = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tr1bfaPASS3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "# Create a config object to write the configuration parameters\n",
        "config = projector.ProjectorConfig()\n",
        "\n",
        "# Add embedding variable\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = embedding_var.name\n",
        "\n",
        "# Link this tensor to its metadata file (e.g. labels) -> we will create this file later\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "\n",
        "# Specify where you find the sprite. -> we will create this image later\n",
        "embedding.sprite.image_path = 'sprite_images.png'\n",
        "embedding.sprite.single_image_dim.extend([img_w, img_h])\n",
        "\n",
        "# Write a projector_config.pbtxt in the logs_path.\n",
        "# TensorBoard will read this file during startup.\n",
        "projector.visualize_embeddings(train_writer, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6JnCs7sUUcLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Run session to evaluate the tensor\n",
        "# with tf.Session() as sess:\n",
        "#   x_test_fc1 = sess.run(embedding_assign, feed_dict={x: X_test})\n",
        "\n",
        "#   # Save the tensor in model.ckpt file\n",
        "#   saver = tf.train.Saver()\n",
        "#   saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVIeYA_cCy6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model\n",
        "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
        "\n",
        "Be sure to only do this once!\n",
        "\n",
        "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "O4b5lSD5H_q9",
        "colab_type": "code",
        "outputId": "c20bc697-5b02-464b-b528-e33965477889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './lenet')\n",
        "    test_accuracy = evaluate(X_validation, y_validation)\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./lenet\n",
            "Validation Accuracy = 0.987400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-KeugG2UcKb",
        "colab_type": "code",
        "outputId": "526a22aa-4f96-4bd3-b062-cccf2827ade8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(validation_accuracy_track)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f756063b400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaAQEZF6KShERKReCgoREanX/wPYhPIUJ0f1ewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r8bS_3E0qKH1",
        "colab_type": "code",
        "outputId": "771bf5b2-bf9a-4748-ceea-02aa3195db51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './lenet')\n",
        "    test_accuracy = evaluate(X_test, y_test)\n",
        "    print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./lenet\n",
            "Test Accuracy = 0.984600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V7Uw7Yj0UaaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIMkpCgsTwRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_tmzQ7mUs8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochTrack = [k for k in range(1,191,10)]\n",
        "# epochTrack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AOxPCQoOUSjc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sio.savemat('LeNEt300-100Tracked.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epochTrack})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ldZP-eobLvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sio.savemat('LeNEt300-100TrackedV2Test98p42Valid98p74tNoDropConnection.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "#                                        'train_accuracy_track':train_accuracy_track,\n",
        "#                                        'connection_probability_track':connection_probability_track,\n",
        "#                                        'epochTrack':epochTrack, 'TestAcc':test_accuracy,\n",
        "#                                                          'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZQ52QIrztzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sio.savemat('V98p74T98p46_LeNEt300_100EpochBasedPRob_Decay1p0005.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epochTrack, 'TestAcc':test_accuracy,\n",
        "                                                         'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVXJD4prT0sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "{'ValidationTracked'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gATWCb50-pbt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with tf.Session() as sess:\n",
        "# #     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './lenet')\n",
        "#     test_accuracy = evaluate(X_test, y_test)\n",
        "#     print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJONJ7CeCy6f",
        "colab_type": "code",
        "outputId": "99ef394d-dcd7-4efc-d863-1bb1c8dfd18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3131
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './lenet')\n",
        "    x_test_fc1 = sess.run(embedding_assign, feed_dict={x: X_test,is_testing: True})\n",
        "\n",
        "    # Save the tensor in model.ckpt file\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), i)\n",
        "    test_accuracy = evaluate(X_test, y_test)\n",
        "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./lenet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key logits_embedding_3 not found in checkpoint\n\t [[{{node save_5/RestoreV2}}]]\n\t [[{{node save_5/RestoreV2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\nCaused by op 'save_5/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-789083789e7d>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-2a49aef686ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     saver.restore(sess, './lenet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_test_fc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_assign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_testing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\nCaused by op 'save_5/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-789083789e7d>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qvRqnUrrCy6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_sprite_image(filename, images):\n",
        "    \"\"\"\n",
        "        Create a sprite image consisting of sample images\n",
        "        :param filename: name of the file to save on disk\n",
        "        :param shape: tensor of flattened images\n",
        "    \"\"\"\n",
        "\n",
        "    # Invert grayscale image\n",
        "    images = 1 - images\n",
        "\n",
        "    # Calculate number of plot\n",
        "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "\n",
        "    # Make the background of sprite image\n",
        "    sprite_image = np.ones((img_h * n_plots, img_w * n_plots))\n",
        "\n",
        "    for i in range(n_plots):\n",
        "        for j in range(n_plots):\n",
        "            img_idx = i * n_plots + j\n",
        "            if img_idx < images.shape[0]:\n",
        "                img = images[img_idx]\n",
        "                sprite_image[i * img_h:(i + 1) * img_h,\n",
        "                j * img_w:(j + 1) * img_w] = img\n",
        "\n",
        "    plt.imsave(filename, sprite_image, cmap='gray')\n",
        "    print('Sprite image saved in {}'.format(filename))\n",
        "\n",
        "def write_metadata(filename, labels):\n",
        "    \"\"\"\n",
        "            Create a metadata file image consisting of sample indices and labels\n",
        "            :param filename: name of the file to save on disk\n",
        "            :param shape: tensor of labels\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"Index\\tLabel\\n\")\n",
        "        for index, label in enumerate(labels):\n",
        "            f.write(\"{}\\t{}\\n\".format(index, label))\n",
        "\n",
        "    print('Metadata file saved in {}'.format(filename))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vE0ULEJ7XGlH",
        "colab_type": "code",
        "outputId": "521734b2-6287-4ee4-e907-495d334f9f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "F-zHFsYHWvrv",
        "colab_type": "code",
        "outputId": "54ffa52c-c52a-47e8-a521-bb74797f586b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Reshape images from vector to matrix\n",
        "x_test_images = np.reshape(np.array(X_test), (-1, img_w, img_h))\n",
        "# Reshape labels from one-hot-encode to index\n",
        "x_test_labels = y_test\n",
        "\n",
        "write_sprite_image(os.path.join(logs_path, 'sprite_images.png'), x_test_images)\n",
        "write_metadata(os.path.join(logs_path, 'metadata.tsv'), x_test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sprite image saved in ./logs/embedding/sprite_images.png\n",
            "Metadata file saved in ./logs/embedding/metadata.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uPVpeenpW8sp",
        "colab_type": "code",
        "outputId": "23e1a68e-78ab-4b89-d0ff-571473bf15b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "# logdir=logs/embedding/\n",
        "LOG_DIR = 'logs/embedding/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 22:31:50--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.73.94.166, 52.45.111.123, 52.4.95.48, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.73.94.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.28M  7.04MB/s    in 2.0s    \n",
            "\n",
            "2019-04-07 22:31:53 (7.04 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sULv8PgRXp2j",
        "colab_type": "code",
        "outputId": "7e8c41b2-028f-4d9d-ff5b-4cf9db24e07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ngrok_url = !curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "        \n",
        "ngrok_url = ngrok_url[0].replace(\"'\", '')\n",
        "print(ngrok_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d310ebff.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7TjVgm-X6N1",
        "colab_type": "code",
        "outputId": "b58870c5-0ee1-4f23-f15e-fd4e0a933754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(ngrok_url, width=700, height=900)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"700\"\n",
              "            height=\"900\"\n",
              "            src=\"https://d310ebff.ngrok.io\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f82b37fed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "u5OZDSZ7X9eO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
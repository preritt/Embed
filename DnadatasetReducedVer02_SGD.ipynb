{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DnadatasetReducedVer02-SGD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/DnadatasetReducedVer02_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "560edb06-2540-46df-f82f-09e97cd80dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.677234</td>\n",
              "      <td>-0.205123</td>\n",
              "      <td>-0.482950</td>\n",
              "      <td>-0.491417</td>\n",
              "      <td>0.074036</td>\n",
              "      <td>0.120849</td>\n",
              "      <td>-0.106411</td>\n",
              "      <td>-0.854025</td>\n",
              "      <td>0.235618</td>\n",
              "      <td>-0.724818</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.452475</td>\n",
              "      <td>-0.076587</td>\n",
              "      <td>0.065689</td>\n",
              "      <td>-0.204755</td>\n",
              "      <td>0.719114</td>\n",
              "      <td>-0.415737</td>\n",
              "      <td>0.151107</td>\n",
              "      <td>-0.278909</td>\n",
              "      <td>-0.022437</td>\n",
              "      <td>0.116028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.968325</td>\n",
              "      <td>-0.901980</td>\n",
              "      <td>-0.612648</td>\n",
              "      <td>-0.320269</td>\n",
              "      <td>0.900248</td>\n",
              "      <td>-1.070258</td>\n",
              "      <td>-0.276023</td>\n",
              "      <td>-1.350481</td>\n",
              "      <td>-0.307156</td>\n",
              "      <td>0.873546</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.312353</td>\n",
              "      <td>-0.154037</td>\n",
              "      <td>-0.097274</td>\n",
              "      <td>-0.028025</td>\n",
              "      <td>-0.198132</td>\n",
              "      <td>-0.364496</td>\n",
              "      <td>0.373894</td>\n",
              "      <td>-0.262713</td>\n",
              "      <td>-0.031868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.144510</td>\n",
              "      <td>-0.639640</td>\n",
              "      <td>0.094091</td>\n",
              "      <td>0.736130</td>\n",
              "      <td>-0.741035</td>\n",
              "      <td>1.317996</td>\n",
              "      <td>-0.332095</td>\n",
              "      <td>1.514341</td>\n",
              "      <td>-0.697174</td>\n",
              "      <td>0.793378</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052664</td>\n",
              "      <td>0.234666</td>\n",
              "      <td>0.514637</td>\n",
              "      <td>0.379384</td>\n",
              "      <td>-0.415597</td>\n",
              "      <td>-0.251387</td>\n",
              "      <td>-0.249521</td>\n",
              "      <td>-0.048087</td>\n",
              "      <td>0.846899</td>\n",
              "      <td>-0.228373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.011300</td>\n",
              "      <td>-0.753063</td>\n",
              "      <td>1.140482</td>\n",
              "      <td>-1.568935</td>\n",
              "      <td>0.673132</td>\n",
              "      <td>0.256885</td>\n",
              "      <td>-1.308196</td>\n",
              "      <td>-0.929054</td>\n",
              "      <td>-1.467942</td>\n",
              "      <td>0.812135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005383</td>\n",
              "      <td>0.306471</td>\n",
              "      <td>0.055101</td>\n",
              "      <td>0.238929</td>\n",
              "      <td>-0.382544</td>\n",
              "      <td>0.214989</td>\n",
              "      <td>-0.098546</td>\n",
              "      <td>0.089057</td>\n",
              "      <td>0.111130</td>\n",
              "      <td>-0.350712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.019436</td>\n",
              "      <td>0.294622</td>\n",
              "      <td>1.569688</td>\n",
              "      <td>0.488142</td>\n",
              "      <td>-0.463129</td>\n",
              "      <td>-0.929467</td>\n",
              "      <td>-1.738224</td>\n",
              "      <td>-0.145351</td>\n",
              "      <td>0.004826</td>\n",
              "      <td>-1.081979</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014322</td>\n",
              "      <td>0.062022</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.140120</td>\n",
              "      <td>-0.348128</td>\n",
              "      <td>-0.529818</td>\n",
              "      <td>-0.252468</td>\n",
              "      <td>-0.330608</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>0.567040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 138 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0 -0.677234 -0.205123 -0.482950 -0.491417  0.074036  0.120849 -0.106411   \n",
              "1 -0.968325 -0.901980 -0.612648 -0.320269  0.900248 -1.070258 -0.276023   \n",
              "2 -1.144510 -0.639640  0.094091  0.736130 -0.741035  1.317996 -0.332095   \n",
              "3  1.011300 -0.753063  1.140482 -1.568935  0.673132  0.256885 -1.308196   \n",
              "4 -0.019436  0.294622  1.569688  0.488142 -0.463129 -0.929467 -1.738224   \n",
              "\n",
              "        7         8         9      ...          128       129       130  \\\n",
              "0 -0.854025  0.235618 -0.724818    ...    -0.452475 -0.076587  0.065689   \n",
              "1 -1.350481 -0.307156  0.873546    ...    -0.062500  0.312353 -0.154037   \n",
              "2  1.514341 -0.697174  0.793378    ...    -0.052664  0.234666  0.514637   \n",
              "3 -0.929054 -1.467942  0.812135    ...     0.005383  0.306471  0.055101   \n",
              "4 -0.145351  0.004826 -1.081979    ...     0.014322  0.062022  0.049797   \n",
              "\n",
              "        131       132       133       134       135       136       137  \n",
              "0 -0.204755  0.719114 -0.415737  0.151107 -0.278909 -0.022437  0.116028  \n",
              "1 -0.097274 -0.028025 -0.198132 -0.364496  0.373894 -0.262713 -0.031868  \n",
              "2  0.379384 -0.415597 -0.251387 -0.249521 -0.048087  0.846899 -0.228373  \n",
              "3  0.238929 -0.382544  0.214989 -0.098546  0.089057  0.111130 -0.350712  \n",
              "4 -0.140120 -0.348128 -0.529818 -0.252468 -0.330608 -0.000366  0.567040  \n",
              "\n",
              "[5 rows x 138 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "e3bdeee9-aa2e-44cb-d515-a53cb74a856a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  1\n",
              "1  1\n",
              "2  1\n",
              "3  2\n",
              "4  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "19ac5c78-b0df-4d31-cf40-bdd8377ccac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "f44caa9f-42a1-4f02-b63d-c48ad930b134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "671b86c3-8896-4409-ec00-e1f7ca438b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pDOMf8vCQFNW"
      },
      "cell_type": "markdown",
      "source": [
        "## without using vaidation data for fitting"
      ]
    },
    {
      "metadata": {
        "id": "P2OQDaKv_x0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_label.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "26e68531-15f1-4d23-cf63-3bbf782044d5",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1683
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(138, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.97153027\n",
            "Iteration 2, loss = 0.38995267\n",
            "Iteration 3, loss = 0.16863707\n",
            "Iteration 4, loss = 0.08644866\n",
            "Iteration 5, loss = 0.04790676\n",
            "Iteration 6, loss = 0.02766120\n",
            "Iteration 7, loss = 0.01804213\n",
            "Iteration 8, loss = 0.01303306\n",
            "Iteration 9, loss = 0.01017363\n",
            "Iteration 10, loss = 0.00846074\n",
            "Iteration 11, loss = 0.00731784\n",
            "Iteration 12, loss = 0.00642295\n",
            "Iteration 13, loss = 0.00578566\n",
            "Iteration 14, loss = 0.00524263\n",
            "Iteration 15, loss = 0.00482185\n",
            "Iteration 16, loss = 0.00445585\n",
            "Iteration 17, loss = 0.00415009\n",
            "Iteration 18, loss = 0.00387484\n",
            "Iteration 19, loss = 0.00363059\n",
            "Iteration 20, loss = 0.00342359\n",
            "Iteration 21, loss = 0.00324253\n",
            "Iteration 22, loss = 0.00306885\n",
            "Iteration 23, loss = 0.00291664\n",
            "Iteration 24, loss = 0.00277493\n",
            "Iteration 25, loss = 0.00265069\n",
            "Iteration 26, loss = 0.00253650\n",
            "Iteration 27, loss = 0.00242954\n",
            "Iteration 28, loss = 0.00233327\n",
            "Iteration 29, loss = 0.00224341\n",
            "Iteration 30, loss = 0.00215908\n",
            "Iteration 31, loss = 0.00208097\n",
            "Iteration 32, loss = 0.00200870\n",
            "Iteration 33, loss = 0.00194052\n",
            "Iteration 34, loss = 0.00187660\n",
            "Iteration 35, loss = 0.00181774\n",
            "Iteration 36, loss = 0.00176193\n",
            "Iteration 37, loss = 0.00170941\n",
            "Iteration 38, loss = 0.00166006\n",
            "Iteration 39, loss = 0.00161241\n",
            "Iteration 40, loss = 0.00156818\n",
            "Iteration 41, loss = 0.00152616\n",
            "Iteration 42, loss = 0.00148629\n",
            "Iteration 43, loss = 0.00144797\n",
            "Iteration 44, loss = 0.00141247\n",
            "Iteration 45, loss = 0.00137653\n",
            "Iteration 46, loss = 0.00134514\n",
            "Iteration 47, loss = 0.00131347\n",
            "Iteration 48, loss = 0.00128475\n",
            "Iteration 49, loss = 0.00125555\n",
            "Iteration 50, loss = 0.00122770\n",
            "Iteration 51, loss = 0.00120178\n",
            "Iteration 52, loss = 0.00117708\n",
            "Iteration 53, loss = 0.00115253\n",
            "Iteration 54, loss = 0.00112934\n",
            "Iteration 55, loss = 0.00110742\n",
            "Iteration 56, loss = 0.00108600\n",
            "Iteration 57, loss = 0.00106536\n",
            "Iteration 58, loss = 0.00104544\n",
            "Iteration 59, loss = 0.00102592\n",
            "Iteration 60, loss = 0.00100787\n",
            "Iteration 61, loss = 0.00099042\n",
            "Iteration 62, loss = 0.00097298\n",
            "Iteration 63, loss = 0.00095668\n",
            "Iteration 64, loss = 0.00094005\n",
            "Iteration 65, loss = 0.00092519\n",
            "Iteration 66, loss = 0.00090977\n",
            "Iteration 67, loss = 0.00089595\n",
            "Iteration 68, loss = 0.00088126\n",
            "Iteration 69, loss = 0.00086789\n",
            "Iteration 70, loss = 0.00085454\n",
            "Iteration 71, loss = 0.00084165\n",
            "Iteration 72, loss = 0.00082940\n",
            "Iteration 73, loss = 0.00081723\n",
            "Iteration 74, loss = 0.00080550\n",
            "Iteration 75, loss = 0.00079436\n",
            "Iteration 76, loss = 0.00078317\n",
            "Iteration 77, loss = 0.00077216\n",
            "Iteration 78, loss = 0.00076203\n",
            "Iteration 79, loss = 0.00075179\n",
            "Iteration 80, loss = 0.00074184\n",
            "Iteration 81, loss = 0.00073234\n",
            "Iteration 82, loss = 0.00072312\n",
            "Iteration 83, loss = 0.00071394\n",
            "Iteration 84, loss = 0.00070467\n",
            "Iteration 85, loss = 0.00069620\n",
            "Iteration 86, loss = 0.00068783\n",
            "Iteration 87, loss = 0.00067950\n",
            "Iteration 88, loss = 0.00067140\n",
            "Iteration 89, loss = 0.00066344\n",
            "Iteration 90, loss = 0.00065580\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(138,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "a8114dcd-e367-403d-f9a8-98f9738b15a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "6f1f6f76-f182-49d1-a0c0-2a3d9a744a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9483333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "54d8d156-8f7e-459f-83a4-d16126f989e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9258010118043845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7rvpGmMDTKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1JsxsNc_922",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "5182d957-ec32-4700-838e-7e31a3aa0168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1186, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 16 -> 104 -> 26"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "004270e8-5260-496b-937a-d5e8c22925f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_H2ratU_fFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# np.float32(clf.intercepts_ [1]).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "49a81e9a-bae9-4c42-d2d0-0e6c48cb98b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Rerun the same thing in tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "757fe4f1-39ca-4eab-d656-a3e130a72fe6",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-3b5d00d1fd96>:19: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.0006365555, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1000, training loss= 0.0006369825, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2000, training loss= 0.00056276785, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3000, training loss= 0.0006393745, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4000, training loss= 0.0006205041, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5000, training loss= 0.00061023, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6000, training loss= 0.0005851029, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7000, training loss= 0.0006016333, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8000, training loss= 0.0005298921, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9000, training loss= 0.0006442769, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 10000, training loss= 0.00057654566, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 11000, training loss= 0.00052608375, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 12000, training loss= 0.00059600355, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 13000, training loss= 0.00046688353, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 14000, training loss= 0.0005057716, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 15000, training loss= 0.0005892336, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 16000, training loss= 0.00061360525, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 17000, training loss= 0.00059323874, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 18000, training loss= 0.0005720067, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 19000, training loss= 0.00057942123, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "Test acc= 92.5801 %\n",
            "Valid acc= 94.833336 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UpCtcB9hQFPI",
        "outputId": "0ebd2a6f-ebb9-45a3-c645-a6c04f6a3839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mT7SryMuQFPO"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "metadata": {
        "id": "KsWd-9SdAe5M",
        "colab_type": "code",
        "outputId": "b5b98686-6431-4bb9-a8bd-0bb55fb453b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_label_one_hot.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "XK_NlYiqAmBT",
        "colab_type": "code",
        "outputId": "721b84af-a731-49de-9252-8042a2852bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label_one_hot.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K-zBUEuGwV98",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:550,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:550,:]\n",
        "valid_test_data = validation_data[550:,:]\n",
        "valid_test_data_label = validation_label_one_hot[550:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E91ru7-owV5i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ykK7OjEnEnSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# num_hidden_neurons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 138\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 4, W2 =3, W3 = 1 from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "id": "46Xf22zJ5gVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d4a443f-f829-49a8-d318-5e09e5b5531d"
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W5Fa3AIQ5n8N",
        "outputId": "d27d4352-f553-4cca-be8b-f9c4e49d1fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51136
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "num_steps = 50000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.041366104, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 50, training loss= 0.08533585, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 100, training loss= 0.061182156, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 150, training loss= 0.0239077, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 200, training loss= 0.011537079, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 250, training loss= 0.014880099, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 300, training loss= 0.009597919, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 350, training loss= 0.0017140863, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 400, training loss= 0.003965519, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 450, training loss= 0.0062928814, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 500, training loss= 0.019585572, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 550, training loss= 0.0034877874, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 600, training loss= 0.017859664, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 650, training loss= 0.0022274582, training acc= 100.0%\n",
            "Validation Accuracy 94.5 ...\n",
            "\n",
            "step 700, training loss= 0.0039734095, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 750, training loss= 0.029170085, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 800, training loss= 0.00031061433, training acc= 100.0%\n",
            "Validation Accuracy 94.66666412353516 ...\n",
            "\n",
            "step 850, training loss= 0.010431312, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 900, training loss= 0.00126229, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 950, training loss= 0.0005864722, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1000, training loss= 0.0003297231, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1050, training loss= 0.008428846, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1100, training loss= 0.001935517, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1150, training loss= 0.00036836433, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1200, training loss= 0.009314197, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1250, training loss= 0.0013461672, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1300, training loss= 0.00073517114, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1350, training loss= 0.0071047256, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1400, training loss= 0.006754647, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1450, training loss= 0.0020228163, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1500, training loss= 0.00045349327, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1550, training loss= 0.0019653556, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1600, training loss= 0.00046897522, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1650, training loss= 0.0011040308, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1700, training loss= 0.0018442173, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1750, training loss= 0.0010090673, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1800, training loss= 0.0010425337, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1850, training loss= 0.000798573, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1900, training loss= 0.0007060385, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 1950, training loss= 0.00052176433, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2000, training loss= 0.0009809758, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2050, training loss= 0.00046748994, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2100, training loss= 0.00054203684, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2150, training loss= 0.00041755894, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2200, training loss= 0.00042241416, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2250, training loss= 0.00073570595, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2300, training loss= 0.0037219855, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2350, training loss= 0.0008362924, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2400, training loss= 0.002800898, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2450, training loss= 0.0005801892, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2500, training loss= 0.0004917451, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2550, training loss= 0.00036915316, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2600, training loss= 0.0004036036, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2650, training loss= 0.00043615323, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2700, training loss= 0.0017266733, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2750, training loss= 0.00086399086, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2800, training loss= 0.00043396142, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2850, training loss= 0.00033286773, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2900, training loss= 0.0010808103, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 2950, training loss= 0.0004376955, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3000, training loss= 0.0002842071, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3050, training loss= 0.00050828105, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3100, training loss= 0.0003722842, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3150, training loss= 0.00042043172, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3200, training loss= 0.0006233987, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3250, training loss= 0.00057870714, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3300, training loss= 0.00044719223, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3350, training loss= 0.00045875733, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3400, training loss= 0.0004977885, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3450, training loss= 0.00045048763, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3500, training loss= 0.00031547187, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3550, training loss= 0.0003734705, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3600, training loss= 0.00039634705, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3650, training loss= 0.00038042368, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3700, training loss= 0.00059878436, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3750, training loss= 0.00043775383, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3800, training loss= 0.00053426187, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3850, training loss= 0.00031836485, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3900, training loss= 0.0005643433, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 3950, training loss= 0.0005060822, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4000, training loss= 0.00052672555, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4050, training loss= 0.00032755698, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4100, training loss= 0.0004992357, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4150, training loss= 0.00065237033, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4200, training loss= 0.00048964453, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4250, training loss= 0.00029805084, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4300, training loss= 0.00043702734, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4350, training loss= 0.00034131535, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4400, training loss= 0.0004989232, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4450, training loss= 0.000314294, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4500, training loss= 0.00034122675, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4550, training loss= 0.0004047364, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4600, training loss= 0.0003007766, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4650, training loss= 0.00060787215, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4700, training loss= 0.00025067906, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4750, training loss= 0.00043936045, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4800, training loss= 0.00038248237, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4850, training loss= 0.00040073937, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4900, training loss= 0.0004085119, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 4950, training loss= 0.00043462316, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5000, training loss= 0.00042278614, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5050, training loss= 0.0004996681, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5100, training loss= 0.00031635477, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5150, training loss= 0.00036466974, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5200, training loss= 0.0003972434, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5250, training loss= 0.00038432586, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5300, training loss= 0.00040364408, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5350, training loss= 0.00036627846, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5400, training loss= 0.0004295692, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5450, training loss= 0.00038557977, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5500, training loss= 0.00045597655, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5550, training loss= 0.00045869438, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5600, training loss= 0.0003230842, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5650, training loss= 0.00047845434, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5700, training loss= 0.00032170903, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5750, training loss= 0.00035003846, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5800, training loss= 0.00040533865, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5850, training loss= 0.00034949134, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5900, training loss= 0.00037813155, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 5950, training loss= 0.0003983105, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6000, training loss= 0.00035709693, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6050, training loss= 0.0005909917, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6100, training loss= 0.00034433373, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6150, training loss= 0.00030031017, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6200, training loss= 0.00045709833, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6250, training loss= 0.00036970188, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6300, training loss= 0.0003433473, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6350, training loss= 0.00034572298, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6400, training loss= 0.0003629895, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6450, training loss= 0.0003600462, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6500, training loss= 0.00040292338, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6550, training loss= 0.00033849283, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6600, training loss= 0.0005092511, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6650, training loss= 0.0004145696, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6700, training loss= 0.0003487179, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6750, training loss= 0.000458143, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6800, training loss= 0.0004509251, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6850, training loss= 0.00039730052, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6900, training loss= 0.00037876426, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 6950, training loss= 0.00039064029, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7000, training loss= 0.00039052294, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7050, training loss= 0.00043239704, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7100, training loss= 0.00026035172, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7150, training loss= 0.00042263302, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7200, training loss= 0.00038556312, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7250, training loss= 0.0003747046, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7300, training loss= 0.0003292949, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7350, training loss= 0.00040192791, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7400, training loss= 0.00032115626, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7450, training loss= 0.0003844913, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7500, training loss= 0.0003431897, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7550, training loss= 0.00048448122, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7600, training loss= 0.00033264526, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7650, training loss= 0.00034765885, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7700, training loss= 0.00032460422, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7750, training loss= 0.0003158851, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7800, training loss= 0.00031778504, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7850, training loss= 0.00044757547, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7900, training loss= 0.00034229786, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 7950, training loss= 0.0003666575, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8000, training loss= 0.00033301508, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8050, training loss= 0.00034796481, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8100, training loss= 0.0005184908, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8150, training loss= 0.00044741662, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8200, training loss= 0.0002596302, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8250, training loss= 0.00039774147, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8300, training loss= 0.00038952928, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8350, training loss= 0.0004152844, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8400, training loss= 0.00038968658, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8450, training loss= 0.0003685005, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8500, training loss= 0.00030644858, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8550, training loss= 0.0003138384, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8600, training loss= 0.0004125312, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8650, training loss= 0.00042544538, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8700, training loss= 0.0003920591, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8750, training loss= 0.00033824236, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8800, training loss= 0.0003004489, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8850, training loss= 0.00049093534, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8900, training loss= 0.00031094163, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 8950, training loss= 0.00031993986, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9000, training loss= 0.00036282963, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9050, training loss= 0.0003614807, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9100, training loss= 0.0003630621, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9150, training loss= 0.00041102452, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9200, training loss= 0.00040902128, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9250, training loss= 0.00040399804, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9300, training loss= 0.0004258719, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9350, training loss= 0.00042064203, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9400, training loss= 0.00031819992, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9450, training loss= 0.0003967401, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9500, training loss= 0.00042571087, training acc= 100.0%\n",
            "Validation Accuracy 94.83333587646484 ...\n",
            "\n",
            "step 9550, training loss= 0.00032564744, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9600, training loss= 0.00036274025, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9650, training loss= 0.0003446621, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9700, training loss= 0.00041089082, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9750, training loss= 0.00028155558, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9800, training loss= 0.00035196837, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9850, training loss= 0.00039326085, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9900, training loss= 0.000424555, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 9950, training loss= 0.00037618182, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10000, training loss= 0.00032548446, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10050, training loss= 0.00033073203, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10100, training loss= 0.00031855132, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10150, training loss= 0.00035708759, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10200, training loss= 0.00035819926, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10250, training loss= 0.0003397641, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10300, training loss= 0.00030904397, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10350, training loss= 0.00032891546, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10400, training loss= 0.00044093435, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10450, training loss= 0.0003221298, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10500, training loss= 0.0003008703, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10550, training loss= 0.0004106945, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10600, training loss= 0.0002972332, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10650, training loss= 0.00040874653, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10700, training loss= 0.0004228106, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10750, training loss= 0.0003485129, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10800, training loss= 0.00028805382, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10850, training loss= 0.00037969596, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10900, training loss= 0.0003314818, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 10950, training loss= 0.00031372922, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11000, training loss= 0.00036559306, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11050, training loss= 0.00024091513, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11100, training loss= 0.00036095388, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11150, training loss= 0.0003263865, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11200, training loss= 0.00035808128, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11250, training loss= 0.00042712776, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11300, training loss= 0.00034146282, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11350, training loss= 0.00023220303, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11400, training loss= 0.0003409223, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11450, training loss= 0.00027466673, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11500, training loss= 0.0003570529, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11550, training loss= 0.00030094493, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11600, training loss= 0.00032415305, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11650, training loss= 0.00036234607, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11700, training loss= 0.0003392542, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11750, training loss= 0.00041181545, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11800, training loss= 0.00032530082, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11850, training loss= 0.00035793625, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11900, training loss= 0.00033984528, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 11950, training loss= 0.0003417238, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12000, training loss= 0.00037951133, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12050, training loss= 0.00030056402, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12100, training loss= 0.00038051466, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12150, training loss= 0.00029245717, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12200, training loss= 0.00035211872, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12250, training loss= 0.00036189854, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12300, training loss= 0.00037248168, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12350, training loss= 0.0003999219, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12400, training loss= 0.00044048444, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12450, training loss= 0.00035327655, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12500, training loss= 0.0003830144, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12550, training loss= 0.0002992097, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12600, training loss= 0.00037420006, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12650, training loss= 0.00033790155, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12700, training loss= 0.0003406318, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12750, training loss= 0.0002970108, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12800, training loss= 0.0004072595, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12850, training loss= 0.00030203204, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12900, training loss= 0.00032190475, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 12950, training loss= 0.00026957053, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13000, training loss= 0.00041808587, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13050, training loss= 0.0003333527, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13100, training loss= 0.00030365674, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13150, training loss= 0.00036623937, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13200, training loss= 0.00039444413, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13250, training loss= 0.0003636954, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13300, training loss= 0.00033148445, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13350, training loss= 0.00038915835, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13400, training loss= 0.00035588563, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13450, training loss= 0.00029600892, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13500, training loss= 0.00042092855, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13550, training loss= 0.00040225545, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13600, training loss= 0.00036523695, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13650, training loss= 0.0003823734, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13700, training loss= 0.00034816735, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13750, training loss= 0.0003714483, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13800, training loss= 0.00030363526, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13850, training loss= 0.0003759462, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13900, training loss= 0.0003190942, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 13950, training loss= 0.00032393183, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14000, training loss= 0.00043254867, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14050, training loss= 0.0003102372, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14100, training loss= 0.0003758671, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14150, training loss= 0.00037805503, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14200, training loss= 0.00040027298, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14250, training loss= 0.00034915455, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14300, training loss= 0.00032402598, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14350, training loss= 0.00028666586, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14400, training loss= 0.0003468151, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14450, training loss= 0.00028365714, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14500, training loss= 0.00040480818, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14550, training loss= 0.00030958574, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14600, training loss= 0.00031897327, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14650, training loss= 0.000375158, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14700, training loss= 0.00037183607, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14750, training loss= 0.0003739217, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14800, training loss= 0.0003643963, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14850, training loss= 0.0003464709, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14900, training loss= 0.00041427455, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 14950, training loss= 0.00028007085, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15000, training loss= 0.0003708999, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15050, training loss= 0.00040386483, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15100, training loss= 0.00034829078, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15150, training loss= 0.00033673164, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15200, training loss= 0.00035202398, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15250, training loss= 0.00036160144, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15300, training loss= 0.00032859592, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15350, training loss= 0.0003631723, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15400, training loss= 0.00037302196, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15450, training loss= 0.00039411642, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15500, training loss= 0.0003343166, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15550, training loss= 0.0002874149, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15600, training loss= 0.0003846658, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15650, training loss= 0.00033266874, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15700, training loss= 0.0003967703, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15750, training loss= 0.00032036778, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15800, training loss= 0.00041971184, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15850, training loss= 0.00040048285, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15900, training loss= 0.00032042857, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 15950, training loss= 0.00033546326, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16000, training loss= 0.00037451705, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16050, training loss= 0.00033870386, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16100, training loss= 0.0003482279, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16150, training loss= 0.00041628547, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16200, training loss= 0.00041056063, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16250, training loss= 0.0002924417, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16300, training loss= 0.0003826805, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16350, training loss= 0.00035876935, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16400, training loss= 0.00034809316, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16450, training loss= 0.00030084534, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16500, training loss= 0.00033900066, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16550, training loss= 0.00027090227, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16600, training loss= 0.00037553674, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16650, training loss= 0.0003222697, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16700, training loss= 0.00028430298, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16750, training loss= 0.00035074947, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16800, training loss= 0.0003538555, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16850, training loss= 0.00029127623, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16900, training loss= 0.00037266294, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 16950, training loss= 0.00039535575, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17000, training loss= 0.00029021074, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17050, training loss= 0.00043071617, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17100, training loss= 0.00032321215, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17150, training loss= 0.0002815682, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17200, training loss= 0.00036125694, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17250, training loss= 0.00037307118, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17300, training loss= 0.0002938398, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17350, training loss= 0.0003871439, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17400, training loss= 0.0003410149, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17450, training loss= 0.0002868076, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17500, training loss= 0.00033562595, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17550, training loss= 0.00033695958, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17600, training loss= 0.0003774837, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17650, training loss= 0.00029787555, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17700, training loss= 0.0003674452, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17750, training loss= 0.00028512173, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17800, training loss= 0.000342651, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17850, training loss= 0.00031332023, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17900, training loss= 0.0003354321, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 17950, training loss= 0.0003786475, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18000, training loss= 0.00033717984, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18050, training loss= 0.00040525262, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18100, training loss= 0.00038238772, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18150, training loss= 0.0002553898, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18200, training loss= 0.00037800093, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18250, training loss= 0.00033831235, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18300, training loss= 0.00035763663, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18350, training loss= 0.00043317673, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18400, training loss= 0.00042220592, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18450, training loss= 0.00028947298, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18500, training loss= 0.00035556484, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18550, training loss= 0.00046777326, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18600, training loss= 0.00031413368, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18650, training loss= 0.00026721152, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18700, training loss= 0.00027773174, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18750, training loss= 0.00035421344, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18800, training loss= 0.00037021865, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18850, training loss= 0.00029941488, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18900, training loss= 0.0003093234, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 18950, training loss= 0.00036208628, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19000, training loss= 0.00029545094, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19050, training loss= 0.0003614945, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19100, training loss= 0.0003852562, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19150, training loss= 0.0003297933, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19200, training loss= 0.00027960204, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19250, training loss= 0.0003175303, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19300, training loss= 0.00044696796, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19350, training loss= 0.00037051752, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19400, training loss= 0.00026990368, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19450, training loss= 0.0003299882, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19500, training loss= 0.0003645336, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19550, training loss= 0.00031434037, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19600, training loss= 0.0002989565, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19650, training loss= 0.00029311396, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19700, training loss= 0.00035637408, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19750, training loss= 0.00034596992, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19800, training loss= 0.00027393195, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19850, training loss= 0.00032990045, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19900, training loss= 0.00039729592, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 19950, training loss= 0.00035504892, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20000, training loss= 0.0003435035, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20050, training loss= 0.0003296266, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20100, training loss= 0.0002971884, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20150, training loss= 0.00027604407, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20200, training loss= 0.00033469548, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20250, training loss= 0.00031648728, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20300, training loss= 0.0002696751, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20350, training loss= 0.00035957017, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20400, training loss= 0.00035193807, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20450, training loss= 0.0003499368, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20500, training loss= 0.00027254014, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20550, training loss= 0.00035806966, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20600, training loss= 0.0002991205, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20650, training loss= 0.00038415118, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20700, training loss= 0.00033200553, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20750, training loss= 0.0003536008, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20800, training loss= 0.0003750607, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20850, training loss= 0.00038960954, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20900, training loss= 0.00036473686, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 20950, training loss= 0.00029635988, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21000, training loss= 0.0003415624, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21050, training loss= 0.00033105456, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21100, training loss= 0.0003030544, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21150, training loss= 0.00033537683, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21200, training loss= 0.00035264154, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21250, training loss= 0.00030737685, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21300, training loss= 0.00037095914, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21350, training loss= 0.00036101852, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21400, training loss= 0.00032152503, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21450, training loss= 0.00039440315, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21500, training loss= 0.00043453646, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21550, training loss= 0.0003204362, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21600, training loss= 0.000374036, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21650, training loss= 0.0003265786, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21700, training loss= 0.00037042837, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21750, training loss= 0.00038601249, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21800, training loss= 0.00031206617, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21850, training loss= 0.00034881016, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21900, training loss= 0.0003665287, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 21950, training loss= 0.0003075241, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22000, training loss= 0.00028799823, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22050, training loss= 0.00039989717, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22100, training loss= 0.00032143932, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22150, training loss= 0.00036503148, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22200, training loss= 0.00037674175, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22250, training loss= 0.00032056146, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22300, training loss= 0.0003392497, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22350, training loss= 0.00029936383, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22400, training loss= 0.00029226486, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22450, training loss= 0.0002907538, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22500, training loss= 0.00030817624, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22550, training loss= 0.00031129475, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22600, training loss= 0.00027200492, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22650, training loss= 0.00031709034, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22700, training loss= 0.00030150163, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22750, training loss= 0.0003126167, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22800, training loss= 0.00036852347, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22850, training loss= 0.00037685427, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22900, training loss= 0.0003436858, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 22950, training loss= 0.00030796663, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23000, training loss= 0.000328107, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23050, training loss= 0.00038583516, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23100, training loss= 0.0003632826, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23150, training loss= 0.00030120162, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23200, training loss= 0.00035722076, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23250, training loss= 0.00036579478, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23300, training loss= 0.00029329836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23350, training loss= 0.0004262146, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23400, training loss= 0.00038977165, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23450, training loss= 0.00026866843, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23500, training loss= 0.00034722325, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23550, training loss= 0.0003957731, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23600, training loss= 0.0003359154, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23650, training loss= 0.0003514084, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23700, training loss= 0.0003483023, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23750, training loss= 0.0004169615, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23800, training loss= 0.00035327423, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23850, training loss= 0.00028769983, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23900, training loss= 0.00035847447, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 23950, training loss= 0.00036419087, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24000, training loss= 0.00037091327, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24050, training loss= 0.00034566122, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24100, training loss= 0.00033355574, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24150, training loss= 0.0003455803, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24200, training loss= 0.00040954267, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24250, training loss= 0.0002838754, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24300, training loss= 0.00035748226, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24350, training loss= 0.00032855957, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24400, training loss= 0.00028677366, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24450, training loss= 0.00031797195, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24500, training loss= 0.00032034595, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24550, training loss= 0.00040707784, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24600, training loss= 0.00036124367, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24650, training loss= 0.00028948838, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24700, training loss= 0.00031753068, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24750, training loss= 0.00030083774, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24800, training loss= 0.0003596833, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24850, training loss= 0.00034790492, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24900, training loss= 0.00031382553, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 24950, training loss= 0.00032829164, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25000, training loss= 0.00038547997, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25050, training loss= 0.00033196565, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25100, training loss= 0.00044329104, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25150, training loss= 0.00034836074, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25200, training loss= 0.00030499412, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25250, training loss= 0.00038371477, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25300, training loss= 0.0003188521, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25350, training loss= 0.00035926775, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25400, training loss= 0.00037238625, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25450, training loss= 0.0002943437, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25500, training loss= 0.00029775777, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25550, training loss= 0.0003400948, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25600, training loss= 0.00031498255, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25650, training loss= 0.00032720342, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25700, training loss= 0.00031304918, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25750, training loss= 0.00032453943, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25800, training loss= 0.00032607815, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25850, training loss= 0.00033792894, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25900, training loss= 0.00032044004, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 25950, training loss= 0.00040110332, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26000, training loss= 0.00031646946, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26050, training loss= 0.0003932046, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26100, training loss= 0.0003503365, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26150, training loss= 0.00035677693, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26200, training loss= 0.0003446407, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26250, training loss= 0.00039884626, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26300, training loss= 0.00045604588, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26350, training loss= 0.00036967656, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26400, training loss= 0.00029675043, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26450, training loss= 0.0003417156, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26500, training loss= 0.00029595595, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26550, training loss= 0.00032075372, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26600, training loss= 0.0002973233, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26650, training loss= 0.00032366117, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26700, training loss= 0.00030652704, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26750, training loss= 0.00032857872, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26800, training loss= 0.00032006818, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26850, training loss= 0.00037357857, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26900, training loss= 0.00029936846, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 26950, training loss= 0.00033856183, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27000, training loss= 0.00034313934, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27050, training loss= 0.00031779995, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27100, training loss= 0.0003095789, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27150, training loss= 0.00035022924, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27200, training loss= 0.00028380944, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27250, training loss= 0.00032644832, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27300, training loss= 0.0002708882, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27350, training loss= 0.0003546958, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27400, training loss= 0.0003564152, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27450, training loss= 0.00035712883, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27500, training loss= 0.00035938487, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27550, training loss= 0.00032782543, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27600, training loss= 0.00033068322, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27650, training loss= 0.00028263964, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27700, training loss= 0.00037011874, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27750, training loss= 0.00030690804, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27800, training loss= 0.00028369992, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27850, training loss= 0.00038383534, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27900, training loss= 0.00032702438, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 27950, training loss= 0.00033933404, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28000, training loss= 0.0003150803, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28050, training loss= 0.00037383108, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28100, training loss= 0.0002962239, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28150, training loss= 0.0003421361, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28200, training loss= 0.00033602797, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28250, training loss= 0.00029854086, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28300, training loss= 0.00034569867, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28350, training loss= 0.00035582864, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28400, training loss= 0.0003394128, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28450, training loss= 0.00031834585, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28500, training loss= 0.00028516425, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28550, training loss= 0.0003182144, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28600, training loss= 0.0003144564, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28650, training loss= 0.00032069016, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28700, training loss= 0.00028097146, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28750, training loss= 0.00028566408, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28800, training loss= 0.0003701388, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28850, training loss= 0.0003300949, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28900, training loss= 0.00030729556, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 28950, training loss= 0.00031523232, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29000, training loss= 0.0003174646, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29050, training loss= 0.00036328353, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29100, training loss= 0.00034723317, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29150, training loss= 0.00037889514, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29200, training loss= 0.00032100422, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29250, training loss= 0.00032580722, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29300, training loss= 0.00035572643, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29350, training loss= 0.0003793306, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29400, training loss= 0.00037150137, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29450, training loss= 0.0003111219, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29500, training loss= 0.00039733096, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29550, training loss= 0.0002896504, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29600, training loss= 0.00031847658, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29650, training loss= 0.0003413137, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29700, training loss= 0.0003508269, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29750, training loss= 0.0002742714, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29800, training loss= 0.0003343202, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29850, training loss= 0.0003488435, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29900, training loss= 0.00033408805, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 29950, training loss= 0.00028351112, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30000, training loss= 0.0003355185, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30050, training loss= 0.00030418, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30100, training loss= 0.0003115103, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30150, training loss= 0.00035666238, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30200, training loss= 0.00039430836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30250, training loss= 0.00034091, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30300, training loss= 0.0003765291, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30350, training loss= 0.00027218045, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30400, training loss= 0.00029217507, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30450, training loss= 0.00029190345, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30500, training loss= 0.00032737298, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30550, training loss= 0.00038605, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30600, training loss= 0.0003137381, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30650, training loss= 0.0004313248, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30700, training loss= 0.00032108053, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30750, training loss= 0.00031433385, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30800, training loss= 0.0003204116, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30850, training loss= 0.00035381404, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30900, training loss= 0.00033018246, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 30950, training loss= 0.00034729164, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31000, training loss= 0.00033209246, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31050, training loss= 0.00033128686, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31100, training loss= 0.00035748878, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31150, training loss= 0.0003458366, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31200, training loss= 0.00026300095, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31250, training loss= 0.00030217814, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31300, training loss= 0.00033027134, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31350, training loss= 0.0003142567, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31400, training loss= 0.0003380013, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31450, training loss= 0.0002970547, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31500, training loss= 0.0002878651, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31550, training loss= 0.0003091732, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31600, training loss= 0.00027663657, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31650, training loss= 0.00033667288, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31700, training loss= 0.0003114637, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31750, training loss= 0.00036292407, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31800, training loss= 0.0003183657, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31850, training loss= 0.00033022708, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31900, training loss= 0.00027106196, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 31950, training loss= 0.00029659376, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32000, training loss= 0.00032971601, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32050, training loss= 0.00029728666, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32100, training loss= 0.0003038826, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32150, training loss= 0.0003488892, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32200, training loss= 0.000308965, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32250, training loss= 0.0002801294, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32300, training loss= 0.0003353791, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32350, training loss= 0.00031649088, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32400, training loss= 0.0002953081, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32450, training loss= 0.00035479967, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32500, training loss= 0.00032685956, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32550, training loss= 0.00028904295, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32600, training loss= 0.00030700487, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32650, training loss= 0.00031316085, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32700, training loss= 0.00032420843, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32750, training loss= 0.00029042413, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32800, training loss= 0.00031013478, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32850, training loss= 0.00032163065, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32900, training loss= 0.00030529485, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 32950, training loss= 0.0003753028, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33000, training loss= 0.00034861127, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33050, training loss= 0.0002798763, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33100, training loss= 0.00033675754, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33150, training loss= 0.00031629615, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33200, training loss= 0.0003193388, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33250, training loss= 0.000336866, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33300, training loss= 0.00032309006, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33350, training loss= 0.00035675502, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33400, training loss= 0.00034021967, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33450, training loss= 0.00030370674, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33500, training loss= 0.00032214492, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33550, training loss= 0.00030974945, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33600, training loss= 0.00033564513, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33650, training loss= 0.00034804, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33700, training loss= 0.00028030836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33750, training loss= 0.000340825, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33800, training loss= 0.0003381785, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33850, training loss= 0.00030437057, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33900, training loss= 0.00031885423, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 33950, training loss= 0.0003271428, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34000, training loss= 0.00035588772, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34050, training loss= 0.00027969124, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34100, training loss= 0.00032590717, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34150, training loss= 0.00037318832, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34200, training loss= 0.00041711706, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34250, training loss= 0.00036382597, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34300, training loss= 0.00040670476, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34350, training loss= 0.00027280944, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34400, training loss= 0.00027940993, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34450, training loss= 0.0003266875, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34500, training loss= 0.00034251742, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34550, training loss= 0.00025029606, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34600, training loss= 0.0003488864, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34650, training loss= 0.0002884249, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34700, training loss= 0.00028313982, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34750, training loss= 0.000271089, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34800, training loss= 0.0002983479, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34850, training loss= 0.00026108723, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34900, training loss= 0.00035429836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 34950, training loss= 0.00033038494, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35000, training loss= 0.00037210717, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35050, training loss= 0.000355682, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35100, training loss= 0.00033835057, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35150, training loss= 0.0003468014, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35200, training loss= 0.00033707483, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35250, training loss= 0.00030127616, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35300, training loss= 0.00033641167, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35350, training loss= 0.00030994794, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35400, training loss= 0.0003225335, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35450, training loss= 0.00031758743, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35500, training loss= 0.00037840963, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35550, training loss= 0.00034115266, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35600, training loss= 0.00031248434, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35650, training loss= 0.00031467553, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35700, training loss= 0.0003426669, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35750, training loss= 0.00036190747, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35800, training loss= 0.00033006462, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35850, training loss= 0.00035230507, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35900, training loss= 0.000346519, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 35950, training loss= 0.00023269067, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36000, training loss= 0.00034250194, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36050, training loss= 0.00032718325, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36100, training loss= 0.00032799414, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36150, training loss= 0.0004081973, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36200, training loss= 0.00035128667, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36250, training loss= 0.0003350958, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36300, training loss= 0.0003460425, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36350, training loss= 0.00031145746, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36400, training loss= 0.00031013697, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36450, training loss= 0.00026555418, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36500, training loss= 0.00030651645, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36550, training loss= 0.00035338174, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36600, training loss= 0.0003353131, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36650, training loss= 0.00031155985, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36700, training loss= 0.0004214539, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36750, training loss= 0.00033268, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36800, training loss= 0.00037551523, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36850, training loss= 0.00033616295, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36900, training loss= 0.00030500954, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 36950, training loss= 0.00038363293, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37000, training loss= 0.00035783523, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37050, training loss= 0.000332186, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37100, training loss= 0.000340784, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37150, training loss= 0.00029765078, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37200, training loss= 0.00033320836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37250, training loss= 0.00037795783, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37300, training loss= 0.00038517267, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37350, training loss= 0.0003561077, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37400, training loss= 0.00027472732, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37450, training loss= 0.00027153594, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37500, training loss= 0.000320394, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37550, training loss= 0.00037923196, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37600, training loss= 0.0003364847, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37650, training loss= 0.0002972137, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37700, training loss= 0.00030254747, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37750, training loss= 0.00027736826, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37800, training loss= 0.00036614208, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37850, training loss= 0.0003251568, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37900, training loss= 0.0003079319, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 37950, training loss= 0.00038203815, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38000, training loss= 0.00033971664, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38050, training loss= 0.00035426475, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38100, training loss= 0.00032381338, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38150, training loss= 0.00037105836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38200, training loss= 0.00035168006, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38250, training loss= 0.00034747916, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38300, training loss= 0.0002897988, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38350, training loss= 0.00026917623, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38400, training loss= 0.00035644384, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38450, training loss= 0.0002915713, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38500, training loss= 0.00032123027, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38550, training loss= 0.00033347984, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38600, training loss= 0.00035216648, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38650, training loss= 0.0003108544, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38700, training loss= 0.00030982087, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38750, training loss= 0.00034115053, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38800, training loss= 0.0003471293, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38850, training loss= 0.00029558633, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38900, training loss= 0.00034336123, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 38950, training loss= 0.0003604189, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39000, training loss= 0.00033619296, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39050, training loss= 0.00023641984, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39100, training loss= 0.0003302722, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39150, training loss= 0.00029868068, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39200, training loss= 0.0003604407, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39250, training loss= 0.00029886933, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39300, training loss= 0.00032400468, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39350, training loss= 0.00035951025, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39400, training loss= 0.00033496728, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39450, training loss= 0.000332519, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39500, training loss= 0.0003179577, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39550, training loss= 0.00033710196, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39600, training loss= 0.00039605514, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39650, training loss= 0.00033328898, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39700, training loss= 0.00033877805, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39750, training loss= 0.00029193144, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39800, training loss= 0.0002828877, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39850, training loss= 0.00034876607, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39900, training loss= 0.0003182019, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 39950, training loss= 0.00036307104, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40000, training loss= 0.00032564774, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40050, training loss= 0.0003646852, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40100, training loss= 0.00035612925, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40150, training loss= 0.0003569068, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40200, training loss= 0.0003493125, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40250, training loss= 0.00030784155, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40300, training loss= 0.00028028886, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40350, training loss= 0.0003271044, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40400, training loss= 0.00031942784, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40450, training loss= 0.00026203078, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40500, training loss= 0.00037081185, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40550, training loss= 0.0003904315, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40600, training loss= 0.00034102247, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40650, training loss= 0.0003287318, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40700, training loss= 0.00026747974, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40750, training loss= 0.00035930282, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40800, training loss= 0.00035577457, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40850, training loss= 0.0003233983, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40900, training loss= 0.0003458787, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 40950, training loss= 0.00029259737, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41000, training loss= 0.0003182325, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41050, training loss= 0.0003334733, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41100, training loss= 0.00031641847, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41150, training loss= 0.00031976603, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41200, training loss= 0.00029696655, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41250, training loss= 0.0003281245, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41300, training loss= 0.00033619333, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41350, training loss= 0.00030603923, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41400, training loss= 0.00029862692, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41450, training loss= 0.00031873255, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41500, training loss= 0.00034929605, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41550, training loss= 0.00032392662, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41600, training loss= 0.0003546021, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41650, training loss= 0.00034062608, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41700, training loss= 0.00036427533, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41750, training loss= 0.00026200674, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41800, training loss= 0.0003237711, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41850, training loss= 0.00032986747, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41900, training loss= 0.00029782148, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 41950, training loss= 0.00029128807, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42000, training loss= 0.0003626906, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42050, training loss= 0.00030384515, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42100, training loss= 0.00033656374, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42150, training loss= 0.0003019508, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42200, training loss= 0.00028709436, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42250, training loss= 0.0002757463, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42300, training loss= 0.00030914665, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42350, training loss= 0.00031543404, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42400, training loss= 0.00031610945, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42450, training loss= 0.00028477027, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42500, training loss= 0.0003612604, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42550, training loss= 0.00032777723, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42600, training loss= 0.00029000864, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42650, training loss= 0.00035195836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42700, training loss= 0.00036878782, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42750, training loss= 0.0003488281, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42800, training loss= 0.00032971147, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42850, training loss= 0.00029476514, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42900, training loss= 0.00029731632, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 42950, training loss= 0.00034354406, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43000, training loss= 0.00037480023, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43050, training loss= 0.00034135458, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43100, training loss= 0.00031903654, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43150, training loss= 0.00035360013, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43200, training loss= 0.0002551668, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43250, training loss= 0.00032231383, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43300, training loss= 0.00030383383, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43350, training loss= 0.00032083114, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43400, training loss= 0.0002827129, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43450, training loss= 0.00027181848, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43500, training loss= 0.0003744759, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43550, training loss= 0.00031564521, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43600, training loss= 0.0003551794, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43650, training loss= 0.00027534965, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43700, training loss= 0.00033825863, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43750, training loss= 0.00027866912, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43800, training loss= 0.0003574929, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43850, training loss= 0.0002866026, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43900, training loss= 0.00029015768, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 43950, training loss= 0.00030864245, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44000, training loss= 0.000298598, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44050, training loss= 0.0003298767, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44100, training loss= 0.0003321059, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44150, training loss= 0.00031437853, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44200, training loss= 0.00034224332, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44250, training loss= 0.00037951214, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44300, training loss= 0.0002906663, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44350, training loss= 0.0002513169, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44400, training loss= 0.0002785571, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44450, training loss= 0.00029851744, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44500, training loss= 0.0003156068, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44550, training loss= 0.0003036132, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44600, training loss= 0.0003462332, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44650, training loss= 0.00028736953, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44700, training loss= 0.00036350184, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44750, training loss= 0.00031200977, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44800, training loss= 0.00030432476, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44850, training loss= 0.0003170012, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44900, training loss= 0.00033240716, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 44950, training loss= 0.00036968442, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45000, training loss= 0.0003124683, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45050, training loss= 0.0003530274, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45100, training loss= 0.0003739811, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45150, training loss= 0.00029048813, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45200, training loss= 0.00032342813, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45250, training loss= 0.00037121642, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45300, training loss= 0.00033011014, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45350, training loss= 0.00030024565, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45400, training loss= 0.00035831888, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45450, training loss= 0.00027427255, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45500, training loss= 0.0003340084, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45550, training loss= 0.00036782245, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45600, training loss= 0.00034058484, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45650, training loss= 0.00036406927, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45700, training loss= 0.00031680745, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45750, training loss= 0.00030398005, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45800, training loss= 0.0003627836, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45850, training loss= 0.00031663495, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45900, training loss= 0.0003355784, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 45950, training loss= 0.00035748625, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46000, training loss= 0.00035793416, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46050, training loss= 0.00035053058, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46100, training loss= 0.00029754636, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46150, training loss= 0.00026348827, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46200, training loss= 0.00032673046, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46250, training loss= 0.00031597633, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46300, training loss= 0.00028339148, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46350, training loss= 0.00037018966, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46400, training loss= 0.00036884405, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46450, training loss= 0.0003868075, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46500, training loss= 0.00034264926, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46550, training loss= 0.00038339553, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46600, training loss= 0.00034638043, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46650, training loss= 0.00036985197, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46700, training loss= 0.00034296024, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46750, training loss= 0.00026801697, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46800, training loss= 0.00028976408, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46850, training loss= 0.0004000125, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46900, training loss= 0.00031734045, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 46950, training loss= 0.00032135437, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47000, training loss= 0.0002942373, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47050, training loss= 0.0003348189, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47100, training loss= 0.00028027664, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47150, training loss= 0.00025129443, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47200, training loss= 0.00032392985, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47250, training loss= 0.00032649506, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47300, training loss= 0.00038309436, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47350, training loss= 0.00033403942, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47400, training loss= 0.0003133355, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47450, training loss= 0.00036276632, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47500, training loss= 0.00034799945, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47550, training loss= 0.0003345078, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47600, training loss= 0.00030161804, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47650, training loss= 0.0003086067, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47700, training loss= 0.00032962582, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47750, training loss= 0.0003379721, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47800, training loss= 0.00036295864, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47850, training loss= 0.00030678482, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47900, training loss= 0.00023804979, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 47950, training loss= 0.00031524608, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48000, training loss= 0.00034347628, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48050, training loss= 0.00029781947, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48100, training loss= 0.00037552754, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48150, training loss= 0.00040399257, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48200, training loss= 0.00029508586, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48250, training loss= 0.00028351747, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48300, training loss= 0.00033882307, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48350, training loss= 0.0003054109, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48400, training loss= 0.0002567615, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48450, training loss= 0.00030925628, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48500, training loss= 0.00035495078, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48550, training loss= 0.00029659984, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48600, training loss= 0.00037757485, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48650, training loss= 0.00031106966, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48700, training loss= 0.00028973373, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48750, training loss= 0.0003875384, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48800, training loss= 0.00031489728, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48850, training loss= 0.00030443026, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48900, training loss= 0.0003220914, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 48950, training loss= 0.0003537553, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49000, training loss= 0.00030018247, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49050, training loss= 0.0002889172, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49100, training loss= 0.00040441085, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49150, training loss= 0.0003017926, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49200, training loss= 0.00030595605, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49250, training loss= 0.0003115564, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49300, training loss= 0.00030402307, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49350, training loss= 0.00038667186, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49400, training loss= 0.0003023324, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49450, training loss= 0.00020401318, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49500, training loss= 0.00024141964, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49550, training loss= 0.00034981902, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49600, training loss= 0.00032667365, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49650, training loss= 0.0003018389, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49700, training loss= 0.00033615658, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49750, training loss= 0.00023150795, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49800, training loss= 0.0003357101, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49850, training loss= 0.0003264813, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49900, training loss= 0.00030014984, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "step 49950, training loss= 0.00037236218, training acc= 100.0%\n",
            "Validation Accuracy 95.0 ...\n",
            "\n",
            "Valid acc= 95.0 %\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwY5Bt2EM3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kwd9EKfLM3Z9",
        "colab_type": "code",
        "outputId": "c270d795-323c-4031-8dae-2b1b7bfc2c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MpHiEL6VM3aB",
        "colab_type": "code",
        "outputId": "e1ba4fa1-aaae-432d-d100-2773b5e6cdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.0\n",
            "191\n",
            "9550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_l2RRE0M3aE",
        "colab_type": "code",
        "outputId": "691fa3c6-3a8e-467e-8626-f26ebefa90a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1400, 3)\n",
            "(2000, 138)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HaKv7GnsM3aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 200\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wFozSByYtUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b52f00ee-4d3d-4086-94cc-b287dddec160"
      },
      "cell_type": "code",
      "source": [
        "aside_valid_test.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "G1MSxJHkHXBa",
        "colab_type": "code",
        "outputId": "8f268e25-69a3-4e0b-f8c2-813bb12386f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20536
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "num_steps = 400000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 1000\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.2348537, training acc= 99.50000047683716%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 1000, training loss= 0.03011016, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 2000, training loss= 0.0023410586, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 3000, training loss= 0.005833473, training acc= 99.50000047683716%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 4000, training loss= 0.0038047521, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 5000, training loss= 0.006515391, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 6000, training loss= 0.0033875112, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 7000, training loss= 0.002537663, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 8000, training loss= 0.0048063644, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 9000, training loss= 0.00257105, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 10000, training loss= 0.0010322462, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 11000, training loss= 0.0022496025, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 12000, training loss= 0.00407504, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 13000, training loss= 0.0020097399, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 14000, training loss= 0.0014869665, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 15000, training loss= 0.0023573046, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 16000, training loss= 0.00244622, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 17000, training loss= 0.0019783606, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 18000, training loss= 0.0066685695, training acc= 99.50000047683716%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 19000, training loss= 0.0009994442, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 20000, training loss= 0.0013938264, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 21000, training loss= 0.0020429231, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 22000, training loss= 0.0020797413, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 23000, training loss= 0.0018102133, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 24000, training loss= 0.00193051, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 25000, training loss= 0.0019026936, training acc= 100.0%\n",
            "Validation Accuracy 91.5 ...\n",
            "\n",
            "step 26000, training loss= 0.001729725, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 27000, training loss= 0.001066332, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 28000, training loss= 0.001339005, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 29000, training loss= 0.0012482094, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 30000, training loss= 0.0012339567, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 31000, training loss= 0.00078549556, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 32000, training loss= 0.0014378144, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 33000, training loss= 0.001213522, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 34000, training loss= 0.0014894283, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 35000, training loss= 0.0024422696, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 36000, training loss= 0.0012078476, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 37000, training loss= 0.0011772614, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 38000, training loss= 0.0016601273, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 39000, training loss= 0.0015972458, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 40000, training loss= 0.0006839825, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 41000, training loss= 0.0020946988, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 42000, training loss= 0.00088676374, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 43000, training loss= 0.0012941038, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 44000, training loss= 0.0016482107, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 45000, training loss= 0.0011114863, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 46000, training loss= 0.0014157848, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 47000, training loss= 0.0013270428, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 48000, training loss= 0.0012687884, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 49000, training loss= 0.0018497013, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 50000, training loss= 0.0016855128, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 51000, training loss= 0.0015001635, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 52000, training loss= 0.000978837, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 53000, training loss= 0.0012259181, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 54000, training loss= 0.0014453713, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 55000, training loss= 0.001148069, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 56000, training loss= 0.0008395672, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 57000, training loss= 0.0014014218, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 58000, training loss= 0.0008578825, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 59000, training loss= 0.001221628, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 60000, training loss= 0.00093531935, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 61000, training loss= 0.0014436664, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 62000, training loss= 0.0008939377, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 63000, training loss= 0.0010034934, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 64000, training loss= 0.00057016884, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 65000, training loss= 0.0009799585, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 66000, training loss= 0.00080207887, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 67000, training loss= 0.0016621676, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 68000, training loss= 0.0013809095, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 69000, training loss= 0.00064478256, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 70000, training loss= 0.0009533223, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 71000, training loss= 0.0011806262, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 72000, training loss= 0.0011030589, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 73000, training loss= 0.0010884489, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 74000, training loss= 0.0010429833, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 75000, training loss= 0.00067018956, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 76000, training loss= 0.0009046922, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 77000, training loss= 0.00085643167, training acc= 100.0%\n",
            "Validation Accuracy 92.0 ...\n",
            "\n",
            "step 78000, training loss= 0.00076670735, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 79000, training loss= 0.0011161086, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 80000, training loss= 0.00078498025, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 81000, training loss= 0.0009187112, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 82000, training loss= 0.001198462, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 83000, training loss= 0.00091239257, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 84000, training loss= 0.00046205174, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 85000, training loss= 0.00093973475, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 86000, training loss= 0.0008485517, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 87000, training loss= 0.0011877249, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 88000, training loss= 0.00086071866, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 89000, training loss= 0.0012445967, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 90000, training loss= 0.000771301, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 91000, training loss= 0.00091016927, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 92000, training loss= 0.0007586148, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 93000, training loss= 0.00078728393, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 94000, training loss= 0.00094919465, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 95000, training loss= 0.0009069363, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 96000, training loss= 0.0005627516, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 97000, training loss= 0.0010289474, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 98000, training loss= 0.0007541635, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 99000, training loss= 0.00069996796, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 100000, training loss= 0.00075536023, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 101000, training loss= 0.0010472578, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 102000, training loss= 0.0009719086, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 103000, training loss= 0.00094476686, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 104000, training loss= 0.00052997324, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 105000, training loss= 0.00074726803, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 106000, training loss= 0.0008709638, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 107000, training loss= 0.00076004124, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 108000, training loss= 0.0010278025, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 109000, training loss= 0.00077548757, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 110000, training loss= 0.00079614075, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 111000, training loss= 0.0007460135, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 112000, training loss= 0.001022042, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 113000, training loss= 0.0007804448, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 114000, training loss= 0.000650687, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 115000, training loss= 0.0005985051, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 116000, training loss= 0.00090839865, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 117000, training loss= 0.0007937001, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 118000, training loss= 0.00089351466, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 119000, training loss= 0.00059922785, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 120000, training loss= 0.0009104279, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 121000, training loss= 0.00078272296, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 122000, training loss= 0.0008847625, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 123000, training loss= 0.0006779827, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 124000, training loss= 0.00061826577, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 125000, training loss= 0.00059583556, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 126000, training loss= 0.00079201115, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 127000, training loss= 0.0007930212, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 128000, training loss= 0.00069673907, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 129000, training loss= 0.0006275169, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 130000, training loss= 0.0008724843, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 131000, training loss= 0.00064737326, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 132000, training loss= 0.00085912267, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 133000, training loss= 0.0008061686, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 134000, training loss= 0.00078748056, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 135000, training loss= 0.0006135512, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 136000, training loss= 0.00087201316, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 137000, training loss= 0.0009887571, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 138000, training loss= 0.0006367568, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 139000, training loss= 0.0009399716, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 140000, training loss= 0.0005877788, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 141000, training loss= 0.0005468168, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 142000, training loss= 0.0007228447, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 143000, training loss= 0.0008125388, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 144000, training loss= 0.0008826481, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 145000, training loss= 0.00079938775, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 146000, training loss= 0.00092311075, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 147000, training loss= 0.0010712132, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 148000, training loss= 0.0006853561, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 149000, training loss= 0.00087954703, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 150000, training loss= 0.0006203289, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 151000, training loss= 0.0008032461, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 152000, training loss= 0.0007545209, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 153000, training loss= 0.0007236629, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 154000, training loss= 0.0007024903, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 155000, training loss= 0.00065265974, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 156000, training loss= 0.00078649615, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 157000, training loss= 0.0007361165, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 158000, training loss= 0.0006026701, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 159000, training loss= 0.00069058756, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 160000, training loss= 0.00067715463, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 161000, training loss= 0.00073673297, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 162000, training loss= 0.00064480037, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 163000, training loss= 0.00073599507, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 164000, training loss= 0.00072883227, training acc= 100.0%\n",
            "Validation Accuracy 93.0 ...\n",
            "\n",
            "step 165000, training loss= 0.00062829856, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 166000, training loss= 0.0008945733, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 167000, training loss= 0.0008124049, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 168000, training loss= 0.0008206669, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 169000, training loss= 0.00049486686, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 170000, training loss= 0.00077229517, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 171000, training loss= 0.0006464303, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 172000, training loss= 0.0006288209, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 173000, training loss= 0.0007312225, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 174000, training loss= 0.00060696295, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 175000, training loss= 0.0005873238, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 176000, training loss= 0.0008893296, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 177000, training loss= 0.00078461657, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 178000, training loss= 0.0007422764, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 179000, training loss= 0.000866539, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 180000, training loss= 0.0006723192, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 181000, training loss= 0.00052393717, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 182000, training loss= 0.00065209775, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 183000, training loss= 0.00063092244, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 184000, training loss= 0.00069805485, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 185000, training loss= 0.00053276855, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 186000, training loss= 0.000519303, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 187000, training loss= 0.00075176026, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 188000, training loss= 0.00061436224, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 189000, training loss= 0.000661416, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 190000, training loss= 0.0006923511, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 191000, training loss= 0.00059808505, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 192000, training loss= 0.00064083893, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 193000, training loss= 0.00048136883, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 194000, training loss= 0.00050130644, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 195000, training loss= 0.0006809638, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 196000, training loss= 0.00066292204, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 197000, training loss= 0.00056931726, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 198000, training loss= 0.0006175018, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 199000, training loss= 0.0006627338, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 200000, training loss= 0.00062320207, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 201000, training loss= 0.00070872455, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 202000, training loss= 0.00067423994, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 203000, training loss= 0.00050578447, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 204000, training loss= 0.0006740562, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 205000, training loss= 0.0007742092, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 206000, training loss= 0.0007584128, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 207000, training loss= 0.0006531946, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 208000, training loss= 0.00058841595, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 209000, training loss= 0.0006614364, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 210000, training loss= 0.0005007464, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 211000, training loss= 0.0005685622, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 212000, training loss= 0.0005720774, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 213000, training loss= 0.00066340354, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 214000, training loss= 0.0005070208, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 215000, training loss= 0.0004937206, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 216000, training loss= 0.0006358066, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 217000, training loss= 0.000706694, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 218000, training loss= 0.00056581624, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 219000, training loss= 0.0006148256, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 220000, training loss= 0.0005751335, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 221000, training loss= 0.00065113744, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 222000, training loss= 0.0004898685, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 223000, training loss= 0.000499303, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 224000, training loss= 0.0005366006, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 225000, training loss= 0.0004349875, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 226000, training loss= 0.00041407702, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 227000, training loss= 0.0005210874, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 228000, training loss= 0.00061276165, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 229000, training loss= 0.00046329034, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 230000, training loss= 0.00061721966, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 231000, training loss= 0.0005577007, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 232000, training loss= 0.0004929922, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 233000, training loss= 0.00056564686, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 234000, training loss= 0.00040308523, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 235000, training loss= 0.0005080456, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 236000, training loss= 0.00040423987, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 237000, training loss= 0.00057470106, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 238000, training loss= 0.00058824447, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 239000, training loss= 0.0006094802, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 240000, training loss= 0.00059025374, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 241000, training loss= 0.0006364321, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 242000, training loss= 0.00056574895, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 243000, training loss= 0.00047673934, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 244000, training loss= 0.0006669549, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 245000, training loss= 0.00050963624, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 246000, training loss= 0.00055759604, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 247000, training loss= 0.0006849953, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 248000, training loss= 0.0005480028, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 249000, training loss= 0.00037795334, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 250000, training loss= 0.00045541525, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 251000, training loss= 0.00034920848, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 252000, training loss= 0.00050913857, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 253000, training loss= 0.00055651413, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 254000, training loss= 0.00054517813, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 255000, training loss= 0.00053208886, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 256000, training loss= 0.0005939145, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 257000, training loss= 0.0006105999, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 258000, training loss= 0.00047242598, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 259000, training loss= 0.00039516122, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 260000, training loss= 0.0005187119, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 261000, training loss= 0.000352846, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 262000, training loss= 0.00036101957, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 263000, training loss= 0.0005695057, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 264000, training loss= 0.0004849687, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 265000, training loss= 0.0004730494, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 266000, training loss= 0.00041444984, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 267000, training loss= 0.00077812606, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 268000, training loss= 0.0003982164, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 269000, training loss= 0.00040385206, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 270000, training loss= 0.0005717813, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 271000, training loss= 0.00045124907, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 272000, training loss= 0.00055587053, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 273000, training loss= 0.00048157907, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 274000, training loss= 0.00044728455, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 275000, training loss= 0.00045696824, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 276000, training loss= 0.0005355204, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 277000, training loss= 0.0005164239, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 278000, training loss= 0.0004015842, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 279000, training loss= 0.00052516913, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 280000, training loss= 0.00039805635, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 281000, training loss= 0.0005118706, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 282000, training loss= 0.00043892855, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 283000, training loss= 0.00055500073, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 284000, training loss= 0.0004938165, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 285000, training loss= 0.00047170868, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 286000, training loss= 0.00039772785, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 287000, training loss= 0.00038605733, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 288000, training loss= 0.000551628, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 289000, training loss= 0.0004212423, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 290000, training loss= 0.00031232386, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 291000, training loss= 0.00048289605, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 292000, training loss= 0.0006187393, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 293000, training loss= 0.0004941412, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 294000, training loss= 0.00047562728, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 295000, training loss= 0.00042938333, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 296000, training loss= 0.0005006927, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 297000, training loss= 0.00055374706, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 298000, training loss= 0.00052241905, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 299000, training loss= 0.00048235833, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 300000, training loss= 0.00044074925, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 301000, training loss= 0.00030603865, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 302000, training loss= 0.0006091047, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 303000, training loss= 0.00051684165, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 304000, training loss= 0.00039083208, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 305000, training loss= 0.00046802394, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 306000, training loss= 0.0004304256, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 307000, training loss= 0.00038410028, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 308000, training loss= 0.00055175356, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 309000, training loss= 0.00049816037, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 310000, training loss= 0.00046797364, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 311000, training loss= 0.00040445323, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 312000, training loss= 0.00042742348, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 313000, training loss= 0.00059771095, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 314000, training loss= 0.0004158992, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 315000, training loss= 0.00053826295, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 316000, training loss= 0.0005752135, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 317000, training loss= 0.000476936, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 318000, training loss= 0.00042276803, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 319000, training loss= 0.00037272845, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 320000, training loss= 0.00042945702, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 321000, training loss= 0.0004695722, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 322000, training loss= 0.0005675062, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 323000, training loss= 0.0005327921, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 324000, training loss= 0.00047360137, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 325000, training loss= 0.00038829912, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 326000, training loss= 0.00043924194, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 327000, training loss= 0.0003100198, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 328000, training loss= 0.00053279125, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 329000, training loss= 0.00032010078, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 330000, training loss= 0.00042782797, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 331000, training loss= 0.00044750297, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 332000, training loss= 0.00036288844, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 333000, training loss= 0.00039669083, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 334000, training loss= 0.0005093832, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 335000, training loss= 0.00050178834, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 336000, training loss= 0.00037482375, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 337000, training loss= 0.0004750392, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 338000, training loss= 0.0004362189, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 339000, training loss= 0.00037499313, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 340000, training loss= 0.0005243396, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 341000, training loss= 0.00035062744, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 342000, training loss= 0.00038392658, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 343000, training loss= 0.00045545623, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 344000, training loss= 0.00039052733, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 345000, training loss= 0.00038711203, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 346000, training loss= 0.00040597902, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 347000, training loss= 0.00040097808, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 348000, training loss= 0.00043786413, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 349000, training loss= 0.00039738737, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 350000, training loss= 0.0005791558, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 351000, training loss= 0.0003634776, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 352000, training loss= 0.0003970353, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 353000, training loss= 0.0005760718, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 354000, training loss= 0.0005013667, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 355000, training loss= 0.0003919899, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 356000, training loss= 0.00040749085, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 357000, training loss= 0.00033770705, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 358000, training loss= 0.00032912238, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 359000, training loss= 0.00039308457, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 360000, training loss= 0.0004184203, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 361000, training loss= 0.0004363905, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 362000, training loss= 0.00037927937, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 363000, training loss= 0.00046585736, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 364000, training loss= 0.00039683582, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 365000, training loss= 0.00047597048, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 366000, training loss= 0.0005759378, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 367000, training loss= 0.0004599007, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 368000, training loss= 0.00040308756, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 369000, training loss= 0.00038839292, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 370000, training loss= 0.00044136486, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 371000, training loss= 0.00044918645, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 372000, training loss= 0.00035251275, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 373000, training loss= 0.00037185723, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 374000, training loss= 0.00043944197, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 375000, training loss= 0.0003794062, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 376000, training loss= 0.00036078526, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 377000, training loss= 0.00037683235, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 378000, training loss= 0.00049502816, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 379000, training loss= 0.0004024155, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 380000, training loss= 0.0003470342, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 381000, training loss= 0.00055619125, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 382000, training loss= 0.000401184, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 383000, training loss= 0.00044158025, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 384000, training loss= 0.00040927093, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 385000, training loss= 0.000522682, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 386000, training loss= 0.00033582194, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 387000, training loss= 0.0004201721, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 388000, training loss= 0.00049276586, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 389000, training loss= 0.00046146734, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 390000, training loss= 0.0005272427, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 391000, training loss= 0.00034744784, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 392000, training loss= 0.00032940763, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 393000, training loss= 0.00043640673, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 394000, training loss= 0.00040342956, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 395000, training loss= 0.00043759533, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 396000, training loss= 0.0004711355, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 397000, training loss= 0.00038082025, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 398000, training loss= 0.00041979388, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "step 399000, training loss= 0.0005007749, training acc= 100.0%\n",
            "Validation Accuracy 92.5 ...\n",
            "\n",
            "Valid acc= 93.0 %\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aYl3LFP7IjVg",
        "colab_type": "code",
        "outputId": "3c13f6cf-db92-4e5e-94d9-46e76e2f3aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYrFJkrJisUmSsmKxSZKyYrFJkrLy/wG+KRIrjxyo9QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9cYJNXuvJFdv",
        "colab_type": "code",
        "outputId": "60f8ce4f-af22-4b0d-ae26-342d2254d553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.0\n",
            "105\n",
            "105000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRpkJTtqM3aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 100 steps"
      ]
    },
    {
      "metadata": {
        "id": "skxkk4QCW-oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07bb7faf-802a-4059-c774-2bf3942b5d10"
      },
      "cell_type": "code",
      "source": [
        "train_label_one_hot.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "metadata": {
        "id": "uSfojsVTXYvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b29d717-62c3-4e9a-9605-f936537994c2"
      },
      "cell_type": "code",
      "source": [
        "rand_perm = np.random.permutation(train_valid_combined.shape[0])\n",
        "rand_perm"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 127, 1471,  611, ...,  152, 1894,  507])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "vhsOxjezXtPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffled = train_valid_combined[rand_perm,:]\n",
        "validation_test_label_one_hot_shuffled = validation_test_label_one_hot[rand_perm,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeynTgWDX2RF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_valid_combined[1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPCwMSvsX0oJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_valid_combined_shuffled[1,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAwX7RnJJb4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 200\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot_shuffled[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot_shuffled[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjYNRgqKVbIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plt.hist((np.argmax(validation_label_one_hot,axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Uifa_UHiM3aK",
        "colab_type": "code",
        "outputId": "daa4e91f-dbd2-4fc2-8f47-3f69ca14e2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3570
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 50000\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 500\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 #+ tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 0.26469457, training acc total= 98.33333492279053%\n",
            "ValidTest acc= 99.5 %\n",
            "step 500, training loss Total= 0.06306044, training acc total= 98.38888645172119%\n",
            "ValidTest acc= 99.5 %\n",
            "step 1000, training loss Total= 0.05201964, training acc total= 98.50000143051147%\n",
            "ValidTest acc= 99.5 %\n",
            "step 1500, training loss Total= 0.045948684, training acc total= 98.61111044883728%\n",
            "ValidTest acc= 99.5 %\n",
            "step 2000, training loss Total= 0.04155818, training acc total= 98.66666793823242%\n",
            "ValidTest acc= 99.5 %\n",
            "step 2500, training loss Total= 0.037894666, training acc total= 98.77777695655823%\n",
            "ValidTest acc= 99.5 %\n",
            "step 3000, training loss Total= 0.03477889, training acc total= 99.11110997200012%\n",
            "ValidTest acc= 99.5 %\n",
            "step 3500, training loss Total= 0.032115217, training acc total= 99.2222249507904%\n",
            "ValidTest acc= 99.5 %\n",
            "step 4000, training loss Total= 0.02951693, training acc total= 99.38889145851135%\n",
            "ValidTest acc= 99.5 %\n",
            "step 4500, training loss Total= 0.027186291, training acc total= 99.5555579662323%\n",
            "ValidTest acc= 99.5 %\n",
            "step 5000, training loss Total= 0.025377484, training acc total= 99.5555579662323%\n",
            "ValidTest acc= 99.5 %\n",
            "step 5500, training loss Total= 0.023907784, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 6000, training loss Total= 0.022662988, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 6500, training loss Total= 0.02148004, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 7000, training loss Total= 0.020461798, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 7500, training loss Total= 0.019567901, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 8000, training loss Total= 0.018711084, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 8500, training loss Total= 0.017968234, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 9000, training loss Total= 0.017265473, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 9500, training loss Total= 0.016576132, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 10000, training loss Total= 0.015967619, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 10500, training loss Total= 0.0152827, training acc total= 99.61110949516296%\n",
            "ValidTest acc= 99.5 %\n",
            "step 11000, training loss Total= 0.014634956, training acc total= 99.6666669845581%\n",
            "ValidTest acc= 99.5 %\n",
            "step 11500, training loss Total= 0.014050067, training acc total= 99.6666669845581%\n",
            "ValidTest acc= 99.5 %\n",
            "step 12000, training loss Total= 0.013488039, training acc total= 99.6666669845581%\n",
            "ValidTest acc= 99.5 %\n",
            "step 12500, training loss Total= 0.012830293, training acc total= 99.72222447395325%\n",
            "ValidTest acc= 99.5 %\n",
            "step 13000, training loss Total= 0.012252177, training acc total= 99.72222447395325%\n",
            "ValidTest acc= 99.5 %\n",
            "step 13500, training loss Total= 0.011837385, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 14000, training loss Total= 0.011487787, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 14500, training loss Total= 0.011208821, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 15000, training loss Total= 0.010924294, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 15500, training loss Total= 0.010688585, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 16000, training loss Total= 0.010434391, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 16500, training loss Total= 0.010181541, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 17000, training loss Total= 0.009961367, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 17500, training loss Total= 0.00974774, training acc total= 99.83333349227905%\n",
            "ValidTest acc= 99.5 %\n",
            "step 18000, training loss Total= 0.009526708, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 18500, training loss Total= 0.009332544, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 19000, training loss Total= 0.009154019, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 19500, training loss Total= 0.008964218, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 20000, training loss Total= 0.008794956, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 20500, training loss Total= 0.008626172, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 21000, training loss Total= 0.008469339, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 21500, training loss Total= 0.0083229765, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 22000, training loss Total= 0.008177905, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 22500, training loss Total= 0.008030584, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 23000, training loss Total= 0.007887129, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 23500, training loss Total= 0.007750858, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 24000, training loss Total= 0.0076465, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 24500, training loss Total= 0.007511671, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 25000, training loss Total= 0.007402378, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 25500, training loss Total= 0.0072867554, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 26000, training loss Total= 0.0071698288, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 26500, training loss Total= 0.0070478837, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 27000, training loss Total= 0.00692485, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 27500, training loss Total= 0.0068058902, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 28000, training loss Total= 0.0066879285, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 28500, training loss Total= 0.0065664556, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 29000, training loss Total= 0.00643952, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 29500, training loss Total= 0.0063207126, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 30000, training loss Total= 0.0061815977, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 30500, training loss Total= 0.006038364, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 31000, training loss Total= 0.0058830827, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 31500, training loss Total= 0.005700561, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 32000, training loss Total= 0.005490279, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 32500, training loss Total= 0.0052808346, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 33000, training loss Total= 0.005148618, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 33500, training loss Total= 0.0050419397, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 34000, training loss Total= 0.0049489234, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 34500, training loss Total= 0.004869045, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 35000, training loss Total= 0.00478781, training acc total= 99.8888909816742%\n",
            "ValidTest acc= 99.5 %\n",
            "step 35500, training loss Total= 0.004714863, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 36000, training loss Total= 0.0046404125, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 36500, training loss Total= 0.0045699244, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 37000, training loss Total= 0.004511208, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 37500, training loss Total= 0.0044521596, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 38000, training loss Total= 0.004396943, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 38500, training loss Total= 0.0043347627, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 39000, training loss Total= 0.0042819404, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 39500, training loss Total= 0.004224355, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 40000, training loss Total= 0.0041708956, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 40500, training loss Total= 0.004118148, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 41000, training loss Total= 0.004062992, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 41500, training loss Total= 0.0040161926, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 42000, training loss Total= 0.0039698924, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 42500, training loss Total= 0.0039179707, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 43000, training loss Total= 0.003861212, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 43500, training loss Total= 0.0038214612, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 44000, training loss Total= 0.003764395, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 44500, training loss Total= 0.0037131873, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 45000, training loss Total= 0.0036637152, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 45500, training loss Total= 0.0036094775, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 46000, training loss Total= 0.0035605088, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 46500, training loss Total= 0.0035042928, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 47000, training loss Total= 0.0034558123, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 47500, training loss Total= 0.0034100863, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 48000, training loss Total= 0.0033535734, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 48500, training loss Total= 0.0032951778, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 49000, training loss Total= 0.0032447665, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "step 49500, training loss Total= 0.0031849423, training acc total= 99.94444251060486%\n",
            "ValidTest acc= 99.5 %\n",
            "ValidValid acc= 99.666664 %\n",
            "ValidTest acc= 99.5 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "3\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ft97oy5cM3aN",
        "colab_type": "code",
        "outputId": "63a3169a-f296-4c49-cce8-296c98e67363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./Pendigit\n",
            "ValidValid acc= 99.666664 %\n",
            "Test acc= 93.67622 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWblrxpgM3aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihtQRjvnM3aV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LUJzvaHZ6B3v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "best_weights = {'G_W1': G_W1np, 'G_b1': G_b1np,'G_W2': G_W2np, 'G_b2': G_b2np}\n",
        "scipy.io.savemat('HarFullDataset03212019_sgd', best_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9WWYbkum6Kl4"
      },
      "cell_type": "markdown",
      "source": [
        "## Verify handover works"
      ]
    },
    {
      "metadata": {
        "id": "2BZiy1Lgx0b4",
        "colab_type": "code",
        "outputId": "c656a113-9e09-4fb4-9e66-74752fce8528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i-MLbTOJQFQJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "id": "4OUfN10LXAQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48387104-dc8d-4157-f0f1-6ec42991e9ba"
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "oGbmg23bXJc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "303c8201-ba29-497e-d803-b1b427144f6c"
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1400, 138)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "qNDRZHqKXQtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4265ba7d-045a-464c-a4b5-bd2fce9c4980"
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(550, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "qskzaaBJYSpb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BkroR_XQFQK",
        "outputId": "dda6f50e-f62e-43ea-cf79-5b04a631cc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308737
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,5):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.08685601, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.05461884, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.040203135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.008837557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.008199044, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.01309715, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.012248204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.019178174, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.015277765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0038450107, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.015640961, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0019637125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.0044189463, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.0016439598, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0017405248, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.00076446333, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0019779205, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.004186938, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0019372951, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.0042792144, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.0028944216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0006404094, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.0020760458, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.00040904077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.0024326777, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.0017994061, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.0004823272, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.0021276288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.000914449, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.00095051737, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.0007077943, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.0006948288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.0015226074, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.00054338906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.00071210385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.0006994944, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.0007994576, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.0005730151, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.00059143803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.00038571603, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.0006129261, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.00060144044, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.0009751951, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0006965092, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.0007168852, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.00053672655, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.0010089364, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.00044425635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.0008847676, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.0006026603, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.0009368035, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.0007447372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.00047929594, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0006713616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.0004339386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.0008802061, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.0008286711, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00033876815, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.00061277696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00036621318, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00041255643, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00050115347, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00081759645, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.00041338528, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.00062392803, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.000794094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00031840376, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00033153515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.0004941848, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00041239586, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.00045861845, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.0005604704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.00056491257, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.0004914455, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.00052909344, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.000409472, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.0005313667, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.0005356347, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.00046588655, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.0004074555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.00046372367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.00060457445, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.0006280958, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.00043809338, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.0003478941, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.0003352874, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.0005670198, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.00040108728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.00042335567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.00036608469, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.0005217064, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.00042762808, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.00043404134, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.00065363315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.0005783547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.00045237056, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.000516793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.00050429406, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.0005938263, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.0005723546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.00045725686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.0003474186, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.00039087265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.00046997797, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.0005252871, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.00043070444, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.0004836438, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.00043195492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.0005093181, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.0004957199, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.00040825503, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.0004824089, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.00033671618, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.00047085743, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.00045227516, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.00039888546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.000569053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.00036219382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.0004863701, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.00039393632, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.0004711576, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.00038718997, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.0004076842, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.00039079448, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.0005371465, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 0.0002938898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 0.0003335582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 0.00034821592, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 0.00048028526, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 0.0003843668, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 0.0002887766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 0.00048825622, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 0.00040751463, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 0.00037641407, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 0.0004400668, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 0.0004338771, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 0.0005122458, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 0.00040242058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 0.0003881933, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.00044591562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 0.00042436982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.00043916234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.0003576157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 0.00055724476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.00033975422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.00042394394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0004686278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00034481066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00040299766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.00035597238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.0004755645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.00034578468, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.00042537547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.00046041436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00045076862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.00025852918, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.0004105224, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.00037004187, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.0003872445, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.0003411115, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0004728973, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.00033148486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.00037742217, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00035072392, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00027231977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.00048598036, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.0004517841, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.00035402112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.00031865225, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00034449447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.00044330495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00037762124, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.00046191967, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00033366826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.0004903832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00037822296, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.00033525657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00033351692, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0003431565, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.00042687834, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.00044546905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0003780371, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00035872706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00035905244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.0005059376, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0003630314, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.0003626846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.00033512944, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00039326132, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00033432743, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0004320601, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.000416309, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.00047996003, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.00029513054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.00032499197, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00042770006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.00045237294, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00039049992, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00044702407, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00028912874, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00026264283, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00042155414, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.0003498544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00042315372, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.00038845048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00035922058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0004022877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.00045444898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0003549185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00031412614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.000327902, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0004517774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0003993307, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00032049947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00036860898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00040039618, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00043957256, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00036459643, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00034969856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0004387744, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.00033278577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.000385952, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.00035041678, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.00048430247, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00038370208, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0004046873, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.00042940775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00034822413, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00038047403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00033475217, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.00037814904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00032486772, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.00036128878, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.0003727189, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00036594633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.00043318918, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0004956565, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0003121014, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.000381232, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0003450139, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.000380559, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00034874727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.00032061504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00045647915, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0003930111, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0004181664, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0003224582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.00043688854, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0004060262, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0003488612, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.00034581404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00036343388, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00040054152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.00033737594, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.00037015427, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0003702135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00031003822, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00030380982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00041307847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00045277647, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00039082472, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0002920644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00038048706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00036420213, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00035746573, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.00030756518, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00035149258, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.0003519602, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.0004109009, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00035547477, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.00036241353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.00043135483, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00045639576, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00047336018, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.000478074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0003517259, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00041279095, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.00030928507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0003647854, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0004218422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0003909406, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0004484178, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00036756074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00033232995, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00033843154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.00032188284, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00035875378, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.0004325262, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.00043012708, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0004817656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0003445464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00037771312, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.00037598243, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00037631436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0003337316, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00035340374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00034600613, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00034063432, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.00044386418, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0003945208, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.08755894, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.068528324, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.01863533, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 300, training loss= 0.009165936, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 400, training loss= 0.043351732, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 500, training loss= 0.015662143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 600, training loss= 0.012064282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 700, training loss= 0.00553073, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 800, training loss= 0.0013180848, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 900, training loss= 0.008316321, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1000, training loss= 0.0015790304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1100, training loss= 0.007991945, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1200, training loss= 0.0073048268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1300, training loss= 0.0011391104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1400, training loss= 0.0010030605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1500, training loss= 0.008486809, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 0.0045432015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 0.011424924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 0.0008417989, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 0.005964216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 0.00970058, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 0.0015683409, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 0.008458384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 0.0018866465, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 0.0011155747, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 0.0071141385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 0.0005494007, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 0.00082672265, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 0.0050114123, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 0.00035700374, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 0.00069174916, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 0.0005994481, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 0.00042874773, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 0.00039681976, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 0.00069926743, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 0.00035002548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 0.0011608787, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 0.0004960394, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 0.00039531078, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 0.00031966507, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 0.0011766229, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 0.0010031854, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 0.0006372663, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 0.0009024665, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 0.0006182589, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 0.0005914691, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 0.00034105673, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 0.00045799228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 0.0006791262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 0.002167136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 0.00031700666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 0.00046925605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5200, training loss= 0.0006360569, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 0.00028747314, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 0.0004718977, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 0.00027983545, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 0.0003678761, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 0.00062588265, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 0.00023701617, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 0.0005568322, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 0.0019522186, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 0.000561047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 0.00038251997, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 0.0003529428, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 0.00036797917, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 0.00024992513, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 0.0014829866, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 0.00025205498, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 0.00042322185, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 0.00028961516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 0.00028447586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 0.000305384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 0.00040217885, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 0.00045150236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 0.00049306214, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 0.00039090827, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 0.0004184355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 0.00037649064, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 0.00041130403, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 0.00033258332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 0.00029941986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 0.00043514505, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 0.00047178983, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 0.0003653497, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 0.00023950197, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 0.00038108585, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 0.00043396544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 0.00031989682, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 0.00022848009, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 0.0002324138, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 0.00027301017, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 0.00038613143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 0.00059089315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 0.00045096618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 0.00035463524, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 0.00041787545, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 0.00029632496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 0.00036307087, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 0.00025881157, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 0.00023647978, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 0.00031512286, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 0.00039872114, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10200, training loss= 0.0005299246, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10300, training loss= 0.00025945573, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 0.00038892013, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 0.00030208696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 0.0002797658, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 0.00043156696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 0.00046395508, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 0.00039598328, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 0.00033754273, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 0.00041676272, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 0.0002559169, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 0.00027242582, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 0.0005501646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.000288096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.00024515725, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.00037446347, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.00029169448, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.00021264706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.00021318276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.00038629712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.00031534742, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.00035677757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.000211693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.00039080548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.0002419162, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.00026549795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.00025757146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.00018931023, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.00026918194, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00027768445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.00021748005, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.0002742851, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.00042773422, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.0003362157, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.00020749713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.0002662776, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.00030263947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.00029298034, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.0002681283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.0003027921, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.0002901938, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.00021940554, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.000280267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.0002820833, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.00023706668, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.00032112587, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.00028645538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.000289177, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.00027558877, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.0002573622, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.00021232919, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.0003436933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.0002612769, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.00022330417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.00020045356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.000289816, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.00027297548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.0002078563, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.0003142052, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.00027300062, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.00033774294, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.00023162615, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.00030758593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.000310519, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.00030836242, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.00017901364, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.00022367487, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.00035550838, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.0002785307, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.000397267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00021913048, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.00024833775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00028955974, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.00030328234, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.00036011223, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.00024320054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.0003325366, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.00035505262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.00032544712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.00024486036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00034749001, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.00024470326, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.00021353805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.00027656957, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.00024032005, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.00023894808, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.0002503791, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.0002381117, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.00031645308, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.00021902705, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.00033007417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.00023038095, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.00023609714, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.00022358706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.00027295548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.00022359494, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00027429452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0002869355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.00024065578, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.00028596376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.0002602356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.00021213693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.00018804688, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.00021685276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0002779562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0002339077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.000188493, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.00028228393, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0002151518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.00035977823, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.00024168384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.00026122562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.00027897095, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.00030826515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.00026423187, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00024059528, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.00028191425, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0003190892, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.0002681143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.00031197717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.00030663708, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.00027748442, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.00018907727, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.00030553213, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00021638785, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.00028815228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00020484216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.00022706666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00026373717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.00024456315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.0002362327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.00028156972, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.000263363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.000264686, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00035676136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00023344066, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.00023998809, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.00028232727, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.00021489011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.00031680983, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00020214438, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.00026640395, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0003043632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.0002615698, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.00025382522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.00023178407, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.00024832488, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.00027673255, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0002402672, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.00021358186, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0002767624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.00022670804, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.00022687353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.00022019345, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00023832823, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00025375214, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.00026957967, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.00025013482, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.00022655701, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00027877823, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.00021119026, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.00032361795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.00022994855, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.00025174633, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.00030977174, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.00024264306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.00025565494, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.00026164242, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.00035473445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.00023130442, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.0002531734, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0002322873, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0001961975, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00025307253, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0001959757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0002602336, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.00027826944, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.00022616793, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.00026126037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0002644887, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0002692502, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00026529463, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.00021507914, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00028471503, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0002145597, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.00022631999, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.00017647391, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00020582078, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.00023947295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.00028923963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0002165814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.000246947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.00028880336, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.00020043713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.00019404133, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00022968008, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0002082309, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.00020143342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.05860594, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.028150743, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 200, training loss= 0.010113064, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 300, training loss= 0.024941286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.028564677, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.026323197, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.005569999, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.004578776, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.008838272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.0015145562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 0.0030964937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 0.006058703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 0.0014782462, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 0.008281071, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1400, training loss= 0.0057804408, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1500, training loss= 0.0035057021, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0006442899, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 0.0010808604, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 0.0011402597, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 0.0011938927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 0.0012655668, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 0.0008949015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 0.004111358, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 0.0017023569, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 0.004344238, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 0.001530028, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 0.0008413191, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 0.0014184169, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 0.0011990301, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 0.00051774783, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 0.00074907806, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 0.0021708785, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 0.0004555888, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 0.0010241491, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 0.000742642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 0.0012771625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 0.0007013873, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 0.0016430485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 0.00090760784, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 0.0012435704, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 0.0008429154, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 0.00096344686, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 0.0015076108, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0013508617, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.0005512345, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.00096729153, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.00067935605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.0005827447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.0007679136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.0006325037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.00071057456, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.0005347626, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.00075379957, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0009106083, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.0008085763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.0009287146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00064748875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00086201297, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.0009342652, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00067109906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00084379216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.0008897142, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00056758855, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.0008647453, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.0006607822, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00074831996, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.00073986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.00046737137, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 0.0006544315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 0.0005642958, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 0.00054150296, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 0.0005644723, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 0.0005440349, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 0.0010049173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 0.00072333263, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 0.00086100027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 0.00068149867, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 0.0005282717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.00079474616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.0007736953, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.0005889074, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.0006598963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.00053892337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.0005478139, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.0005124435, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.0007557706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.0004915973, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.0007145332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.00073817035, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.00064198626, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.0005112143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.0005410173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.0007577721, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.0005990519, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.0005112153, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.0005082929, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.00050948537, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.00049260515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.0005672483, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.00047960685, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.00051416794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.0008973271, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.0006407015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.0005946142, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.0005716287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.0007826618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 0.00048451254, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 0.0005071711, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 0.00063991256, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 0.00057461805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 0.0006333905, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 0.00050659536, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 0.0004605921, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 0.0006132863, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 0.0005220028, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.00057450554, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.00053309434, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.00044431884, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.00050642586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.00068105373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.0006452608, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.0008026443, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.00046918908, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.0005682219, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.00062570226, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.0006428158, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.0005754342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.0005305734, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.00050593173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.0006638236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.00054629985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00056428235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.00064428104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.000600896, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.0005521342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.0004964337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.0005133342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.0006006321, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.0005225689, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.0005483305, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.00041579898, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.0005733708, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.00053594256, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.00057226256, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.00070202595, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.0005648764, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.0005397675, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.00060419575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.00061557506, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.0005449011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.0005366584, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.0005845141, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.0005355482, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.0006164472, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.0006305337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.0006762168, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.00062162004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.0004985983, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.0005853495, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.00059663935, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.0005078461, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.0006120322, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.00067988306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.00036863115, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.00073779677, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.0006526974, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.0005684225, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.0005807098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.0005397843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.0005402391, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.0005038881, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.0006431398, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00051207107, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.00045240374, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00050843804, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.0005267473, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.0005415621, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.0005047142, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.00043131574, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.00056343444, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.00050023216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0005003581, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00063697447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.0005807085, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0005451639, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.00048393034, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.0006032346, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.0005167731, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.000555199, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.00051320926, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.00052792445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.0006197324, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.00041182945, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.00049215904, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.00054940174, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.0004852266, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.0004231662, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.00073304586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00052190543, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.00045635956, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.0005027656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.000383257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.0005695591, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.0004011588, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.00041589755, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0004956315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0005741647, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0005179627, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0004754929, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.00057276525, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.00043365647, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0005644026, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.000545225, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0004316122, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0005717812, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.00047124043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.00052191725, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00053555367, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.00043723077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.00051517313, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.00063801516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.00053122814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.0005213397, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.0003792472, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.0003576439, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.00042694923, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00048022327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0005461456, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00046367716, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.00055576663, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00043176135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.00041556387, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.00052944553, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.00071089383, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0004908189, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0005685926, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00048529785, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00054793956, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.00043536763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.0006150155, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.00059972994, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.0005068846, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00042838836, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.0005400467, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0005008653, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.00038335525, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.00043201994, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.000483868, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.00052366283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.00049950293, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.00048035866, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.0005687293, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0005000577, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.00058553123, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.00045792433, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.00046974025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00054754823, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00047785335, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.00047214256, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0006359468, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0003966867, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00048650557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.00055694033, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0003559169, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0005215172, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.00036988733, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.00055687584, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.0005976027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0004945062, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.00051599985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.00054752355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0004723976, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.00041495575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.00054064003, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.00044360533, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00065643014, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.00046612107, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.00050530804, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.00039170004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.00048659864, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0005656284, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0006820399, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.00050868257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00056536973, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.0004429854, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00046301517, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.00047372197, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.00055585447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0005702379, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00051007676, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.00048714597, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.00042040268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0005410969, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.00050719676, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0005186187, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.00043752493, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.00058393844, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00056052965, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0004666063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0006396569, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.65351754, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.06984714, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 200, training loss= 0.04053099, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 300, training loss= 0.013317289, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.005728286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 500, training loss= 0.02424548, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 600, training loss= 0.019516595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 700, training loss= 0.013780385, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 0.0047951485, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 900, training loss= 0.0012514369, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1000, training loss= 0.0063638273, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1100, training loss= 0.0062393686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1200, training loss= 0.006982211, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1300, training loss= 0.0048140027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1400, training loss= 0.0015394862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1500, training loss= 0.004139285, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1600, training loss= 0.0010245751, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1700, training loss= 0.0014744189, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1800, training loss= 0.00055647094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1900, training loss= 0.00066214544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2000, training loss= 0.00092234544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2100, training loss= 0.00087741564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2200, training loss= 0.001888277, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2300, training loss= 0.00037819074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2400, training loss= 0.0010454212, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2500, training loss= 0.00076323247, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2600, training loss= 0.001400356, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2700, training loss= 0.0014899309, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2800, training loss= 0.001318251, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2900, training loss= 0.0017933589, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3000, training loss= 0.00060409016, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3100, training loss= 0.0009115287, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3200, training loss= 0.00062281336, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3300, training loss= 0.0006010528, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3400, training loss= 0.00043732778, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3500, training loss= 0.0007998019, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3600, training loss= 0.0005184099, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3700, training loss= 0.00074069796, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3800, training loss= 0.001246416, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3900, training loss= 0.001064971, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4000, training loss= 0.00077627366, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4100, training loss= 0.00080344, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4200, training loss= 0.00091205357, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4300, training loss= 0.0007335101, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4400, training loss= 0.0005399617, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4500, training loss= 0.00094639324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4600, training loss= 0.0005294313, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4700, training loss= 0.0005003723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4800, training loss= 0.0003216843, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4900, training loss= 0.00049310434, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5000, training loss= 0.0004680435, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5100, training loss= 0.00068635936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5200, training loss= 0.00065944146, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5300, training loss= 0.0007960134, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5400, training loss= 0.0007813245, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5500, training loss= 0.0004241638, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5600, training loss= 0.00030390036, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5700, training loss= 0.0004776904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5800, training loss= 0.00076332036, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5900, training loss= 0.00045415928, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6000, training loss= 0.0005561485, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 0.00043854027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 0.00054623745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 0.00051191455, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.0006230699, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.0004007507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.0007331765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00061956624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.0006611133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00044637133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.00046627715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.0006462026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.00028718723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.00043530858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.00064725697, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.0004621318, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.00061645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.0006995208, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.0006307631, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.000511011, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.00051474624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.0003869948, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.00044496942, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.0005503079, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.00045002627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.00044227942, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.0005070708, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.00046444964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.00046668894, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.0004927614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.0004895081, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.00039449838, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.00059695315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.0003735212, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.00042027576, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.00048460573, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.00053669885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.00061230105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.00050854235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.00046371986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.00042578176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.0004937805, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.00040785002, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.00056719827, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.00051485846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.00044823176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.00061281794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.00057074695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.00031976186, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.00055925536, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.00048033125, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.00057425356, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.00045345895, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.0004634403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.00055697846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.0004505593, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.00043897185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.000381045, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.0002552502, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.00047181762, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.00037785503, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.00059872825, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.00044549775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.00053237175, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.00043901886, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 0.00044533398, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 0.00052120996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 0.00045617373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 0.000489509, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 0.00034212874, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 0.00044344162, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 0.00034621512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 0.0004552281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 0.0005619445, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 0.00043670821, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 0.0004905392, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 0.00046064888, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 0.0005381904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 0.0004258737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 0.00053810625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14000, training loss= 0.0003774673, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14100, training loss= 0.0004213022, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 0.0004320793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 0.00049423944, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 0.0005206281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14500, training loss= 0.000457303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14600, training loss= 0.00040607486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14700, training loss= 0.0005904917, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14800, training loss= 0.0003674052, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14900, training loss= 0.00041814693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15000, training loss= 0.00065639336, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15100, training loss= 0.00053859985, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15200, training loss= 0.00043277495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15300, training loss= 0.00045958514, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15400, training loss= 0.00045208703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15500, training loss= 0.00050300366, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15600, training loss= 0.00046490293, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15700, training loss= 0.0003565466, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 0.0005711211, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 0.00047713504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16000, training loss= 0.00046543698, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16100, training loss= 0.00034641582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16200, training loss= 0.0005571496, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16300, training loss= 0.00053088577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16400, training loss= 0.0003942917, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16500, training loss= 0.0005190625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 0.0004444403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 0.00045465562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16800, training loss= 0.0004351643, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16900, training loss= 0.00045518868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17000, training loss= 0.0004591773, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17100, training loss= 0.00033834542, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17200, training loss= 0.0005891334, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17300, training loss= 0.0005036234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17400, training loss= 0.00052887906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17500, training loss= 0.0003349593, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17600, training loss= 0.00051420374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17700, training loss= 0.00039077376, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17800, training loss= 0.00042268593, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17900, training loss= 0.00038516935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18000, training loss= 0.00038637302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18100, training loss= 0.00030897695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18200, training loss= 0.00035953787, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18300, training loss= 0.0004721439, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18400, training loss= 0.00049806037, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18500, training loss= 0.000498418, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18600, training loss= 0.00046389515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18700, training loss= 0.0005256381, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18800, training loss= 0.00040542634, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18900, training loss= 0.0004560196, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19000, training loss= 0.00044719334, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19100, training loss= 0.0004814054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19200, training loss= 0.0003708139, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19300, training loss= 0.00035162788, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.00044347811, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.00030113145, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.00044074134, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.0004509937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19800, training loss= 0.00044599923, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19900, training loss= 0.00037611494, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20000, training loss= 0.00035558766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20100, training loss= 0.00045002258, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20200, training loss= 0.0003410722, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20300, training loss= 0.00051288656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20400, training loss= 0.00043620792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20500, training loss= 0.00048174523, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20600, training loss= 0.0005051027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20700, training loss= 0.00046225172, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20800, training loss= 0.0004330558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20900, training loss= 0.00041898552, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21000, training loss= 0.00054808706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21100, training loss= 0.00052935217, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21200, training loss= 0.00029755748, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21300, training loss= 0.0004683957, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21400, training loss= 0.00043086222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21500, training loss= 0.00043196714, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21600, training loss= 0.00039211137, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21700, training loss= 0.0003831248, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21800, training loss= 0.00037310805, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21900, training loss= 0.00035570675, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22000, training loss= 0.00040048282, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22100, training loss= 0.00041146425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22200, training loss= 0.00038779582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22300, training loss= 0.0004896174, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22400, training loss= 0.00032678907, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22500, training loss= 0.0003581912, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22600, training loss= 0.00044276353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22700, training loss= 0.00033792315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22800, training loss= 0.00042702266, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22900, training loss= 0.00040563478, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23000, training loss= 0.00030997422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23100, training loss= 0.00042757404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23200, training loss= 0.00043681054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23300, training loss= 0.00041047912, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23400, training loss= 0.00032674737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23500, training loss= 0.00040173385, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23600, training loss= 0.00034865827, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23700, training loss= 0.00040701163, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23800, training loss= 0.00045054522, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23900, training loss= 0.0004064335, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24000, training loss= 0.0004245724, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24100, training loss= 0.0003534073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24200, training loss= 0.00041953017, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24300, training loss= 0.00050707057, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24400, training loss= 0.0005442539, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24500, training loss= 0.0004367337, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.00036433374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.00028226935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.00043045086, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24900, training loss= 0.0005029206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25000, training loss= 0.0003356465, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25100, training loss= 0.00031804977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.0004140818, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.00035613205, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.00033706866, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.00042830769, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.0004682987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25700, training loss= 0.00043393442, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25800, training loss= 0.00045805267, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0004846461, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.00033739093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.00040601788, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.0004551405, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.00044007058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.00045653447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.00033783662, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0003404202, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.00037571264, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0004147835, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.00035852927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.00038818683, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0003933302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.00040034633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.00042333858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.0004303374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.00041548512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.00040770188, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.00041092501, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.00036944766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.0003923587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.00040347793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.0003997764, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.00029964707, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.0004410799, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.00030545227, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.00046327268, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0004302934, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.0004308985, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.00036225512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.00034537062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.00046765292, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29100, training loss= 0.000377943, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29200, training loss= 0.00035275152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29300, training loss= 0.00043322102, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29400, training loss= 0.00033564732, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29500, training loss= 0.00038267972, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29600, training loss= 0.00043996604, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29700, training loss= 0.00030803843, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29800, training loss= 0.00035063052, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29900, training loss= 0.00035895722, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.014651392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.019398117, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.014324623, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.0006228391, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.00022449518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.012988832, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.0009840167, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 700, training loss= 0.0018355546, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 800, training loss= 0.00027725007, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0011822149, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.0017691295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0065029077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1200, training loss= 0.0014902209, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.00095098757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0008753985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.000518083, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0006866932, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.00043934427, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0011211373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.0014449613, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.0005230694, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.00081862544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.0008216816, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.0007855733, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.0008621514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.00068146165, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.0019447184, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.00065514894, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.00052439363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.00081619876, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.000630963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.0010247285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.00030040968, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.0004226642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.00049263204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.00097351114, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.000941599, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.00043752737, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.00046416512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.0009604766, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.00031051924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.00047749988, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.0005418372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.00037439022, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.00045315275, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.0003571011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.00091962883, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.0005349066, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.0007646176, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.0006167341, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.00040738436, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.00038533576, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.0005382814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0006400876, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.000396317, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00083956006, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00061929226, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00053904456, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.00046693915, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00029565254, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00030436905, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00026040126, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00034357386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.00043102592, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.00050652906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00038980614, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.00042223796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.0004966389, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 0.00029878426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 0.00037562262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 0.00021570585, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 0.0003721116, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 0.0004351971, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 0.00038490898, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 0.0004285203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 0.0003153466, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 0.0004578784, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 0.0003845719, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.00034973506, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.00033375554, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.00031554667, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.0006193326, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.00035020366, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.00048420543, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.00055604556, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.00033798395, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.000615059, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.0004768999, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.0003369591, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.0002493119, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.00038883096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.0005160147, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.0003407601, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.0005404907, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.00026438164, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.00048591133, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.00042471048, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.0004839333, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.00034348792, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.0006292437, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.00049931905, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.0004149141, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.00040781792, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.00041863247, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.00029878557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.00043999281, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 0.00050872384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 0.00040141947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 0.00041334511, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 0.0003254434, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 0.00036803496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 0.00043696392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 0.00056982203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 0.0004987238, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 0.00037820943, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.00053521036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.00041590712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.00033498282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.000368416, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.00045220787, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.00034788816, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.00036811025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.00045107602, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.00035075453, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.00045865553, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.00035235123, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.000524336, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.00043059327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.00029339257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.00049787335, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.00027535923, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00040688328, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.0004837198, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.00040443288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.00036623847, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.00045477337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.00029333596, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.00042444054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.00048065698, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.00040070913, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.000409609, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.00032726434, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.0004858437, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.00030137747, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.00039073982, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.00039429122, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.00042111645, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.0002930417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.000278722, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.0003884547, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.00031453578, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.00028700902, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.00037224416, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.00043568516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.00038941874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.000424369, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.00039157041, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.00032100145, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.00044924486, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.00037927498, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.00038286112, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.00026874113, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.0003390008, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.00040157643, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.0004117784, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.0003735962, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.00035770814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.00036793624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.0003237472, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.0004685956, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.00039468618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.0005506426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00041849734, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.00033550404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00031112056, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.00039262298, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.0004936624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.00036158488, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.00025144438, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.00034025687, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.00033159618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0003994888, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00027515105, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.00046050292, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.00032220728, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.00052633893, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.00040630923, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.0004095773, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.0003689513, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.00034279528, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.00038455575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.00028861634, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.00034980758, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.00031538756, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.00032333686, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.00034845452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.00029831842, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.00046628734, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00033739262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.00030714384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.00034127993, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0003597916, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.00044489605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.0004664208, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.00034821487, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.00030253862, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.00039530458, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.00040405267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.0004021276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.00040225516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0004029791, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.00038743712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0003319008, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.00034369354, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0003663061, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.00033269115, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0003379321, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00037337735, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.00043081702, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0003817683, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.00035382272, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.00041723176, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.00035467232, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.0003714593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.00038616464, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.000393499, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00034867538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0002976824, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00038827112, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.00036362922, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00034458592, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.0003609932, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.00038525765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.000296115, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0003473414, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.00034173508, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00042144294, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00037951447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.00043120657, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.0003046845, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.00034611006, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.00044819596, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00029880827, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.00038799964, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.0003952905, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.00030920102, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.000411794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.00024033811, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.00040876112, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.00038807484, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.00038929455, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.0002600883, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0003485796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.00032695674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0003925693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0003603948, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00034413632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00035014743, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.000440888, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.00034145016, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.00037091385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00028784925, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.0003544272, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.00030684337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.00027997786, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0003961622, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.00030087968, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.00033825194, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.00029402666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.00038967404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.00037388012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.0003613544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.00036425568, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.00033285277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.0004386686, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00030927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.00030955757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0003506135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.00033658306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.0003290191, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.00035372944, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.00031354703, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.00032982143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00030110037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.00040153996, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00038014122, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0003652137, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0003332891, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0004295718, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00039354182, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.00033578512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.000387577, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.00036720894, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0003434381, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.0004033015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.00033660623, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.00037548243, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00025599846, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.00036068735, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.00035468515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.2701457, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.04422241, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.07123617, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 300, training loss= 0.02495913, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.0049901265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.04213755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.03424513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.012644611, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.011911021, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.0032110668, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 0.0028111998, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 0.001105816, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 0.0023504698, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 0.006904355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1400, training loss= 0.010272196, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1500, training loss= 0.005637567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1600, training loss= 0.00867073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1700, training loss= 0.009938478, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1800, training loss= 0.00059162517, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 0.00031486223, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2000, training loss= 0.0003002701, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2100, training loss= 0.01230935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2200, training loss= 0.0010663044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2300, training loss= 0.008421573, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2400, training loss= 0.00074072374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2500, training loss= 0.0021670046, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2600, training loss= 0.0006028013, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2700, training loss= 0.00042120443, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2800, training loss= 0.0004262775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2900, training loss= 0.0003250811, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3000, training loss= 0.00055324193, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3100, training loss= 0.008027873, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 0.0003765298, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 0.0006502623, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 0.0010601785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 0.00088472705, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 0.00063321076, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3700, training loss= 0.00065452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3800, training loss= 0.00037664486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3900, training loss= 0.008084881, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4000, training loss= 0.0075675747, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4100, training loss= 0.00075165456, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4200, training loss= 0.0005284857, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4300, training loss= 0.0004871314, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4400, training loss= 0.00052753877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4500, training loss= 0.00037817153, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4600, training loss= 0.00043358697, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4700, training loss= 0.00048489598, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4800, training loss= 0.0004905069, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4900, training loss= 0.00044902513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5000, training loss= 0.00049454503, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5100, training loss= 0.00055155385, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5200, training loss= 0.00052285, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5300, training loss= 0.00036667121, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5400, training loss= 0.00031207709, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5500, training loss= 0.00041404736, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5600, training loss= 0.00038759765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5700, training loss= 0.00047435542, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5800, training loss= 0.00033914996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5900, training loss= 0.00036526434, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6000, training loss= 0.00034254737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6100, training loss= 0.00034063324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6200, training loss= 0.0003991202, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6300, training loss= 0.00032656785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6400, training loss= 0.0062794047, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6500, training loss= 0.0005065849, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6600, training loss= 0.00035367062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6700, training loss= 0.00043317987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6800, training loss= 0.00032767447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6900, training loss= 0.006076195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7000, training loss= 0.00037904838, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7100, training loss= 0.00037062238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7200, training loss= 0.00037035294, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7300, training loss= 0.00035875422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7400, training loss= 0.0004739311, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7500, training loss= 0.00044886253, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7600, training loss= 0.00034640185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7700, training loss= 0.00038408392, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7800, training loss= 0.00045433157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7900, training loss= 0.0054500825, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8000, training loss= 0.0055045276, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8100, training loss= 0.00032819094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8200, training loss= 0.005290308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8300, training loss= 0.005196669, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8400, training loss= 0.00039450574, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8500, training loss= 0.00036201766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8600, training loss= 0.0004142941, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8700, training loss= 0.0003600108, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8800, training loss= 0.00034316673, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8900, training loss= 0.004854775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9000, training loss= 0.0003729292, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9100, training loss= 0.00037658992, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9200, training loss= 0.00042333337, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9300, training loss= 0.00036179207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9400, training loss= 0.00034291053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9500, training loss= 0.00044724773, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9600, training loss= 0.004504659, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9700, training loss= 0.0045768796, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9800, training loss= 0.00031649694, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9900, training loss= 0.00033532272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10000, training loss= 0.00045147128, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10100, training loss= 0.0003357368, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10200, training loss= 0.00036936268, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10300, training loss= 0.0040316135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10400, training loss= 0.00044237697, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10500, training loss= 0.00037227062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10600, training loss= 0.00040853635, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10700, training loss= 0.00036369637, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10800, training loss= 0.0037345027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10900, training loss= 0.00035823075, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11000, training loss= 0.00036838232, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11100, training loss= 0.00037838076, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11200, training loss= 0.00044502836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11300, training loss= 0.0003548794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11400, training loss= 0.00035994564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11500, training loss= 0.000340089, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11600, training loss= 0.00030416917, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11700, training loss= 0.0031998665, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11800, training loss= 0.00036973783, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11900, training loss= 0.00039590476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12000, training loss= 0.00030448905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12100, training loss= 0.0003018759, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12200, training loss= 0.00040709274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12300, training loss= 0.0003284476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 0.00033195777, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 0.0004983868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 0.0003262176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 0.00038526737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 0.00040006195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 0.002695456, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 0.00045457156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 0.00029834837, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 0.000513456, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 0.00038953932, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 0.00045620758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 0.0024745632, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 0.00036757914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 0.00044032698, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 0.00039436863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 0.00039741612, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14000, training loss= 0.0004267123, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14100, training loss= 0.00037160303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 0.0022279934, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 0.002049498, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 0.00032399574, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14500, training loss= 0.0018704173, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14600, training loss= 0.00038735394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00038800572, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00035949316, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.00033939636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.00034184085, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.0010426093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.0002975428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.0003934195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00032497392, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.00027105573, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.00038778578, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.0002282776, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.000315855, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.00032712633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.00036971256, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.0003902048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.0006388358, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00038947986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00034677377, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.00037934977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.00030489438, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.0003040721, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.00033876888, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00031143063, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.00038492956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00030830238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.0004958296, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00040227966, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.00043835933, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00037162236, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.00039323707, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00041498043, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0003383684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.0004884703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.0003167477, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0003297376, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00033905578, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00038187506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.00036329043, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.00020001482, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.00031872452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.0004017193, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00036002978, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00038433317, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.0003288214, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.00039255453, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0003282688, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0002938504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.00027735106, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00032306704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0003981057, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00040197474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00032758128, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0003136023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00031392006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00030349757, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00033194912, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00040378314, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.00026437768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0003250218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.00031042687, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0003209958, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00033846148, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00033330626, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0003224384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00034947315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.00036201204, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00034619504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.000312083, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00039082393, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00029129427, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00034395608, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00028235547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.00030037112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0003519427, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.00034492483, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.00028751898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.00029384758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.0002836928, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.000332151, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0002984289, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00044704854, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00029831455, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.000348795, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.00033542849, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00029339347, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0003358393, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00038917235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00036149373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.00038480136, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.00026674938, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.00037611582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.00030967884, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.0002837814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00037529683, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00034533473, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0003311832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00031270547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.00037475955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.00031136218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00034849034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.00032884, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0003292935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.00028038956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.000260379, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00033806867, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00029283713, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0002741536, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0003282183, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.00032971927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0003337528, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00033310734, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00029445422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00030333328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00032082008, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0002636601, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00027406137, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00033440135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0003459807, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.00041884984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00023289384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00032662108, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00032415698, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00035732836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.00032991727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.00036869253, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.0003209363, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00041050758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00032709967, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00033878908, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00031985133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0002977699, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.00023815192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00044552606, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.00036179446, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0002680185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00029960927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00029648744, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0003328358, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0002905565, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.0003878631, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00042647152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.00040161778, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00026241518, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0003336457, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00031889474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0003395752, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00032377001, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00034211532, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00024835882, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00035290828, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00036783115, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0002801555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.00029283544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.11616591, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.053230245, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.017645301, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.0103792, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.010725632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.017644515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.010243322, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.0018422267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.0056304755, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.016375417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.0012973147, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.013906844, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.010176103, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.00073017384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.017529693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.00063333055, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0050184666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.00067190104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.002194869, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.00099377, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.0018492701, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0036451523, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.0011771121, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.0024582027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.00066908606, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.00043694268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.0006036959, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.0009609865, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.0024933487, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.0008502853, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.0022938165, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.00057069224, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.00081483426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.0020852282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.0005327887, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.0016141264, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.0006164575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.0005071043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.0008038756, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.0013514678, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.0004772392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.0008524096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.0007594795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0008510286, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.0010226518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.00062283454, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.0008702583, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.0012528761, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.0009958467, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.0008670298, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.0005194609, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.000788063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.00078037765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0007025701, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.000945042, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00067781715, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.0005479875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.0006029831, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.0007667764, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00051770534, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.001060593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.0006402447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.0006399064, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.0007522161, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.00041247238, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.0009864836, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.00047766176, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.00048231072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 0.0007252601, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 0.0010245036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 0.0006930076, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 0.0005130506, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 0.0005702227, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 0.00057587924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 0.000503986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 0.0007085368, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 0.0007187878, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 0.00051227486, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.0008655202, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.00082172244, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.0007688843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.0007341049, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.0006810514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.00076534285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.0005342543, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.0006375683, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.00060694444, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.00058654277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.0004896608, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.00068380975, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.00076054747, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.00077580183, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.0007676072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.00064397184, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.0004986703, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.0005699614, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.0006669618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.0006541274, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.00071447436, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.00090379175, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.00052299653, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.00048764134, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.00060844223, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.000589788, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.0006877927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.0007698551, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 0.0007272341, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 0.0005163788, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 0.00047610313, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 0.0005162352, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 0.0005152294, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 0.00070585415, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 0.00068172195, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 0.00049229385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 0.0006209235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 0.00057121, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 0.0005885532, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 0.0007600379, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 0.00060667575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 0.00057811645, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 0.00057583046, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 0.0005132383, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 0.00051213376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 0.0005346698, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 0.0005418425, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12500, training loss= 0.0006795691, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 0.0005759779, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 0.00053977856, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 0.000642396, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 0.00048194104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 0.00055543135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 0.0005469289, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 0.00054882455, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 0.000633065, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 0.00047050533, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 0.0006349863, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 0.0004600553, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 0.00054156507, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 0.0005506807, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13900, training loss= 0.0006035156, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 0.0004912535, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 0.00053309556, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 0.00050850783, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 0.0005114773, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14400, training loss= 0.0005758373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 0.000479461, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 0.0006353043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 0.0006823564, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 0.00058013876, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 0.00048668397, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 0.0005526512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 0.00062457426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 0.00043080677, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 0.00055477663, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 0.0006725169, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 0.0006732335, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 0.0006029345, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15700, training loss= 0.0005493625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15800, training loss= 0.0004849212, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15900, training loss= 0.0005200207, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 0.0006634731, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 0.0004639066, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 0.0007946041, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 0.00053566496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 0.00054040353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 0.0006210524, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 0.0007245073, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16700, training loss= 0.00059073156, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16800, training loss= 0.00049659004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16900, training loss= 0.00047834878, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17000, training loss= 0.0004460717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17100, training loss= 0.00045198284, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17200, training loss= 0.00065073394, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17300, training loss= 0.0007349618, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17400, training loss= 0.00064246735, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17500, training loss= 0.00055205816, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 0.00066264224, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 0.00048234244, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 0.00065689627, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 0.0006215715, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 0.00056926656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 0.00042971538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.0005351909, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 0.00042956608, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 0.0004594776, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 0.000570768, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 0.0005265246, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 0.0005488424, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 0.00059250265, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 0.0005281724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.0004312781, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 0.0005530674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19200, training loss= 0.0005414712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.0005864843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19400, training loss= 0.00045522163, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19500, training loss= 0.0005613046, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19600, training loss= 0.00054621097, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.00052882475, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 0.0005927836, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 0.00052808, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.0004490164, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.000570086, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.0005481594, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.00038842062, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.00059026125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20500, training loss= 0.00052894576, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20600, training loss= 0.000575051, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20700, training loss= 0.00043750642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.0006584098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.0006202885, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.00043353098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0005064356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0006024277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0006251106, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.0005333467, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.00054163835, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.00053559477, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.0005631756, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.0005922963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.0006217351, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.00055906794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.0006384548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.00050887954, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.00065767375, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.000470287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.0005396047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.00065297604, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0007026058, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.0003866648, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.00064728817, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.0005021469, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.00061508815, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.0005428698, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.0004956947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.0005118327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.0005329478, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.000490761, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0005021946, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.00061166275, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.000520299, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.0004218763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.00047187155, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.00047735532, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.0005498274, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0004415154, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0004033848, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0005816966, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.00051272317, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.00047933083, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.0006509825, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.00047194725, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.00057775906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.0004943498, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.00054438674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.0004561712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.00048235126, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.00050840015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.00044063086, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0005164731, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.00047438277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0005434886, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.0005696858, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.00053476315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.00058478146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.00052926433, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.00051477004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.0005017459, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.000574044, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.00051127165, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.0006124526, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0005723304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.00050774735, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.00058738404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.00042496255, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.0006554324, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.00052116043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0006021401, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.0005022465, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.0005865662, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0005024849, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.00057666446, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.00043193315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.00038501655, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.00047891214, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.00050143077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.00047546154, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0005941445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.0005493902, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.000588512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.000649319, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0005004693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.00047920417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.00044378868, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.0005006613, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.00044419416, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.00043201304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.00044516646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00059929915, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.0005033296, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0004845851, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.20143537, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.0712985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.053365797, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.006748234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.0004359486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.0058047245, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.025087906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 700, training loss= 0.0031705543, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 800, training loss= 0.007910906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 900, training loss= 0.008587778, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 0.0014651897, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1100, training loss= 0.008149452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1200, training loss= 0.003787494, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1300, training loss= 0.0056300717, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1400, training loss= 0.00072996825, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1500, training loss= 0.0030727459, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1600, training loss= 0.0006806816, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1700, training loss= 0.0004743562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1800, training loss= 0.0004764789, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 0.00052751746, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2000, training loss= 0.0005389059, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2100, training loss= 0.0010358299, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2200, training loss= 0.0010990881, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2300, training loss= 0.00091223995, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2400, training loss= 0.0015544932, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2500, training loss= 0.0005028331, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2600, training loss= 0.00094866374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2700, training loss= 0.0017964637, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2800, training loss= 0.0012291434, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2900, training loss= 0.00063429674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3000, training loss= 0.000860006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3100, training loss= 0.00079610915, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3200, training loss= 0.0010287444, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3300, training loss= 0.00076384324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3400, training loss= 0.00044977106, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3500, training loss= 0.00036817868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3600, training loss= 0.0007795996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3700, training loss= 0.00050825346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3800, training loss= 0.00050062896, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3900, training loss= 0.0006559866, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4000, training loss= 0.00076212233, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4100, training loss= 0.0007295141, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4200, training loss= 0.0007340329, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4300, training loss= 0.0005353223, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4400, training loss= 0.00060644967, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4500, training loss= 0.0005207182, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4600, training loss= 0.0005312911, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4700, training loss= 0.0005623899, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4800, training loss= 0.000513093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 4900, training loss= 0.00079279806, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5000, training loss= 0.00050601707, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5100, training loss= 0.0007114399, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5200, training loss= 0.00057213934, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5300, training loss= 0.00034640913, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5400, training loss= 0.00041516434, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5500, training loss= 0.00061146397, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 5600, training loss= 0.0005208171, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 0.00041515162, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 0.00048275493, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 0.0005918804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 0.0005063281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 0.0004423002, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 0.00042882358, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 0.000370082, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.00038763598, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.0005753016, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00045552812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00048303828, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.00040799315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00049954554, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.00049620133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.00050406245, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.0005026175, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.0004428363, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.000409721, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.00046391977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.0004897867, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.000490985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.0005069283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.00040383806, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.00062488817, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.0005350395, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.00060222775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.00045180027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.0005577265, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.00048416757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.0005100888, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.0004787376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.00042801863, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.00047793318, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.0004031034, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.0004904964, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.00048829895, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.00038503247, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.0003683228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.00041537717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.00038490852, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.00039482533, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.00041679756, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.000514538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.00042597778, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.00057374063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.00045017665, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.00048450285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.00041133264, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.00050821464, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 0.0004927371, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 0.00041972785, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 0.00044329005, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 0.00061649433, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 0.00037799086, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 0.00034956247, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 0.0005923347, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 0.0005713692, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 0.00055627874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.00038772283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.0005355543, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.00040257085, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.00037988691, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.0005455646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.00047674362, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.00038552826, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.00042360602, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.00060667354, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.000516822, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.00037377884, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.0004565251, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.0005497948, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.0005909956, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.0005112404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.00046672818, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00044283518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.0004401983, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.0004556026, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.00040062895, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.0005218661, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.0003677148, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.00050443574, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.000508304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.00043785432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.0005318757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.00039261204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.0004807523, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.00047513662, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.00036118607, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.0003725686, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.0005051451, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.00040721448, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.00046232544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.00043396835, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.000444891, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.00048514642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.00054499565, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.0004036522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.00041872184, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.00050557725, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.0005491639, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.00065769156, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.00047687837, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.00047834442, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.00062161195, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.00040444938, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.0004480538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.00040912908, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.0005073995, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.00047025454, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.00040200376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.00047885888, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.0004223203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.00033643964, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.0004326015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.0004209492, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00040626494, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.0005569297, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00043479234, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.00043860223, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.00038995358, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.00046194214, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.0004338992, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.00046308312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.0005053087, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0004009327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00043171356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.00045673593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0004496437, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.0003669287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.0004213518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.0004475907, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.00032092337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.00041282186, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.0004894542, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.0004429794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.0005506331, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.00047208354, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.0003352705, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.00048651334, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.00047358815, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.0003510037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00046210713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0003966059, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.0003805282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0004556168, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.00046068415, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.00036055746, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.00044872245, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0003760404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.0004656646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.00041831666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.00051728054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.00045075943, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.00043933056, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.0004857544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.00036516195, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0004264924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.00039122553, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.00038271217, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0005536244, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00050100096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.00037769118, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.00035107622, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.0004608426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.00045534872, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.00038198428, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.00045009257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.00043656124, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0004353317, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00042677004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0004571001, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00036964897, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.00040748809, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00040529008, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.00041682628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.00038075348, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.0004265071, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.00044784235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.00038153955, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00046939316, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00036887117, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.0005412015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.00042523132, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.00050694915, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.000411634, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00039871014, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.00047720634, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.00042494744, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.00039811688, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.0004956731, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0004040425, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.00048464895, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.00041926253, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0003780076, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.000332249, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.00037799103, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.00035107712, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.00042486656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.0003937163, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00036918934, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00043579267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0003901778, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.00047679842, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0004657724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00045502797, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.00035132343, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0004308666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.0005197713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.00031162504, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.00033167098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.00042583427, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.00044809445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.00041334532, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.00042152504, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.00028718583, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.00045136685, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.00035491155, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.00038518306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00034905117, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.0003404985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.00036775798, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0003781957, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.00039691673, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.0004924105, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.0004854283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.00043583364, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00043968606, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.00045383512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00041722582, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.00047469116, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.0005192064, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.0005519923, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00042621396, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.00037734423, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.00049215875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.00041391607, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.0004249146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.00039940473, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.00043520026, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.0005006359, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00038837947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.00031928218, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0004577236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.06610002, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.052616924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.014497359, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.021698257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.0012794873, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.0007269047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.01159553, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.0009814635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.0011214201, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0016103511, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.0005718046, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.009133257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.0014871135, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.00074724894, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0025306544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.0009763452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.002062459, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.0043555363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0017796041, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.0012166988, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.00051210646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.00057033444, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.00072213536, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.0006852387, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.0016351771, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.0005969139, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.0008914549, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.0004996062, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.00050363404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.001366936, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.00064871385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.0008242514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.0005246764, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.00049638003, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.0010543164, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.00089438196, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.0012926364, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.00072642753, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.00078702933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.0007418195, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.0009146575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.00047795635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.00054520805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0010342629, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.00077937805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.0005349501, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.0005503025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.00085524825, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.00070765073, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.00070829544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.00087790436, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.00045908624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.0007477523, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0005843606, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.000693062, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00040866339, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00061039435, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00056823646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.0011073763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00057459204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00048502005, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00091411796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00043249485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.000700897, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.0004303245, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00046290705, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.0004938848, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.00048352178, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 0.0006605722, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 0.00056829763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 0.00044456776, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 0.00054161326, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 0.00071017595, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 0.00033304986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 0.0007534691, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 0.00055090204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 0.0005054349, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 0.00060329586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.0007409509, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.00065228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.00049998355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.0007031514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.00046010382, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.0006418295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.0005011596, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.0007291094, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.00070059416, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.0004914469, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.0006911428, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.00043920754, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.0005027716, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.00047805143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.00047279825, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.0005523846, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.00039378452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.0006830146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.0006070942, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.0006042, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.00048724824, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.00041790048, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.0004153795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.0006468875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.0004961285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.0005697484, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.00055859325, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.0006395494, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 0.0007044877, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 0.00033757495, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 0.00048364053, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 0.00049114827, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 0.00042018478, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 0.00059967325, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 0.0003966297, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 0.00038957232, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 0.0005920278, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.00064663927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.00049440126, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.0005202896, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.0005064299, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.0004659753, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.00047397785, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.0005662231, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.0005990609, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.0005604683, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.00050615356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.00042500472, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.00053785194, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.0005273904, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.0005913266, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.00040197835, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.00038378962, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00039992627, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.0005832098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.0005847684, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.0005613911, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.0005932947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.0006134928, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.0004367184, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.00039421485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.00043216502, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.00041325475, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.00048589727, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.00053477293, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.0004386446, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.0005554861, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.0006259196, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.0004040563, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.0004991143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.00058489066, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.00047492934, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.0004216649, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.000489306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.00049105886, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.0005809803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.00052939076, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.00041238498, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.0005040473, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.0006280529, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.00035855078, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.0005697929, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.00038509778, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.00043274724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.00054590387, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.0005583439, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.0004388041, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.00041966187, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.00044391095, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.00046734657, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.00056311453, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.0004509857, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.0003917877, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.00043940032, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00051159586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.00036101337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00041336604, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.00042754193, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.0004793651, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.00053323567, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.0004945879, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.0005801843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.000436544, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0003967525, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00047006967, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.00041955654, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.00038799248, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.00046658414, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.000462783, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.00048119246, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.0004424628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.00044608736, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.00061297935, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.00036083124, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.00041970797, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.00046772222, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.00040659713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.00046182037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.0005141372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.000423373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00039215866, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.00040663173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.00041577528, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.0004546549, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.0003839277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.00051836803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.0003717942, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.0005804332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.00040424077, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.00049192656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.00040277964, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.0005138432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.00047595194, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.00047063432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0004200211, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0003238619, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0005026806, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.00035556708, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.0004468951, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00045017392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0005050148, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.00044335666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.0005023038, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.0004355594, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.0003530031, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.0003825292, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.0005644028, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0003360236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00047402046, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.0005611233, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00033066474, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.0004674796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00049137784, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.00048092456, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.00034251492, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.0004109862, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.0004063219, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.0005019501, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00037532955, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00043141012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.00045227664, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.00045636055, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.00041495613, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.00036379125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00032891356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.000515811, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.00046144667, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.000542557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.00046314043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.00047839928, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.00040505445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.0005378492, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.00035865043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.00044612572, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.0005299212, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.0005029617, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.00035748392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.00041549592, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00042119887, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00034347054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.0003378288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.0004779874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.00039396668, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00048758538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.00040353095, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.0003868022, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.00036996297, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.00039312933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.00037694824, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.00039411685, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.0003713486, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.0004999677, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0004374642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.00047199844, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.00047715497, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0005619805, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.00046457103, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00034005402, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.00038391468, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0004147627, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.00037131854, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.00040975222, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.00036819666, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.00047820978, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.0004416329, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00042676344, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.00037321963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00045669285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.0003803764, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.00039522845, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.00032933528, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00044946914, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.0005574592, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.00045258933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.0003017004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.00046482362, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.00035969703, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.00044481966, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.00045485212, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00038699256, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.00041758144, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0003928629, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.03708127, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.012602485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.04653295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.0025071271, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.024783276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.04734295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.024105232, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.00042976014, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.00222336, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.02332831, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1000, training loss= 0.0037366021, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1100, training loss= 0.00037726335, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1200, training loss= 0.00834224, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1300, training loss= 0.014396613, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1400, training loss= 0.0019173644, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1500, training loss= 0.0014577102, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1600, training loss= 0.0013179033, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1700, training loss= 0.0004331843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1800, training loss= 0.0007036106, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 1900, training loss= 0.00039388525, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2000, training loss= 0.0013193771, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2100, training loss= 0.008914648, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2200, training loss= 0.0012992788, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2300, training loss= 0.00041862985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2400, training loss= 0.0012554098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2500, training loss= 0.00048798328, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2600, training loss= 0.000978298, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2700, training loss= 0.000796453, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 0.0010776408, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 0.0007849039, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 0.0003246026, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 0.00034729773, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 0.0011085283, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 0.00032753893, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 0.0010787114, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 0.00076950947, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 0.0007765625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 0.00042879663, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 0.00045767552, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 0.00047309007, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 0.00074760977, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 0.0006726605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 0.00030600902, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 0.0005007355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 0.00055473036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 0.000358337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 0.00054131664, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 0.0007870432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 0.0005464869, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 0.00034781426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 0.00048341102, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 0.0003217528, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5200, training loss= 0.0004470276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 0.00044232057, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 0.0005566764, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 0.0005684227, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 0.000460232, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 0.0002974657, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 0.0004781069, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 0.00036608177, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 0.0003375718, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 0.00034211657, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 0.0004060396, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 0.00043497432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 0.00038189034, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 0.00036505362, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 0.0005131575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 0.0003271802, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 0.0003546705, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 0.00035957183, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 0.000428566, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 0.00038280222, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 0.00042919, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 0.0005162476, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 0.000438458, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 0.0005144011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 0.00024527372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 0.00051088363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 0.0004014036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 0.00041525843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 0.00037360837, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 0.00036131218, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 0.00032075236, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 0.00038683004, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 0.00048217282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 0.0003547589, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 0.00042540516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 0.00030104088, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 0.00033311808, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 0.00044361106, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 0.0005150602, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 0.00039984306, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 0.00036917778, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 0.00040890143, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 0.00049137353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 0.00033288202, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 0.0003434693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 0.00032104042, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 0.00035164668, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 0.00048402586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 0.000335401, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 0.000367384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10200, training loss= 0.0003450286, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10300, training loss= 0.00035870096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 0.00052628305, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 0.0003883992, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 0.00040445614, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 0.00042112765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 0.00041552243, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 0.00045408902, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 0.0004029292, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 0.0003621536, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 0.00035371407, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 0.0003826492, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 0.0003649369, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 0.00042283378, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 0.0003541216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 0.00033396942, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 0.0004091535, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 0.00045267172, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 0.00028461503, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 0.00027967631, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 0.00037978994, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 0.00036261522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 0.00036442728, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12500, training loss= 0.00036125095, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 0.00048377967, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 0.00044504483, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 0.000318933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 0.0004409036, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 0.00033915538, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 0.00037376385, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 0.0003856555, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 0.00045007814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 0.0003584203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 0.00038811122, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 0.00053935417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 0.00038306677, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 0.00038722437, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13900, training loss= 0.00032709073, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 0.0004225869, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 0.00035676558, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 0.00030751678, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 0.00033369192, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14400, training loss= 0.00039429925, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 0.0003663215, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 0.0003584417, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 0.00034832413, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 0.00040691893, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 0.00038477156, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 0.00042197033, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 0.00030824484, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 0.0004385212, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 0.00035816978, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 0.00037923743, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 0.00028501742, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 0.00039965063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15700, training loss= 0.00038597977, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15800, training loss= 0.0003533775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15900, training loss= 0.00037963002, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 0.00046747664, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 0.00035239314, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 0.0003673616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 0.00038448203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 0.00040429994, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 0.00035866557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 0.00041201874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16700, training loss= 0.00031516797, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16800, training loss= 0.0003185675, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16900, training loss= 0.0003151704, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17000, training loss= 0.0003403448, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17100, training loss= 0.00033698496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17200, training loss= 0.0004002626, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17300, training loss= 0.0003983325, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17400, training loss= 0.00027942503, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17500, training loss= 0.0004377665, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 0.00035102252, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 0.00028667372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 0.00033356572, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 0.00042141307, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 0.00032944125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 0.0003593536, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.00041139076, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 0.00030421175, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 0.00028681091, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 0.0005097002, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 0.0003938806, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 0.0003317173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 0.00037940015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 0.00034763312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.00036379672, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 0.0003562809, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19200, training loss= 0.00035098166, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.000370597, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19400, training loss= 0.00037280383, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19500, training loss= 0.0003201909, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19600, training loss= 0.00036371098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.00030112398, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 0.00042280063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 0.00032874075, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.00037457264, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.00032003532, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.00037550268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.00036615692, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.0003589829, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20500, training loss= 0.00031008932, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20600, training loss= 0.0003219883, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20700, training loss= 0.0004001469, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.00032983196, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.00030756838, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.00040640973, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.0003272717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.0003757145, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.0004038687, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.00036933352, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.00033328502, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.0004253183, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.00042145973, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.00032272248, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.0003121624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.00040350304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.00040097974, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.00035848963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.00042806804, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.0003845159, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.00029335418, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0003699541, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.00036107664, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.00040009274, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.00032114534, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.00038240931, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.0003500919, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.00042941002, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.00032639952, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.00036033287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.00037489537, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.00029968834, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0003159402, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.00044776854, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.00042039173, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.00024442788, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.0003318725, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.00034017384, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.000321056, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.0003742738, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.0002798404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.0003754912, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0003419119, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.00039022742, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.00030453358, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.00028464047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.00031788455, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.00036817786, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.00030369643, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.00041685192, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.00031962796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.00032327903, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.00033208108, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.0003361567, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.0003124108, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.00040436955, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.00025579656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.00037987775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.00032626427, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0003164403, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.00031400847, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.00033841183, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.0004054461, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.00029572332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.000296733, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.0003191582, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.0004051616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.00033058514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.00038918562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.000327571, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.00037496892, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.00029958776, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.00036514696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.000354693, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.0003761669, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.00033322826, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.00040016344, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.00031365166, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.00033629543, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.0003699562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.000387017, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.0004331051, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.00036510575, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.00032405235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.00032957277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.00026150228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0004178843, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0004485555, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.00031881387, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.00029591474, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.00040296928, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.00033293111, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.00034445012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.00026387535, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.00037197786, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.015018732, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.05644872, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.021784948, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.020965207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.004723043, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.005146901, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.00060804165, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.0028883575, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.015408785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.0021429926, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 0.001554149, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 0.0007819792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 0.004908122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 0.0009484524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1400, training loss= 0.0012975349, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1500, training loss= 0.00033879562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1600, training loss= 0.0019805871, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1700, training loss= 0.0014256452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1800, training loss= 0.0006771553, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1900, training loss= 0.0010654558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2000, training loss= 0.0006398616, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2100, training loss= 0.0008011644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2200, training loss= 0.0008823745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2300, training loss= 0.0008977219, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 0.0007552373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2500, training loss= 0.0007360247, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 0.000558124, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 0.00055955775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 0.00067533227, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 0.0015998833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 0.0006231031, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 0.00078884535, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 0.00087725866, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 0.00048479176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 0.0012666868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 0.00077317527, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 0.0011652774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 0.0008732381, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 0.0007776208, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 0.00046745833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 0.00041597648, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 0.00057674636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 0.0009206609, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 0.0005511702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 0.00041312393, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 0.0010815661, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 0.0006065703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 0.00078727474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 0.0005121704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 0.0005346636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 0.00028761476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 0.00043778546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 0.00066171243, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 0.00063711347, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 0.0007428656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 0.0007551613, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 0.00069818133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 0.00046831428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 0.00041305815, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 0.0004717968, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 0.00039286923, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 0.00031805664, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 0.00052780646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 0.00061404693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.00042737424, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.00043641956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00048257387, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.0005936661, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.0004383632, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00055336766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.0005112884, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.0004639055, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.00035973627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.0004199499, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.00034509346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.00034993258, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.0006166982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.00030714972, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.00042980135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.00042509093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.00042832427, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.00049987494, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.00049839594, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.00074559177, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.00061083375, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.0005112639, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.00040791027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.00052321004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.00040397438, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.00034599268, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.000493224, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.0004346058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.00045395308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.0004423638, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.00039549722, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.0004422403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.00034088478, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.0004945488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.00039902507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.00065257447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.00040330278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.00038130325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.0004464662, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.00038299986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.0004684155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.00039948316, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.00036702777, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.0006846684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.0005260332, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.00043513323, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.00026612653, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.00049049425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.00052035, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.0003612513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.00039932682, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.0005844869, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.0007058028, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.00031084724, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.00045629108, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.00041551728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.00036192674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.0004941347, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.0004936538, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.00032361437, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.00046654308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 0.00034674242, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 0.00039751478, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 0.00046598192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 0.00033938093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 0.0005087206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 0.00043543422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 0.0003028741, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 0.0005306093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 0.0003118117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 0.00035824563, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 0.00047793298, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 0.00049430784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 0.00053202914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 0.0003228672, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.00047405786, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 0.00056370045, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.0004658481, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.0006045755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 0.0003885778, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.000426078, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.00044461119, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0003410153, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00038264348, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00038182456, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.000545171, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.0004098636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.00045274355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.0003977488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.00055456534, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00034819247, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.00039907504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.00046851614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.00042308526, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.0004037652, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.00039692206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0003697534, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.00035498623, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.0005340374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00047129596, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00033382786, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.00035537302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.00034002974, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.00039431767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.000546297, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.0003269031, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.00048712292, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.0004689971, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.00035610457, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.0003193275, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.00044307002, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00033935302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.00027217693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00034433167, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0005164265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.00039568936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.0004236644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.00039632144, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00034694327, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00037357927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.00046073206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0004394601, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.00040485378, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.00036850682, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.0005132842, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00038865517, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.00036097816, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.0004151736, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.0003660863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0003866682, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.00039534055, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00036828395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0005136783, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00032562856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00035769984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00038756483, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.0004204558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00036694336, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00042230164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00040613126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0003793821, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00033494623, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0003518332, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.00039480545, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00039527827, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0004302772, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0004334429, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00041359547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.00035527904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00035818026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00030843646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0003953116, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0003422881, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00031826113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00029307426, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.00037616244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0004127353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.00044005425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0005074563, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0003191619, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00046720228, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.00030204447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0003857249, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00042715896, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00038417403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00031373705, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.00036788546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.0003976696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.00036684025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00043820404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00039984062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0002785773, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0003542428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0004229163, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.00043277003, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.00044315105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00039414916, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00030570748, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0003624885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00037271495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0003614332, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.00043158542, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.0004635041, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0003965696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0003591227, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0003512166, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0003496282, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00030697996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00040892372, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0003786288, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0004257373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0004818021, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00042038475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00037255307, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00040250644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00039673218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00040332158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.00043505552, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0002849745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00042801525, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00039699965, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0003312448, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00036104958, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00042112276, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00033562994, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00038392417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0003808552, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.000383805, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00038458567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00037486674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.0003833067, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00034425835, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.0003483646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0003680804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.00030607168, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00032938592, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0003758272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0003644675, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00033773074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00032678884, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00034922868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0003527472, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00035279075, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.000417223, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.000340102, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00033545666, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.00038524898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00038520768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.00042636227, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00041874367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00030929613, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.0003088119, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00035616267, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00032880538, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.00029515434, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.00041072362, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.3099932, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.0072819786, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.047588695, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 300, training loss= 0.00068083673, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 400, training loss= 0.0066711474, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.003349491, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.013625341, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.00041372108, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.002694127, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0012500739, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.00023955284, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0011677514, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.00045671596, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.009276024, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.00040716078, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.007594271, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0007816766, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.00046195585, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0016472817, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.00042455632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.00093950314, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0006652499, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.005131857, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.0005034881, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.00036116986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.00040597268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.0004178496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.00029068353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2800, training loss= 0.0004979088, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 2900, training loss= 0.0021481009, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3000, training loss= 0.00048279556, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3100, training loss= 0.00053157745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3200, training loss= 0.0012238963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3300, training loss= 0.00024638363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3400, training loss= 0.00029109896, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3500, training loss= 0.00027055774, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3600, training loss= 0.00047748012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3700, training loss= 0.00046536286, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3800, training loss= 0.00028046858, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 3900, training loss= 0.00031599044, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4000, training loss= 0.00046629208, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4100, training loss= 0.0003899348, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4200, training loss= 0.00035064176, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4300, training loss= 0.00030835235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4400, training loss= 0.00045512337, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4500, training loss= 0.00037637952, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4600, training loss= 0.00030195332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4700, training loss= 0.0003592985, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4800, training loss= 0.000459729, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 4900, training loss= 0.0002567915, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5000, training loss= 0.00033212706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5100, training loss= 0.0003696802, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5200, training loss= 0.00030827883, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5300, training loss= 0.00034185025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5400, training loss= 0.00029907524, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5500, training loss= 0.00033760027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5600, training loss= 0.00035160562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5700, training loss= 0.00035117276, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5800, training loss= 0.00041645623, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 5900, training loss= 0.00029546372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6000, training loss= 0.00035274323, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6100, training loss= 0.0003289714, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6200, training loss= 0.00028851154, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6300, training loss= 0.0003909828, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6400, training loss= 0.00030746087, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6500, training loss= 0.00028947945, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6600, training loss= 0.00039533208, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6700, training loss= 0.00040468684, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6800, training loss= 0.0002555758, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 6900, training loss= 0.00040090803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7000, training loss= 0.00030216257, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7100, training loss= 0.00038341165, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7200, training loss= 0.00039456616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7300, training loss= 0.00034171072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7400, training loss= 0.00038453352, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7500, training loss= 0.00034051674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7600, training loss= 0.00025937063, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7700, training loss= 0.0003322769, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7800, training loss= 0.00036313053, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 7900, training loss= 0.00033401872, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8000, training loss= 0.00031145915, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8100, training loss= 0.00038468497, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8200, training loss= 0.00031622997, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8300, training loss= 0.000287304, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8400, training loss= 0.0003204215, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8500, training loss= 0.00039738038, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8600, training loss= 0.0003351288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8700, training loss= 0.00035736087, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8800, training loss= 0.00029119465, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 8900, training loss= 0.00023805373, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9000, training loss= 0.00043730033, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9100, training loss= 0.00033885715, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9200, training loss= 0.00032127707, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9300, training loss= 0.00037449188, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9400, training loss= 0.00032818934, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9500, training loss= 0.00033452138, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9600, training loss= 0.00040108923, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9700, training loss= 0.00036550284, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9800, training loss= 0.0003438802, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 9900, training loss= 0.0003955635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10000, training loss= 0.00042530734, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10100, training loss= 0.00035730697, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10200, training loss= 0.00034214772, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10300, training loss= 0.00035473017, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10400, training loss= 0.00034185933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10500, training loss= 0.0002765333, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10600, training loss= 0.00039765105, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10700, training loss= 0.0004221043, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10800, training loss= 0.00029147568, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 10900, training loss= 0.00032506447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11000, training loss= 0.00028446125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11100, training loss= 0.00028973742, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11200, training loss= 0.00031956617, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11300, training loss= 0.00041022952, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11400, training loss= 0.000380265, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11500, training loss= 0.00028044806, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11600, training loss= 0.0002508578, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11700, training loss= 0.0003683983, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11800, training loss= 0.0003480106, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 11900, training loss= 0.00037797305, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12000, training loss= 0.00040475454, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12100, training loss= 0.00032305645, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12200, training loss= 0.00024221717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12300, training loss= 0.00027080072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12400, training loss= 0.00031072795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12500, training loss= 0.0003424346, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12600, training loss= 0.00036344875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12700, training loss= 0.00030445392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12800, training loss= 0.00037713355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 12900, training loss= 0.00028748548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13000, training loss= 0.00034540548, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13100, training loss= 0.0003046342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13200, training loss= 0.00042209978, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13300, training loss= 0.0003204719, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13400, training loss= 0.00032015817, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13500, training loss= 0.0003777386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13600, training loss= 0.00029885978, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13700, training loss= 0.00028596516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13800, training loss= 0.00032870885, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 13900, training loss= 0.00036058098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14000, training loss= 0.00028574924, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14100, training loss= 0.00029969012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14200, training loss= 0.00029570353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14300, training loss= 0.0004214529, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14400, training loss= 0.00033198745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14500, training loss= 0.0002879081, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14600, training loss= 0.00030262518, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14700, training loss= 0.00042219242, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14800, training loss= 0.0003271034, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 14900, training loss= 0.00034003446, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15000, training loss= 0.0003240397, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15100, training loss= 0.00038816305, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15200, training loss= 0.00030778928, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15300, training loss= 0.00034781967, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15400, training loss= 0.00025200823, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15500, training loss= 0.00036504449, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15600, training loss= 0.0003527123, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15700, training loss= 0.00030772487, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15800, training loss= 0.00035955865, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 15900, training loss= 0.00029274193, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16000, training loss= 0.0003801101, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16100, training loss= 0.00029851877, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16200, training loss= 0.0003201006, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16300, training loss= 0.00035607797, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16400, training loss= 0.00027997993, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16500, training loss= 0.00028521262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16600, training loss= 0.00034742098, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16700, training loss= 0.0003367829, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16800, training loss= 0.0003662175, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 16900, training loss= 0.00026281382, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17000, training loss= 0.00036200165, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17100, training loss= 0.00040237152, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17200, training loss= 0.0002851492, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17300, training loss= 0.0002929707, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17400, training loss= 0.00037633037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17500, training loss= 0.000355308, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17600, training loss= 0.0002653287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17700, training loss= 0.0003354918, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17800, training loss= 0.00031733463, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 17900, training loss= 0.0003823853, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18000, training loss= 0.00034666125, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18100, training loss= 0.00032171386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18200, training loss= 0.00030858922, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18300, training loss= 0.00031287275, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18400, training loss= 0.00032319775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18500, training loss= 0.00027572628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18600, training loss= 0.0002809802, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18700, training loss= 0.00033846142, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18800, training loss= 0.0002855166, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 18900, training loss= 0.0003231064, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19000, training loss= 0.00029520818, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19100, training loss= 0.0003244688, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19200, training loss= 0.00034001147, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19300, training loss= 0.00031235485, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19400, training loss= 0.00036885517, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19500, training loss= 0.00027412313, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19600, training loss= 0.00035126175, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19700, training loss= 0.00032560076, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19800, training loss= 0.0003513206, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 19900, training loss= 0.00030435665, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20000, training loss= 0.00032671515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20100, training loss= 0.00038626717, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20200, training loss= 0.00036192226, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20300, training loss= 0.0003106938, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20400, training loss= 0.0003276315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20500, training loss= 0.0003637372, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20600, training loss= 0.00023154139, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20700, training loss= 0.00036065927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20800, training loss= 0.000326449, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 20900, training loss= 0.00033453282, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21000, training loss= 0.00029586427, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21100, training loss= 0.00025952255, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21200, training loss= 0.00033797967, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21300, training loss= 0.00031442172, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21400, training loss= 0.00036003586, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21500, training loss= 0.0003779392, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21600, training loss= 0.00031005807, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21700, training loss= 0.00028239342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21800, training loss= 0.00036319406, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 21900, training loss= 0.00034834316, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22000, training loss= 0.000331756, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22100, training loss= 0.00028463552, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22200, training loss= 0.00029946066, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22300, training loss= 0.00026341938, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22400, training loss= 0.00028007376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22500, training loss= 0.00030905154, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22600, training loss= 0.0002776637, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22700, training loss= 0.0003032332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22800, training loss= 0.00030619508, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 22900, training loss= 0.00027948414, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23000, training loss= 0.00033089909, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23100, training loss= 0.00031807495, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23200, training loss= 0.0002999249, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23300, training loss= 0.00036368324, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23400, training loss= 0.00025514356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23500, training loss= 0.00027383724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23600, training loss= 0.0002685423, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23700, training loss= 0.0004005047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23800, training loss= 0.00037250153, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 23900, training loss= 0.00027764522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24000, training loss= 0.00035603356, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24100, training loss= 0.00028342765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24200, training loss= 0.00034567647, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24300, training loss= 0.00036197752, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24400, training loss= 0.00030589217, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24500, training loss= 0.00026754534, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24600, training loss= 0.000353928, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24700, training loss= 0.0002713779, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24800, training loss= 0.0002826401, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 24900, training loss= 0.00033189298, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25000, training loss= 0.00024169765, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25100, training loss= 0.00025278277, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25200, training loss= 0.00032260927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25300, training loss= 0.00030096524, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25400, training loss= 0.00027884115, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25500, training loss= 0.00036583617, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25600, training loss= 0.00029553674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25700, training loss= 0.00034711554, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25800, training loss= 0.00027941327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 25900, training loss= 0.00029404662, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26000, training loss= 0.0002962058, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26100, training loss= 0.00034636245, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26200, training loss= 0.00028723988, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26300, training loss= 0.00029805792, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26400, training loss= 0.0002989132, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26500, training loss= 0.00032721218, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26600, training loss= 0.00027217824, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26700, training loss= 0.00030027606, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26800, training loss= 0.00028766246, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 26900, training loss= 0.00033987788, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27000, training loss= 0.00029421007, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27100, training loss= 0.00024902227, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27200, training loss= 0.00029725078, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27300, training loss= 0.00027303136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27400, training loss= 0.00028397763, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27500, training loss= 0.00022892529, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27600, training loss= 0.0003080333, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27700, training loss= 0.00028004023, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27800, training loss= 0.00035346768, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 27900, training loss= 0.00034470012, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28000, training loss= 0.00028468628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28100, training loss= 0.0002910696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28200, training loss= 0.00029874273, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28300, training loss= 0.00033914048, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28400, training loss= 0.00031491747, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28500, training loss= 0.0002981359, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28600, training loss= 0.00035949072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28700, training loss= 0.00032011897, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28800, training loss= 0.00031676, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 28900, training loss= 0.00031975782, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29000, training loss= 0.0002736767, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29100, training loss= 0.0002522687, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29200, training loss= 0.0003286625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29300, training loss= 0.00034804147, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29400, training loss= 0.00032577428, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29500, training loss= 0.00032068134, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29600, training loss= 0.0002730571, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29700, training loss= 0.00023258584, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29800, training loss= 0.00032006376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 29900, training loss= 0.00026933342, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.11397405, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.021806072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.024574757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.0014466571, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.030843182, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.013372327, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.009152681, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.0020060202, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.0013510047, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0010122899, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.01258711, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0025760287, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.026009647, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.011927058, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0007133104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.0005153447, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0006864803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.020174585, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0110371625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.0016129529, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.00068054325, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0004614452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.017372312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.003998731, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.0012978129, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.00048553836, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.009061593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.0009919842, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.00835812, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.007795529, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.0007365897, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.00060275814, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.013802621, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.00087894045, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.0014064854, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.00090764504, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.00058587233, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.0071526244, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.0007816584, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.005967303, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.006962742, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.0011524969, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.0005676103, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0005959842, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.0053032646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.0005969049, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.005029285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.00048493873, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.00094044436, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.00054791145, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.004534025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.00048346567, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.00075573626, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.00067168777, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.00088264386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00056371075, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00053426344, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00088862405, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.0007768741, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.0005945355, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00069213315, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00072189054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00048760112, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.003609808, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.00074018136, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00049385155, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.0006843793, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.00067693624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.00090967695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.0005708224, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.00071257324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.0005611152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.0005365221, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.0006266646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.0005283062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.0004493948, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.0005693727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.002381808, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.0018727906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.000599865, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.0005619785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.00056190667, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.000560496, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.0006473809, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.00060816127, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.0015910041, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.00065025507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.0015727909, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.0006179541, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.0004905799, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.00055353943, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.00052571157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.001628492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.00090822944, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.00078327535, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.0011844492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.0014602875, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.00054935546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.0012230657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.00059762405, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.0006282712, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.0010997863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.0005672814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.0011195163, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.001038751, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.0005893905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.0007207067, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.0011533218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.00053676876, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.0006286482, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.0005544668, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.0006646903, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.00093872036, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.00068735814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.00065799005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.00055923685, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.0010118532, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.0005620678, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.00051035715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.0008252074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.00063417986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.0005117375, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.0008697851, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.0004856404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.0005415538, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 0.00070458185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 0.0006406096, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 0.0004736295, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 0.00058329507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 0.00048943167, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 0.00060047186, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 0.0006844671, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 0.00071882305, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 0.0007614113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 0.00068882044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 0.00056411553, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 0.00054954784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 0.0006997587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 0.00069260184, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.0006375294, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 0.00083622354, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.00079669524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.00061095017, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 0.00071408105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.0007922076, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.0005561977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0006746181, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00042455533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00066629815, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.0006895085, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.0005206328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.0005177548, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.00057138177, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.0006730873, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.0008687433, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.0007053638, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.0005970858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.000503082, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.0007574986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.0006130241, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0004421624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.00043710004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.00054380106, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00057880534, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00052322506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.0006047321, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.00068627053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.0007033145, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.00059351337, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00053374417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.0007166095, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00055718014, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.00054340565, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00052059814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.0005610415, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00051248557, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.0005367996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00068361097, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0006842123, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.00059896475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.00078093447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.00046723755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00046037705, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.0005424242, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.00057801715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0004883826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.0005071323, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.0005456764, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00052442, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00072792545, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.00050162943, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.00044363108, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.000513158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0004582143, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0006413818, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00048699882, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.00066481676, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00048706686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00050250575, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00058932544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00049728085, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00067507004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.0007133281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00053984596, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.00066203525, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00061277486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.00056904677, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0007956597, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.0005897617, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00054730044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.00061126763, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00046366025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.00065266696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00049005233, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00060667517, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00064576673, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00054821034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00054020784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0004876203, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0006012823, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.00046222052, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.00062233146, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0005129188, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0006740993, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00050995237, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.00042434936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0005777638, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00049683417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00063158054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.0005283956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.00048589308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00058866147, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.000608287, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00054377824, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00062132836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0006289155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0005456006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0004772151, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.00047684787, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.00050584105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00046698048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00047278567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0005246994, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0006038381, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.00054318557, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0004975699, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00050116715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0006354885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0007209084, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0005542478, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0006206083, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.000567877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0004644847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0006346977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0005752149, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0005107207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00069490937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00056109595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00048108088, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00067521236, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00055198616, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0006929393, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0005240081, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0005783488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.000662422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0005430404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0007084947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00064872793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00042647394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.0007308877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0007553167, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.00074906764, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00068471994, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.0006528893, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00044200194, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0005516468, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00057210814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0005168794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0004404855, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00054108456, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0005411834, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0005628971, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00051466294, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00047184937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0005868128, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.00049710966, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.000535625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00046787207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.000532312, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0005397706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0006180953, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00055720395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0006022646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0005366017, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00048647073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00071260403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00057718734, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0006115148, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.00047422326, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0007136775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.342102, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.06325482, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 200, training loss= 0.059519164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 300, training loss= 0.0864801, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 400, training loss= 0.032620836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 500, training loss= 0.010075964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 600, training loss= 0.025701847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 700, training loss= 0.00161061, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 800, training loss= 0.024663493, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 900, training loss= 0.005450472, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1000, training loss= 0.00070459506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1100, training loss= 0.012340493, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 0.01764435, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1300, training loss= 0.0090250755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1400, training loss= 0.0007198907, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1500, training loss= 0.0006253389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1600, training loss= 0.009693428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1700, training loss= 0.0023117792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1800, training loss= 0.0048057265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1900, training loss= 0.0015747943, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2000, training loss= 0.005460644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2100, training loss= 0.002250847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2200, training loss= 0.0011670083, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2300, training loss= 0.000793417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2400, training loss= 0.0011296755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2500, training loss= 0.00094043603, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2600, training loss= 0.0005728708, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2700, training loss= 0.0005828233, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2800, training loss= 0.0027021053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2900, training loss= 0.000884388, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 3000, training loss= 0.0005878382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 3100, training loss= 0.0009891847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 3200, training loss= 0.0016819919, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3300, training loss= 0.00079199695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3400, training loss= 0.0010168614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3500, training loss= 0.0013770226, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3600, training loss= 0.00044694237, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3700, training loss= 0.00066962105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3800, training loss= 0.00073528173, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3900, training loss= 0.00069601403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4000, training loss= 0.00060963136, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4100, training loss= 0.00049091206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4200, training loss= 0.0011800512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4300, training loss= 0.000417822, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4400, training loss= 0.0007963662, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4500, training loss= 0.0009017382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4600, training loss= 0.0008816809, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4700, training loss= 0.000721458, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4800, training loss= 0.0011788837, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4900, training loss= 0.00061580155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5000, training loss= 0.0005255514, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5100, training loss= 0.000616502, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5200, training loss= 0.00072940363, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5300, training loss= 0.0011159867, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5400, training loss= 0.00071974366, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5500, training loss= 0.0007271648, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5600, training loss= 0.0007563316, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5700, training loss= 0.0006240568, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5800, training loss= 0.0005715547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5900, training loss= 0.0005278991, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6000, training loss= 0.00071556016, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6100, training loss= 0.00062121043, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6200, training loss= 0.0006669826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6300, training loss= 0.00056640164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6400, training loss= 0.0005993835, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6500, training loss= 0.0005788913, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6600, training loss= 0.00089751766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6700, training loss= 0.0006627389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6800, training loss= 0.00067581766, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6900, training loss= 0.0007300355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7000, training loss= 0.00076925894, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7100, training loss= 0.000722964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7200, training loss= 0.0007290669, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7300, training loss= 0.00046546664, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7400, training loss= 0.00052980566, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7500, training loss= 0.0006216203, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7600, training loss= 0.0007043925, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7700, training loss= 0.0006211255, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7800, training loss= 0.0008301972, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7900, training loss= 0.0005488262, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8000, training loss= 0.0005607707, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8100, training loss= 0.00039485804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8200, training loss= 0.00063166645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8300, training loss= 0.000598908, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8400, training loss= 0.0007162102, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8500, training loss= 0.00060259755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8600, training loss= 0.00045172006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8700, training loss= 0.00058735657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8800, training loss= 0.0005166361, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8900, training loss= 0.00056664646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9000, training loss= 0.00053891743, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9100, training loss= 0.00062752346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9200, training loss= 0.00067354384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9300, training loss= 0.00052933133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9400, training loss= 0.0007101195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9500, training loss= 0.0005467804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9600, training loss= 0.0006787174, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9700, training loss= 0.0005957352, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9800, training loss= 0.00037117544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 9900, training loss= 0.00055903295, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10000, training loss= 0.0005626578, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10100, training loss= 0.00065630395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10200, training loss= 0.0005403341, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10300, training loss= 0.0006677656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10400, training loss= 0.0006346399, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10500, training loss= 0.00060190755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10600, training loss= 0.00053528155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10700, training loss= 0.0005618863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10800, training loss= 0.000529911, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 10900, training loss= 0.0005395111, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11000, training loss= 0.0008151007, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11100, training loss= 0.00041134586, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11200, training loss= 0.0005279958, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11300, training loss= 0.00049397256, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11400, training loss= 0.00046698886, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11500, training loss= 0.00044236955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11600, training loss= 0.0005093366, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11700, training loss= 0.0005842921, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11800, training loss= 0.00065900886, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 11900, training loss= 0.00060978235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12000, training loss= 0.0006142773, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12100, training loss= 0.00047141404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12200, training loss= 0.00055063254, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12300, training loss= 0.00046841346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12400, training loss= 0.00055090117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12500, training loss= 0.0006408007, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12600, training loss= 0.00068038644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12700, training loss= 0.0007069318, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12800, training loss= 0.0005917768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 12900, training loss= 0.00063751, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13000, training loss= 0.0005377846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13100, training loss= 0.00056875165, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13200, training loss= 0.00050903985, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13300, training loss= 0.00063084625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13400, training loss= 0.00049404055, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13500, training loss= 0.00054637645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13600, training loss= 0.00065316784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13700, training loss= 0.00039640156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13800, training loss= 0.00068770885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 13900, training loss= 0.00054385397, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14000, training loss= 0.00042639533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14100, training loss= 0.00061432715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14200, training loss= 0.00054899853, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14300, training loss= 0.0006534822, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14400, training loss= 0.000671748, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14500, training loss= 0.00052166067, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14600, training loss= 0.00062867184, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14700, training loss= 0.00071577274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14800, training loss= 0.0004497508, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 14900, training loss= 0.00051017175, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 15000, training loss= 0.0006587539, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15100, training loss= 0.00058114686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15200, training loss= 0.0006888239, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15300, training loss= 0.0005337608, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15400, training loss= 0.00071525935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15500, training loss= 0.0004898747, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15600, training loss= 0.00050604186, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15700, training loss= 0.00045973825, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15800, training loss= 0.0005490436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15900, training loss= 0.00039753848, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16000, training loss= 0.00047347887, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16100, training loss= 0.00058752927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16200, training loss= 0.00058770226, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16300, training loss= 0.00055026123, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16400, training loss= 0.0006306563, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16500, training loss= 0.00063605857, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16600, training loss= 0.0005686686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16700, training loss= 0.00051854044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16800, training loss= 0.0006271375, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16900, training loss= 0.0005345383, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17000, training loss= 0.00054368854, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17100, training loss= 0.0004349979, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17200, training loss= 0.0004750441, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17300, training loss= 0.00066642, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17400, training loss= 0.00063730567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17500, training loss= 0.0006359808, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17600, training loss= 0.000493533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17700, training loss= 0.0006625077, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17800, training loss= 0.0005012088, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17900, training loss= 0.0005009069, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18000, training loss= 0.00041274895, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18100, training loss= 0.000687239, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18200, training loss= 0.00051238097, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18300, training loss= 0.00076588074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18400, training loss= 0.0005318433, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18500, training loss= 0.00059893564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18600, training loss= 0.00039115868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18700, training loss= 0.0005403265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18800, training loss= 0.00056604436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18900, training loss= 0.0006145777, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19000, training loss= 0.0005269828, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19100, training loss= 0.0006558573, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19200, training loss= 0.00039595278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19300, training loss= 0.0005362968, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19400, training loss= 0.0005210553, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19500, training loss= 0.00038921094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19600, training loss= 0.000423703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19700, training loss= 0.00056385156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19800, training loss= 0.0005362704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 19900, training loss= 0.00044852236, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20000, training loss= 0.00052024785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20100, training loss= 0.00062204327, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20200, training loss= 0.00040910064, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20300, training loss= 0.00056054763, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20400, training loss= 0.0006470202, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20500, training loss= 0.00038727466, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20600, training loss= 0.00046550747, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20700, training loss= 0.00059396506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20800, training loss= 0.00064489606, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 20900, training loss= 0.00054915826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21000, training loss= 0.00048382225, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21100, training loss= 0.00051019137, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21200, training loss= 0.0005538322, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21300, training loss= 0.0005380794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21400, training loss= 0.0005346852, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21500, training loss= 0.0005316006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21600, training loss= 0.00050765317, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21700, training loss= 0.00045188388, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21800, training loss= 0.00047047235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 21900, training loss= 0.00055840844, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22000, training loss= 0.0005671118, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22100, training loss= 0.0005434386, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22200, training loss= 0.00065161637, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22300, training loss= 0.0005608428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22400, training loss= 0.000498383, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22500, training loss= 0.0004407816, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22600, training loss= 0.0005548512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 22700, training loss= 0.000481624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22800, training loss= 0.00046585355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 22900, training loss= 0.00054227654, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23000, training loss= 0.00050414656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23100, training loss= 0.00042784587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23200, training loss= 0.0004819727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23300, training loss= 0.00058193004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23400, training loss= 0.00051835354, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23500, training loss= 0.0004723732, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23600, training loss= 0.00051500776, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23700, training loss= 0.00052086945, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23800, training loss= 0.00046037376, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 23900, training loss= 0.00050178624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24000, training loss= 0.00055527536, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24100, training loss= 0.00055414636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24200, training loss= 0.00052930624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24300, training loss= 0.00061480934, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24400, training loss= 0.00063817314, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24500, training loss= 0.00059272395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24600, training loss= 0.00052595604, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24700, training loss= 0.0006173932, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24800, training loss= 0.0004953477, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 24900, training loss= 0.00040300714, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25000, training loss= 0.0004392438, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 25100, training loss= 0.0005201318, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.0005086998, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.00048205862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.00046886317, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.0004142361, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25600, training loss= 0.00056284247, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25700, training loss= 0.00049691286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25800, training loss= 0.00048639684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25900, training loss= 0.0005676306, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26000, training loss= 0.00048510922, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26100, training loss= 0.0005324007, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26200, training loss= 0.000531161, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26300, training loss= 0.00036943745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26400, training loss= 0.00045119209, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26500, training loss= 0.0005151951, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26600, training loss= 0.0004949099, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26700, training loss= 0.00042558947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26800, training loss= 0.0005420038, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 26900, training loss= 0.000500137, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27000, training loss= 0.0004894897, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27100, training loss= 0.0006508079, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27200, training loss= 0.00046545058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27300, training loss= 0.0005560876, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27400, training loss= 0.00054125383, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27500, training loss= 0.00049053325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27600, training loss= 0.00041619525, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27700, training loss= 0.00049362564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27800, training loss= 0.00048340048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 27900, training loss= 0.00057532906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28000, training loss= 0.00051258574, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28100, training loss= 0.000487804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28200, training loss= 0.0006648244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28300, training loss= 0.00051352824, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28400, training loss= 0.0005308393, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28500, training loss= 0.0004195674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28600, training loss= 0.0005446546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28700, training loss= 0.00043718197, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28800, training loss= 0.00040227617, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 28900, training loss= 0.0004957951, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29000, training loss= 0.0003392703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29100, training loss= 0.0005806485, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29200, training loss= 0.00044222432, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29300, training loss= 0.00048563414, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29400, training loss= 0.0004491115, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29500, training loss= 0.00045662158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29600, training loss= 0.00047346725, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29700, training loss= 0.00042248226, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29800, training loss= 0.00048504473, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 29900, training loss= 0.0004851749, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 86.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.2765628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.05951261, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.03427775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.015712108, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.018324167, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.0071404595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.015625142, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.0018244451, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.0021197728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.019358568, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1000, training loss= 0.001337626, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 1100, training loss= 0.010946463, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 0.003147234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1300, training loss= 0.002838389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1400, training loss= 0.0004780157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1500, training loss= 0.008827049, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1600, training loss= 0.00050719676, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1700, training loss= 0.001949794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1800, training loss= 0.0020598415, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1900, training loss= 0.0008625373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2000, training loss= 0.0009775381, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2100, training loss= 0.004795812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2200, training loss= 0.00093968044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2300, training loss= 0.002623796, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2400, training loss= 0.0036207214, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2500, training loss= 0.0006037018, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2600, training loss= 0.0014486117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2700, training loss= 0.000519349, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2800, training loss= 0.001068905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 2900, training loss= 0.00083646167, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3000, training loss= 0.0008751977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3100, training loss= 0.0006565951, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3200, training loss= 0.0012530987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3300, training loss= 0.0011220862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3400, training loss= 0.0009064784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3500, training loss= 0.0018486278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3600, training loss= 0.0011676433, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3700, training loss= 0.0009177555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3800, training loss= 0.0006335901, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 3900, training loss= 0.0006134999, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4000, training loss= 0.0008401093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4100, training loss= 0.0015577651, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4200, training loss= 0.00093480776, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4300, training loss= 0.00069750164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4400, training loss= 0.0009358324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4500, training loss= 0.00049882417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4600, training loss= 0.00079050753, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4700, training loss= 0.0010631987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4800, training loss= 0.00056016847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 4900, training loss= 0.0010333722, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5000, training loss= 0.0006387279, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5100, training loss= 0.0007933958, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5200, training loss= 0.0007288048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5300, training loss= 0.00073181966, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5400, training loss= 0.0009754586, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5500, training loss= 0.0010636831, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5600, training loss= 0.0013078916, training acc= 100.0%\n",
            "Validation Accuracy valid 94.18181610107422 ...\n",
            "\n",
            "step 5700, training loss= 0.001143856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 5800, training loss= 0.00067464047, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 5900, training loss= 0.00062384666, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6000, training loss= 0.00066449714, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6100, training loss= 0.000562172, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6200, training loss= 0.00053123076, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6300, training loss= 0.00065550616, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6400, training loss= 0.00050067663, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6500, training loss= 0.0003859875, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6600, training loss= 0.0009382713, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6700, training loss= 0.00066319655, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6800, training loss= 0.00092142925, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 6900, training loss= 0.0005222079, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7000, training loss= 0.0007771178, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7100, training loss= 0.0005602869, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7200, training loss= 0.0006457162, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7300, training loss= 0.0008107702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7400, training loss= 0.0005670339, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7500, training loss= 0.0005439302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7600, training loss= 0.0005617164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7700, training loss= 0.00065956195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7800, training loss= 0.0004421031, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 7900, training loss= 0.00054755737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8000, training loss= 0.000559344, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8100, training loss= 0.0007202964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8200, training loss= 0.00077658205, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8300, training loss= 0.0006489123, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8400, training loss= 0.0006125269, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8500, training loss= 0.00072602846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8600, training loss= 0.00077132415, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8700, training loss= 0.00060906797, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8800, training loss= 0.00060618634, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 8900, training loss= 0.00091305585, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9000, training loss= 0.00061011396, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9100, training loss= 0.0006522811, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9200, training loss= 0.0004933543, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9300, training loss= 0.0005983547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9400, training loss= 0.000599102, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9500, training loss= 0.000608686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9600, training loss= 0.0005036342, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9700, training loss= 0.00061944243, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9800, training loss= 0.00069703226, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 9900, training loss= 0.0007167991, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10000, training loss= 0.0004072155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10100, training loss= 0.00049933034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10200, training loss= 0.00056893093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10300, training loss= 0.000542962, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10400, training loss= 0.00060875644, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10500, training loss= 0.0005136272, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10600, training loss= 0.00073615665, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10700, training loss= 0.00055703195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10800, training loss= 0.0005363612, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 10900, training loss= 0.00065961096, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11000, training loss= 0.00057465216, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11100, training loss= 0.0004808274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11200, training loss= 0.00067798275, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11300, training loss= 0.0005428835, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11400, training loss= 0.0006047395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11500, training loss= 0.0005642301, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11600, training loss= 0.0005898954, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11700, training loss= 0.000691988, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11800, training loss= 0.00067558856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 11900, training loss= 0.00056347635, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12000, training loss= 0.0005191122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12100, training loss= 0.0007582209, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12200, training loss= 0.00060220074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12300, training loss= 0.0005808059, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12400, training loss= 0.00051087287, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12500, training loss= 0.00057845155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12600, training loss= 0.0005146325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12700, training loss= 0.0005693516, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12800, training loss= 0.0006423956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 12900, training loss= 0.0004914872, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13000, training loss= 0.00058886025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13100, training loss= 0.0005060674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13200, training loss= 0.0006057254, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13300, training loss= 0.00059729617, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13400, training loss= 0.00073774176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13500, training loss= 0.00047150382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13600, training loss= 0.0005499425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13700, training loss= 0.0006588168, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13800, training loss= 0.0004932012, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 13900, training loss= 0.0006408868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14000, training loss= 0.00042302726, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14100, training loss= 0.00058815745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14200, training loss= 0.00067810935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14300, training loss= 0.0005458221, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14400, training loss= 0.00048759504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14500, training loss= 0.00066981814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14600, training loss= 0.0005202056, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14700, training loss= 0.0005348044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14800, training loss= 0.0004553552, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 14900, training loss= 0.00047720812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15000, training loss= 0.00065308734, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15100, training loss= 0.0005851475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15200, training loss= 0.00061028515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15300, training loss= 0.00048761905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15400, training loss= 0.00042899113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15500, training loss= 0.0006769558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15600, training loss= 0.000628963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15700, training loss= 0.00044672852, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15800, training loss= 0.0006798042, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 15900, training loss= 0.0005996804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16000, training loss= 0.00048762964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16100, training loss= 0.0006274011, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16200, training loss= 0.0005085889, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16300, training loss= 0.00059135124, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16400, training loss= 0.0005367819, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16500, training loss= 0.0004947411, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16600, training loss= 0.000699971, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16700, training loss= 0.0004296711, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16800, training loss= 0.0005365787, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 16900, training loss= 0.00046274194, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17000, training loss= 0.0004925986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17100, training loss= 0.00047542428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17200, training loss= 0.000561885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17300, training loss= 0.00051548134, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17400, training loss= 0.0005436379, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17500, training loss= 0.0005064049, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17600, training loss= 0.0005299696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17700, training loss= 0.0006200222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17800, training loss= 0.0005303889, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 17900, training loss= 0.0005229179, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18000, training loss= 0.0005140972, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18100, training loss= 0.00067956035, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18200, training loss= 0.0003990755, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 18300, training loss= 0.0005220895, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18400, training loss= 0.00052788254, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18500, training loss= 0.00047513627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18600, training loss= 0.0006499278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 18700, training loss= 0.00035428395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18800, training loss= 0.00047890213, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18900, training loss= 0.00048665062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19000, training loss= 0.00045583257, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19100, training loss= 0.00046244715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19200, training loss= 0.00061433803, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19300, training loss= 0.0005264377, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.00048187826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.00046707474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.00042248724, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.00047284417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19800, training loss= 0.00056842406, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19900, training loss= 0.00046301982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20000, training loss= 0.00050741696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20100, training loss= 0.00050963706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20200, training loss= 0.0004702552, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20300, training loss= 0.0006392506, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20400, training loss= 0.00052821985, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20500, training loss= 0.00058517343, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20600, training loss= 0.00061102345, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20700, training loss= 0.0004970346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20800, training loss= 0.0004316801, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 20900, training loss= 0.000501312, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21000, training loss= 0.00063620263, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21100, training loss= 0.00054801826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21200, training loss= 0.0005047407, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21300, training loss= 0.00049390073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21400, training loss= 0.0005911909, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21500, training loss= 0.000573306, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21600, training loss= 0.00040449976, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21700, training loss= 0.00043354064, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21800, training loss= 0.0005725982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 21900, training loss= 0.00058365136, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22000, training loss= 0.00050481246, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22100, training loss= 0.00049316627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22200, training loss= 0.00047604158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22300, training loss= 0.00038421396, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22400, training loss= 0.00054193323, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22500, training loss= 0.00046548105, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22600, training loss= 0.00060699077, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22700, training loss= 0.0005253708, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22800, training loss= 0.0005976673, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 22900, training loss= 0.00046660705, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23000, training loss= 0.0004484021, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23100, training loss= 0.00046014166, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23200, training loss= 0.00055543263, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23300, training loss= 0.0006536389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23400, training loss= 0.0005471546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23500, training loss= 0.0004917259, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23600, training loss= 0.0005746577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23700, training loss= 0.00053729455, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23800, training loss= 0.0005705333, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 23900, training loss= 0.0004921009, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24000, training loss= 0.00040815858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24100, training loss= 0.0004566274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24200, training loss= 0.00044504728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24300, training loss= 0.00054121367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24400, training loss= 0.00052728876, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24500, training loss= 0.00049698225, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24600, training loss= 0.0005246195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24700, training loss= 0.0006321098, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24800, training loss= 0.00055435265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 24900, training loss= 0.0005351526, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25000, training loss= 0.00053115364, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25100, training loss= 0.00049688225, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25200, training loss= 0.00039670023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25300, training loss= 0.00045692126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25400, training loss= 0.00046906946, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 25500, training loss= 0.0004367727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00067562185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0005449463, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00050247624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0005110792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0005143368, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0006469514, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.0004636765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00043321133, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00069615914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0005238877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00052570505, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.0004285053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00053353107, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00052402285, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0004918473, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0005276984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00053454156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.000515382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00051933696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00055458513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.0004688562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0005118839, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.00056378066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0004876849, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.00048729836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.0005975131, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.0005860847, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00052342296, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.0005056748, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.00047331577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00048784493, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.0005338382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0005411555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.0004560061, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.00042391452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0005369784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.00047373894, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00056494866, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0005003415, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00052916777, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00056110113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00042144427, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0004782922, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0005638674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 94.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.16406432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.06081904, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.04377345, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 300, training loss= 0.010189983, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.008629178, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.0033250733, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.011143487, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.0031480244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.029207464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.000543408, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1000, training loss= 0.0023847136, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1100, training loss= 0.0007478687, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1200, training loss= 0.00075688626, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1300, training loss= 0.0006221416, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1400, training loss= 0.00048032985, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1500, training loss= 0.0005513688, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1600, training loss= 0.0004327103, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1700, training loss= 0.00062246807, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1800, training loss= 0.00748865, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 1900, training loss= 0.00045308872, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2000, training loss= 0.00043632835, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2100, training loss= 0.00063545274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2200, training loss= 0.0065716715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2300, training loss= 0.0004724069, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2400, training loss= 0.00042976363, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2500, training loss= 0.00040216444, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2600, training loss= 0.0004706479, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2700, training loss= 0.00050368364, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2800, training loss= 0.0007403986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 2900, training loss= 0.00041708077, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3000, training loss= 0.000504013, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 3100, training loss= 0.0004442028, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 0.00061707495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 0.0005187015, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 0.00045316515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 0.0018196984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 0.00041389276, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 0.00050090667, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 0.0004512356, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 0.002552188, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 0.0025060524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 0.0011148646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 0.00053193426, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 0.00043440145, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 0.0003777384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 0.0009163867, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 0.00036366962, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 0.00081884494, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 0.00044307642, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 0.00060745515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 0.00048898836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 0.00041291825, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 0.000650857, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 0.0003194881, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 0.00034446633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 0.000695716, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 0.0005912483, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 0.00047791464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 0.0010659609, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 0.00049201073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 0.00068744284, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 0.0005013572, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 0.00039038513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 0.0009677916, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.00047131238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.00040951665, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00091319066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00094218465, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6800, training loss= 0.0008472122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 6900, training loss= 0.00041893325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7000, training loss= 0.0007185878, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7100, training loss= 0.0003832947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7200, training loss= 0.0007842044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7300, training loss= 0.00047832154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7400, training loss= 0.00043289823, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7500, training loss= 0.000488029, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7600, training loss= 0.0005467701, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7700, training loss= 0.00039560968, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7800, training loss= 0.0004530389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 7900, training loss= 0.0005209023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8000, training loss= 0.0006237469, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8100, training loss= 0.0004896068, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8200, training loss= 0.00032220344, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8300, training loss= 0.00047987656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8400, training loss= 0.00048359283, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8500, training loss= 0.00046025572, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8600, training loss= 0.00055156864, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8700, training loss= 0.00076517765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8800, training loss= 0.00045726297, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8900, training loss= 0.0004961583, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9000, training loss= 0.000482865, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9100, training loss= 0.00042608858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9200, training loss= 0.00047784694, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9300, training loss= 0.0005447025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9400, training loss= 0.00048430887, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9500, training loss= 0.00044373877, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9600, training loss= 0.00042580283, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9700, training loss= 0.0004416907, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9800, training loss= 0.00041947656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9900, training loss= 0.00046817795, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10000, training loss= 0.0004820195, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10100, training loss= 0.00039479375, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10200, training loss= 0.00043143547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10300, training loss= 0.0004895843, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10400, training loss= 0.00044592645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10500, training loss= 0.0005439409, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10600, training loss= 0.0003856919, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10700, training loss= 0.00049998023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10800, training loss= 0.0004403155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10900, training loss= 0.0004389453, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11000, training loss= 0.00041466934, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11100, training loss= 0.00041974452, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11200, training loss= 0.00038909185, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11300, training loss= 0.0005338855, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11400, training loss= 0.00037516523, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11500, training loss= 0.0004954828, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11600, training loss= 0.00041081363, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11700, training loss= 0.00059593417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11800, training loss= 0.00048002088, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11900, training loss= 0.0004519814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12000, training loss= 0.0003452418, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12100, training loss= 0.0005459201, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12200, training loss= 0.00044409127, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12300, training loss= 0.00040260557, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 0.0005051267, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 0.00045942664, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 0.00037409828, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 0.0005548351, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 0.00048776862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 0.0004643632, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 0.0003730063, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 0.0003840545, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 0.0005211479, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 0.0004115811, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 0.0005314974, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 0.0005095323, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 0.0004900669, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 0.00039414302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 0.00039350995, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 0.00057510426, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14000, training loss= 0.0004725826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14100, training loss= 0.00043712236, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 0.0004375547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 0.0005080468, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 0.00050059904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14500, training loss= 0.00035590175, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14600, training loss= 0.00038845005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14700, training loss= 0.00046198888, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14800, training loss= 0.00039670864, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14900, training loss= 0.00042678497, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15000, training loss= 0.0005356774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15100, training loss= 0.00036408158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15200, training loss= 0.0004837984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15300, training loss= 0.00044866497, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15400, training loss= 0.00046116774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15500, training loss= 0.00052013964, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15600, training loss= 0.0003895441, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15700, training loss= 0.0004326587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15800, training loss= 0.0005507654, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 15900, training loss= 0.00042314696, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16000, training loss= 0.00038079984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16100, training loss= 0.00036186387, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16200, training loss= 0.0005655424, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16300, training loss= 0.00045687356, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16400, training loss= 0.0004614646, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16500, training loss= 0.00039220782, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16600, training loss= 0.00045260417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16700, training loss= 0.0004857591, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16800, training loss= 0.0003141216, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 16900, training loss= 0.00048635947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17000, training loss= 0.00038184988, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17100, training loss= 0.0004137416, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17200, training loss= 0.0004600762, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17300, training loss= 0.0004556929, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17400, training loss= 0.00036291176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17500, training loss= 0.00050208624, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17600, training loss= 0.00041902292, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17700, training loss= 0.0004719992, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17800, training loss= 0.00043127284, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 17900, training loss= 0.00045309326, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18000, training loss= 0.00051901065, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18100, training loss= 0.00047189122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18200, training loss= 0.00044265893, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18300, training loss= 0.00039977796, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18400, training loss= 0.00044845394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18500, training loss= 0.0004379428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18600, training loss= 0.0004792558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18700, training loss= 0.00049115735, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18800, training loss= 0.00040942716, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 18900, training loss= 0.00036960808, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19000, training loss= 0.00038662303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19100, training loss= 0.00051350065, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19200, training loss= 0.00046049623, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19300, training loss= 0.00039624792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19400, training loss= 0.00041700725, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19500, training loss= 0.00034655293, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19600, training loss= 0.00047771013, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 19700, training loss= 0.00035384813, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00039200045, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00040709486, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00043929773, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0004274663, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00054356776, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00049830734, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0005132023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00049178593, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.00040010657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0004129288, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00036408615, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00039381834, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.00047523703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00043673214, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.00036757192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00040924305, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00042572044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00040452895, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00047412963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.0005180094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00050596625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.00046900398, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.00039371947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0003897812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.0004307269, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0003810879, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00047237295, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.00035950312, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.0004688371, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.0004731214, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00046397117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00042540568, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0004462421, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00038768703, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.00035154595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00051752315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0003847547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.0003496539, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0004500369, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.00038509927, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.00047852666, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.000476454, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00039678003, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00029956055, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.0004230673, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.0004684496, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0005219608, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.0003318176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00043189805, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.00042067244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0003647855, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0003316724, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0003794855, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00039424023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00044302378, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.00044685556, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.00039056916, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0004720715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.0004509767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0004482596, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00042752817, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.0003417487, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00047425536, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.00045442986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00044858785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0003533158, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00037012034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0005088774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00050936564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00044660422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00042114587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00041797862, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0003882365, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0003929723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00039325436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00039463682, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00038067155, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00045141054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00044839006, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.00043412243, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.00044646813, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00041574906, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.00043474417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.00040473355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00045646576, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00045438996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00045339594, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0002904982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00039922234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00041109938, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0004806729, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00043645524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.00042841118, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.000390122, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0004995222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.0004280812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00042417613, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00035997512, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00046236097, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0004726636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.00043009143, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.00047558424, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.006283905, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.017303359, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.0020587707, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.004675796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 400, training loss= 0.0068520578, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.009789996, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.00044949175, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.0021421865, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.0019953602, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.0019566338, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.0014055354, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0030094148, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.00045233037, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.00056768116, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.00039466558, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.0011812111, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0008127816, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.0006181614, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0018112496, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.0010856751, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.00050245965, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0013793878, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.00067899073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2300, training loss= 0.0006156154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2400, training loss= 0.00093954353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2500, training loss= 0.00047542615, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2600, training loss= 0.0011780955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 0.0004560313, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 0.0005327369, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 0.00046515607, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 0.0008946459, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 0.00046761768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 0.0005563686, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 0.00073389866, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 0.0006355408, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3500, training loss= 0.00041381412, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3600, training loss= 0.0006454464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3700, training loss= 0.00061702286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3800, training loss= 0.0005691668, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3900, training loss= 0.0006745266, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4000, training loss= 0.0005688482, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4100, training loss= 0.00086174987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4200, training loss= 0.0003179031, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4300, training loss= 0.00052196154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4400, training loss= 0.00052258174, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4500, training loss= 0.00045577704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4600, training loss= 0.00054258824, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4700, training loss= 0.0006728439, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4800, training loss= 0.0006618893, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 4900, training loss= 0.0007191061, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5000, training loss= 0.00060677517, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5100, training loss= 0.0004947199, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5200, training loss= 0.00068616256, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5300, training loss= 0.00046435013, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5400, training loss= 0.00056596904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5500, training loss= 0.0006262148, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5600, training loss= 0.00048236412, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5700, training loss= 0.00039628384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5800, training loss= 0.00058349053, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 5900, training loss= 0.00062815176, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6000, training loss= 0.0004008292, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6100, training loss= 0.00040080494, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6200, training loss= 0.00031708868, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6300, training loss= 0.00041830394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6400, training loss= 0.00063086464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6500, training loss= 0.0003798641, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00057396584, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00057029555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.0004541011, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00039848074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.00047435833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.00047147117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.00054650084, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.0005206731, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.00037649614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.00044927004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.0004120025, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.00039972266, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.00040142154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.000461492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.00042489677, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.0004266665, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.00034069218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.00045365765, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.00041173527, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.00039113974, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.0007038634, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.0004399184, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.0005309116, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.00054352346, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.0005003081, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.0006318117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.000368815, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.00044743772, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.00039653716, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.00041295087, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.00046435214, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.0005224202, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.0003690838, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.00040125416, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.0004014184, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.00030305044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.0003428628, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.00047576398, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.00045237812, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.00037667356, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.0004161655, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.0005109336, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.00037689807, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.00042057846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.00050415314, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.0003733329, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.0003255316, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.00036535933, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.0004605775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.00048634538, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.00046668027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.00047415833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.00063536846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.00045328162, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.0004069728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.00035675164, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.00037885373, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.00034464814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.00044166774, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 0.00037013192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 0.00039671946, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 0.00026416313, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 0.00040242093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 0.00036690838, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 0.0004446883, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 0.0004079259, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 0.00050518656, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 0.00039943602, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 0.00034680802, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 0.00050245156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 0.00037567524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 0.0003796174, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 0.0004219306, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.00044608559, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 0.00037612865, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.00048942276, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.00038889033, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 0.00048701148, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.00036712582, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.0004864007, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0003580922, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.0004484911, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00049186556, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.00034590618, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.00039832824, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.0003795814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.00037903956, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.00038158114, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00035726328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.0003440947, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.0003518637, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.00038379998, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.000353293, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.00044094727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.0004849622, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.00040050285, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.00030370924, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.0004331852, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00036830507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.0004491218, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.00040205018, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.00042819712, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.00043599718, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00037562908, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.00034758064, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00041855135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.00047927542, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00034763126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.00048383893, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00041371063, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.0004434911, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.0004072937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.00035464944, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.00040253627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.00047212827, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0004681596, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00035784784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00034223462, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.00029095955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0005111525, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.00039078368, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.00045802235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00033669642, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00033439245, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.00033616676, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.00039063944, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.00040843154, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.00036826113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0003564951, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00039649758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0004778736, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00041122024, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00044245194, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00042627793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00048187058, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00043750543, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00044027882, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00036715242, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0003921935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.0003677044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0004256713, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.00041883433, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00035595574, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00036335422, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.00031459492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.0003467204, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.0004440487, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.0003485858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00034845815, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00044622607, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.0004567165, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00029214233, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00044457224, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.00036704767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.00041595302, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.00032934273, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.00045028553, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.00048207474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00035847325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.00035785945, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.00047505306, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00036476704, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00049028953, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00035570015, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0003939475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00038437525, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.0004008307, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00033377192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00048592096, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.00041363275, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.00041354576, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.00035743546, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0004303183, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.00045292688, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00033835234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00039679665, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.00040773375, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00044934222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.00041123555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.00047612013, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00035744728, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.0005056619, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.00037699527, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0004488706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.00040736207, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00035987038, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00038723284, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.0003575399, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.0005012362, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0004124891, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00037566785, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00038116804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00042544107, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00035779126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00040831996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.00042764112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00038452735, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00032160184, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00035036437, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.00052112347, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.00039479157, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00041236015, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00041343583, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00046371113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.00040692263, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.0003987156, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00040479514, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00044173334, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00034928723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.0004482273, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00030934784, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.00040385628, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.00033524286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00037252676, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0003571639, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.00036332614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.0004132832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.0002691067, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00037563324, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.00040093594, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00037977533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00037810783, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.00039290066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00047139367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.00028867647, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00044521544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.000420028, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00032889002, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00030834915, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00040461874, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.0003694938, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.0004243618, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0003553782, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.00033984464, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.27199572, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.07106997, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.07645705, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.008695343, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 400, training loss= 0.04124274, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 500, training loss= 0.016773472, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 600, training loss= 0.011018531, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 700, training loss= 0.0042286394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 800, training loss= 0.012324603, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 900, training loss= 0.0029394475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1000, training loss= 0.0027203518, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1100, training loss= 0.0016074281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1200, training loss= 0.00078441034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1300, training loss= 0.011542724, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1400, training loss= 0.00084854604, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1500, training loss= 0.0009180206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1600, training loss= 0.00056750723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1700, training loss= 0.0007260739, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1800, training loss= 0.0012002359, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 1900, training loss= 0.004818653, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2000, training loss= 0.00094507047, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2100, training loss= 0.00035971904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2200, training loss= 0.0004946232, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2300, training loss= 0.0006462804, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2400, training loss= 0.0028892504, training acc= 100.0%\n",
            "Validation Accuracy valid 94.36363220214844 ...\n",
            "\n",
            "step 2500, training loss= 0.0011158842, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2600, training loss= 0.0011080507, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2700, training loss= 0.0011304622, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2800, training loss= 0.00042086813, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 2900, training loss= 0.00046993856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3000, training loss= 0.0005975832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3100, training loss= 0.00056513917, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3200, training loss= 0.000709581, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3300, training loss= 0.002002832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3400, training loss= 0.0008310046, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3500, training loss= 0.00044105266, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3600, training loss= 0.0009548222, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3700, training loss= 0.0018060737, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3800, training loss= 0.00035851216, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 3900, training loss= 0.0018760951, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4000, training loss= 0.001959329, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4100, training loss= 0.0015885851, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4200, training loss= 0.0006225739, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4300, training loss= 0.00055400253, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4400, training loss= 0.00044615744, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4500, training loss= 0.001609633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4600, training loss= 0.0006297533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4700, training loss= 0.000496332, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4800, training loss= 0.0003667385, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 4900, training loss= 0.0014340754, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5000, training loss= 0.0005575607, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5100, training loss= 0.00035156365, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5200, training loss= 0.0012635973, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5300, training loss= 0.00072003057, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5400, training loss= 0.0005083265, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5500, training loss= 0.00057551893, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5600, training loss= 0.00048030168, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5700, training loss= 0.0005213863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5800, training loss= 0.0004613466, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 5900, training loss= 0.001059189, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6000, training loss= 0.0002787905, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6100, training loss= 0.0010082425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6200, training loss= 0.00037027767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6300, training loss= 0.00048901996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6400, training loss= 0.000934261, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6500, training loss= 0.0005560775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6600, training loss= 0.0005747281, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6700, training loss= 0.0011716147, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6800, training loss= 0.00040653255, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 6900, training loss= 0.00034723894, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7000, training loss= 0.00044001068, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7100, training loss= 0.0004326238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7200, training loss= 0.0005732202, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7300, training loss= 0.00049000187, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7400, training loss= 0.0008825442, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7500, training loss= 0.0006832358, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7600, training loss= 0.00041326278, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7700, training loss= 0.0005818633, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7800, training loss= 0.00078359374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 7900, training loss= 0.00040135725, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8000, training loss= 0.0005249338, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8100, training loss= 0.00048218112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8200, training loss= 0.0005413571, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8300, training loss= 0.0007838598, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8400, training loss= 0.0004834631, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8500, training loss= 0.00032397767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.54545593261719 ...\n",
            "\n",
            "step 8600, training loss= 0.00033675757, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8700, training loss= 0.00042188584, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8800, training loss= 0.0005497178, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 8900, training loss= 0.0004302062, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9000, training loss= 0.0005569173, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9100, training loss= 0.00032511662, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9200, training loss= 0.00038075846, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9300, training loss= 0.00049504894, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9400, training loss= 0.0004042518, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9500, training loss= 0.00039652895, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9600, training loss= 0.00061491027, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9700, training loss= 0.0005386723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9800, training loss= 0.0005127325, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 9900, training loss= 0.0004209982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10000, training loss= 0.00041682547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10100, training loss= 0.0004059328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10200, training loss= 0.00037603837, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10300, training loss= 0.00042789627, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10400, training loss= 0.0003734349, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10500, training loss= 0.0004192384, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10600, training loss= 0.0004177022, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10700, training loss= 0.00040650315, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10800, training loss= 0.0004148636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 10900, training loss= 0.00047250328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11000, training loss= 0.00037950705, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11100, training loss= 0.00048802595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11200, training loss= 0.00032341125, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11300, training loss= 0.00059358706, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11400, training loss= 0.00044405498, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11500, training loss= 0.00045733538, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11600, training loss= 0.00035840413, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11700, training loss= 0.00037511048, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11800, training loss= 0.00048987, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 11900, training loss= 0.00039615424, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12000, training loss= 0.00045601296, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12100, training loss= 0.00040658945, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12200, training loss= 0.00048189488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12300, training loss= 0.00036575235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12400, training loss= 0.00049555727, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12500, training loss= 0.00039826476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12600, training loss= 0.00046154135, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12700, training loss= 0.00043258935, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12800, training loss= 0.00041194458, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 12900, training loss= 0.00048004574, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13000, training loss= 0.00034604938, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13100, training loss= 0.00041751788, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13200, training loss= 0.00038390953, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13300, training loss= 0.0003662562, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13400, training loss= 0.00031485833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13500, training loss= 0.00036101337, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13600, training loss= 0.00046692867, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13700, training loss= 0.00042933127, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13800, training loss= 0.00038881897, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 13900, training loss= 0.00036475871, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14000, training loss= 0.00035627533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14100, training loss= 0.00052477815, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14200, training loss= 0.00059178966, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14300, training loss= 0.00038370988, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14400, training loss= 0.0004316931, training acc= 100.0%\n",
            "Validation Accuracy valid 94.7272720336914 ...\n",
            "\n",
            "step 14500, training loss= 0.00042929043, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.00047335745, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00049684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.00042121403, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.00038999692, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.00032602693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.00051225355, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.00037841446, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.00052722445, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00030197535, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.0004090695, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.00037856994, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.000410848, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.00034480004, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.00036170075, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.00039841904, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.0003270198, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.00055091345, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00038131725, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.00035713415, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.0003805666, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.00031490586, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.00036155965, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.00040432648, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00037886394, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.0003461609, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00030486044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.00048674503, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00056241604, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.00047217717, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00045220216, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.0004142465, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00034983509, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0004059131, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.0004427106, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.00047202338, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.00033280914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00049316126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00045673834, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.00036904044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.00041386593, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.00029043833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.0003593986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00044581527, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.0003670451, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.00032378832, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.00049376587, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.00037157748, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.00036476317, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.0004091811, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00038170992, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.0003367735, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00043449085, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.00047300517, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.00036108654, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00033604223, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.0003730152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00038970882, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.00034634367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0003486073, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00042687618, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.00030700353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.0004654488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00042094203, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.0003617261, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0004186071, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00030848736, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.000466713, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00044532598, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00037527908, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.0003693903, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00038808308, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00044476625, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.0004582926, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.0004983598, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.0003380109, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.0004115716, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.00039894495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0003747642, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00036848368, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.0004915091, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.00033453957, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00048791335, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.00030888428, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00037957702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.000295884, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00036377768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.00040406288, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00043113116, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.0003506694, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.000474411, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.0003758159, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.0004487241, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0004061716, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.00043921152, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.0003838657, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.0004279395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.00044530738, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00032868335, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.00045529797, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.00035046026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00038093198, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.00029358952, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.0004318896, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.00028920194, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.0004619814, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.00042249836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.0004777093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.00034419436, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.00033255413, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.0003568303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00042108377, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.0004015066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.00037481793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00036460455, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.00039485408, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.00035233915, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00039964303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.00035959645, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.00048462793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.00035995615, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0003380768, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00046287954, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.0004713409, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.00043597046, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.00031833476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.00047407098, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00030206793, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00040247137, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.00039168197, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00045320005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00044427963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.00034221474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0004406343, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.00033534074, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.0004216149, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.00024807733, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00035411885, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.00033555718, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00038203914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.0004022782, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.00048554054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00036264883, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.00045591244, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00039407713, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.0003145702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.0004089354, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.0003355789, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00030840051, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.00036381005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00040610612, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00034483735, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00040224448, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.0003147758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.0003087063, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 94.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.026909309, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.024445113, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 200, training loss= 0.040497713, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 300, training loss= 0.0042156084, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 400, training loss= 0.0062236027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 500, training loss= 0.012746085, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 600, training loss= 0.0015991601, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 700, training loss= 0.003493179, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 800, training loss= 0.0014034107, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 900, training loss= 0.01318381, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1000, training loss= 0.0003802869, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1100, training loss= 0.0068425434, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1200, training loss= 0.00041928946, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1300, training loss= 0.00085346226, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0005826146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.0031995354, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.001190188, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.0005276738, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.00053760025, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.00069544965, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.00043823605, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0015279106, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.0010145897, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.00083383906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.00046015898, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.00066463335, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.00054259796, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2700, training loss= 0.00049674424, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2800, training loss= 0.00081253494, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2900, training loss= 0.0010348449, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3000, training loss= 0.0013667389, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3100, training loss= 0.00040776475, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3200, training loss= 0.00046908745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3300, training loss= 0.0003800503, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3400, training loss= 0.00054878986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.0004506706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.0006007386, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.0007541104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.0007704593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.00039332273, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.0010254716, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.00048839056, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.00047227624, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.00033327696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.00067273935, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.00027743774, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.00066784484, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.00030253155, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.00047754508, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.0005353991, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.0007431829, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.0005168627, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.0004246054, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0005521531, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.00029156794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00079379376, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00045489563, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00048382516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.00057485537, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00053486845, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.00044769555, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00042200217, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00046469312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.0005128328, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.00037504281, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00049515965, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6600, training loss= 0.00037540996, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6700, training loss= 0.00038639767, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6800, training loss= 0.00062674575, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 6900, training loss= 0.00035769702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7000, training loss= 0.000521299, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7100, training loss= 0.00035428838, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7200, training loss= 0.00033058235, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7300, training loss= 0.00040649285, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7400, training loss= 0.00048887066, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7500, training loss= 0.00042906925, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7600, training loss= 0.00062437495, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7700, training loss= 0.0003688237, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7800, training loss= 0.0004476191, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 7900, training loss= 0.00051439693, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8000, training loss= 0.00055211707, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8100, training loss= 0.0003881114, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8200, training loss= 0.00047487026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8300, training loss= 0.00038701453, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8400, training loss= 0.000450117, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8500, training loss= 0.00040841723, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8600, training loss= 0.00037650485, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8700, training loss= 0.00043075116, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8800, training loss= 0.00043488952, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 8900, training loss= 0.00042535635, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9000, training loss= 0.00037381286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9100, training loss= 0.00032592035, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9200, training loss= 0.0005453011, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9300, training loss= 0.00055934844, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9400, training loss= 0.00052387425, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9500, training loss= 0.00041772792, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9600, training loss= 0.0005153595, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9700, training loss= 0.00044403475, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9800, training loss= 0.0003818291, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 9900, training loss= 0.000495136, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10000, training loss= 0.00039608977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10100, training loss= 0.0003935306, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10200, training loss= 0.0004969856, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10300, training loss= 0.00050266227, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10400, training loss= 0.00032022758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10500, training loss= 0.00036192863, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10600, training loss= 0.00043033046, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10700, training loss= 0.00042183854, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10800, training loss= 0.00031407113, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 10900, training loss= 0.00041432836, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11000, training loss= 0.00033904918, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11100, training loss= 0.00043122954, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11200, training loss= 0.00044644787, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11300, training loss= 0.00029221206, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11400, training loss= 0.00042263823, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11500, training loss= 0.00040343555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11600, training loss= 0.0003425721, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11700, training loss= 0.0004444753, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11800, training loss= 0.00044364238, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 11900, training loss= 0.00044278367, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12000, training loss= 0.00042952228, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12100, training loss= 0.00032956112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12200, training loss= 0.0004302471, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12300, training loss= 0.00041925936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12400, training loss= 0.00038406858, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12500, training loss= 0.00050243264, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12600, training loss= 0.0004926515, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12700, training loss= 0.00032606127, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12800, training loss= 0.00045644023, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 12900, training loss= 0.00030076533, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13000, training loss= 0.0004342447, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13100, training loss= 0.0003927654, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13200, training loss= 0.0004035711, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13300, training loss= 0.0003932034, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13400, training loss= 0.00047552236, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13500, training loss= 0.00056454435, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13600, training loss= 0.00042375544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13700, training loss= 0.00035548257, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13800, training loss= 0.00040655382, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 13900, training loss= 0.00032437342, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14000, training loss= 0.00029757334, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14100, training loss= 0.0003572212, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14200, training loss= 0.00041447513, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14300, training loss= 0.00035659556, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14400, training loss= 0.00041507345, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14500, training loss= 0.00036971876, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14600, training loss= 0.0003748198, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14700, training loss= 0.00035819467, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14800, training loss= 0.0004238277, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 14900, training loss= 0.0003487389, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15000, training loss= 0.0003103875, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15100, training loss= 0.0004160212, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15200, training loss= 0.0004268967, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15300, training loss= 0.0003802674, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15400, training loss= 0.00029509343, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15500, training loss= 0.00030547794, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15600, training loss= 0.00035947093, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15700, training loss= 0.0003262541, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15800, training loss= 0.0003861555, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 15900, training loss= 0.00036624313, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16000, training loss= 0.00046669118, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16100, training loss= 0.00049367547, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16200, training loss= 0.00034006304, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16300, training loss= 0.00038576542, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16400, training loss= 0.0003671399, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16500, training loss= 0.00039690177, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16600, training loss= 0.0003112685, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16700, training loss= 0.0004264334, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16800, training loss= 0.0004040968, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 16900, training loss= 0.00045044874, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17000, training loss= 0.0005006636, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17100, training loss= 0.00034859357, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17200, training loss= 0.0003112966, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17300, training loss= 0.00042001955, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17400, training loss= 0.00033930963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17500, training loss= 0.00046594578, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17600, training loss= 0.00032641762, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17700, training loss= 0.00046180008, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17800, training loss= 0.0003901327, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 17900, training loss= 0.00037266896, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18000, training loss= 0.00042970898, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18100, training loss= 0.0003287813, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18200, training loss= 0.00033387833, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18300, training loss= 0.00031479026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18400, training loss= 0.0003553702, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18500, training loss= 0.0003820684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18600, training loss= 0.00046104094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18700, training loss= 0.00037919258, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18800, training loss= 0.00046903937, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 18900, training loss= 0.00037912192, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19000, training loss= 0.00043774353, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19100, training loss= 0.00034708148, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19200, training loss= 0.00034566328, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19300, training loss= 0.0003543448, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19400, training loss= 0.00030767234, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19500, training loss= 0.00035415697, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19600, training loss= 0.00031658984, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19700, training loss= 0.00034851092, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19800, training loss= 0.0003676028, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 19900, training loss= 0.0003297344, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20000, training loss= 0.00037284463, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20100, training loss= 0.00036555715, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20200, training loss= 0.00029793056, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20300, training loss= 0.0002991095, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20400, training loss= 0.0003482736, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20500, training loss= 0.00032922643, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20600, training loss= 0.0003693413, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20700, training loss= 0.00034049005, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20800, training loss= 0.00040707365, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 20900, training loss= 0.00037363524, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21000, training loss= 0.0003496407, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21100, training loss= 0.00033025758, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21200, training loss= 0.00031292826, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21300, training loss= 0.00042923982, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21400, training loss= 0.00032633683, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21500, training loss= 0.00033642986, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21600, training loss= 0.00041488395, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21700, training loss= 0.00029732057, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21800, training loss= 0.00034030684, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 21900, training loss= 0.00031267933, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22000, training loss= 0.00032818312, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22100, training loss= 0.00041656126, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22200, training loss= 0.00030758488, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22300, training loss= 0.0003599094, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22400, training loss= 0.00033929953, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22500, training loss= 0.00030629087, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22600, training loss= 0.00030447752, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22700, training loss= 0.00035800374, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22800, training loss= 0.0003183045, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 22900, training loss= 0.00033143806, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23000, training loss= 0.0002528468, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23100, training loss= 0.00039159632, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23200, training loss= 0.00033363255, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23300, training loss= 0.00039594484, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23400, training loss= 0.00035134936, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23500, training loss= 0.00038199418, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23600, training loss= 0.00036114044, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23700, training loss= 0.00043709722, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23800, training loss= 0.0003361569, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 23900, training loss= 0.00029834567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24000, training loss= 0.00034514067, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24100, training loss= 0.00034804735, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24200, training loss= 0.00034754857, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24300, training loss= 0.00038347417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24400, training loss= 0.0003641779, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24500, training loss= 0.000354213, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24600, training loss= 0.00041051544, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24700, training loss= 0.00037656655, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24800, training loss= 0.00042114046, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 24900, training loss= 0.0002974614, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25000, training loss= 0.00033921588, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25100, training loss= 0.000383527, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25200, training loss= 0.00030785313, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25300, training loss= 0.00040525015, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25400, training loss= 0.00029581564, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25500, training loss= 0.00031223224, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25600, training loss= 0.00029343925, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25700, training loss= 0.00034897492, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25800, training loss= 0.0002964528, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 25900, training loss= 0.00038280443, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26000, training loss= 0.0002706567, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26100, training loss= 0.0004250175, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26200, training loss= 0.00036484638, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26300, training loss= 0.0003522474, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26400, training loss= 0.0003888679, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26500, training loss= 0.0004143917, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26600, training loss= 0.0003238476, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26700, training loss= 0.00038679523, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26800, training loss= 0.00025875354, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 26900, training loss= 0.0003288284, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27000, training loss= 0.0003221404, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27100, training loss= 0.00034489852, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27200, training loss= 0.00029149491, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27300, training loss= 0.00035240286, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27400, training loss= 0.0004444323, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27500, training loss= 0.00035226907, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27600, training loss= 0.00032314577, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27700, training loss= 0.0003114914, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27800, training loss= 0.0003233303, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 27900, training loss= 0.0002780589, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28000, training loss= 0.00037795003, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28100, training loss= 0.00036204647, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28200, training loss= 0.00039149553, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28300, training loss= 0.0004036659, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28400, training loss= 0.00037414161, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28500, training loss= 0.00031001752, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28600, training loss= 0.000261654, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28700, training loss= 0.00037432503, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28800, training loss= 0.0003745558, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 28900, training loss= 0.00034963997, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29000, training loss= 0.00038800115, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29100, training loss= 0.00051704276, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29200, training loss= 0.00037754275, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29300, training loss= 0.00029264204, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29400, training loss= 0.0003785675, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29500, training loss= 0.00025764963, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29600, training loss= 0.00035635327, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29700, training loss= 0.00039943264, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29800, training loss= 0.00031820798, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 29900, training loss= 0.00028315056, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 92.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.08149065, training acc= 100.0%\n",
            "Validation Accuracy valid 95.2727279663086 ...\n",
            "\n",
            "step 100, training loss= 0.08157267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 200, training loss= 0.013591821, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 300, training loss= 0.03528688, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 400, training loss= 0.0506441, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 500, training loss= 0.010032977, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 600, training loss= 0.0044976026, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 700, training loss= 0.02884608, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 800, training loss= 0.0074134287, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 900, training loss= 0.00034868903, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1000, training loss= 0.021749526, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1100, training loss= 0.0048253443, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1200, training loss= 0.00044714188, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 1300, training loss= 0.0003095596, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1400, training loss= 0.0003896027, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1500, training loss= 0.00038767312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1600, training loss= 0.0005267415, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1700, training loss= 0.00043093332, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1800, training loss= 0.0014744131, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 1900, training loss= 0.003333926, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2000, training loss= 0.000279603, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2100, training loss= 0.0075280913, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2200, training loss= 0.00036937033, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2300, training loss= 0.004158158, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2400, training loss= 0.00039054235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2500, training loss= 0.0004596295, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 2600, training loss= 0.002747017, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2700, training loss= 0.0022052417, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2800, training loss= 0.0007577147, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 2900, training loss= 0.0032645054, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3000, training loss= 0.003100112, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3100, training loss= 0.00030715775, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3200, training loss= 0.00063281215, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3300, training loss= 0.00037897975, training acc= 100.0%\n",
            "Validation Accuracy valid 94.90908813476562 ...\n",
            "\n",
            "step 3400, training loss= 0.00042686748, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3500, training loss= 0.002262982, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3600, training loss= 0.0022391297, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3700, training loss= 0.00027698601, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3800, training loss= 0.0007286472, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 3900, training loss= 0.0004353399, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4000, training loss= 0.00060883927, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4100, training loss= 0.0014809942, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4200, training loss= 0.00038068995, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4300, training loss= 0.0005734776, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4400, training loss= 0.0012460151, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4500, training loss= 0.0004201146, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4600, training loss= 0.0003633486, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4700, training loss= 0.0009895825, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4800, training loss= 0.0003730782, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 4900, training loss= 0.00066768285, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5000, training loss= 0.0003647565, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5100, training loss= 0.0004542469, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5200, training loss= 0.0003852516, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5300, training loss= 0.0004620459, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5400, training loss= 0.0003103821, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5500, training loss= 0.00052580313, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5600, training loss= 0.00037045815, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5700, training loss= 0.00045415346, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5800, training loss= 0.00037088525, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 5900, training loss= 0.00043801757, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6000, training loss= 0.0003483111, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6100, training loss= 0.00038845534, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6200, training loss= 0.00041078022, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6300, training loss= 0.00044093866, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6400, training loss= 0.0004550353, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6500, training loss= 0.00027420875, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6600, training loss= 0.00035694745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6700, training loss= 0.00066134013, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6800, training loss= 0.00036683792, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 6900, training loss= 0.0003588687, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7000, training loss= 0.000681628, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7100, training loss= 0.00045966232, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7200, training loss= 0.0005510775, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7300, training loss= 0.0004150171, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7400, training loss= 0.00046570963, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7500, training loss= 0.00045429418, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7600, training loss= 0.0004670147, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7700, training loss= 0.000369479, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7800, training loss= 0.0004229139, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 7900, training loss= 0.0006142515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8000, training loss= 0.00045113234, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8100, training loss= 0.00040542096, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8200, training loss= 0.0004770566, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8300, training loss= 0.00047306635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8400, training loss= 0.00031605488, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8500, training loss= 0.0003476363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8600, training loss= 0.00035934302, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8700, training loss= 0.00041693312, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8800, training loss= 0.00047294228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 8900, training loss= 0.00037372866, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9000, training loss= 0.00035168786, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9100, training loss= 0.00035829467, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9200, training loss= 0.00046410557, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9300, training loss= 0.00042010166, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9400, training loss= 0.00034335593, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9500, training loss= 0.00032712563, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9600, training loss= 0.00041126832, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9700, training loss= 0.0005139595, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9800, training loss= 0.00037522736, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 9900, training loss= 0.0002891793, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10000, training loss= 0.00036186972, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10100, training loss= 0.00040495573, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10200, training loss= 0.0003440044, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10300, training loss= 0.00027858274, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10400, training loss= 0.0003957363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10500, training loss= 0.00039242642, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10600, training loss= 0.00044023045, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10700, training loss= 0.0003978119, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10800, training loss= 0.00044474093, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 10900, training loss= 0.00026945255, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11000, training loss= 0.00041246574, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11100, training loss= 0.000342186, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11200, training loss= 0.00039856395, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11300, training loss= 0.00038220116, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11400, training loss= 0.00030803363, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11500, training loss= 0.00036406587, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11600, training loss= 0.00037154325, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11700, training loss= 0.00042909203, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11800, training loss= 0.0002982267, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 11900, training loss= 0.0003439822, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12000, training loss= 0.00037216741, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12100, training loss= 0.00036906195, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12200, training loss= 0.0004536552, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12300, training loss= 0.00046079248, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12400, training loss= 0.00037126933, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12500, training loss= 0.00030971615, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12600, training loss= 0.00037833926, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12700, training loss= 0.00044617042, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12800, training loss= 0.0003715635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 12900, training loss= 0.0003667079, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13000, training loss= 0.0003653452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13100, training loss= 0.00033113288, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13200, training loss= 0.00041973643, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13300, training loss= 0.0003541696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13400, training loss= 0.00030079632, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13500, training loss= 0.00037778515, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13600, training loss= 0.00037659204, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13700, training loss= 0.00042143252, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13800, training loss= 0.00036569952, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 13900, training loss= 0.0003116747, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14000, training loss= 0.00026566745, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14100, training loss= 0.0003770011, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14200, training loss= 0.0002913723, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14300, training loss= 0.00031739665, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14400, training loss= 0.00043562532, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14500, training loss= 0.00031540554, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14600, training loss= 0.00038035228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14700, training loss= 0.0005029024, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14800, training loss= 0.00033527138, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 14900, training loss= 0.00031608724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15000, training loss= 0.00037442739, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15100, training loss= 0.0003931743, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15200, training loss= 0.00029532576, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15300, training loss= 0.00038743936, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15400, training loss= 0.0003699348, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15500, training loss= 0.00034135615, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15600, training loss= 0.0003455729, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15700, training loss= 0.00037783445, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15800, training loss= 0.00026936774, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 15900, training loss= 0.00035267803, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16000, training loss= 0.00036426663, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16100, training loss= 0.00031389637, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16200, training loss= 0.00035099432, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16300, training loss= 0.00040573906, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16400, training loss= 0.00046066992, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16500, training loss= 0.00043880625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16600, training loss= 0.00031127475, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16700, training loss= 0.000402046, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16800, training loss= 0.00035026213, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 16900, training loss= 0.0003664006, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17000, training loss= 0.00041418217, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17100, training loss= 0.00040788302, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17200, training loss= 0.00037823562, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17300, training loss= 0.00039403088, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17400, training loss= 0.00034057882, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17500, training loss= 0.0003127626, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17600, training loss= 0.0004070156, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17700, training loss= 0.0004338848, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17800, training loss= 0.000346821, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 17900, training loss= 0.00043104755, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18000, training loss= 0.0003916458, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18100, training loss= 0.0005116953, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18200, training loss= 0.00024331268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18300, training loss= 0.00038223268, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18400, training loss= 0.0003870706, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18500, training loss= 0.00030303997, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18600, training loss= 0.00031602502, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18700, training loss= 0.0003989299, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18800, training loss= 0.00033864976, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 18900, training loss= 0.0003669452, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19000, training loss= 0.00033412015, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19100, training loss= 0.00034612996, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19200, training loss= 0.00029668646, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19300, training loss= 0.000367292, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19400, training loss= 0.00039338812, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19500, training loss= 0.00044911625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19600, training loss= 0.000239491, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19700, training loss= 0.00044069398, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19800, training loss= 0.00035982707, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 19900, training loss= 0.0004369647, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20000, training loss= 0.0003728752, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20100, training loss= 0.00031430623, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20200, training loss= 0.00039125426, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20300, training loss= 0.00027167224, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20400, training loss= 0.00033011302, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20500, training loss= 0.00039443228, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20600, training loss= 0.00033397874, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20700, training loss= 0.0003474163, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20800, training loss= 0.000390056, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 20900, training loss= 0.00034166727, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21000, training loss= 0.0003657235, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21100, training loss= 0.00044251917, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21200, training loss= 0.0004219838, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21300, training loss= 0.0002436589, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21400, training loss= 0.0003858838, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21500, training loss= 0.0003052582, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21600, training loss= 0.00036287625, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21700, training loss= 0.00031886794, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21800, training loss= 0.0003486377, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 21900, training loss= 0.0003590584, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22000, training loss= 0.00036616088, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22100, training loss= 0.00037821042, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22200, training loss= 0.0003370212, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22300, training loss= 0.00029550566, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22400, training loss= 0.00036055164, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22500, training loss= 0.0004190711, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22600, training loss= 0.00037931738, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22700, training loss= 0.00039557522, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22800, training loss= 0.00033051104, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 22900, training loss= 0.00032551782, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23000, training loss= 0.00032570513, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23100, training loss= 0.00034984847, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23200, training loss= 0.00035328072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23300, training loss= 0.00030835616, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23400, training loss= 0.00028098052, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23500, training loss= 0.00034963072, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23600, training loss= 0.00028228512, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23700, training loss= 0.00036805254, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23800, training loss= 0.0004110021, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 23900, training loss= 0.00039298637, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24000, training loss= 0.0003272298, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24100, training loss= 0.00037754688, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24200, training loss= 0.00032012083, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24300, training loss= 0.00034711443, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24400, training loss= 0.00032621637, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24500, training loss= 0.00038775397, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24600, training loss= 0.00028010336, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24700, training loss= 0.0003172678, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24800, training loss= 0.0002941878, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 24900, training loss= 0.00041309424, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25000, training loss= 0.0003770789, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25100, training loss= 0.00031904777, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25200, training loss= 0.00031306167, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25300, training loss= 0.00030269922, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25400, training loss= 0.0003499658, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25500, training loss= 0.00038591507, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25600, training loss= 0.00042024013, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25700, training loss= 0.00032441466, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25800, training loss= 0.00031787172, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 25900, training loss= 0.00034714292, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26000, training loss= 0.0003190885, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26100, training loss= 0.00031274237, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26200, training loss= 0.00036907138, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26300, training loss= 0.00038362216, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26400, training loss= 0.00032365724, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26500, training loss= 0.0003035925, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26600, training loss= 0.0003736608, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26700, training loss= 0.00039782916, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26800, training loss= 0.00033929214, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 26900, training loss= 0.00035315307, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27000, training loss= 0.0003094029, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27100, training loss= 0.00040567404, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27200, training loss= 0.00037394412, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27300, training loss= 0.0003519748, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27400, training loss= 0.00029820568, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27500, training loss= 0.00035581988, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27600, training loss= 0.00035384603, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27700, training loss= 0.0003489772, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27800, training loss= 0.0003361262, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 27900, training loss= 0.00035621604, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28000, training loss= 0.00027598708, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28100, training loss= 0.00035144194, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28200, training loss= 0.00032524753, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28300, training loss= 0.00036740405, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28400, training loss= 0.00037267656, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28500, training loss= 0.00030656703, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28600, training loss= 0.00042042555, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28700, training loss= 0.00036529804, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28800, training loss= 0.00026816898, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 28900, training loss= 0.00045640592, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29000, training loss= 0.000388245, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29100, training loss= 0.00031306635, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29200, training loss= 0.00034860795, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29300, training loss= 0.00028103057, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29400, training loss= 0.00030048075, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29500, training loss= 0.0003894696, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29600, training loss= 0.00035063986, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29700, training loss= 0.00037959652, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29800, training loss= 0.00030686674, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "step 29900, training loss= 0.0003600829, training acc= 100.0%\n",
            "Validation Accuracy valid 95.09090423583984 ...\n",
            "\n",
            "Valid acc= 95.27273 %\n",
            "Validation Accuracy Test 90.0 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BoQHpkHzQ0YO"
      },
      "cell_type": "markdown",
      "source": [
        "#### Valid acc= 98.799995 %\n",
        "#### Validation Accuracy Test 98.51380157470703 ...\n",
        "W1 = 4 ...\n",
        "W2 = 1 ...\n",
        "W3 = 0 ...\n",
        "Highest validation accuracy, to brake tie Validation test accuracy was used which is highest for this combination"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SeaxvipDvrKA"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85832be8-0de9-4f6b-ee23-58cb914d8757"
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Test_track)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "WaOrJ6tu4YUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90a81f6f-44db-408a-ce0a-71c68e199dd1"
      },
      "cell_type": "code",
      "source": [
        "min(ValidAccuracy_Track)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.27273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "205843ad-5c32-49e1-d69f-c3175cd2f12b"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAmOMiTlLBMYYE3OWCIwxJub+P+EJd1LLWAx4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6cbb763e-8286-4430-f240-0d4862c3c4ca"
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SW9qZGWUQFQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1082690c-6232-4a14-d0e0-7e73cf1866a7"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oWFUJtzdQFQx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ee5a25c6-f57b-4353-d514-55570a405bb5"
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK23VSP79XQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5nSzdyLhJ3K-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EpochBased of 04182019_Satim_FullDatasetSGD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/EpochBased_of_04182019_Satim_FullDatasetSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "db9c44b4-5f5b-41f0-f424-bea2c7a36813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.127273</td>\n",
              "      <td>-0.095238</td>\n",
              "      <td>-0.289256</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.054545</td>\n",
              "      <td>-0.157895</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.188119</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.484375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>-0.603306</td>\n",
              "      <td>-0.096774</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.015385</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.609375</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.609375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.074380</td>\n",
              "      <td>0.354839</td>\n",
              "      <td>0.327273</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.207921</td>\n",
              "      <td>-0.010526</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.380952</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>-0.225806</td>\n",
              "      <td>-0.163636</td>\n",
              "      <td>-0.410526</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.383333</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.347368</td>\n",
              "      <td>-0.484375</td>\n",
              "      <td>0.09375</td>\n",
              "      <td>0.087379</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.218750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.1250</td>\n",
              "      <td>-0.184466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287356</td>\n",
              "      <td>-0.183333</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.267327</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>-0.03125</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6   \\\n",
              "0  0.0000  0.127273 -0.095238 -0.289256  0.032258  0.054545 -0.157895   \n",
              "1  0.0000 -0.090909 -0.571429 -0.603306 -0.096774 -0.090909 -0.494737   \n",
              "2  0.5625  0.490909  0.333333 -0.074380  0.354839  0.327273  0.052632   \n",
              "3  0.0000 -0.018182 -0.380952 -0.471074 -0.225806 -0.163636 -0.410526   \n",
              "4  0.0000 -0.018182 -0.285714 -0.471074  0.032258 -0.090909 -0.326316   \n",
              "\n",
              "         7       8         9     ...           26        27        28  \\\n",
              "0 -0.265625 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.138462   \n",
              "1 -0.562500 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.015385   \n",
              "2 -0.187500  0.1875  0.242718    ...     0.103448 -0.233333  0.200000   \n",
              "3 -0.437500 -0.3750 -0.242718    ...    -0.011494 -0.383333 -0.138462   \n",
              "4 -0.500000 -0.1250 -0.184466    ...     0.287356 -0.183333  0.230769   \n",
              "\n",
              "         29        30        31       32        33        34        35  \n",
              "0 -0.188119 -0.431579 -0.546875 -0.15625 -0.126214 -0.431579 -0.484375  \n",
              "1 -0.049505 -0.431579 -0.609375 -0.15625 -0.126214 -0.494737 -0.609375  \n",
              "2  0.207921 -0.010526 -0.312500 -0.15625  0.009709 -0.326316 -0.437500  \n",
              "3 -0.049505 -0.347368 -0.484375  0.09375  0.087379 -0.031579 -0.218750  \n",
              "4  0.267327 -0.031579 -0.281250 -0.03125 -0.126214 -0.431579 -0.546875  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "1413190a-0006-4912-f626-e4d7a18e765d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  5\n",
              "1  5\n",
              "2  5\n",
              "3  5\n",
              "4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "8d9dc031-48af-41a3-f599-12344a45b6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "d9a78cc4-7f4b-44e8-de26-db72697cb4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "7ac30a66-d27c-41ba-ff65-6f51cd64f71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "d78b75af-abc2-4908-fe70-5b73954b0797",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(90, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.95444174\n",
            "Iteration 2, loss = 0.41361696\n",
            "Iteration 3, loss = 0.37376292\n",
            "Iteration 4, loss = 0.35310299\n",
            "Iteration 5, loss = 0.33669458\n",
            "Iteration 6, loss = 0.32397037\n",
            "Iteration 7, loss = 0.31519296\n",
            "Iteration 8, loss = 0.30943933\n",
            "Iteration 9, loss = 0.30110286\n",
            "Iteration 10, loss = 0.29639559\n",
            "Iteration 11, loss = 0.29181714\n",
            "Iteration 12, loss = 0.28519907\n",
            "Iteration 13, loss = 0.27945018\n",
            "Iteration 14, loss = 0.27446988\n",
            "Iteration 15, loss = 0.27230486\n",
            "Iteration 16, loss = 0.26854954\n",
            "Iteration 17, loss = 0.26347512\n",
            "Iteration 18, loss = 0.25999897\n",
            "Iteration 19, loss = 0.25824005\n",
            "Iteration 20, loss = 0.25456133\n",
            "Iteration 21, loss = 0.24952501\n",
            "Iteration 22, loss = 0.24607191\n",
            "Iteration 23, loss = 0.24673228\n",
            "Iteration 24, loss = 0.24442729\n",
            "Iteration 25, loss = 0.24115307\n",
            "Iteration 26, loss = 0.23827513\n",
            "Iteration 27, loss = 0.23520357\n",
            "Iteration 28, loss = 0.23354455\n",
            "Iteration 29, loss = 0.22978524\n",
            "Iteration 30, loss = 0.22810795\n",
            "Iteration 31, loss = 0.22567502\n",
            "Iteration 32, loss = 0.22661689\n",
            "Iteration 33, loss = 0.22176630\n",
            "Iteration 34, loss = 0.22185255\n",
            "Iteration 35, loss = 0.21909550\n",
            "Iteration 36, loss = 0.21857916\n",
            "Iteration 37, loss = 0.21802408\n",
            "Iteration 38, loss = 0.21273616\n",
            "Iteration 39, loss = 0.21271724\n",
            "Iteration 40, loss = 0.21180686\n",
            "Iteration 41, loss = 0.20911150\n",
            "Iteration 42, loss = 0.20824662\n",
            "Iteration 43, loss = 0.20727753\n",
            "Iteration 44, loss = 0.20444614\n",
            "Iteration 45, loss = 0.20458268\n",
            "Iteration 46, loss = 0.20322771\n",
            "Iteration 47, loss = 0.20093423\n",
            "Iteration 48, loss = 0.19972227\n",
            "Iteration 49, loss = 0.19969319\n",
            "Iteration 50, loss = 0.19881669\n",
            "Iteration 51, loss = 0.19614789\n",
            "Iteration 52, loss = 0.19417483\n",
            "Iteration 53, loss = 0.19168104\n",
            "Iteration 54, loss = 0.19479601\n",
            "Iteration 55, loss = 0.19010506\n",
            "Iteration 56, loss = 0.19106383\n",
            "Iteration 57, loss = 0.19142207\n",
            "Iteration 58, loss = 0.18865416\n",
            "Iteration 59, loss = 0.18610193\n",
            "Iteration 60, loss = 0.18574850\n",
            "Iteration 61, loss = 0.18561203\n",
            "Iteration 62, loss = 0.18429022\n",
            "Iteration 63, loss = 0.18052444\n",
            "Iteration 64, loss = 0.18136414\n",
            "Iteration 65, loss = 0.18031222\n",
            "Iteration 66, loss = 0.17744159\n",
            "Iteration 67, loss = 0.18027992\n",
            "Iteration 68, loss = 0.17645335\n",
            "Iteration 69, loss = 0.17403393\n",
            "Iteration 70, loss = 0.17429126\n",
            "Iteration 71, loss = 0.17618357\n",
            "Iteration 72, loss = 0.17183623\n",
            "Iteration 73, loss = 0.17166370\n",
            "Iteration 74, loss = 0.17217259\n",
            "Iteration 75, loss = 0.16904945\n",
            "Iteration 76, loss = 0.17088875\n",
            "Iteration 77, loss = 0.17259165\n",
            "Iteration 78, loss = 0.16779362\n",
            "Iteration 79, loss = 0.16512526\n",
            "Iteration 80, loss = 0.16614422\n",
            "Iteration 81, loss = 0.16629507\n",
            "Iteration 82, loss = 0.16287885\n",
            "Iteration 83, loss = 0.16415537\n",
            "Iteration 84, loss = 0.16234924\n",
            "Iteration 85, loss = 0.16424623\n",
            "Iteration 86, loss = 0.15978972\n",
            "Iteration 87, loss = 0.16143070\n",
            "Iteration 88, loss = 0.15866024\n",
            "Iteration 89, loss = 0.15941105\n",
            "Iteration 90, loss = 0.15681068\n",
            "Iteration 91, loss = 0.15561312\n",
            "Iteration 92, loss = 0.15621932\n",
            "Iteration 93, loss = 0.15605395\n",
            "Iteration 94, loss = 0.15510723\n",
            "Iteration 95, loss = 0.15339714\n",
            "Iteration 96, loss = 0.15174013\n",
            "Iteration 97, loss = 0.15426171\n",
            "Iteration 98, loss = 0.15044099\n",
            "Iteration 99, loss = 0.15172792\n",
            "Iteration 100, loss = 0.14968459\n",
            "Iteration 101, loss = 0.14847401\n",
            "Iteration 102, loss = 0.14847588\n",
            "Iteration 103, loss = 0.14778554\n",
            "Iteration 104, loss = 0.14824874\n",
            "Iteration 105, loss = 0.14742960\n",
            "Iteration 106, loss = 0.14452012\n",
            "Iteration 107, loss = 0.14947363\n",
            "Iteration 108, loss = 0.14322124\n",
            "Iteration 109, loss = 0.14478542\n",
            "Iteration 110, loss = 0.14181720\n",
            "Iteration 111, loss = 0.14135020\n",
            "Iteration 112, loss = 0.14072554\n",
            "Iteration 113, loss = 0.13985860\n",
            "Iteration 114, loss = 0.13897508\n",
            "Iteration 115, loss = 0.13912146\n",
            "Iteration 116, loss = 0.13914079\n",
            "Iteration 117, loss = 0.13889620\n",
            "Iteration 118, loss = 0.13568594\n",
            "Iteration 119, loss = 0.13788100\n",
            "Iteration 120, loss = 0.13676511\n",
            "Iteration 121, loss = 0.13544847\n",
            "Iteration 122, loss = 0.13301428\n",
            "Iteration 123, loss = 0.13581044\n",
            "Iteration 124, loss = 0.13166328\n",
            "Iteration 125, loss = 0.13556177\n",
            "Iteration 126, loss = 0.13061816\n",
            "Iteration 127, loss = 0.12774804\n",
            "Iteration 128, loss = 0.13414609\n",
            "Iteration 129, loss = 0.12788896\n",
            "Iteration 130, loss = 0.12703824\n",
            "Iteration 131, loss = 0.12845110\n",
            "Iteration 132, loss = 0.12680860\n",
            "Iteration 133, loss = 0.12745193\n",
            "Iteration 134, loss = 0.12698741\n",
            "Iteration 135, loss = 0.12842388\n",
            "Iteration 136, loss = 0.12634677\n",
            "Iteration 137, loss = 0.12352253\n",
            "Iteration 138, loss = 0.12330926\n",
            "Iteration 139, loss = 0.12610248\n",
            "Iteration 140, loss = 0.12203222\n",
            "Iteration 141, loss = 0.12216357\n",
            "Iteration 142, loss = 0.11924790\n",
            "Iteration 143, loss = 0.11957397\n",
            "Iteration 144, loss = 0.12033362\n",
            "Iteration 145, loss = 0.11740384\n",
            "Iteration 146, loss = 0.11871911\n",
            "Iteration 147, loss = 0.11659951\n",
            "Iteration 148, loss = 0.12022110\n",
            "Iteration 149, loss = 0.11646908\n",
            "Iteration 150, loss = 0.11516562\n",
            "Iteration 151, loss = 0.11565456\n",
            "Iteration 152, loss = 0.11418154\n",
            "Iteration 153, loss = 0.11264107\n",
            "Iteration 154, loss = 0.11497207\n",
            "Iteration 155, loss = 0.11319484\n",
            "Iteration 156, loss = 0.11410818\n",
            "Iteration 157, loss = 0.11406045\n",
            "Iteration 158, loss = 0.10999054\n",
            "Iteration 159, loss = 0.11248917\n",
            "Iteration 160, loss = 0.11442108\n",
            "Iteration 161, loss = 0.11135488\n",
            "Iteration 162, loss = 0.11127527\n",
            "Iteration 163, loss = 0.10752335\n",
            "Iteration 164, loss = 0.10901415\n",
            "Iteration 165, loss = 0.10863796\n",
            "Iteration 166, loss = 0.10790327\n",
            "Iteration 167, loss = 0.10961160\n",
            "Iteration 168, loss = 0.10851879\n",
            "Iteration 169, loss = 0.10602720\n",
            "Iteration 170, loss = 0.10630070\n",
            "Iteration 171, loss = 0.10501613\n",
            "Iteration 172, loss = 0.10583980\n",
            "Iteration 173, loss = 0.10541182\n",
            "Iteration 174, loss = 0.10096666\n",
            "Iteration 175, loss = 0.10404634\n",
            "Iteration 176, loss = 0.10221237\n",
            "Iteration 177, loss = 0.10075696\n",
            "Iteration 178, loss = 0.09931985\n",
            "Iteration 179, loss = 0.10203152\n",
            "Iteration 180, loss = 0.10096311\n",
            "Iteration 181, loss = 0.09975398\n",
            "Iteration 182, loss = 0.09955987\n",
            "Iteration 183, loss = 0.09993594\n",
            "Iteration 184, loss = 0.09770182\n",
            "Iteration 185, loss = 0.09802935\n",
            "Iteration 186, loss = 0.09803881\n",
            "Iteration 187, loss = 0.09618500\n",
            "Iteration 188, loss = 0.09616072\n",
            "Iteration 189, loss = 0.09800732\n",
            "Iteration 190, loss = 0.09534339\n",
            "Iteration 191, loss = 0.09352430\n",
            "Iteration 192, loss = 0.09372701\n",
            "Iteration 193, loss = 0.09739990\n",
            "Iteration 194, loss = 0.09370456\n",
            "Iteration 195, loss = 0.09311714\n",
            "Iteration 196, loss = 0.09235983\n",
            "Iteration 197, loss = 0.09294382\n",
            "Iteration 198, loss = 0.09261564\n",
            "Iteration 199, loss = 0.09151696\n",
            "Iteration 200, loss = 0.09206768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(90,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "f393b48e-2b5c-408d-fc40-11eed714760e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710051546391752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "62728091-b022-4bb6-8b0e-6ee9e920d32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858001502629602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "9a2cad6d-1576-4f4d-b088-36bc7ddf1738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "5be20402-f34c-431d-f07a-ff5ec8b3a4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 36 -> 90 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "12509248-5b53-462b-c0dd-2f32d9f5d7eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "22055d06-3255-4b80-8965-e2006cd40568"
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.train.GradientDescentOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "6cd10ec8-1bd2-4e9b-abf9-6a7205d19e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "hid_neuron = [374]\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-45-4106bc23d37b>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.054217033, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1000, training loss= 0.06791636, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2000, training loss= 0.113990285, training acc= 94.9999988079071%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 3000, training loss= 0.05273371, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 4000, training loss= 0.08585536, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 5000, training loss= 0.08647766, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 6000, training loss= 0.07679716, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 7000, training loss= 0.063332275, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 8000, training loss= 0.06664811, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 9000, training loss= 0.07144175, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 10000, training loss= 0.08180145, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 11000, training loss= 0.06436531, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 12000, training loss= 0.08577333, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 13000, training loss= 0.078104615, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 14000, training loss= 0.08586474, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 15000, training loss= 0.081860274, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 16000, training loss= 0.092953704, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 17000, training loss= 0.076337166, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 18000, training loss= 0.11437439, training acc= 94.49999928474426%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 19000, training loss= 0.06445277, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "Test acc= 89.600006 %\n",
            "Valid acc= 88.88054 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5A_PHV3bS7ui"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G5BxkTLzUAok"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test¶"
      ]
    },
    {
      "metadata": {
        "id": "mejHTwMYhEzu",
        "colab_type": "code",
        "outputId": "0c01782c-009b-44a3-8a02-10bd8706da32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(validation_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1331, 36)\n",
            "(3104, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTuhfaojYc6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Init wt from scratch"
      ]
    },
    {
      "metadata": {
        "id": "D18PlNIUYb0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reinitialize wt\n",
        "## Define weights of the layer\n",
        "# G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "# G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "# G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "# G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init(clf.coefs_[0].shape))\n",
        "G_b1 = tf.Variable(xavier_init(clf.intercepts_ [0].shape))\n",
        "\n",
        "G_W2 =  tf.Variable(xavier_init(clf.coefs_[1].shape))\n",
        "G_b2 = tf.Variable(xavier_init(clf.intercepts_ [1].shape))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 5, W2 =4, W3 = 0 from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "id": "UrVkojh_6eHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9kAl8OWdm3MG",
        "colab_type": "code",
        "outputId": "c3db874b-4efb-498e-ac40-c1ee2bc5edc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "efqck-gfeuQZ",
        "colab_type": "code",
        "outputId": "b70276bd-cfba-4e83-a1cc-34a995a53b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [374]\n",
        "num_steps = 2000\n",
        "batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 1\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 2.3412712, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 1, training loss= 2.3364384, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 2, training loss= 2.3316276, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 3, training loss= 2.3268385, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 4, training loss= 2.3220718, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 5, training loss= 2.3173263, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 6, training loss= 2.312602, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 7, training loss= 2.3078988, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 8, training loss= 2.3032176, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n",
            "step 9, training loss= 2.2985585, training acc= 9.858247637748718%\n",
            "Validation Accuracy 8.2644624710083 ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-eac822ae64af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_accuracy_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mbest_accuracy_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./statlog_letter1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mG_W1np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_b1np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_W2np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_b2np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG_W1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_b1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_W2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_b2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m           self.export_meta_graph(\n\u001b[0;32m-> 1196\u001b[0;31m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wMGtqz4Bqu7B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7stX_1nwgQlH",
        "colab_type": "code",
        "outputId": "71c592f4-10ed-4914-a33e-6b9373c7ebba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEisKNhERiRUFm4iIxIqCTUREYuX/AZ2g76+kVdRlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JXnnuX8tgSPg",
        "colab_type": "code",
        "outputId": "3433896f-aee6-438e-8b01-a5c99691b53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),3,1)\n",
        "valid_accuracy_filtered = val_accuracy\n",
        "\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])\n",
        "print(train_losses[0+np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.105934\n",
            "233\n",
            "233\n",
            "0.16911136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SKIUwe_umoF9",
        "colab_type": "code",
        "outputId": "a80754fe-ac16-424d-9201-e83c7c646545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "combined_train_valid.shape[]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "9M9I0j_zYxEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffle_indices = np.random.permutation(train_valid_combined.shape[0])\n",
        "train_valid_combined_shuffled = train_valid_combined[train_valid_combined_shuffle_indices,:]\n",
        "validation_test_label_one_hot_shuffled = validation_test_label_one_hot[train_valid_combined_shuffle_indices,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9tHloYDY0a9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 400\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot_shuffled[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot_shuffled[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K3sN3oKQ3dx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "073a3762-73df-48b0-ff5c-aeca151b1bdc"
      },
      "cell_type": "code",
      "source": [
        "number_of_ex = train_data.shape[0]\n",
        "number_of_ex"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "YjBzdsHU3k3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7883df4-3ece-4547-a1ee-f8151d2d92a4"
      },
      "cell_type": "code",
      "source": [
        "combined_train_valid.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4035, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "_7HQJzPm7sW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def next_set_data(num, data, labels):\n",
        "#     '''\n",
        "#     Return a total of `num` random samples and labels. \n",
        "#     '''\n",
        "# #     idx = np.arange(0 , len(data))\n",
        "# #     np.random.shuffle(idx)\n",
        "# #     idx = idx[:num]\n",
        "# #     data_shuffle = [data[ i] for i in idx]\n",
        "# #     labels_shuffle = [labels[ i] for i in idx]\n",
        "#     number_of_ex = data.shape[0]\n",
        "\n",
        "#     start = \n",
        "    \n",
        "#     return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjWhkxwPYulB",
        "colab_type": "code",
        "outputId": "18c60710-409b-444e-fd11-2ccb65a5078a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6970
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = train_data.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 10000\n",
        "batch_size = 200\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "#                 saver.save(sess, './statlog_letterAdam11')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 2.2383213, training acc total= 9.219330549240112%\n",
            "ValidTest acc= 11.0 %\n",
            "epoch 50, training loss Total= 1.0015643, training acc total= 74.77075457572937%\n",
            "ValidTest acc= 73.25 %\n",
            "epoch 100, training loss Total= 0.79775786, training acc total= 77.37298607826233%\n",
            "ValidTest acc= 78.25 %\n",
            "epoch 150, training loss Total= 0.70003587, training acc total= 79.20693755149841%\n",
            "ValidTest acc= 80.0 %\n",
            "epoch 200, training loss Total= 0.63853145, training acc total= 80.64436316490173%\n",
            "ValidTest acc= 81.25 %\n",
            "epoch 250, training loss Total= 0.5956811, training acc total= 81.68525695800781%\n",
            "ValidTest acc= 81.5 %\n",
            "epoch 300, training loss Total= 0.56406724, training acc total= 82.10656642913818%\n",
            "ValidTest acc= 81.5 %\n",
            "epoch 350, training loss Total= 0.5397412, training acc total= 82.57744908332825%\n",
            "ValidTest acc= 81.75 %\n",
            "epoch 400, training loss Total= 0.52029973, training acc total= 82.77571201324463%\n",
            "ValidTest acc= 82.25 %\n",
            "epoch 450, training loss Total= 0.5043838, training acc total= 82.99875855445862%\n",
            "ValidTest acc= 82.75 %\n",
            "epoch 500, training loss Total= 0.49103874, training acc total= 83.12267661094666%\n",
            "ValidTest acc= 82.5 %\n",
            "epoch 550, training loss Total= 0.47966275, training acc total= 83.32093954086304%\n",
            "ValidTest acc= 82.25 %\n",
            "epoch 600, training loss Total= 0.4698597, training acc total= 83.37050676345825%\n",
            "ValidTest acc= 82.5 %\n",
            "epoch 650, training loss Total= 0.4613067, training acc total= 83.5439920425415%\n",
            "ValidTest acc= 83.0 %\n",
            "epoch 700, training loss Total= 0.45376268, training acc total= 83.5439920425415%\n",
            "ValidTest acc= 83.0 %\n",
            "epoch 750, training loss Total= 0.4470401, training acc total= 83.69268774986267%\n",
            "ValidTest acc= 83.25 %\n",
            "epoch 800, training loss Total= 0.44100186, training acc total= 83.99008512496948%\n",
            "ValidTest acc= 83.25 %\n",
            "epoch 850, training loss Total= 0.43553397, training acc total= 84.0644359588623%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 900, training loss Total= 0.43056607, training acc total= 84.0644359588623%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 950, training loss Total= 0.4260173, training acc total= 84.18835401535034%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 1000, training loss Total= 0.42182755, training acc total= 84.36183333396912%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 1050, training loss Total= 0.41793215, training acc total= 84.38661694526672%\n",
            "ValidTest acc= 83.5 %\n",
            "epoch 1100, training loss Total= 0.41431138, training acc total= 84.43618416786194%\n",
            "ValidTest acc= 83.5 %\n",
            "epoch 1150, training loss Total= 0.41094422, training acc total= 84.48575139045715%\n",
            "ValidTest acc= 83.5 %\n",
            "epoch 1200, training loss Total= 0.40778112, training acc total= 84.46096777915955%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 1250, training loss Total= 0.40480796, training acc total= 84.43618416786194%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 1300, training loss Total= 0.40200382, training acc total= 84.46096777915955%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 1350, training loss Total= 0.39935344, training acc total= 84.63444709777832%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 1400, training loss Total= 0.39683574, training acc total= 84.65923070907593%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 1450, training loss Total= 0.39445204, training acc total= 84.70879793167114%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 1500, training loss Total= 0.39219323, training acc total= 84.78314876556396%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 1550, training loss Total= 0.3900421, training acc total= 84.80793237686157%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 1600, training loss Total= 0.38799974, training acc total= 84.90706086158752%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1650, training loss Total= 0.38605225, training acc total= 84.93184447288513%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1700, training loss Total= 0.38418087, training acc total= 84.93184447288513%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1750, training loss Total= 0.38238394, training acc total= 84.93184447288513%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1800, training loss Total= 0.38065848, training acc total= 84.95662808418274%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1850, training loss Total= 0.37900016, training acc total= 85.03097891807556%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1900, training loss Total= 0.37740508, training acc total= 85.05576252937317%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 1950, training loss Total= 0.3758707, training acc total= 85.1548969745636%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 2000, training loss Total= 0.37439477, training acc total= 85.22924184799194%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2050, training loss Total= 0.37297305, training acc total= 85.25402545928955%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2100, training loss Total= 0.37159884, training acc total= 85.27880907058716%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2150, training loss Total= 0.37027127, training acc total= 85.25402545928955%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2200, training loss Total= 0.36898577, training acc total= 85.32837629318237%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2250, training loss Total= 0.3677354, training acc total= 85.30359268188477%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2300, training loss Total= 0.3665243, training acc total= 85.32837629318237%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2350, training loss Total= 0.3653494, training acc total= 85.30359268188477%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2400, training loss Total= 0.36421025, training acc total= 85.37794351577759%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 2450, training loss Total= 0.36309892, training acc total= 85.37794351577759%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 2500, training loss Total= 0.36200976, training acc total= 85.4027271270752%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 2550, training loss Total= 0.36093953, training acc total= 85.4275107383728%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 2600, training loss Total= 0.35989487, training acc total= 85.4275107383728%\n",
            "ValidTest acc= 84.0 %\n",
            "epoch 2650, training loss Total= 0.35887313, training acc total= 85.45229434967041%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2700, training loss Total= 0.35787088, training acc total= 85.47707796096802%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2750, training loss Total= 0.3568895, training acc total= 85.47707796096802%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 2800, training loss Total= 0.35591486, training acc total= 85.50186157226562%\n",
            "ValidTest acc= 84.5 %\n",
            "epoch 2850, training loss Total= 0.3549608, training acc total= 85.52663922309875%\n",
            "ValidTest acc= 84.75 %\n",
            "epoch 2900, training loss Total= 0.3540218, training acc total= 85.52663922309875%\n",
            "ValidTest acc= 84.75 %\n",
            "epoch 2950, training loss Total= 0.35310045, training acc total= 85.60099005699158%\n",
            "ValidTest acc= 84.75 %\n",
            "epoch 3000, training loss Total= 0.35219437, training acc total= 85.6753408908844%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3050, training loss Total= 0.35130215, training acc total= 85.6753408908844%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3100, training loss Total= 0.35042423, training acc total= 85.77447533607483%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3150, training loss Total= 0.34956515, training acc total= 85.77447533607483%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3200, training loss Total= 0.34871915, training acc total= 85.82404255867004%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3250, training loss Total= 0.3478728, training acc total= 85.87360382080078%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3300, training loss Total= 0.34703633, training acc total= 85.923171043396%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3350, training loss Total= 0.3462109, training acc total= 85.99752187728882%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3400, training loss Total= 0.34539714, training acc total= 86.09665632247925%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3450, training loss Total= 0.34459177, training acc total= 86.09665632247925%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 3500, training loss Total= 0.34379554, training acc total= 86.14622354507446%\n",
            "ValidTest acc= 85.25 %\n",
            "epoch 3550, training loss Total= 0.34301367, training acc total= 86.14622354507446%\n",
            "ValidTest acc= 85.25 %\n",
            "epoch 3600, training loss Total= 0.3422367, training acc total= 86.1957848072052%\n",
            "ValidTest acc= 85.25 %\n",
            "epoch 3650, training loss Total= 0.3414708, training acc total= 86.22056841850281%\n",
            "ValidTest acc= 85.5 %\n",
            "epoch 3700, training loss Total= 0.34071225, training acc total= 86.27013564109802%\n",
            "ValidTest acc= 85.5 %\n",
            "epoch 3750, training loss Total= 0.33996856, training acc total= 86.29491925239563%\n",
            "ValidTest acc= 85.5 %\n",
            "epoch 3800, training loss Total= 0.33923852, training acc total= 86.36927008628845%\n",
            "ValidTest acc= 85.5 %\n",
            "epoch 3850, training loss Total= 0.33851537, training acc total= 86.39405369758606%\n",
            "ValidTest acc= 85.5 %\n",
            "epoch 3900, training loss Total= 0.33780503, training acc total= 86.41883730888367%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 3950, training loss Total= 0.3371039, training acc total= 86.4683985710144%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4000, training loss Total= 0.33641157, training acc total= 86.49318218231201%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4050, training loss Total= 0.33572727, training acc total= 86.49318218231201%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4100, training loss Total= 0.33504683, training acc total= 86.49318218231201%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4150, training loss Total= 0.33438018, training acc total= 86.49318218231201%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4200, training loss Total= 0.33371994, training acc total= 86.51796579360962%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4250, training loss Total= 0.33306572, training acc total= 86.51796579360962%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 4300, training loss Total= 0.33241886, training acc total= 86.51796579360962%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4350, training loss Total= 0.3317849, training acc total= 86.56753301620483%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4400, training loss Total= 0.33115435, training acc total= 86.51796579360962%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4450, training loss Total= 0.330531, training acc total= 86.59231662750244%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4500, training loss Total= 0.32991126, training acc total= 86.61710023880005%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4550, training loss Total= 0.3292965, training acc total= 86.64188385009766%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4600, training loss Total= 0.32868606, training acc total= 86.69145107269287%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4650, training loss Total= 0.32808253, training acc total= 86.66666746139526%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4700, training loss Total= 0.3274818, training acc total= 86.66666746139526%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4750, training loss Total= 0.32688564, training acc total= 86.69145107269287%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4800, training loss Total= 0.326297, training acc total= 86.69145107269287%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4850, training loss Total= 0.3257141, training acc total= 86.69145107269287%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4900, training loss Total= 0.3251331, training acc total= 86.74101829528809%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 4950, training loss Total= 0.32455832, training acc total= 86.79057955741882%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5000, training loss Total= 0.323987, training acc total= 86.79057955741882%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5050, training loss Total= 0.32341793, training acc total= 86.84014678001404%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5100, training loss Total= 0.322852, training acc total= 86.84014678001404%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5150, training loss Total= 0.32228902, training acc total= 86.84014678001404%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5200, training loss Total= 0.3217312, training acc total= 86.84014678001404%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5250, training loss Total= 0.32117736, training acc total= 86.88971400260925%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5300, training loss Total= 0.32062867, training acc total= 86.88971400260925%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5350, training loss Total= 0.32008252, training acc total= 86.88971400260925%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5400, training loss Total= 0.31953865, training acc total= 86.91449761390686%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5450, training loss Total= 0.31900162, training acc total= 86.91449761390686%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5500, training loss Total= 0.31847298, training acc total= 86.93928122520447%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5550, training loss Total= 0.31794262, training acc total= 86.93928122520447%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5600, training loss Total= 0.31741336, training acc total= 86.96406483650208%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5650, training loss Total= 0.316889, training acc total= 86.98884844779968%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5700, training loss Total= 0.31636986, training acc total= 87.0384156703949%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5750, training loss Total= 0.31585237, training acc total= 87.0631992816925%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 5800, training loss Total= 0.31533983, training acc total= 87.08798289299011%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 5850, training loss Total= 0.31483352, training acc total= 87.16232776641846%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 5900, training loss Total= 0.3143283, training acc total= 87.16232776641846%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 5950, training loss Total= 0.31382507, training acc total= 87.13754415512085%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6000, training loss Total= 0.313324, training acc total= 87.16232776641846%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6050, training loss Total= 0.31282538, training acc total= 87.18711137771606%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6100, training loss Total= 0.31233016, training acc total= 87.26146221160889%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6150, training loss Total= 0.31184167, training acc total= 87.2862458229065%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6200, training loss Total= 0.31135115, training acc total= 87.2862458229065%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6250, training loss Total= 0.31086588, training acc total= 87.2862458229065%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 6300, training loss Total= 0.31038266, training acc total= 87.2862458229065%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6350, training loss Total= 0.3099023, training acc total= 87.33581304550171%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6400, training loss Total= 0.30942446, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6450, training loss Total= 0.3089499, training acc total= 87.3110294342041%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6500, training loss Total= 0.30847877, training acc total= 87.3110294342041%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6550, training loss Total= 0.30800825, training acc total= 87.33581304550171%\n",
            "ValidTest acc= 86.25 %\n",
            "epoch 6600, training loss Total= 0.30754495, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.25 %\n",
            "epoch 6650, training loss Total= 0.30709103, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6700, training loss Total= 0.306639, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6750, training loss Total= 0.30618918, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6800, training loss Total= 0.3057391, training acc total= 87.33581304550171%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6850, training loss Total= 0.30529204, training acc total= 87.33581304550171%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6900, training loss Total= 0.30484965, training acc total= 87.36059665679932%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 6950, training loss Total= 0.30441046, training acc total= 87.43494153022766%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7000, training loss Total= 0.30397385, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7050, training loss Total= 0.30354008, training acc total= 87.43494153022766%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7100, training loss Total= 0.30311167, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.25 %\n",
            "epoch 7150, training loss Total= 0.30268598, training acc total= 87.38538026809692%\n",
            "ValidTest acc= 86.25 %\n",
            "epoch 7200, training loss Total= 0.30226314, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7250, training loss Total= 0.30184126, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7300, training loss Total= 0.30142426, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7350, training loss Total= 0.30101302, training acc total= 87.50929236412048%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7400, training loss Total= 0.30060717, training acc total= 87.50929236412048%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7450, training loss Total= 0.30020654, training acc total= 87.50929236412048%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7500, training loss Total= 0.29980662, training acc total= 87.48450875282288%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7550, training loss Total= 0.29941055, training acc total= 87.48450875282288%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7600, training loss Total= 0.29901552, training acc total= 87.48450875282288%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7650, training loss Total= 0.29862255, training acc total= 87.48450875282288%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7700, training loss Total= 0.29823294, training acc total= 87.53407597541809%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7750, training loss Total= 0.29784724, training acc total= 87.5588595867157%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7800, training loss Total= 0.2974632, training acc total= 87.63321042060852%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7850, training loss Total= 0.29708326, training acc total= 87.63321042060852%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7900, training loss Total= 0.29670632, training acc total= 87.65799403190613%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 7950, training loss Total= 0.29633254, training acc total= 87.63321042060852%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 8000, training loss Total= 0.29596016, training acc total= 87.68277764320374%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 8050, training loss Total= 0.2955906, training acc total= 87.68277764320374%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 8100, training loss Total= 0.2952243, training acc total= 87.68277764320374%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 8150, training loss Total= 0.2948608, training acc total= 87.68277764320374%\n",
            "ValidTest acc= 86.75 %\n",
            "epoch 8200, training loss Total= 0.29450005, training acc total= 87.73234486579895%\n",
            "ValidTest acc= 86.75 %\n",
            "epoch 8250, training loss Total= 0.29414073, training acc total= 87.78190612792969%\n",
            "ValidTest acc= 86.75 %\n",
            "epoch 8300, training loss Total= 0.2937824, training acc total= 87.8066897392273%\n",
            "ValidTest acc= 86.75 %\n",
            "epoch 8350, training loss Total= 0.29342735, training acc total= 87.8314733505249%\n",
            "ValidTest acc= 86.75 %\n",
            "epoch 8400, training loss Total= 0.2930732, training acc total= 87.85625696182251%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8450, training loss Total= 0.2927224, training acc total= 87.90582418441772%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8500, training loss Total= 0.29237524, training acc total= 87.90582418441772%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8550, training loss Total= 0.29203176, training acc total= 87.90582418441772%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8600, training loss Total= 0.29169124, training acc total= 87.90582418441772%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8650, training loss Total= 0.29135343, training acc total= 87.93060779571533%\n",
            "ValidTest acc= 87.0 %\n",
            "epoch 8700, training loss Total= 0.2910181, training acc total= 87.93060779571533%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 8750, training loss Total= 0.29068533, training acc total= 87.95539140701294%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 8800, training loss Total= 0.29035518, training acc total= 87.95539140701294%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 8850, training loss Total= 0.29002517, training acc total= 88.00495862960815%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 8900, training loss Total= 0.28969705, training acc total= 88.00495862960815%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 8950, training loss Total= 0.28937465, training acc total= 87.98017501831055%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 9000, training loss Total= 0.28905344, training acc total= 87.98017501831055%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 9050, training loss Total= 0.28873426, training acc total= 88.00495862960815%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9100, training loss Total= 0.2884184, training acc total= 88.02974224090576%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9150, training loss Total= 0.28810275, training acc total= 88.05452585220337%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9200, training loss Total= 0.28779033, training acc total= 88.1040871143341%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9250, training loss Total= 0.2874782, training acc total= 88.1040871143341%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9300, training loss Total= 0.2871662, training acc total= 88.12887072563171%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9350, training loss Total= 0.2868567, training acc total= 88.17843794822693%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9400, training loss Total= 0.28655005, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9450, training loss Total= 0.28624526, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9500, training loss Total= 0.2859427, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9550, training loss Total= 0.2856418, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9600, training loss Total= 0.28534153, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9650, training loss Total= 0.28504464, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9700, training loss Total= 0.28474852, training acc total= 88.22800517082214%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9750, training loss Total= 0.2844561, training acc total= 88.22800517082214%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9800, training loss Total= 0.28416583, training acc total= 88.25278878211975%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9850, training loss Total= 0.2838753, training acc total= 88.25278878211975%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9900, training loss Total= 0.28358477, training acc total= 88.25278878211975%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 9950, training loss Total= 0.28329676, training acc total= 88.27757239341736%\n",
            "ValidTest acc= 87.5 %\n",
            "ValidValid acc= 86.4012 %\n",
            "ValidTest acc= 87.5 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onW-VbaLZJPc",
        "colab_type": "code",
        "outputId": "82c4ff88-d6d1-48f0-f8e9-73712aa7efc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, number_of_epoch, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, tracked_valid_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oim1QKC5B1eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3213
        },
        "outputId": "d8526727-7e90-4c59-ca66-8c619532cc50"
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = train_data.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 100000\n",
        "batch_size = 200\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "              saver.save(sess, './statlog_letterAdam123')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 2.2383213, training acc total= 9.219330549240112%\n",
            "ValidTest acc= 11.0 %\n",
            "epoch 1000, training loss Total= 0.42182755, training acc total= 84.36183333396912%\n",
            "ValidTest acc= 83.75 %\n",
            "epoch 2000, training loss Total= 0.37439477, training acc total= 85.22924184799194%\n",
            "ValidTest acc= 84.25 %\n",
            "epoch 3000, training loss Total= 0.35219437, training acc total= 85.6753408908844%\n",
            "ValidTest acc= 85.0 %\n",
            "epoch 4000, training loss Total= 0.33641157, training acc total= 86.49318218231201%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 5000, training loss Total= 0.323987, training acc total= 86.79057955741882%\n",
            "ValidTest acc= 86.0 %\n",
            "epoch 6000, training loss Total= 0.313324, training acc total= 87.16232776641846%\n",
            "ValidTest acc= 85.75 %\n",
            "epoch 7000, training loss Total= 0.30397385, training acc total= 87.41016387939453%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 8000, training loss Total= 0.29596016, training acc total= 87.68277764320374%\n",
            "ValidTest acc= 86.5 %\n",
            "epoch 9000, training loss Total= 0.28905344, training acc total= 87.98017501831055%\n",
            "ValidTest acc= 87.25 %\n",
            "epoch 10000, training loss Total= 0.28300735, training acc total= 88.30235600471497%\n",
            "ValidTest acc= 87.5 %\n",
            "epoch 11000, training loss Total= 0.2775221, training acc total= 88.59975337982178%\n",
            "ValidTest acc= 87.75 %\n",
            "epoch 12000, training loss Total= 0.2725799, training acc total= 88.84758353233337%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 13000, training loss Total= 0.26824728, training acc total= 88.97150158882141%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 14000, training loss Total= 0.2643507, training acc total= 89.07063007354736%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 15000, training loss Total= 0.26085767, training acc total= 89.1697645187378%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 16000, training loss Total= 0.25763452, training acc total= 89.39281105995178%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 17000, training loss Total= 0.25463337, training acc total= 89.56629633903503%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 18000, training loss Total= 0.25181437, training acc total= 89.66542482376099%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 19000, training loss Total= 0.24910747, training acc total= 89.7149920463562%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 20000, training loss Total= 0.24650362, training acc total= 89.78934288024902%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 21000, training loss Total= 0.24405491, training acc total= 89.81412649154663%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 22000, training loss Total= 0.241778, training acc total= 89.93804454803467%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 23000, training loss Total= 0.23953019, training acc total= 90.08674025535583%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 24000, training loss Total= 0.23732188, training acc total= 90.13630747795105%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 25000, training loss Total= 0.23522688, training acc total= 90.16109108924866%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 26000, training loss Total= 0.23322713, training acc total= 90.18587470054626%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 27000, training loss Total= 0.2313185, training acc total= 90.26022553443909%\n",
            "ValidTest acc= 88.0 %\n",
            "epoch 28000, training loss Total= 0.22949934, training acc total= 90.35935401916504%\n",
            "ValidTest acc= 88.25 %\n",
            "epoch 29000, training loss Total= 0.2276985, training acc total= 90.38413763046265%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 30000, training loss Total= 0.22595987, training acc total= 90.53283929824829%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 31000, training loss Total= 0.22430563, training acc total= 90.70631861686707%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 32000, training loss Total= 0.22269887, training acc total= 90.78066945075989%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 33000, training loss Total= 0.22111985, training acc total= 90.90458750724792%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 34000, training loss Total= 0.21959834, training acc total= 90.92936515808105%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 35000, training loss Total= 0.21809822, training acc total= 91.02849960327148%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 36000, training loss Total= 0.21662055, training acc total= 91.0780668258667%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 37000, training loss Total= 0.215181, training acc total= 91.17720127105713%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 38000, training loss Total= 0.21377912, training acc total= 91.20198488235474%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 39000, training loss Total= 0.21238354, training acc total= 91.25154614448547%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 40000, training loss Total= 0.21102393, training acc total= 91.30111336708069%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 41000, training loss Total= 0.20971225, training acc total= 91.30111336708069%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 42000, training loss Total= 0.20842324, training acc total= 91.3506805896759%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 43000, training loss Total= 0.2071509, training acc total= 91.44981503486633%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 44000, training loss Total= 0.20595649, training acc total= 91.49938225746155%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 45000, training loss Total= 0.20478189, training acc total= 91.52416586875916%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 46000, training loss Total= 0.20359573, training acc total= 91.57372713088989%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 47000, training loss Total= 0.20244163, training acc total= 91.57372713088989%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 48000, training loss Total= 0.20127837, training acc total= 91.57372713088989%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 49000, training loss Total= 0.20009279, training acc total= 91.5985107421875%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 50000, training loss Total= 0.19896272, training acc total= 91.62329435348511%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 51000, training loss Total= 0.19786255, training acc total= 91.69764518737793%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 52000, training loss Total= 0.19677365, training acc total= 91.69764518737793%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 53000, training loss Total= 0.19562614, training acc total= 91.77199602127075%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 54000, training loss Total= 0.19453165, training acc total= 91.74721240997314%\n",
            "ValidTest acc= 89.5 %\n",
            "epoch 55000, training loss Total= 0.19346811, training acc total= 91.84634685516357%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 56000, training loss Total= 0.19243014, training acc total= 91.84634685516357%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 57000, training loss Total= 0.19137742, training acc total= 91.84634685516357%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 58000, training loss Total= 0.19032443, training acc total= 91.89590811729431%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 59000, training loss Total= 0.18927401, training acc total= 91.89590811729431%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 60000, training loss Total= 0.18824728, training acc total= 91.94547533988953%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 61000, training loss Total= 0.18724169, training acc total= 91.97025895118713%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 62000, training loss Total= 0.1861991, training acc total= 91.97025895118713%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 63000, training loss Total= 0.18518053, training acc total= 92.09417700767517%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 64000, training loss Total= 0.18420686, training acc total= 92.21808910369873%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 65000, training loss Total= 0.1832359, training acc total= 92.24287271499634%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 66000, training loss Total= 0.18227406, training acc total= 92.21808910369873%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 67000, training loss Total= 0.18132111, training acc total= 92.21808910369873%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 68000, training loss Total= 0.18037964, training acc total= 92.31722354888916%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 69000, training loss Total= 0.17941217, training acc total= 92.41635799407959%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 70000, training loss Total= 0.178444, training acc total= 92.41635799407959%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 71000, training loss Total= 0.17751694, training acc total= 92.51549243927002%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 72000, training loss Total= 0.17656596, training acc total= 92.51549243927002%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 73000, training loss Total= 0.17563368, training acc total= 92.51549243927002%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 74000, training loss Total= 0.17472023, training acc total= 92.61462092399597%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 75000, training loss Total= 0.17383009, training acc total= 92.58983731269836%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 76000, training loss Total= 0.17294653, training acc total= 92.61462092399597%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 77000, training loss Total= 0.17207071, training acc total= 92.61462092399597%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 78000, training loss Total= 0.17120479, training acc total= 92.63940453529358%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 79000, training loss Total= 0.17034747, training acc total= 92.63940453529358%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 80000, training loss Total= 0.16949855, training acc total= 92.61462092399597%\n",
            "ValidTest acc= 88.5 %\n",
            "epoch 81000, training loss Total= 0.16866669, training acc total= 92.63940453529358%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 82000, training loss Total= 0.16784537, training acc total= 92.6889717578888%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 83000, training loss Total= 0.16702886, training acc total= 92.7137553691864%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 84000, training loss Total= 0.16621998, training acc total= 92.73853898048401%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 85000, training loss Total= 0.16542245, training acc total= 92.76332259178162%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 86000, training loss Total= 0.16464336, training acc total= 92.81288981437683%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 87000, training loss Total= 0.163871, training acc total= 92.81288981437683%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 88000, training loss Total= 0.16310944, training acc total= 92.86245107650757%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 89000, training loss Total= 0.16236539, training acc total= 92.83766746520996%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 90000, training loss Total= 0.16160993, training acc total= 92.86245107650757%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 91000, training loss Total= 0.16084649, training acc total= 92.91201829910278%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 92000, training loss Total= 0.16008607, training acc total= 92.9863691329956%\n",
            "ValidTest acc= 88.75 %\n",
            "epoch 93000, training loss Total= 0.15935063, training acc total= 92.9863691329956%\n",
            "ValidTest acc= 88.75 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5OI5AzVB4N9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMcMrIU6B4LM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGJobkitB4IC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWDc2yEckOZ6",
        "colab_type": "code",
        "outputId": "50b7759d-2b5d-4865-ac18-f01ad4dca5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 300000\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 10000\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(150000, num_steps):\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            track_step.append(step)\n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "            tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              if (validationTest_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_letterAdam\n",
            "step 150000, training loss Total= 0.28337076, training acc total= 87.93060779571533%\n",
            "ValidTest acc= 88.0 %\n",
            "step 160000, training loss Total= 0.27946484, training acc total= 88.1040871143341%\n",
            "ValidTest acc= 88.5 %\n",
            "step 170000, training loss Total= 0.27584106, training acc total= 88.20322155952454%\n",
            "ValidTest acc= 88.75 %\n",
            "step 180000, training loss Total= 0.27245057, training acc total= 88.40148448944092%\n",
            "ValidTest acc= 89.0 %\n",
            "step 190000, training loss Total= 0.2692739, training acc total= 88.50061893463135%\n",
            "ValidTest acc= 89.0 %\n",
            "step 200000, training loss Total= 0.2662712, training acc total= 88.64932060241699%\n",
            "ValidTest acc= 89.0 %\n",
            "step 210000, training loss Total= 0.2634308, training acc total= 88.82279992103577%\n",
            "ValidTest acc= 89.0 %\n",
            "step 220000, training loss Total= 0.2607301, training acc total= 88.99628520011902%\n",
            "ValidTest acc= 89.25 %\n",
            "step 230000, training loss Total= 0.2581373, training acc total= 89.02106285095215%\n",
            "ValidTest acc= 89.5 %\n",
            "step 240000, training loss Total= 0.25567746, training acc total= 89.09541368484497%\n",
            "ValidTest acc= 89.75 %\n",
            "step 250000, training loss Total= 0.25332367, training acc total= 89.1945481300354%\n",
            "ValidTest acc= 89.75 %\n",
            "step 260000, training loss Total= 0.2510495, training acc total= 89.31846618652344%\n",
            "ValidTest acc= 89.75 %\n",
            "step 270000, training loss Total= 0.24886955, training acc total= 89.34324383735657%\n",
            "ValidTest acc= 89.75 %\n",
            "step 280000, training loss Total= 0.24678023, training acc total= 89.51672911643982%\n",
            "ValidTest acc= 90.0 %\n",
            "step 290000, training loss Total= 0.24477716, training acc total= 89.59107995033264%\n",
            "ValidTest acc= 90.0 %\n",
            "ValidValid acc= 88.12923 %\n",
            "ValidTest acc= 90.0 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XHNXeSqGqqtp",
        "colab_type": "code",
        "outputId": "2cafe42f-4611-4661-b53d-613446f754bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 450000\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 10000\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(300000, num_steps):\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            track_step.append(step)\n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "            tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              if (validationTest_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_letterAdam\n",
            "step 300000, training loss Total= 0.244777, training acc total= 89.59107995033264%\n",
            "ValidTest acc= 90.0 %\n",
            "step 310000, training loss Total= 0.24283686, training acc total= 89.61586356163025%\n",
            "ValidTest acc= 90.0 %\n",
            "step 320000, training loss Total= 0.24094816, training acc total= 89.73977565765381%\n",
            "ValidTest acc= 90.0 %\n",
            "step 330000, training loss Total= 0.23910639, training acc total= 89.73977565765381%\n",
            "ValidTest acc= 90.0 %\n",
            "step 340000, training loss Total= 0.23729514, training acc total= 89.78934288024902%\n",
            "ValidTest acc= 90.0 %\n",
            "step 350000, training loss Total= 0.2355384, training acc total= 89.93804454803467%\n",
            "ValidTest acc= 90.0 %\n",
            "step 360000, training loss Total= 0.23385364, training acc total= 89.93804454803467%\n",
            "ValidTest acc= 90.0 %\n",
            "step 370000, training loss Total= 0.23222238, training acc total= 89.96282815933228%\n",
            "ValidTest acc= 90.0 %\n",
            "step 380000, training loss Total= 0.23062278, training acc total= 89.9876058101654%\n",
            "ValidTest acc= 90.0 %\n",
            "step 390000, training loss Total= 0.22906926, training acc total= 90.01238942146301%\n",
            "ValidTest acc= 89.75 %\n",
            "step 400000, training loss Total= 0.22756699, training acc total= 90.01238942146301%\n",
            "ValidTest acc= 89.75 %\n",
            "step 410000, training loss Total= 0.22609548, training acc total= 90.01238942146301%\n",
            "ValidTest acc= 90.0 %\n",
            "step 420000, training loss Total= 0.2246542, training acc total= 90.06195664405823%\n",
            "ValidTest acc= 90.0 %\n",
            "step 430000, training loss Total= 0.22323647, training acc total= 90.11152386665344%\n",
            "ValidTest acc= 90.25 %\n",
            "step 440000, training loss Total= 0.2218549, training acc total= 90.13630747795105%\n",
            "ValidTest acc= 90.25 %\n",
            "ValidValid acc= 88.58001 %\n",
            "ValidTest acc= 90.25 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rg7cQuCsw66k",
        "colab_type": "code",
        "outputId": "97587994-b278-4b94-c168-4c2ad61f605f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 600000\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 20000\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(450000, num_steps):\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            track_step.append(step)\n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "            tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              if (validationTest_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_letterAdam\n",
            "step 460000, training loss Total= 0.22050172, training acc total= 90.18587470054626%\n",
            "ValidTest acc= 90.25 %\n",
            "step 480000, training loss Total= 0.21790107, training acc total= 90.26022553443909%\n",
            "ValidTest acc= 90.25 %\n",
            "step 500000, training loss Total= 0.21537104, training acc total= 90.38413763046265%\n",
            "ValidTest acc= 90.0 %\n",
            "step 520000, training loss Total= 0.21289638, training acc total= 90.5824065208435%\n",
            "ValidTest acc= 90.5 %\n",
            "step 540000, training loss Total= 0.21050033, training acc total= 90.68153500556946%\n",
            "ValidTest acc= 90.5 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wC_9RTLQ6eHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 1 steps\n"
      ]
    },
    {
      "metadata": {
        "id": "-BYDFCmNoVy-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 443\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_iSjwuvqyVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfOmgUcBoW14",
        "colab_type": "code",
        "outputId": "d1ffcd48-b133-4bde-8f7e-ed5e23db32ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "nNOf_xPDp-Kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "# G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "# G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "# G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "# G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init(clf.coefs_[0].shape))\n",
        "G_b1 = tf.Variable(xavier_init(clf.intercepts_ [0].shape))\n",
        "\n",
        "G_W2 =  tf.Variable(xavier_init(clf.coefs_[1].shape))\n",
        "G_b2 = tf.Variable(xavier_init(clf.intercepts_ [1].shape))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2gf_uEy6eHl",
        "colab_type": "code",
        "outputId": "bd7ad45b-904a-45c9-f80a-2901694d3117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4930
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 2800\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 10\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 1\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "    \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit2')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 2.3230484, training acc total= 10.19539088010788%\n",
            "step 10, training loss Total= 2.2801585, training acc total= 10.19539088010788%\n",
            "step 20, training loss Total= 2.2395625, training acc total= 10.19539088010788%\n",
            "step 30, training loss Total= 2.2001646, training acc total= 10.19539088010788%\n",
            "step 40, training loss Total= 2.160777, training acc total= 10.19539088010788%\n",
            "step 50, training loss Total= 2.1240113, training acc total= 10.170340538024902%\n",
            "step 60, training loss Total= 2.0882378, training acc total= 10.170340538024902%\n",
            "step 70, training loss Total= 2.0537684, training acc total= 10.170340538024902%\n",
            "step 80, training loss Total= 2.0214164, training acc total= 10.170340538024902%\n",
            "step 90, training loss Total= 1.9892347, training acc total= 10.170340538024902%\n",
            "step 100, training loss Total= 1.9577996, training acc total= 10.19539088010788%\n",
            "step 110, training loss Total= 1.9292663, training acc total= 10.245490819215775%\n",
            "step 120, training loss Total= 1.9003811, training acc total= 10.220441222190857%\n",
            "step 130, training loss Total= 1.8716888, training acc total= 10.29559150338173%\n",
            "step 140, training loss Total= 1.8443228, training acc total= 10.345691442489624%\n",
            "step 150, training loss Total= 1.817004, training acc total= 10.495992004871368%\n",
            "step 160, training loss Total= 1.7903543, training acc total= 10.67134290933609%\n",
            "step 170, training loss Total= 1.7650456, training acc total= 10.971944034099579%\n",
            "step 180, training loss Total= 1.739987, training acc total= 11.297595500946045%\n",
            "step 190, training loss Total= 1.7168069, training acc total= 11.497996002435684%\n",
            "step 200, training loss Total= 1.6938932, training acc total= 11.92384734749794%\n",
            "step 210, training loss Total= 1.6701297, training acc total= 13.226452469825745%\n",
            "step 220, training loss Total= 1.6486553, training acc total= 14.504007995128632%\n",
            "step 230, training loss Total= 1.6268299, training acc total= 16.33266508579254%\n",
            "step 240, training loss Total= 1.6053115, training acc total= 19.13827657699585%\n",
            "step 250, training loss Total= 1.5853118, training acc total= 21.392785012722015%\n",
            "step 260, training loss Total= 1.5650655, training acc total= 23.396793007850647%\n",
            "step 270, training loss Total= 1.5452564, training acc total= 25.20039975643158%\n",
            "step 280, training loss Total= 1.5265648, training acc total= 26.678356528282166%\n",
            "step 290, training loss Total= 1.5079696, training acc total= 28.682366013526917%\n",
            "step 300, training loss Total= 1.4902536, training acc total= 30.58617115020752%\n",
            "step 310, training loss Total= 1.4734231, training acc total= 32.064127922058105%\n",
            "step 320, training loss Total= 1.456092, training acc total= 33.39178264141083%\n",
            "step 330, training loss Total= 1.4395709, training acc total= 34.89478826522827%\n",
            "step 340, training loss Total= 1.4231294, training acc total= 36.52304708957672%\n",
            "step 350, training loss Total= 1.4078919, training acc total= 37.42485046386719%\n",
            "step 360, training loss Total= 1.3933504, training acc total= 38.37675452232361%\n",
            "step 370, training loss Total= 1.3792456, training acc total= 39.478957653045654%\n",
            "step 380, training loss Total= 1.3658087, training acc total= 40.95691442489624%\n",
            "step 390, training loss Total= 1.3526113, training acc total= 41.85871779918671%\n",
            "step 400, training loss Total= 1.3397126, training acc total= 42.58517026901245%\n",
            "step 410, training loss Total= 1.3273548, training acc total= 44.23847794532776%\n",
            "step 420, training loss Total= 1.3156075, training acc total= 45.816633105278015%\n",
            "step 430, training loss Total= 1.3039249, training acc total= 47.52004146575928%\n",
            "step 440, training loss Total= 1.2928162, training acc total= 49.34869706630707%\n",
            "step 450, training loss Total= 1.2820195, training acc total= 51.05210542678833%\n",
            "step 460, training loss Total= 1.2717856, training acc total= 53.00601124763489%\n",
            "step 470, training loss Total= 1.2617586, training acc total= 54.45891618728638%\n",
            "step 480, training loss Total= 1.2518748, training acc total= 55.811625719070435%\n",
            "step 490, training loss Total= 1.2421273, training acc total= 57.0891797542572%\n",
            "step 500, training loss Total= 1.2324538, training acc total= 58.391785621643066%\n",
            "step 510, training loss Total= 1.2235041, training acc total= 59.59419012069702%\n",
            "step 520, training loss Total= 1.214637, training acc total= 60.74649095535278%\n",
            "step 530, training loss Total= 1.2062192, training acc total= 61.873745918273926%\n",
            "step 540, training loss Total= 1.1978337, training acc total= 62.87575364112854%\n",
            "step 550, training loss Total= 1.1897343, training acc total= 63.702404499053955%\n",
            "step 560, training loss Total= 1.1817713, training acc total= 64.77956175804138%\n",
            "step 570, training loss Total= 1.1741114, training acc total= 65.38076400756836%\n",
            "step 580, training loss Total= 1.1670302, training acc total= 66.03206396102905%\n",
            "step 590, training loss Total= 1.1597514, training acc total= 66.58316850662231%\n",
            "step 600, training loss Total= 1.152542, training acc total= 67.28456616401672%\n",
            "step 610, training loss Total= 1.1458004, training acc total= 67.81061887741089%\n",
            "step 620, training loss Total= 1.1391981, training acc total= 68.46192479133606%\n",
            "step 630, training loss Total= 1.1327628, training acc total= 69.41382884979248%\n",
            "step 640, training loss Total= 1.1263764, training acc total= 69.91482973098755%\n",
            "step 650, training loss Total= 1.1201324, training acc total= 70.19038200378418%\n",
            "step 660, training loss Total= 1.1142215, training acc total= 70.44088244438171%\n",
            "step 670, training loss Total= 1.108161, training acc total= 70.94188332557678%\n",
            "step 680, training loss Total= 1.1025515, training acc total= 71.34268283843994%\n",
            "step 690, training loss Total= 1.096763, training acc total= 71.59318923950195%\n",
            "step 700, training loss Total= 1.0912261, training acc total= 71.84368968009949%\n",
            "step 710, training loss Total= 1.0858059, training acc total= 72.11923599243164%\n",
            "step 720, training loss Total= 1.0804002, training acc total= 72.52004146575928%\n",
            "step 730, training loss Total= 1.0750799, training acc total= 73.02104234695435%\n",
            "step 740, training loss Total= 1.0698354, training acc total= 73.39679598808289%\n",
            "step 750, training loss Total= 1.064763, training acc total= 73.77254366874695%\n",
            "step 760, training loss Total= 1.0598385, training acc total= 74.04809594154358%\n",
            "step 770, training loss Total= 1.055052, training acc total= 74.37374591827393%\n",
            "step 780, training loss Total= 1.0502422, training acc total= 74.69939589500427%\n",
            "step 790, training loss Total= 1.0456583, training acc total= 74.77455139160156%\n",
            "step 800, training loss Total= 1.0411272, training acc total= 75.0%\n",
            "step 810, training loss Total= 1.036581, training acc total= 75.10020136833191%\n",
            "step 820, training loss Total= 1.0322983, training acc total= 75.30060410499573%\n",
            "step 830, training loss Total= 1.0279543, training acc total= 75.52605271339417%\n",
            "step 840, training loss Total= 1.0237569, training acc total= 75.72645545005798%\n",
            "step 850, training loss Total= 1.0196158, training acc total= 75.87675452232361%\n",
            "step 860, training loss Total= 1.0155329, training acc total= 76.02705359458923%\n",
            "step 870, training loss Total= 1.0114472, training acc total= 76.20240449905396%\n",
            "step 880, training loss Total= 1.007425, training acc total= 76.40280723571777%\n",
            "step 890, training loss Total= 1.0035754, training acc total= 76.50300860404968%\n",
            "step 900, training loss Total= 0.9997586, training acc total= 76.5531063079834%\n",
            "step 910, training loss Total= 0.9960243, training acc total= 76.72845721244812%\n",
            "step 920, training loss Total= 0.9923795, training acc total= 76.80360674858093%\n",
            "step 930, training loss Total= 0.9886365, training acc total= 76.92885994911194%\n",
            "step 940, training loss Total= 0.985116, training acc total= 77.05410718917847%\n",
            "step 950, training loss Total= 0.9816221, training acc total= 77.12925672531128%\n",
            "step 960, training loss Total= 0.97811997, training acc total= 77.25450992584229%\n",
            "step 970, training loss Total= 0.9746423, training acc total= 77.50501036643982%\n",
            "step 980, training loss Total= 0.9711903, training acc total= 77.50501036643982%\n",
            "step 990, training loss Total= 0.9677866, training acc total= 77.55510807037354%\n",
            "step 1000, training loss Total= 0.96453196, training acc total= 77.65530943870544%\n",
            "step 1010, training loss Total= 0.96122694, training acc total= 77.65530943870544%\n",
            "step 1020, training loss Total= 0.9580105, training acc total= 77.70541310310364%\n",
            "step 1030, training loss Total= 0.9548419, training acc total= 77.78056263923645%\n",
            "step 1040, training loss Total= 0.95163715, training acc total= 77.95591354370117%\n",
            "step 1050, training loss Total= 0.9485299, training acc total= 77.98095941543579%\n",
            "step 1060, training loss Total= 0.9454327, training acc total= 78.15631031990051%\n",
            "step 1070, training loss Total= 0.9423889, training acc total= 78.25651168823242%\n",
            "step 1080, training loss Total= 0.9393642, training acc total= 78.18136215209961%\n",
            "step 1090, training loss Total= 0.9365017, training acc total= 78.2314658164978%\n",
            "step 1100, training loss Total= 0.93357754, training acc total= 78.2064139842987%\n",
            "step 1110, training loss Total= 0.9307462, training acc total= 78.2314658164978%\n",
            "step 1120, training loss Total= 0.9278563, training acc total= 78.2314658164978%\n",
            "step 1130, training loss Total= 0.92502147, training acc total= 78.30661535263062%\n",
            "step 1140, training loss Total= 0.9221891, training acc total= 78.38176488876343%\n",
            "step 1150, training loss Total= 0.919447, training acc total= 78.48196625709534%\n",
            "step 1160, training loss Total= 0.91670203, training acc total= 78.60721349716187%\n",
            "step 1170, training loss Total= 0.9140506, training acc total= 78.68236303329468%\n",
            "step 1180, training loss Total= 0.91143256, training acc total= 78.68236303329468%\n",
            "step 1190, training loss Total= 0.90880966, training acc total= 78.65731716156006%\n",
            "step 1200, training loss Total= 0.9062969, training acc total= 78.63226532936096%\n",
            "step 1210, training loss Total= 0.90373373, training acc total= 78.63226532936096%\n",
            "step 1220, training loss Total= 0.90116674, training acc total= 78.63226532936096%\n",
            "step 1230, training loss Total= 0.89854515, training acc total= 78.73246669769287%\n",
            "step 1240, training loss Total= 0.8960635, training acc total= 78.73246669769287%\n",
            "step 1250, training loss Total= 0.8935151, training acc total= 78.80761623382568%\n",
            "step 1260, training loss Total= 0.89111745, training acc total= 78.93286347389221%\n",
            "step 1270, training loss Total= 0.8887508, training acc total= 78.90781760215759%\n",
            "step 1280, training loss Total= 0.88635737, training acc total= 78.90781760215759%\n",
            "step 1290, training loss Total= 0.8840412, training acc total= 78.90781760215759%\n",
            "step 1300, training loss Total= 0.8816918, training acc total= 78.95791530609131%\n",
            "step 1310, training loss Total= 0.8794079, training acc total= 78.9829671382904%\n",
            "step 1320, training loss Total= 0.8770705, training acc total= 78.95791530609131%\n",
            "step 1330, training loss Total= 0.8748406, training acc total= 78.9829671382904%\n",
            "step 1340, training loss Total= 0.87264305, training acc total= 78.93286347389221%\n",
            "step 1350, training loss Total= 0.8704663, training acc total= 79.05811667442322%\n",
            "step 1360, training loss Total= 0.8682928, training acc total= 79.10821437835693%\n",
            "step 1370, training loss Total= 0.8661573, training acc total= 79.15831804275513%\n",
            "step 1380, training loss Total= 0.8640317, training acc total= 79.18336391448975%\n",
            "step 1390, training loss Total= 0.8618732, training acc total= 79.23346757888794%\n",
            "step 1400, training loss Total= 0.85983074, training acc total= 79.20841574668884%\n",
            "step 1410, training loss Total= 0.8576981, training acc total= 79.25851941108704%\n",
            "step 1420, training loss Total= 0.85561264, training acc total= 79.28356528282166%\n",
            "step 1430, training loss Total= 0.85351735, training acc total= 79.28356528282166%\n",
            "step 1440, training loss Total= 0.8514984, training acc total= 79.30861711502075%\n",
            "step 1450, training loss Total= 0.8494993, training acc total= 79.38376665115356%\n",
            "step 1460, training loss Total= 0.84741294, training acc total= 79.38376665115356%\n",
            "step 1470, training loss Total= 0.84543645, training acc total= 79.38376665115356%\n",
            "step 1480, training loss Total= 0.8434776, training acc total= 79.45891618728638%\n",
            "step 1490, training loss Total= 0.84154516, training acc total= 79.50901985168457%\n",
            "step 1500, training loss Total= 0.8396167, training acc total= 79.55911755561829%\n",
            "step 1510, training loss Total= 0.837681, training acc total= 79.55911755561829%\n",
            "step 1520, training loss Total= 0.83576757, training acc total= 79.58416938781738%\n",
            "step 1530, training loss Total= 0.8338557, training acc total= 79.55911755561829%\n",
            "step 1540, training loss Total= 0.831976, training acc total= 79.60922122001648%\n",
            "step 1550, training loss Total= 0.83013856, training acc total= 79.53406572341919%\n",
            "step 1560, training loss Total= 0.8282697, training acc total= 79.55911755561829%\n",
            "step 1570, training loss Total= 0.82645214, training acc total= 79.55911755561829%\n",
            "step 1580, training loss Total= 0.8246677, training acc total= 79.55911755561829%\n",
            "step 1590, training loss Total= 0.822798, training acc total= 79.6342670917511%\n",
            "step 1600, training loss Total= 0.82103556, training acc total= 79.60922122001648%\n",
            "step 1610, training loss Total= 0.81928223, training acc total= 79.6342670917511%\n",
            "step 1620, training loss Total= 0.817535, training acc total= 79.6593189239502%\n",
            "step 1630, training loss Total= 0.81583714, training acc total= 79.6342670917511%\n",
            "step 1640, training loss Total= 0.8140503, training acc total= 79.6342670917511%\n",
            "step 1650, training loss Total= 0.812317, training acc total= 79.60922122001648%\n",
            "step 1660, training loss Total= 0.81068856, training acc total= 79.60922122001648%\n",
            "step 1670, training loss Total= 0.80896133, training acc total= 79.53406572341919%\n",
            "step 1680, training loss Total= 0.8072747, training acc total= 79.55911755561829%\n",
            "step 1690, training loss Total= 0.80561525, training acc total= 79.58416938781738%\n",
            "step 1700, training loss Total= 0.80399925, training acc total= 79.60922122001648%\n",
            "step 1710, training loss Total= 0.80235505, training acc total= 79.6342670917511%\n",
            "step 1720, training loss Total= 0.80077106, training acc total= 79.6342670917511%\n",
            "step 1730, training loss Total= 0.7991567, training acc total= 79.73446846008301%\n",
            "step 1740, training loss Total= 0.79753006, training acc total= 79.68437075614929%\n",
            "step 1750, training loss Total= 0.79596454, training acc total= 79.73446846008301%\n",
            "step 1760, training loss Total= 0.79437476, training acc total= 79.6593189239502%\n",
            "step 1770, training loss Total= 0.7928126, training acc total= 79.60922122001648%\n",
            "step 1780, training loss Total= 0.79124236, training acc total= 79.73446846008301%\n",
            "step 1790, training loss Total= 0.78972656, training acc total= 79.7595202922821%\n",
            "step 1800, training loss Total= 0.78819835, training acc total= 79.70941662788391%\n",
            "step 1810, training loss Total= 0.78672516, training acc total= 79.80961799621582%\n",
            "step 1820, training loss Total= 0.78518236, training acc total= 79.80961799621582%\n",
            "step 1830, training loss Total= 0.7837133, training acc total= 79.83466982841492%\n",
            "step 1840, training loss Total= 0.78223854, training acc total= 79.83466982841492%\n",
            "step 1850, training loss Total= 0.7807666, training acc total= 79.85972166061401%\n",
            "step 1860, training loss Total= 0.7793081, training acc total= 79.85972166061401%\n",
            "step 1870, training loss Total= 0.77783644, training acc total= 79.85972166061401%\n",
            "step 1880, training loss Total= 0.77638453, training acc total= 79.85972166061401%\n",
            "step 1890, training loss Total= 0.7749341, training acc total= 79.83466982841492%\n",
            "step 1900, training loss Total= 0.7735284, training acc total= 79.85972166061401%\n",
            "step 1910, training loss Total= 0.7721626, training acc total= 79.85972166061401%\n",
            "step 1920, training loss Total= 0.7707957, training acc total= 79.85972166061401%\n",
            "step 1930, training loss Total= 0.7693881, training acc total= 79.90981936454773%\n",
            "step 1940, training loss Total= 0.7679771, training acc total= 79.95991706848145%\n",
            "step 1950, training loss Total= 0.7666064, training acc total= 79.98496890068054%\n",
            "step 1960, training loss Total= 0.7652859, training acc total= 79.95991706848145%\n",
            "step 1970, training loss Total= 0.7639237, training acc total= 79.95991706848145%\n",
            "step 1980, training loss Total= 0.7625521, training acc total= 79.95991706848145%\n",
            "step 1990, training loss Total= 0.76120365, training acc total= 79.93487119674683%\n",
            "step 2000, training loss Total= 0.7599229, training acc total= 79.95991706848145%\n",
            "step 2010, training loss Total= 0.758577, training acc total= 79.98496890068054%\n",
            "step 2020, training loss Total= 0.7573002, training acc total= 79.98496890068054%\n",
            "step 2030, training loss Total= 0.7560204, training acc total= 79.98496890068054%\n",
            "step 2040, training loss Total= 0.75472724, training acc total= 79.98496890068054%\n",
            "step 2050, training loss Total= 0.75345206, training acc total= 80.01002073287964%\n",
            "step 2060, training loss Total= 0.7521928, training acc total= 80.01002073287964%\n",
            "step 2070, training loss Total= 0.7509221, training acc total= 80.03507256507874%\n",
            "step 2080, training loss Total= 0.7496682, training acc total= 80.03507256507874%\n",
            "step 2090, training loss Total= 0.74841875, training acc total= 80.03507256507874%\n",
            "step 2100, training loss Total= 0.74716973, training acc total= 80.06011843681335%\n",
            "step 2110, training loss Total= 0.7459093, training acc total= 80.06011843681335%\n",
            "step 2120, training loss Total= 0.74469763, training acc total= 80.03507256507874%\n",
            "step 2130, training loss Total= 0.7434753, training acc total= 80.03507256507874%\n",
            "step 2140, training loss Total= 0.7422803, training acc total= 80.08517026901245%\n",
            "step 2150, training loss Total= 0.74108, training acc total= 80.08517026901245%\n",
            "step 2160, training loss Total= 0.73992974, training acc total= 80.08517026901245%\n",
            "step 2170, training loss Total= 0.7387752, training acc total= 80.11022210121155%\n",
            "step 2180, training loss Total= 0.73760545, training acc total= 80.11022210121155%\n",
            "step 2190, training loss Total= 0.73640525, training acc total= 80.11022210121155%\n",
            "step 2200, training loss Total= 0.73522705, training acc total= 80.16031980514526%\n",
            "step 2210, training loss Total= 0.73402953, training acc total= 80.21042346954346%\n",
            "step 2220, training loss Total= 0.73285383, training acc total= 80.23546934127808%\n",
            "step 2230, training loss Total= 0.7317149, training acc total= 80.21042346954346%\n",
            "step 2240, training loss Total= 0.7305431, training acc total= 80.23546934127808%\n",
            "step 2250, training loss Total= 0.7294165, training acc total= 80.23546934127808%\n",
            "step 2260, training loss Total= 0.72830033, training acc total= 80.23546934127808%\n",
            "step 2270, training loss Total= 0.7271797, training acc total= 80.26052117347717%\n",
            "step 2280, training loss Total= 0.7260784, training acc total= 80.28557300567627%\n",
            "step 2290, training loss Total= 0.7249388, training acc total= 80.28557300567627%\n",
            "step 2300, training loss Total= 0.7238366, training acc total= 80.28557300567627%\n",
            "step 2310, training loss Total= 0.722727, training acc total= 80.31061887741089%\n",
            "step 2320, training loss Total= 0.7216502, training acc total= 80.33567070960999%\n",
            "step 2330, training loss Total= 0.720576, training acc total= 80.33567070960999%\n",
            "step 2340, training loss Total= 0.7194839, training acc total= 80.33567070960999%\n",
            "step 2350, training loss Total= 0.7184141, training acc total= 80.36072254180908%\n",
            "step 2360, training loss Total= 0.71733737, training acc total= 80.33567070960999%\n",
            "step 2370, training loss Total= 0.7162607, training acc total= 80.36072254180908%\n",
            "step 2380, training loss Total= 0.7151877, training acc total= 80.38577437400818%\n",
            "step 2390, training loss Total= 0.7141637, training acc total= 80.38577437400818%\n",
            "step 2400, training loss Total= 0.7131304, training acc total= 80.38577437400818%\n",
            "step 2410, training loss Total= 0.7120932, training acc total= 80.38577437400818%\n",
            "step 2420, training loss Total= 0.7110507, training acc total= 80.38577437400818%\n",
            "step 2430, training loss Total= 0.7100412, training acc total= 80.36072254180908%\n",
            "step 2440, training loss Total= 0.70902747, training acc total= 80.36072254180908%\n",
            "step 2450, training loss Total= 0.70802605, training acc total= 80.38577437400818%\n",
            "step 2460, training loss Total= 0.70702237, training acc total= 80.38577437400818%\n",
            "step 2470, training loss Total= 0.70600903, training acc total= 80.38577437400818%\n",
            "step 2480, training loss Total= 0.70502406, training acc total= 80.38577437400818%\n",
            "step 2490, training loss Total= 0.70405114, training acc total= 80.38577437400818%\n",
            "step 2500, training loss Total= 0.703062, training acc total= 80.4108202457428%\n",
            "step 2510, training loss Total= 0.7021186, training acc total= 80.4358720779419%\n",
            "step 2520, training loss Total= 0.70115674, training acc total= 80.4358720779419%\n",
            "step 2530, training loss Total= 0.700207, training acc total= 80.46092391014099%\n",
            "step 2540, training loss Total= 0.6992804, training acc total= 80.46092391014099%\n",
            "step 2550, training loss Total= 0.6983591, training acc total= 80.48596978187561%\n",
            "step 2560, training loss Total= 0.6974071, training acc total= 80.48596978187561%\n",
            "step 2570, training loss Total= 0.6964706, training acc total= 80.48596978187561%\n",
            "step 2580, training loss Total= 0.6955399, training acc total= 80.5110216140747%\n",
            "step 2590, training loss Total= 0.6945885, training acc total= 80.5110216140747%\n",
            "step 2600, training loss Total= 0.69368005, training acc total= 80.48596978187561%\n",
            "step 2610, training loss Total= 0.69276595, training acc total= 80.46092391014099%\n",
            "step 2620, training loss Total= 0.6918351, training acc total= 80.5110216140747%\n",
            "step 2630, training loss Total= 0.690912, training acc total= 80.5110216140747%\n",
            "step 2640, training loss Total= 0.690031, training acc total= 80.5360734462738%\n",
            "step 2650, training loss Total= 0.6891193, training acc total= 80.56111931800842%\n",
            "step 2660, training loss Total= 0.68824047, training acc total= 80.5360734462738%\n",
            "step 2670, training loss Total= 0.68733424, training acc total= 80.56111931800842%\n",
            "step 2680, training loss Total= 0.6864184, training acc total= 80.58617115020752%\n",
            "step 2690, training loss Total= 0.68552035, training acc total= 80.68637251853943%\n",
            "step 2700, training loss Total= 0.6846165, training acc total= 80.71142435073853%\n",
            "step 2710, training loss Total= 0.68373334, training acc total= 80.71142435073853%\n",
            "step 2720, training loss Total= 0.6828573, training acc total= 80.71142435073853%\n",
            "step 2730, training loss Total= 0.68199235, training acc total= 80.71142435073853%\n",
            "step 2740, training loss Total= 0.68111193, training acc total= 80.73647022247314%\n",
            "step 2750, training loss Total= 0.68025523, training acc total= 80.76152205467224%\n",
            "step 2760, training loss Total= 0.67937666, training acc total= 80.78657388687134%\n",
            "step 2770, training loss Total= 0.6785171, training acc total= 80.78657388687134%\n",
            "step 2780, training loss Total= 0.6776859, training acc total= 80.78657388687134%\n",
            "step 2790, training loss Total= 0.6768418, training acc total= 80.78657388687134%\n",
            "ValidValid acc= 80.16529 %\n",
            "ValidTest acc= 83.972916 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "1\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "je7OjX3E6eHo",
        "colab_type": "code",
        "outputId": "70daba93-fe6f-40bc-91ef-e06aac480908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./Pendigit2\n",
            "ValidValid acc= 96.24342 %\n",
            "Test acc= 91.049995 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L6MDqb9a6eHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwsn__mE6eHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y4u4i4HzTxZI"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iS2Vm-EOx1az",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# contd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Qq4-Y2IRx1Nl",
        "outputId": "32429ab1-8010-4abb-8380-4d22bd573711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(valid_validation_data.shape)\n",
        "print(valid_test_data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 36)\n",
            "(331, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4ZTEAcHAT1nX",
        "outputId": "70896e6a-bac4-414e-9f4e-353c87b91c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597210
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "# hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,7):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 1.8787977, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.31329447, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.21906441, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.19732076, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.19835934, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.24405302, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.13411662, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.22033933, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.08951901, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.17645441, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 1000, training loss= 0.10896182, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.07195005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.15884392, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.08193417, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.17177877, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.19582757, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.113960825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.12956136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.122660056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.14094788, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.10311641, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.13765934, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.10325155, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.11353492, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.11217652, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.06921399, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.12896287, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.14321212, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.10865586, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.13230555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.13740438, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.098931566, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.07288448, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.059909873, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.10110669, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.09175815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.095672145, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.12328446, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.1071218, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.097845, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.12053114, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.08493434, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.06875472, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.096695706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.078817874, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.080637276, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.11208922, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.06569346, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.084097505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.100890145, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.06782614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.11094068, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.07136125, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.079359695, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.12750007, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.08815857, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.098410636, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.0760577, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.0648673, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.08215423, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.14472315, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.08973067, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.053350586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.05545748, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.06443736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.041131068, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.0996937, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.12811872, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.11608111, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.13533175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.09554125, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.07371354, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.04961843, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.070294864, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.07680015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.051051907, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.06626982, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.075678036, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.11656638, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.15082501, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.072371215, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.098125905, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.096396536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.07995257, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.12740833, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.11112548, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.08091103, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.033726413, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.07997398, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.117365964, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.060300533, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.08415135, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.05215323, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.07893438, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.07175355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.05887298, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.03571506, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.07116796, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.060126066, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.06543007, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.05083836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.0869903, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.10110801, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.11088665, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.10126825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.0904119, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.06212945, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.037921645, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.058070593, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.05964901, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.092572056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.11616923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.05814428, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.083505206, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.104571566, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.08314328, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.066539496, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.101065174, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.07496343, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.0730208, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.12224668, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.07331172, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.0631239, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.11805102, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.053174138, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.09031227, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.07944183, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.0636691, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.059721828, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.060611233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.08106676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.050864413, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.11169109, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.09116188, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.06624702, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.08869779, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.081999436, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.05398161, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.07134722, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.065916695, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.040935367, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.07632005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.06131834, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.07607688, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.09951028, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.08662537, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.066041745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.092228726, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.033713743, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.06032875, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.06640318, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.07965839, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.059748396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.031544257, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.06977751, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.046604197, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.07014711, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.10405025, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.07469725, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.094381705, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.08039187, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.072708085, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.07427178, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.055489533, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.07488479, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.037578017, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.06717983, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.04157237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.07204887, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.073991686, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.03782278, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.05582404, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.101543695, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.048080586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.041279957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.08118234, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.072037145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07901871, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.061720416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.06664769, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.07524802, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.06284073, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.05196266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.07961662, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.05260076, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.056414694, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.11788901, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.07023439, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.055892523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.107784964, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.07611287, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.051269546, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.06603397, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.060537353, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.04827953, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.06448138, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.058488376, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.051629726, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.09114489, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.041027308, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.037795343, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.08741108, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.06787415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.05288887, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.08545852, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.11132184, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.085244544, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.07167363, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.035616774, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.106453955, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.069704585, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.09460581, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.0908805, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.10226748, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.08722501, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.05686175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.043305386, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.066137366, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.07292591, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.045971982, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.06670334, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.05833571, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.037013806, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.07026385, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.05831898, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.057324454, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.05918296, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.08736916, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.0600712, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.06036386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.07029314, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.05557288, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.04610209, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.052491747, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.059675284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.040012747, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.04249861, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.085240275, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.05786244, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.04274164, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.09651503, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.039375685, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.060604125, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.09046997, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.059745625, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.06825395, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.044709414, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.08521943, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.08201543, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.05605641, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.07429356, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.088543385, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.0932014, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.041442998, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.054024756, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.08616741, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.048439056, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.07378781, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.059433017, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.05265018, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.085033, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.044733178, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.05633752, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.041250303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.07428171, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.06265948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.047805283, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.035349477, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.071917415, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.054823555, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.0851532, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.0723118, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.05260974, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.03607575, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.049885575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.071495876, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.047155347, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.0924913, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.037974454, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.05619809, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.046073504, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.045400146, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.1178669, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.07721205, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.06682156, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.072126925, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.07602849, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.09501362, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.07698727, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.06397659, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.09087461, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.081988454, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.088517696, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.08147143, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.057466537, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.07018813, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.092857525, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.0662551, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.080683514, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.055336826, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.8669784, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.41153133, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.34161448, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.1714831, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.23951814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 500, training loss= 0.19235867, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.3510214, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.15166502, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.09685003, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.14724502, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 1000, training loss= 0.19515991, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 1100, training loss= 0.30118847, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 1200, training loss= 0.16731386, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 1300, training loss= 0.12868759, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.2185177, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.17895481, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.28654748, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.17761356, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.034540374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.14281338, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.20386598, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.14207828, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.07424441, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.10232183, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.25197226, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2500, training loss= 0.1407514, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.11403775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.27484423, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.10627612, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2900, training loss= 0.07441405, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3000, training loss= 0.08731943, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.09893837, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.13359328, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.104141675, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.116757065, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.09953098, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.06544046, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.1287204, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.16027114, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.10340636, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.10953777, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.117390394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.06120449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.114162914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.118693374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.11140357, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.14651157, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.06703263, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.12187153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.11576648, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.118640415, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.097678564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 0.08712508, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.115623556, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 5400, training loss= 0.08841747, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.19111025, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.11814143, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.09801694, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.07333848, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.09094153, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.073554, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.053011384, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.08759176, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.08882591, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.11449965, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.081002526, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.057186276, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.050877303, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.13390256, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.13211057, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.06772051, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.15210366, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.060943007, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7300, training loss= 0.11480993, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7400, training loss= 0.054638203, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7500, training loss= 0.11199723, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7600, training loss= 0.09346095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7700, training loss= 0.081986, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7800, training loss= 0.0660906, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7900, training loss= 0.031709306, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8000, training loss= 0.099718384, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8100, training loss= 0.16802993, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8200, training loss= 0.041433703, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8300, training loss= 0.10764575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 0.051169407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8500, training loss= 0.12845764, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8600, training loss= 0.08761301, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8700, training loss= 0.10270538, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8800, training loss= 0.057762783, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 8900, training loss= 0.08533003, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 9000, training loss= 0.05832055, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 9100, training loss= 0.08129101, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9200, training loss= 0.087329194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9300, training loss= 0.05756411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9400, training loss= 0.07253018, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9500, training loss= 0.07439175, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9600, training loss= 0.08274462, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9700, training loss= 0.073336184, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.06962776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.07390785, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.10275363, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 10100, training loss= 0.07395534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.12662789, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.06432499, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.055968594, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.0955595, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.11675681, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 10700, training loss= 0.086276814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.07576582, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.059274673, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 11000, training loss= 0.05854425, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.05679775, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.057452552, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.06915609, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.039214294, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.09799844, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.05585389, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.052296296, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.09787792, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.07034361, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.11594956, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.06825777, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.092269525, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.07755401, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.044162538, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12500, training loss= 0.07467455, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.0891436, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.07010872, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12800, training loss= 0.06640037, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12900, training loss= 0.06642555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13000, training loss= 0.06183152, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.08442112, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13200, training loss= 0.07267572, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.046535864, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.08038612, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13500, training loss= 0.08646368, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.066430375, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13700, training loss= 0.046273895, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.07809611, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.0926122, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14000, training loss= 0.10716568, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.053511493, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.06620866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14300, training loss= 0.038534634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14400, training loss= 0.06328362, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.0448783, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.08979313, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.06116731, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.059626527, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.07769446, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.06966679, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.062692694, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.05505189, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.090719536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.04700519, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.05145658, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.07194744, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.061673474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.045164518, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.047915097, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.059872296, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.039643653, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16200, training loss= 0.072941534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.0742195, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.07722622, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.049321473, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.05290524, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.037269674, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.051893964, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.062700704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.087657176, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.0923779, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.1030673, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.06008751, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.06317049, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.022805851, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.09792554, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.06747627, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.033709627, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.040713828, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.042646155, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.072074205, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.1169331, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.08264029, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.055810135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.037216708, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.06682419, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.051598277, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18800, training loss= 0.06727533, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.061681997, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.08774077, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.08223958, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.06123963, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.08363893, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.06746719, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.06188343, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.06283846, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.054039434, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.0679692, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.08031615, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07360935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.10841051, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.07225336, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.026436917, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.05547949, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.04279402, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.10255562, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.04286736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.077874534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.044046238, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.06193257, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.05053378, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.046735495, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.034740284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.10353929, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.0525736, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0466336, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.058685333, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.07967361, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.04870759, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.029637916, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.05262947, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.06754799, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.0640908, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.0791298, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.032089002, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.06475577, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.037198372, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.083023936, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.035148922, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.060086142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.03680984, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.06999068, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.039599486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.06383395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.039052274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.048938856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.039267637, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.035425875, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.06824485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.085406534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.051766228, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.03673348, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.058374733, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.061399054, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.06575741, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.061171904, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.07871482, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.055612203, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.067121685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.042849287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.03765676, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.05441629, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.050053097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.044911228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.047325402, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.03551503, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.0677258, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.059746873, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.04330472, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.04520365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.049957093, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.06873965, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.02736453, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.08629507, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.05400285, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.045032542, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.07319172, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.033904616, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.04240804, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.026283596, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.073911175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.038227588, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.061059043, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.0459851, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.08366363, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.052238613, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.063529804, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.083323956, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.07568755, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.088436626, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.06016911, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.053816997, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.059867263, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28400, training loss= 0.06565526, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.029410392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.07486291, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.06617124, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.080392346, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.053426117, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.05583138, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.059365712, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.06225365, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.034227233, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.0601592, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.04363171, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.05305224, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.029908754, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.0360748, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.028091444, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 82.17522430419922 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.2419358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.21928136, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.31161878, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.20062082, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.19221315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.22144869, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.1342762, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.15737484, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.091824695, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.16092741, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.10947572, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.12416142, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.0747229, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.115003824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.09416789, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.10110897, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.13466518, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.10380363, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.18493423, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.090723276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.09472178, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.09633021, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.07791084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.15448068, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.11336123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.15699887, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.10505038, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.086095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.11932026, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.09549892, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.13155675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.131107, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.12523304, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.123966895, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.11219302, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.11010953, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.07568015, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.14680205, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.09552686, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.12042235, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.18787424, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09079555, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.09904989, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.08754794, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.09835611, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.07825981, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.10124525, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.08624997, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.06960506, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.071545266, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.07435163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.11308515, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.12172401, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.09473933, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.084266305, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.07476204, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.0795527, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.09542574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.058400206, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.110353336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.10131514, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.087061405, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.074749984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.07273972, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.1275672, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.08294325, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.09816309, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.05536671, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.08760651, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.10110347, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.12267533, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.086499065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.09617354, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.13052435, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.12411974, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.0703792, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.08508599, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.10079104, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.06937312, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.09182428, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.055358406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.13431656, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.064738736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.04634894, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.085043594, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.041623473, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.09884322, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.093322776, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.091728136, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.07543423, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.07431031, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.08556825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.04307738, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.088402, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.110481486, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.14446092, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.06632742, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.07254453, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.13125841, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.07568459, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.08174353, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.06297856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.12024027, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.0790342, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.14376213, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.101375386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.04124177, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.08945964, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.10543978, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.07828062, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.0798314, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.12148771, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.08988106, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.06641044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.09898397, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.08565348, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.06770131, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.07613748, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.13479316, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.11781359, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.093798816, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.073136106, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.08256607, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.062611654, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.102745354, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.1073834, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.106166095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.10524063, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.11807289, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.11459386, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.094318435, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.11211606, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.054813206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.08384302, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.061445832, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.06125469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.080555454, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.10494353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.09263104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.07440251, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.11241536, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.090366855, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.09227409, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.08616507, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.13167392, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.08755718, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.12800741, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.0856353, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.05782622, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.10151931, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.09497928, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.0778672, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.08517265, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.085695766, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.06381779, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.08908939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.094828956, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.0718711, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.06218625, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.04814444, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.056720108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.09429648, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.06208807, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.096713714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.09921887, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.10406393, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.07026325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.0699293, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.078235894, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.054523855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.084499255, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.10168531, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.1114274, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.08807281, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.064019844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.058713775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.103849575, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07397422, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.053921424, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.08745353, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.10864946, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.099211715, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.052314218, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.06286949, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.13060522, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.0956315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.049072742, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18700, training loss= 0.07257333, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.11705314, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.08003053, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.06522943, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.09774278, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.08319454, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.07104771, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.06997952, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.05070389, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.042929545, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.061680898, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.049011536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.09108657, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.066800244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.07120319, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.09647781, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.04928945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.050176486, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.085906476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.06839396, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.061095454, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.10728638, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.058580317, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.08440446, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.07106234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.07736544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.058437116, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.07602876, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.073976405, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.0824406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.0835047, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.13302341, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.05305323, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.08230676, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.09872319, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.0792169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.0929856, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.08369737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.056715753, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.06278806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.059417337, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.04760538, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.067660764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.07202801, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.0559352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.061062567, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.09109889, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.09347461, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23500, training loss= 0.120650634, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.10939666, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.09145743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.04684072, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.04261209, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24000, training loss= 0.04808557, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.069524705, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.07373673, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.088100016, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24400, training loss= 0.07265675, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.10842409, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.091551825, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.09837892, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.08318498, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.061858617, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.08079885, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.107272714, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.10001457, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.10415143, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.07646702, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.111350976, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.07015905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.085022554, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.08029978, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.08792597, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26000, training loss= 0.08353105, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.069251016, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.12209186, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.12306043, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.08167896, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26500, training loss= 0.114017025, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.06926214, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.09859177, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.07567684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.074475296, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.06612985, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.10014276, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27200, training loss= 0.10098541, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27300, training loss= 0.059340894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.06774376, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.08334305, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.059560873, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27700, training loss= 0.052830525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.1007102, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.041638475, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.089057356, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.06236815, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0704756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.053527262, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.06586984, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.07337542, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.03735242, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.11256059, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.07661377, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.06724351, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.07500516, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.051369067, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.10591193, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.12723562, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.08716812, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.060630422, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.08799999, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.06511815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.07845961, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.11883555, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.5385652, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.29816687, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.36322328, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.29612446, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.18227112, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 500, training loss= 0.19444597, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.2563533, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.38362283, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.336456, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 900, training loss= 0.2168042, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.20553724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.31748888, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.12278623, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.14630061, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.18151075, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.17770457, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.20468023, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.24634421, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1800, training loss= 0.15100634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.0990645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.16723628, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.18557456, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.18324432, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.13481078, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.15672565, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.18042107, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.14828633, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.06913692, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.18140426, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2900, training loss= 0.18720868, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3000, training loss= 0.09948429, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.19100894, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.10483147, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.102023676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.10062036, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.100364774, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.1503343, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.14550048, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.078520015, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.063688755, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.10151934, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.15241635, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.16652368, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.06045492, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.09765354, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.101113506, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.08874222, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.16803217, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.17848778, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.17097923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.11572878, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.072405726, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.09299891, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.10624902, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.17983416, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.053877123, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.06700986, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.06619573, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.08226667, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.13905108, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.11246638, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.14007688, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.14839512, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.10338419, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.107820585, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.1234065, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.12704977, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.057324015, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6800, training loss= 0.1539066, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6900, training loss= 0.073468395, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7000, training loss= 0.10570265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.11869605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.13482039, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.10232104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.10544861, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.118524276, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.06517005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.07488248, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.08669281, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.10375573, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.07558278, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.10112852, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.08821221, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.06580777, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.12628397, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.06921874, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.11355983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.083130345, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.106089994, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.06505518, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.08913341, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.07957456, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.086129084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.12092324, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.050858714, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.08829323, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.06378179, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.09778473, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.071072996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.13366184, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.043737583, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.050770946, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.11711298, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.11457217, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.09528133, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.07913635, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.062966004, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.07471998, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.045993462, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.053265117, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.10296651, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.115188956, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.07038615, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.13176177, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.06823335, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.04477375, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.07883599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.053566817, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.10320048, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.0846069, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.09795316, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.08101599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.09719938, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.062224515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.1104625, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.062024802, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.07037809, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.075629085, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.106552616, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12900, training loss= 0.075661354, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.06440343, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.08344101, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.100663036, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.09678433, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.07221147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.09919216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.10728982, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.04729792, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.08853062, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.06279948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.06089868, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.07226132, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.076765895, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.06780586, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.13498071, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.09239628, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.10620442, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.06569944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.11322156, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.058068573, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.06777075, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.073201284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.124852955, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.08602202, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.052045234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.08285326, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.087565556, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.05403472, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.044923965, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.064383164, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.07571512, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.046102688, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.1002711, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.059395485, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.08641178, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.09222484, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.06578937, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.050501827, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.07678471, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.06726371, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.087894276, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.06322825, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.047602266, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.09216433, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.0701071, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.096225515, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.062053923, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.08752587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.07462442, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.056755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.07120688, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.05339611, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.050917603, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.087907165, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.06442572, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.06546632, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.06565423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.045627844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.082538724, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.09464065, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.05962439, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.03701621, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.05794353, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.06780231, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.073607825, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.082932174, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.06906533, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.084396645, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.05786291, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.076676786, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.029972825, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.051507886, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.07706167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.036045384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.07682047, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.07510759, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.0478822, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.09141353, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.04222891, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.05599012, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.04176673, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.060504638, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.08256396, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.045863867, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.064553946, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.062453374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.094110996, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.06910883, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.036422644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.083563454, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.048855644, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.07151159, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.09044815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.052206174, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.05038812, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.06437971, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.061867546, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.08466395, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.096181214, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.04106313, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.053442344, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.10099519, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.054871637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.056319144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.06402123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.10527094, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.06938213, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23700, training loss= 0.081667185, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.04393564, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.07651179, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.03761341, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.05846258, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.054235168, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.052308153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.07395061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.10395681, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.0731222, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.07658296, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.08454921, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.06480348, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.10434551, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.044726647, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.09145166, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.08461146, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.061841674, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.056547605, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.048170947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.053813454, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.060303893, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.088127226, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.07304616, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.04980823, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.0599227, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.05130279, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.07177429, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.09623204, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.07589258, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.041128702, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.06742214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.10378274, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.067275785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.05159071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.05598921, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.0799433, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.07381212, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.097991206, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.04299799, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.08410019, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.07519799, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.058093898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.06456386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28100, training loss= 0.058275808, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.057895966, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.06411169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.06054603, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.073350474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.076166406, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.058109544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.066017754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.072999634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.10880946, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.049286686, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.072617814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.029714186, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.05954421, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.058550507, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.0783632, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.062447574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.0852206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.06820509, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.041245, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.41391215, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.30413836, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.19564834, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.1748373, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.13817325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.14556265, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.14676696, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.22202924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.12080476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.19377378, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.11009622, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1200, training loss= 0.14553711, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.100620925, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.10255164, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1500, training loss= 0.10754444, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.07772983, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.09895713, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.13665363, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.11110772, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.14272282, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.13661912, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.0849539, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.08742817, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.11435491, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.13412651, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.10520038, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.069898136, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.0934516, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.080010936, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.07469648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.11864261, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.05859367, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.073841445, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.098147884, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.12926966, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.105319664, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.114045545, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.119305834, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.12627357, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.06811087, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09600979, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.113604516, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.03959155, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.11899194, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.108596966, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.10140632, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.14083886, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07931744, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.03984187, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.1272034, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.136893, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.1470221, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.0606243, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.07859771, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.049863704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.08898117, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.06962657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.045360047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.05196798, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.09209794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.11020556, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.10512078, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.071242325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.11648303, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.053580165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.10807572, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.07639897, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.13682397, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.08720128, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.060466424, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.08900009, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.08767517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.09689608, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.05056519, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.051440123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.05678635, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.106661856, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.073537536, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.0811394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.07926037, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.107617825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.06923111, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.057238437, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.06500422, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.058917485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.045173448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.09576747, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.07088944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.059996266, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.062415227, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.0800123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.08017422, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.07065395, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.08092815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.1166654, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.08651082, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.046818316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.058207385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.100797996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.078023866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.060386788, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.05412625, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.112369716, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.06462945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.10930124, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.048009705, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.07904665, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.061918024, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.04443524, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.073987275, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.09945898, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.042880505, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.06171631, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.07266568, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.08542804, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.05854547, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.1016731, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.10309325, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.03847889, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.10158847, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.048570126, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.049074452, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.046871327, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.06740227, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.063840374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.06819524, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.07557535, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.0599246, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.08031517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.057265505, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.06572992, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.09904756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.12686649, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.07359843, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.04419493, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.050153818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.052532554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.05456975, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.0610691, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.049352314, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.06582936, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.070943624, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.08361693, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.07023038, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.06530939, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.04558408, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.05543727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.042676024, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.10859993, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.08593682, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.08275447, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.07618761, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.06887384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.0860752, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.08716429, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.065396145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.08331276, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.07479382, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.051512722, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.04940863, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.058050785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.0698432, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.052763905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.0697381, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.06138195, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.06227857, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.06383638, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.06436291, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.0585215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.05824742, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.056873407, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.05515911, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.070658, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.07109527, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.06699424, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.08752682, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07589468, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.06664747, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.03768105, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.10279836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.068918645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.05278475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.06315662, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.055385645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.054564435, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.07511883, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.09777945, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.055675283, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.056759685, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.054182477, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.07569737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.053939633, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.054594126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.05539114, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.055253588, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.09292377, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.06643716, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.07689263, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.060331345, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.068315916, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.05515944, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.08891708, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.045216914, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.07523844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.077564284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.06690482, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.050743222, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.07116694, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.053737886, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.063792594, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.051014565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.07212059, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.06538894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.05856371, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.08559096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.04952086, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.052495085, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.06712729, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.03276641, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.11336751, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.06002307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.06970814, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.10917619, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.08414534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.06248661, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.06179803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.048727825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.05322621, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.06527576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.068262875, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.06748854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.065976955, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.065341264, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.04248405, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.054562047, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.05872876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.050625857, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.07899688, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.082426056, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.053645995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.0626875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.06384726, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.054321803, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.048660554, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.079831764, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.06939426, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.05237488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.045030005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.13411573, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.040990554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.06513399, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.050058343, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.056826405, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.080263354, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.061381564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.07806174, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.07254345, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.03612274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.06737653, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.11807623, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.07665192, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.07279609, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.054383542, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.046049554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.071766935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.10956012, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.056801226, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.07547372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.07141065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.10175146, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.094627276, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.09117485, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.053699434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.066117704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.0466354, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.051250033, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.06554157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.06336649, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.045086764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.061907746, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.058741927, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.096293315, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.05566609, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.06525333, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.08382037, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.050773542, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.087192036, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.057134803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.057202615, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.07711893, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.05977457, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.06301241, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.04087346, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.082372546, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.09128531, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.09876329, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.0407373, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.078833625, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.0534275, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.08157348632812 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.488962, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.44848213, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.14386098, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.25324354, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.3531509, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.1863093, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.18852393, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.21924762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.24741447, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.22489527, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.23406136, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.24527846, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.14891239, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.1359323, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.22868304, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1500, training loss= 0.10941508, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1600, training loss= 0.10158675, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.08289545, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.24364595, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.2639922, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.11151268, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2100, training loss= 0.117097, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2200, training loss= 0.16495843, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.1221075, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.19633932, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.107667305, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.08376064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.1417691, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.055135336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.12667194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.10474855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.1064613, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.09068622, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.13832046, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.13202791, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.14018646, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.06308036, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.122022845, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.19802754, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.18067746, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.15660341, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.09833858, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.059446942, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.06594267, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 4400, training loss= 0.12618256, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.12829219, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 4600, training loss= 0.113394074, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 4700, training loss= 0.13220613, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.1036341, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 4900, training loss= 0.06863471, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.06752745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.13163589, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.1304898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.08353219, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.114209644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.09889331, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 5600, training loss= 0.12000461, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 5700, training loss= 0.09464087, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 0.1256413, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.10629358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 0.08084999, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6100, training loss= 0.0828445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 0.10590231, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 0.069260426, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 0.10991942, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 0.07337129, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6600, training loss= 0.055768248, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 0.17394209, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6800, training loss= 0.03517202, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 6900, training loss= 0.10434965, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.07604893, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7100, training loss= 0.07840619, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 0.082005076, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7300, training loss= 0.071736716, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7400, training loss= 0.118346445, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7500, training loss= 0.06449832, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7600, training loss= 0.090815425, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7700, training loss= 0.07165036, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7800, training loss= 0.0735592, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7900, training loss= 0.12820213, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8000, training loss= 0.06623283, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.06465868, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.09451914, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8300, training loss= 0.102332845, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.13131681, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.04869827, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8600, training loss= 0.060133863, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.06623496, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.063152544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8900, training loss= 0.06685805, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.059123825, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.10063932, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.107773386, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.052657235, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.136138, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.04150154, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.12734704, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.1621782, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.102368966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.12486104, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.087918036, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.06011331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.07616015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.116154864, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.10278995, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.045011446, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.107972436, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.09738173, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.10533502, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.0655153, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.08736881, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.09503567, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.07449182, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.07280945, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.123605326, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.07184037, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.107328825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.05115512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.060171645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.07898812, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.07341837, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.041954182, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.07380223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.062695935, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.04824808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.08392283, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.04455427, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.07239298, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.09738957, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.072053336, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.10669526, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.09180596, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.10449479, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.10769451, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.05905015, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.05183957, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.06237129, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.09142122, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.048204366, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.067579694, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.10467892, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.0678611, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.07357318, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.05967926, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.087463975, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.07889471, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.054724157, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.08237978, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.09872975, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.070477955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.12640972, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.043319795, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.07779994, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.067225985, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.044848118, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.059520032, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.08091705, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.053418186, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.104234986, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.061348855, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.09680503, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.053725403, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.080012955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.05211317, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.099227645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.03842588, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.048491895, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.044370502, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.059793305, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.10044054, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.072270475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.053821333, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.037227657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.06116007, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 0.04563869, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.07246805, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.04208899, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.09117998, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.067465365, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.049711302, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.06322648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.045571726, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.06683079, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.08717259, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.07799214, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.0629694, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.05038448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18700, training loss= 0.08743807, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18800, training loss= 0.043928195, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.06346319, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.071350865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.05582229, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.04332212, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.08145662, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.039839394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19500, training loss= 0.049928546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.1050362, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.07270112, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.050451454, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.08439763, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20000, training loss= 0.09756339, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.05673485, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.06567829, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.12581085, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20400, training loss= 0.07161905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.06789644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.086794, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.08588081, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20800, training loss= 0.050510045, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.06468064, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21000, training loss= 0.08248427, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21100, training loss= 0.053385086, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21200, training loss= 0.07633592, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21300, training loss= 0.0912389, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21400, training loss= 0.037052102, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21500, training loss= 0.06920594, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21600, training loss= 0.043719783, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.043741357, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21800, training loss= 0.08202254, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21900, training loss= 0.07385249, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22000, training loss= 0.06762055, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.032396425, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22200, training loss= 0.04707421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22300, training loss= 0.064861536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.06293741, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22500, training loss= 0.036366474, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22600, training loss= 0.068937145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22700, training loss= 0.06259374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.07901293, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22900, training loss= 0.07921704, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.084469706, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.062413055, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.039276537, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.058250476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23400, training loss= 0.054980483, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23500, training loss= 0.057110347, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23600, training loss= 0.086161606, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23700, training loss= 0.086262874, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23800, training loss= 0.065762125, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23900, training loss= 0.0535541, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24000, training loss= 0.08540148, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.047147747, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24200, training loss= 0.080704205, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.047019113, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24400, training loss= 0.07987865, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24500, training loss= 0.060726862, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.063374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24700, training loss= 0.08013677, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24800, training loss= 0.105166815, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24900, training loss= 0.055060636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25000, training loss= 0.054312717, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.0786918, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25200, training loss= 0.048849206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25300, training loss= 0.100231186, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25400, training loss= 0.06576704, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25500, training loss= 0.056095053, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25600, training loss= 0.043812763, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25700, training loss= 0.07824494, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25800, training loss= 0.049674697, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25900, training loss= 0.06084584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26000, training loss= 0.07312889, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26100, training loss= 0.060065605, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.083841614, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.060627293, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26400, training loss= 0.04736125, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26500, training loss= 0.06549867, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26600, training loss= 0.07277383, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26700, training loss= 0.06027789, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26800, training loss= 0.064576186, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.049742438, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.09501008, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.054084595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27200, training loss= 0.051255554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.060317405, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27400, training loss= 0.098769054, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.041419145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.04756597, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.103079855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.048825603, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.031753566, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28000, training loss= 0.07751622, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.054443777, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.07658341, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.06537335, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28400, training loss= 0.040607106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28500, training loss= 0.05770576, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28600, training loss= 0.0465281, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.05263033, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.057818707, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.060804207, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.0681992, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.06293433, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.05637433, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.048832797, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.045036636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.05950966, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.055568524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29700, training loss= 0.05142994, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29800, training loss= 0.04541605, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29900, training loss= 0.05755655, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0799003, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.26575556, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.19981803, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.20848103, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.14083907, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.19132088, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.14816809, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.13016567, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.1797489, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.17278677, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.10451121, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.16788448, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.1512158, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.12839356, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.1476442, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.1582761, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.13803226, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.08236456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.11207226, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.11895755, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.1980514, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.09912895, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.106782675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.079122886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.15136507, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.11409798, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.13945147, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.13140112, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.09256793, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.087827586, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.17659666, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.12167741, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.118882835, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.116986886, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.09560223, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.14965114, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.077242434, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.11680536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.07584439, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.09881572, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.09972803, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.08517441, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.08217846, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.07348431, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.12835097, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.07273712, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.0941938, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.11859615, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.080018565, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.102031074, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.094238825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.078819364, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.069409795, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.107678056, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.12320311, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.09417794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.06853675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.12006454, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.1070868, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.0900363, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.084704764, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.074279815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.09824701, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.08689127, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.11575244, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.091671765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.042980038, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.09691149, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.11664438, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.082783476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.10854069, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.10336645, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.087318435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.09652111, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.0950811, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.09647623, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.077914, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.10861044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.10661789, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.08695425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.09253386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.15224355, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.10709542, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.06736534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.11037169, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.0841807, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.07020084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.12538615, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.13750303, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.12811749, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.09320484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.08713281, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.07979632, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.076963976, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.100150555, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.09329531, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.105495304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.07940933, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.09419842, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.07512102, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.12710574, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.05990201, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.08347818, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.07005365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.09464475, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.08784376, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.08916326, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.08048744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.08038065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.09666397, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.15515694, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.108128615, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.12719083, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.07690148, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.09850563, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.07965827, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.101484224, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.06456244, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.08808991, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.07781612, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.07412806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.06986283, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.08606012, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.07487771, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.049971152, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12500, training loss= 0.13156015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.112790965, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.08213355, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.07706919, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.063433684, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.08447832, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.08903396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.09712674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.106141105, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.077135734, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.1266484, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.10658529, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.07277295, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.07780233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.0718184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.07963055, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.087398835, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07625674, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.061538063, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.07571636, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.08619805, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.052448936, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.07878082, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.1031074, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.08533263, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.07821643, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.08765575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.09176353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.057817057, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.09010521, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.119444266, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.057751663, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.09258132, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.13144165, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.081195496, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.07917547, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.083499976, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.09208303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.07486184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.13033862, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.10248892, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.12189427, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.07482489, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.06892099, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.07729618, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.05631038, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.10895765, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.09289034, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.09440649, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.052796114, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.06375357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.06697021, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.1312336, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.06613269, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.06961681, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.098011546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.10010934, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.09548618, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.08338128, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.07551458, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.09724906, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.06340626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18700, training loss= 0.07357849, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.08523543, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.08751522, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.07168639, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.09290215, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.06841912, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.085874625, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.107226595, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.09438519, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.082457155, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.07735102, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.07689712, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.08292763, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07757488, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.07185627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.067198746, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.08025611, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.062460728, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.06962234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.07663311, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.08524293, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.07954137, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.09088885, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.06546045, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.07695469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.10266126, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.07406435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.0824403, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.077864386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.073206484, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.06607171, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.10852234, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.10576391, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.06869531, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.09685685, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.0924237, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.11191271, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.06450417, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.071012124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.10063975, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.067082584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.09430433, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.09077148, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.077341385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.09042697, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.08068214, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.14783536, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.08202104, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.042855397, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.08804686, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.06877053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.08829649, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.087531306, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.08911136, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.11549253, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.06559869, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.07195789, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.06605392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.09184751, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0789957, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.11597077, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.09759642, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.08324486, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.10912599, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.09211446, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.080876745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.06581074, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.07536892, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.10844964, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.13901743, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.078177944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.066057, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.064779684, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.074967556, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.07541406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.07790171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.08630999, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.092241116, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.058569163, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.0769587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.10531212, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.110626996, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.06917413, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.08834638, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.08846264, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.078830875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.10521751, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0879628, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.084732324, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.097408995, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.08198444, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.10152741, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.07227159, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.06071651, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.105397984, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.055322595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.08478936, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.10906083, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.10111292, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.07734408, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.08109986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.06846231, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.06306876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.053575225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.11926959, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.050971095, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.09503901, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.060115032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.049125634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.09865764, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.07710091, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.053658176, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.09885799, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.2678685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.36723268, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.23699732, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.36511216, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.22380038, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.34876958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.18574065, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.21366058, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.2107333, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.19289628, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.1402365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.18293433, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.21218215, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.15221027, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.10931039, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.15155263, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.11441417, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.15817587, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.122364305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.1245019, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.1092629, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.11417867, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.14748238, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.14466839, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.15830927, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.16537932, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.14309339, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.12888987, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.08808327, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.17507465, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.17789857, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.14031246, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.10598331, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.1966356, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.118168496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.15313967, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.115397, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.10797818, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.07648345, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.112418614, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.097240046, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.1817274, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.106514715, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.07894837, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.09913205, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.13327035, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.10421374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.13942258, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.1466865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.15259434, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.12125547, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.11805141, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.087800376, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.107049584, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.092785574, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.14405374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.087661445, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.10435381, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.12754796, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.08827198, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.093806185, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.11619248, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.15693271, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.12520115, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.15938017, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.097243905, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.079867944, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.08944322, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.115944706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.07113951, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.111134484, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.08031438, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.07408577, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.08023834, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.07868925, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.08267284, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.09379087, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.07644861, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.13942024, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.05116228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.10251248, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.10115204, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.13318545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.15717559, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.1347902, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.09815774, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.15683877, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.116505265, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.17424846, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.117378585, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.11257499, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.09612151, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.10713845, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.10822777, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.11397805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.12975131, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.1359823, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.11968473, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.062192496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.109582044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.055806536, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.104934655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.069010966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.07341487, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.08037802, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.12861581, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.09008341, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.12044239, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.12076167, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.1398545, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.09014821, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.085732244, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.09512513, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.086782694, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.043336555, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.13809054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.0562005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.06501995, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.09712656, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.07187002, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.06539108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.081592456, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.09693945, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.08741367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.06335971, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.099375606, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.057273448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.055974264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.10137766, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.069487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.064221315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.09959054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13200, training loss= 0.09466355, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.08474624, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.083045706, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13500, training loss= 0.082117364, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.0789692, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13700, training loss= 0.075517446, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.0703561, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.12297368, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.058513332, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.13016205, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07399701, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.09324441, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.066086344, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.123598054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.073084734, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.10516858, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.06227693, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.060389828, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.07313427, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.09079126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.11479034, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.08437174, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.05221277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.08665258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.05915472, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.046595573, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.07740099, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.11378636, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.098085664, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.1505107, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16200, training loss= 0.08585829, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.05028515, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.09877607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.07818916, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.057319593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.070364445, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.061078407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.05966853, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.09789264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.085138224, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.08097969, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.063155025, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.079238825, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.12289083, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.067205034, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.10193064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.067122504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.0885983, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.0578323, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.109281056, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.069571815, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.06740164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.066918835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.048550643, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.066411875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.042623293, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.058310833, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.09223398, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.14814276, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 0.09083279, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.09547914, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.0992414, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.06844338, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.08608658, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.121148586, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.047139917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.09125136, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.11306315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.10265483, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.06365857, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.11032283, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.07701318, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.046747312, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.073702626, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.05550629, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.09469729, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.10287564, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.071602166, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.085210286, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.0804949, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.07757036, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.09014805, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.11372185, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.10060444, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.07278402, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.08352845, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.069198154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.059680916, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22000, training loss= 0.09660644, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.06637384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.04288022, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.072235465, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.12399679, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.087899186, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.0634499, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.07186142, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.08285722, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.070595406, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.057990212, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.0634639, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.03902069, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.05136013, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.055752527, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.08162135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.078152895, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.06819766, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.077797845, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.07201533, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.08484433, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.07009969, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.07887049, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.052943576, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.07013126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.06739037, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.07600045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24700, training loss= 0.0519345, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.1280627, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24900, training loss= 0.10815015, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25000, training loss= 0.10276722, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.033355188, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25200, training loss= 0.10080463, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25300, training loss= 0.041888803, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25400, training loss= 0.062495448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.07652135, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.0406425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.08504779, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.05501728, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.108189486, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.07970647, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.06286429, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.06047917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.04778586, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.11621205, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.06679565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.06824132, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26700, training loss= 0.08767043, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.054454755, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.08582967, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.07448196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.06367918, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.049449842, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.06368696, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.0890277, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.07336378, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27600, training loss= 0.08689918, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27700, training loss= 0.07223197, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.06451671, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27900, training loss= 0.05839215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28000, training loss= 0.04932132, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.076790355, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.100980215, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.030245084, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.04765893, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.07574906, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.07640402, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.06138372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.050082166, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.07209943, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29000, training loss= 0.07610275, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29100, training loss= 0.06676429, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29200, training loss= 0.06646108, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.09930135, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.08751189, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.057063647, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29600, training loss= 0.099955425, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.06945608, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.067786865, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.092833094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.6094115, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.10544776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.22018407, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.18646324, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.26351953, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.16047199, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.29509887, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.19631246, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.15110205, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.16409871, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.13117932, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.17141254, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.13613251, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.1436574, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.1424493, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.1061793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.19917303, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.1549648, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.14229551, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.079548076, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.11718962, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.07515504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.16230837, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.13622677, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.12889914, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.11925819, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.108915664, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.10156854, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.066628605, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.10793761, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.13234787, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.09453744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.07879298, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.1266772, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.060194194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.12710127, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.071897656, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.1470863, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.08970751, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.09585653, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.078075126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09605522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.049642917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.13610362, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.12553096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.07945442, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.045533277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.06682462, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.088713996, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.07307733, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.115126245, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.12950005, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.13076764, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.1377569, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.09946426, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.08243515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.0737331, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.074878134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.061050665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.11583605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.080517, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.058493327, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.07389685, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.06404114, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.091140084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.054365933, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.08194684, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.094196275, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.14353456, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.0967432, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.09387016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.08926036, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.061141726, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.051840495, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.09208312, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.06128327, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.08719148, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.07770307, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.09232421, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.081474654, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.08593923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.08435424, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.120165266, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.1186031, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.09969787, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.04314655, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.037031367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.08179708, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.065936945, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.11412465, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.08355601, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.06196717, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.038908463, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.08699351, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.08524897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.08099868, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.076491214, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.060644824, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.07581419, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.061396837, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.069106735, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.07233816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.0739538, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.15715802, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.06906191, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.09770502, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.054471474, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.04551473, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.08546772, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.10885217, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.056039758, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.0677514, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.10347579, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.11200183, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.14966384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.074136436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.112295024, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.035276137, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.059434503, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.08325344, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.07894345, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.070401534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.07516352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.1056922, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.042878486, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.09317934, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.09118289, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.075857304, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.09655654, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.07519008, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.08568263, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.095598646, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.08802109, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.09886493, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.08809245, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.064992815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.072295606, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.099079385, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.14420691, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.04911084, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.07365566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.06685658, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.07916885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.1422231, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.084308386, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.06202485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.054216154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.06996479, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.04265323, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.08569792, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.040462386, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.10244824, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.057262983, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.07007599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.078324676, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.06398758, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.113873005, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.055908687, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.11497264, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.07937806, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.11355002, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.06123328, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.069695346, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.06453234, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.06205293, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.033573505, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.077483684, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.09114599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.09098961, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.07003742, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.04338953, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.073328055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.09448253, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.07286966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.08488503, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.06845091, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.093067765, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.099598765, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.110869184, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.068593115, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.066655636, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.117993556, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.072762854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.051607978, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.07688581, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.05917881, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.069200724, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.09415177, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.07697842, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.07644371, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.08952862, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.04483179, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.12820551, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.058381725, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.07860223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.09360018, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.04625043, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.0991801, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.096557945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.07248812, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.072359756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.099955566, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.05445391, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.060153443, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.075994805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.07872588, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.055484768, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.053955734, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.10457101, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.04566578, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.07612559, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.07345146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.07532695, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.08973422, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.04212776, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.078011654, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.048005488, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.04388383, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.0739724, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.05932919, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.0831961, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.072061874, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.038467064, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.072709136, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.08500101, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.059891827, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.050076377, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.06091374, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.05563673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.04564084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.041537564, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.052691843, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.09107526, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.06737327, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.06681648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.058403682, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.069548376, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.034212664, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.07633532, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.05727482, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.090196215, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.08139789, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.062232293, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.055515226, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.057095017, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.060420156, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.07434842, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.07440662, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.087189436, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.064259835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.08507858, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.071480356, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.07677429, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.06657898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.07869281, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.044486515, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.058701087, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.08237005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.054214675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.060939815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.062870614, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.099062264, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.07866825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.072784476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.09274355, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.06699291, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.08984562, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.05480839, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.073219955, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.05465119, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.042598184, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.06679709, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.077455185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.08471992, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0704996, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.060802292, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.057704713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.055748023, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.07510884, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.0568538, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.06808716, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.09423139, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.04866421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.0717087, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.051987845, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.072497375, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.059354126, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.06281891, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.06291004, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.07472111, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.053874116, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.080717206, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.07832443, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.06843773, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.095306836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.07056333, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.06279683, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.11180282, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.06940113, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.07336645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.4673004, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.31591168, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.33599946, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.30030268, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.17216966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.2538923, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.22893965, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.28299278, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.15621912, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.12512511, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.12602553, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.13357806, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.21081874, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.20270076, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.29007116, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.10724597, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.18477309, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.16805212, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.117188856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.2748592, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.13192171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.14015853, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.12199714, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.1742302, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.119872116, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.11439758, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.10801485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.09362494, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.18278307, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.09574939, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.14842641, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.09202598, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.16117026, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.12670863, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3400, training loss= 0.124839894, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.09348191, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.11250581, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.061549015, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.094262026, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.1373374, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.11700338, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.08977358, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.1507383, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.16771203, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.13231304, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.084177576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.121800005, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.1031542, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.07590848, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.16514829, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.07763431, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.078136496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.14791325, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.08320297, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.15116209, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.107752584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.16148293, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.04768228, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.15124582, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.16494755, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.08314457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.090342425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.06553122, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.086038336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.05140592, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.08454504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.075829685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.09707992, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.13424791, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.053487297, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.060255136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.10709222, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.11379407, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.091457024, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.098237365, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.10670555, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.116116986, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.10559264, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.14916465, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.09010266, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.061655357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.094158076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.06831123, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.118343726, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.11287334, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.07874724, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.12943871, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.09772353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.06363829, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.05778542, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.11174097, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.11553895, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.120433375, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.05714958, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 0.09452945, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.09562566, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.052109923, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.1024093, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.11143115, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.15413313, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.09574486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.10230648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.07418938, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.06280941, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.04532097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.13583449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.055685103, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.07689983, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.047381308, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.090178356, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.10785368, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.10196036, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.044276237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.084422015, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.083746925, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.066898584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.08986199, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.06815033, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.1124029, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.06248653, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.07556356, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.05742403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.090368204, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.08173187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.043304384, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.04845455, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.13419917, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.07842318, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.10558512, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.07522692, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13000, training loss= 0.081968315, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.11250393, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.06582286, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.08139603, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.100963436, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.07332446, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.07682393, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.116412744, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.069031455, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.08833127, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.061896466, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.06743411, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07508165, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.12123437, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.07164809, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.060493365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.084566385, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.09718607, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.12783283, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.063919924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.096671626, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.07307644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.07196405, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.076044016, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.05134908, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.06756741, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.060265422, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.07842262, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.06575483, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.09261563, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.07321114, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.10511645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.06935519, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.10071059, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.06571426, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.06537266, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.11059934, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.09067671, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.061520867, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.09431043, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.058809206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.06401123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.049436904, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.09694177, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.065386266, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.060691044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.055434223, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.07080125, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.061323687, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.109853536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.059839856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.071135834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.10544902, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.09611432, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.0610314, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.06899616, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.05827012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.06868991, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.06394422, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.06611103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.08889122, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.09870148, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.071133286, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.048700176, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.0728623, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.05958008, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.078051925, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.054840542, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.08075904, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.05525845, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.10284127, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.059005536, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.05646802, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.05692164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.07628682, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.05387343, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.05933275, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.088071935, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.079935245, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.061821394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.05017394, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.06880069, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.061483018, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.081455566, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.09290715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.06517704, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.0826983, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.067019, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.066508755, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.047754705, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.040536463, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.03866698, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.07417468, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.048038483, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.039592683, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.055265408, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.06631342, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.08483522, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.073324, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.07599796, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.09826892, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.05337905, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.047215216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.060897984, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.0681573, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.045920398, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.0659209, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.06552759, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.050679147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.06783799, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.05128803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.059574142, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.10117533, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.06215073, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.06982584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.07143116, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.07977916, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.046856783, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.07523121, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.06922274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.03449477, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.06736659, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.047396913, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.078980766, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.047687575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.071358666, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.0865293, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.057355624, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.07472804, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.09654292, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.07175049, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.08425074, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.0457334, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.03750486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.04853992, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.062697574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.072439715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.10620667, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.06277248, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.12825218, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.0904611, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.13132694, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.05979879, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.09468201, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.0715775, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.043106325, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.06558746, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.078601144, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.059847616, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.089880645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.091486, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.087244324, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.051886715, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.074305914, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.07980779, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.048192263, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.091207504, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.07066086, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.05691534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.06919384, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.040917728, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.10611706, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.0869942, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.055477004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.07173178, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.08030833, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.0803503, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.0643226, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.10224959, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.044406146, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9879438, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.29932967, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.18955517, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.1700235, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.20410562, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.25228807, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.24731806, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.26276484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.21266279, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.21889484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.11486944, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.22281429, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.16994774, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.1274473, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.1268689, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1500, training loss= 0.13418685, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1600, training loss= 0.075063966, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.1688576, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.09946373, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.16328336, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.119418465, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.11281742, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.083242126, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.10070195, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.12793308, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.09636372, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.08003186, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.068726115, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.13598129, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.06850943, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.17376375, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.046718795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.06679671, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.12411892, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.16063002, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.10326941, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.09307325, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.10606274, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.09576681, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.13668552, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.08650254, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09569686, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.09374992, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.11982824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.13413967, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.091296524, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.052287493, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.12556607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.10620367, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.09462497, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.087795645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.17491665, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.09849839, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.08246634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.054972365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.06548666, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.08151084, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.08005817, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.07589875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.08782336, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.12607446, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.077575386, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.08935197, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.11401128, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.0714958, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.091664225, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.11112045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.049696475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.08218739, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.0936974, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.11853032, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.063108824, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.09832379, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.12552445, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.06332276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.08373506, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.06822136, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.08361532, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.07617513, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.07833895, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.09402059, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.10368708, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.06915766, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.12536426, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.10104819, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.034518816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.08999135, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.05692435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.061879784, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.07204029, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.099731885, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.11491856, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.07339568, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.09812248, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.078569375, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.11748795, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.094038785, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.09409367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.07381193, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.080162026, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.064209856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.085230336, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.09812663, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.08608198, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.07746771, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.07121497, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.07436098, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.06496872, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.08853348, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.037481394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.049283043, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.08892422, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.07832362, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.087129116, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.11644648, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.10033427, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.05188992, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.06072349, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.074836075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.09918388, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.09057967, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.049530044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.047240723, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.051196523, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.09542473, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.060826596, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.12616295, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.093421474, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.08764996, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.042583063, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.09306207, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.04557531, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.13983774, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.052656636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.06536643, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.06605491, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.08120472, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.057930548, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.07121783, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.069917865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.08734475, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.08488114, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.06973562, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.0820622, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.080513164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.10973263, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.048430618, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.068049, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.09406376, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.053957596, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.07731661, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.05073891, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.061099146, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.058452852, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.06601663, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.043782808, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.070680395, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.047529124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.06347868, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.09875025, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.060086153, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.087601066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.026722124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.063907586, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.04306437, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.06155149, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.05507549, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.11356254, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.06280856, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.04465274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.06925525, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.076064534, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.09480719, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.048154287, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.056524727, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.05097649, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.04548354, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.06338218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.061035387, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.04922316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.09167285, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.07691665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.046856206, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.052532904, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.058720566, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.07896224, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.071015745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.06509893, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.06766764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.080145486, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.08065401, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.06306456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.06946607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.083985135, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.0858859, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.08995452, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.06173189, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.055432975, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.087900564, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.056571856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.07752841, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.052320193, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.06457053, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.052221093, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.067111775, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.057700932, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.061627276, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.043558594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.059852097, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.08252138, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.044469073, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.060520317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.07142911, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.056806035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.038887475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.055445753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.05203916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.10230574, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.045108818, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.07345937, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.055165615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.07946289, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.061791167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.062200613, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.053120315, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.04894512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.045848485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.06958108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.11589025, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.0463458, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.05742932, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.046247616, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.070310175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.03574582, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.05569174, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.0829703, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.0689915, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.05469185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.06714183, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.046393808, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.03751127, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.051895283, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.07133104, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.04227856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.061934546, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.07285169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.059705786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.044375595, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.05852382, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.045057215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.053409006, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.05357316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.07518856, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.083792225, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.063817464, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.051782787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.076029316, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.08355516, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.049824975, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.069836274, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.07212231, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.07976613, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.07248654, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.05508615, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.06056959, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.05947463, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.08112092, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.053228553, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.049804296, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.056063373, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.0570127, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.072302416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.06225291, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.05123941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.057412293, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.06486818, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.06770861, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.050428778, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.06901907, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.050463937, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.061439, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.06522156, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.06434561, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.047758173, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.06448678, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.07945573, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.1052065, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.06412127, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.064848155, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.036609203, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.05149019, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.08161569, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.057701234, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.047545478, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.058831133, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.073264554, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.05446381, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.051904246, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.05460748, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.049487524, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.515049, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.36126077, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.22694433, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.19602269, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.19712144, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.09778253, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.18156758, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.16315109, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.23048195, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 900, training loss= 0.20340917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1000, training loss= 0.12345757, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.12029523, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1200, training loss= 0.275794, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1300, training loss= 0.14648366, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.097605385, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.19105074, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.13284032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.097990975, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.10700237, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.16699217, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.09966941, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.10938521, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.11050132, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.13861793, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.08961373, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.08728139, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.14589457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.08909748, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.09220656, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.1306666, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.08449921, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.111366, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.12140249, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.09900849, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.1613584, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.11322507, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.107532024, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.06758711, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.10739555, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.09532408, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4000, training loss= 0.0998572, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.074130796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4200, training loss= 0.091666155, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.077205986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.06235553, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.088879794, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.063493304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.070298575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.12801388, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.05742003, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.081760526, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.14244618, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.06601953, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.0639775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5400, training loss= 0.14962122, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.12558602, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.09763574, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.107607976, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.10491654, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.078334086, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.042123515, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.09759602, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.107725516, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.084338434, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.09927166, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.088632755, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.0953472, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.09710124, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.0777265, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.08590091, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.07322327, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.0869328, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.09937415, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.045707203, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.072808795, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.093519196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.13764171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.11472084, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.03205964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.052223247, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.09958797, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.07292452, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.06994442, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.09177342, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.060967404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.05493218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.11375553, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.054579813, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.0740749, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.09125247, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.07349854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.070019916, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.11241767, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.051533982, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 0.08823572, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.10859073, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.12278523, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.09869876, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.10557338, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.07796642, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.122365065, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.058273766, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.07415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.05468318, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.06487128, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.037041396, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.062066983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.056127343, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.075249985, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.0831266, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.07053287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.08698707, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.088284485, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.107826054, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.054174438, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.070244014, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.030690324, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.08868118, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.053871874, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.086123325, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.08886763, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.09513145, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.07782851, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.060067013, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.08930992, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.116271526, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.07719997, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.10937904, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.065513186, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.0555929, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.07894269, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.06339447, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13200, training loss= 0.08367106, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.065878265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.047454692, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13500, training loss= 0.095289655, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.10024391, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.06206847, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.08927785, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.08948458, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.06490836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.08343916, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07029045, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.08214944, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.07955318, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.060171437, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.07677428, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.06837824, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.0815403, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.0753603, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.054507505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.0987836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.08686068, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.0459833, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.05013971, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.085729785, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.0887951, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.07857236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.059395023, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.05774323, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.090800956, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.067815624, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.123308726, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.08863533, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.07610606, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.0695657, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.041493047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.0948685, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.05019739, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.097490706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.037896805, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.041543663, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17200, training loss= 0.08109852, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.051386636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.08402516, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.07351969, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.08942043, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.07201074, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.043718148, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.10303827, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.08543191, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.065380074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.0920215, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.06794176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.06790256, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.078849934, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.052584615, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.08361643, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.056020275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.09375086, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.10841838, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.06477528, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.046004824, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.064481035, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.1004868, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.09051157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.069082305, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.14103958, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.084109776, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.08586891, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.05808143, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.0818054, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.06265145, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.08067312, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.034874287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.04408448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.04462517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.055996828, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.05398299, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.0681976, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.058332723, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.06276168, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.09487574, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.06497587, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.08038385, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.080152236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.085415505, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.072212666, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.054437708, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.05564175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.072587006, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.08615812, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.04021672, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.06770805, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.034300126, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.06121339, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.0517331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.03918492, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.072259605, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.11050601, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.053005002, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.06753801, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.066793196, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.03923671, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.06940938, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.05778934, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.048128728, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.07093555, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.069331974, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.06510663, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.08940641, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.045688454, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.052869417, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.074095726, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.054320496, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.054344855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0685325, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.07713729, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.06019162, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.08230858, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.036620803, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.047097083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.11093658, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.038073458, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.07196113, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.09161284, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.06387744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.06998101, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.051711433, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.07358699, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.0592064, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.056967102, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.05911342, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.07478486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.046526473, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.07738273, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.049567204, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.07663196, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.047885545, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.0476054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.055704318, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.07675265, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.063103765, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.074875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.073395185, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.052964285, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.050345544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.031921953, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.07579251, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.0482099, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.039751403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.07784835, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.053292435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.047633365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.063603394, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.111100875, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.059409603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.060058687, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.06505002, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.076064765, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.07295072, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.09780727, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.06417804, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.08255719, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.07745395, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.052595038, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.04939906, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.04732513, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.053370394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.053043135, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.08157348632812 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7870776, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.26114258, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.26835692, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.084229566, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.2050871, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.16215967, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 600, training loss= 0.11368775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.18969668, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.14957254, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.0938017, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.08266727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.09864727, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.102997124, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.18629315, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.0865067, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.14117274, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.1519712, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.1250536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.11266239, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.1484979, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.15481472, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.087994374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.17101252, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.12539731, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.11409228, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.071110904, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.11577642, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.14753795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.07571572, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.13085942, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.08169444, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.13822249, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.07191891, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.10981281, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3400, training loss= 0.1059041, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.11278921, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.1153867, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.13044035, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.109879665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.0844382, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.078258336, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.17363298, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.062465705, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.13238217, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.10085904, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.15481392, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.112812415, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.07324817, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.110427044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.118273236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.095532976, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.12634416, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.09159449, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.09543533, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.08317415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.10851617, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.12544554, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.09905577, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.09318253, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.11334421, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.08465244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.11895984, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.11576708, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.1317892, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.10187242, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.114834204, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.08216866, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.078262836, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.087585986, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.060284134, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.07079939, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.0548381, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.088275395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.124408595, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.07235489, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.0793544, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.09372362, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.13773997, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.107221894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.15677436, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.09940101, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.12617788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.12722571, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.066362165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.09225839, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.14893639, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.07655289, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.07121835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.10787773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.091042124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.08046807, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.08927152, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.111834966, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.094646655, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.11291518, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.12680706, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.11317261, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.068953566, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.07084155, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.078543745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.09553331, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.08800858, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.11084807, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.057224233, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.079521954, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.09909729, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.04242605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.12879775, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.097566426, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.069654904, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.06754037, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.092183314, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.08652856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.07929442, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.056164242, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.062840395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.07013598, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.10795765, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.08720922, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.09396755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.08502003, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.07450135, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.08787959, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.11606771, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.105499946, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.111447416, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.08563132, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.10513791, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.101660125, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.09320634, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.084461525, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.060542356, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.09817684, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.06931182, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.066754796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.08530992, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.09109015, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.10466888, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.07421028, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.06308059, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.069302075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.08364107, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.06025898, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.09860558, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.12800293, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.12355554, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.08611628, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.06258369, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.060925763, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.13793689, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.0627347, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.06543716, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.06713097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.072713934, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.091479294, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.070622854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.07962034, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.079225995, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.10227144, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.06413581, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.08309044, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.12715043, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.088336624, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.08780421, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.067901574, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.07119786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.06738553, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.09421217, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.055173036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.091291554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.065523244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.10289865, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.111043386, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.065371715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.110914245, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.0917659, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.07109149, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.06082778, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.07293628, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.07751358, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.058725756, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.08239484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.08444395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.07592105, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08124935, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.0996587, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.057771444, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.078415394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.049872633, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.09525258, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.100716494, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.08339019, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.1143023, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.078570545, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.08016354, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.09701249, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.0783258, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.061218478, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.048778493, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.09296157, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.11476054, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.07292038, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.11467326, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.10916805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.11302892, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.06317177, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.073170625, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.063966, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.086783804, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.08259449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.071417145, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.064733565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.062612884, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.09739329, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.06789606, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.080357246, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.06696939, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.07478974, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.108662345, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.08314251, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.10815971, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.06648796, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.11119237, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.07496359, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.07033575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.07386569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.086912856, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.07569902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.101865485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.13039719, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.07314538, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.08017251, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.09856105, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23300, training loss= 0.078803204, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.099514656, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23500, training loss= 0.061116006, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.0714839, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.075523786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.06970054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.06598789, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.08741682, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.060950335, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.0773371, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.06528904, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.07658552, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.07193147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.07434443, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24700, training loss= 0.11042117, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24800, training loss= 0.09517654, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.075710565, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.099330164, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.09189993, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.064012505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.08705474, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25400, training loss= 0.0674489, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.09574056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.12267567, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.052440267, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.097362235, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.097354345, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.049860932, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.065196656, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.05486619, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.11036759, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.07926922, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26500, training loss= 0.10529127, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26600, training loss= 0.08626825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.08604939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.07099284, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.06495384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.059893157, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.086727284, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.08744486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.062168777, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.08730174, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.06894288, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.08745386, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.11502977, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27800, training loss= 0.08240787, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.103137985, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.109481834, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.07064822, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.10963161, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.070507534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.08587642, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.0821247, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.1016191, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.081224866, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.056185026, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.12575075, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.10123122, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.06676233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.1209839, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.07789667, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.07568692, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.06740286, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.087865956, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.07599139, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.08103462, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.059531488, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.158017, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.2840752, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.2555632, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.27510983, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.18872921, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.2574191, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 600, training loss= 0.3513794, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.15682434, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.2736183, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.1737486, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.16368522, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.105626695, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.18605821, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.13570192, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.18973765, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.20171902, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.09387106, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.10764134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.16227861, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.14039883, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.18277967, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.113870196, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.1363894, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.18067472, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2400, training loss= 0.083587706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2500, training loss= 0.1322106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.10270723, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.21283364, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.14401637, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.14827594, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.19808343, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.11301806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.14334178, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.04685323, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.1351797, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.100686535, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.12220965, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.090338305, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.08962232, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.16919741, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.10068979, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.12280142, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.13564742, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.115678094, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.110375606, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.15546408, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.20264207, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.13953672, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.15156502, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.11804821, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.14911425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.113556266, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.08438751, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.1595966, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.096676394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.093226224, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.10759525, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.08861892, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.08516063, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.10044145, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.14011998, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.076189354, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.09965412, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.073505156, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.08487599, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.114624366, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.18303601, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.12825124, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.15574813, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.12114557, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.05773493, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.13607094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.11807772, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.05414135, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.09096312, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.11110296, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.12517077, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.102727085, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.13289927, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.15603969, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.089326225, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.0824537, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.14019619, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.09328884, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.14769658, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.110387415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.09784489, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.1265991, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.12214978, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.09677343, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.07793413, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.120508194, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.1301163, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.08167865, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.06793071, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.09925129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.06246788, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.11059727, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.07564623, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.10737543, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.06530106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.09554109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.13910547, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.079979494, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.11439782, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.06791528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.04793973, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.08217438, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.10046674, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.12253239, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.1077041, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.10651496, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.1094874, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.09895634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.10124632, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.09527012, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.08523395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.14843498, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.110361695, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.07107867, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.085379854, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.085294515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.09258883, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.058766782, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.12952183, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.10010504, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.10403423, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.0991566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.05810003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.09041386, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.08777137, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.13290595, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.09839873, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.09363767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.107214436, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.11228921, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.0738193, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.0898239, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.04032481, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.13905147, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.06241502, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.100882754, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.12323557, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.0818021, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.08886567, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.08804603, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.049628045, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.067903005, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.11786231, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.09780891, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.08530925, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.06622167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.09130534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.08305432, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.07077131, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.1430081, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.07451145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.066912435, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.061959386, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.12183755, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.05139585, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.08913657, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.11005049, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.073683515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.13054924, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.071102, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.086362526, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.13936335, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.06339278, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.055251263, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.07411247, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.09957095, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.06507196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.099038355, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.0789987, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.059101455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.08388686, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07452729, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.060308002, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.086871676, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.08561229, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.12335953, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.06477402, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.06882926, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.10164598, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.072318725, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.066115834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.112803385, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.07291247, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.07754487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.057201855, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.07271325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.08463307, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.06919356, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.060908005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.07694535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.12436389, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.079251975, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.07517664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.06222824, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.124464005, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.105271086, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.07135903, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.053318884, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.09776096, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.078707814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.09401083, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.10010626, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.06496676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.083419815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.054998472, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.10698702, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.09288816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.07731601, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.048508804, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.084905386, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.064083755, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.08333762, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21800, training loss= 0.09451376, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.07256849, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.07417403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.03405561, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22200, training loss= 0.06827544, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22300, training loss= 0.07229872, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.11614792, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22500, training loss= 0.052137226, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.09231645, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.099357985, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.07863592, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.079853974, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.088594876, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.113044254, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.053690217, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.081561334, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.07596135, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.04564941, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.09497743, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.07611266, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.076326, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.121356726, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.06755738, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.044560112, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.1261791, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.072008274, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.098377034, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.10702827, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.07200944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.09466612, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.06499511, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.07153054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.05983537, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.09387487, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.05390931, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.060148682, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.09313092, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.07437637, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.08914678, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.09045728, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.09875308, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25900, training loss= 0.063931495, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.055595856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.055230163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26200, training loss= 0.065962225, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.04664501, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.057631485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.052898236, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.06160067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.11009568, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.09287134, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26900, training loss= 0.088126734, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27000, training loss= 0.09084964, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.07350588, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.086226724, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.08588707, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.07904737, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.086206615, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.10225733, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.069310844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.08738967, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.059808105, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.08537075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.11579706, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.095994145, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.06484307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.07632133, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28500, training loss= 0.07226311, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28600, training loss= 0.075331725, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28700, training loss= 0.0908375, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28800, training loss= 0.059724804, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.07503623, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29000, training loss= 0.10988968, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29100, training loss= 0.0746274, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29200, training loss= 0.09491733, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.067526124, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.07405024, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29500, training loss= 0.08089732, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29600, training loss= 0.062441736, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29700, training loss= 0.07103875, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.05469492, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.043996423, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.2852201, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.27477598, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.1986383, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.1896073, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.21522686, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.1941736, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.15549807, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.103192806, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.12322274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.18169326, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.111451894, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.11303123, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.109279566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.14519824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.1531688, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.17891358, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.08343151, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.10897668, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.130679, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.07679639, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.14809585, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.15331988, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.10283675, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.117495164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.08092798, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.07735872, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.118751824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.11002819, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.12849279, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.12804233, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.1448671, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.0723664, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.117761485, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.07318585, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.1018176, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.100483656, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.14633304, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.15710217, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.11944947, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.09165748, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.15415826, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.08316013, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.11920055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.13636456, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.08314918, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.08966388, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.06856659, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.10225957, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07169462, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.03639413, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.09588527, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.08818744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.14556889, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.05527082, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.09667133, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.10424747, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.06414813, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.11505279, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.09528853, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.079483375, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.08289251, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.10151446, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.1108286, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.113236174, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.1051695, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.08209902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.060558364, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.079145834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.07826255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.08622153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.0894098, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.12494465, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.14594132, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.12850937, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.1112445, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.06617871, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.08953863, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.08210128, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.07231957, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.10802327, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.08680989, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.09927909, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.1439471, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.07759941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.11244866, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.10527128, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.080390505, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.10639082, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.072083406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.096923575, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.10667865, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.11009103, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.067957856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.0825482, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.072982326, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.10494935, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.058834475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.13513209, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.05441843, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.09361728, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.13703744, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.12095665, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.10832872, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.1015507, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.109074, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.08795514, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.07253249, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.1082084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.08087997, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.103418075, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.07042975, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.103658125, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.085156366, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.11246138, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.059482306, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.09230866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.085835814, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.071639925, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.08760276, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.08086207, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.084219486, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.09881266, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.072592914, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.1091374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.07370422, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12500, training loss= 0.07828538, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.085014805, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.05986203, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12800, training loss= 0.078811616, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12900, training loss= 0.08174795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13000, training loss= 0.059745185, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.072162084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13200, training loss= 0.07280944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.062169544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.08774394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.06699476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.05248047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.06665504, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.07038127, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.08719808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.073032185, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.062718704, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.091055386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.102187514, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.07445939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.09683412, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.06536888, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.071723655, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.08157035, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.111250624, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.07372433, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.060990483, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.075465865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.07976465, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.0817935, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.070219524, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.110712335, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.0703989, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.060118835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.06564402, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.101776406, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.08001737, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.10562658, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.0813261, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.06317361, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.054410778, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.09228188, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.082885146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.09415858, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.07964884, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.12024157, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.09131394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.13410106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.05715534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.0891287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.06972319, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.082193986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.06054325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.077846825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.08367326, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.05168757, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.10909437, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.12209054, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.123087525, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08013382, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.07721629, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.09920493, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.053690694, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.07163022, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.07194227, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.06982629, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.09032284, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.057183664, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.11470471, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.06569758, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.05573986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.09087785, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.08965109, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.089948654, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.08249046, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07481247, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.041098308, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.08084681, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.12870358, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.05792139, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.06602305, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.05714942, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.07652414, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.049827702, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.08644857, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.10634195, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.0976485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.08414321, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.0642817, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.08714687, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21500, training loss= 0.07933976, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.06723237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.08656027, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.14298649, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.07171427, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.08403787, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.08021346, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22200, training loss= 0.079906255, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.06775761, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.042639233, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.059987016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.06883543, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22700, training loss= 0.10749625, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.089999706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.06253444, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.07305481, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.085278414, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.071434736, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.07570907, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.08910638, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.12857372, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.08870476, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.08092553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.05550047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.059004337, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.07501024, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.060466345, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.06051242, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.114064954, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.062481478, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.09602412, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.06908492, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.07043487, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.07501307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.12888028, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.04006254, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.08944325, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.09831275, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.1253237, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.08021526, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.08237784, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.05310991, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.049947813, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.09844422, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.054849975, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.054017797, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.078493565, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.06121698, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.069063455, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.10405916, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.08056013, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.12466651, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.056367304, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.060735114, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.05351074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.07771467, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.06320402, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.06278646, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.059864193, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.054094806, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.060002267, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.07046951, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.08237257, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.08997208, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.035620674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.08565035, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.080741525, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.099688075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.0809417, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.10041979, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.10158797, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.09007709, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.086612925, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.06691611, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.07297423, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.082861364, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.059717488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.084926486, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.1109523, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.05406598, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.08072336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.09379914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.086795494, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.099467084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.06445445, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.6135507, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.28546375, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.15907021, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.22815868, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.42611554, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.143871, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.16417646, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.1972347, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.18047772, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.1716694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.15922675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.12020561, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.1662254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.16994368, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.27789497, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.14821166, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.16068885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.1698204, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.11220435, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.18997608, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.12167426, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.19031337, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.19566165, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.0850788, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.16527064, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.07405028, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.120049536, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.13574782, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.15020071, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.13073654, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.15322883, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.14225264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.11461737, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.23624575, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.079713345, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.08525069, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.09093501, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.14397316, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.12967983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.066297345, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.10361881, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09505476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.13467005, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.14885218, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.090159945, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.1330213, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.16010502, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.08453324, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.09113166, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.093531154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.08875098, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.099219486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.14833747, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.1024492, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.09824415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.13108408, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.09137651, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.12928852, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.11449542, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.14000344, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.07753997, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.12368132, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.13003792, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.073317125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.15143764, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.062163234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.07967251, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.10716595, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.11626793, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.11206547, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.111530684, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.11270036, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.08744102, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.15022956, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.077425465, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.0824368, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.1335036, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.11320074, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.08959357, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.037193313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.14653513, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.09659824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.14212394, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.06363216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.09808902, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.14299141, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.091244094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.1272077, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.09210522, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.07512512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.08449834, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.061599568, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.07558296, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.042321607, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.09029081, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.13776405, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.07578695, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.11960444, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.10179146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.14915264, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.08024935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.10115667, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.11469308, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.112796694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.1229961, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.14466356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.09531985, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.09208535, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.069184594, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.10433833, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.09568564, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.08310046, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.095590636, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.12561327, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.0764319, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.056258038, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.09871809, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.07584492, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.1103021, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.08285538, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.06238682, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.08450726, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.08066866, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.07070535, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.12659039, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.097336225, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.07736674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.06409285, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.0954512, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.096238166, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.1207957, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.06998767, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.091440454, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.07842238, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.09117113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.09442507, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.066746466, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.10858101, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.06401471, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.09604206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.11719838, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.118428186, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.09742857, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.0600218, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.09274875, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.081659675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.07703528, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.084819704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.08217797, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.098551765, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.1124319, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.12090474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.07842507, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.08208892, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.050549354, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.08079703, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.10552661, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.048818704, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.13425018, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.09381487, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.08423208, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.110506065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.0673216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.066835, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.08510248, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.10058359, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.13328741, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.07751973, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.056018874, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.08354648, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.095320754, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.100203946, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.04525561, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.10375636, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.07187128, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.05570372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.09079414, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.07290646, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17800, training loss= 0.05863955, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.08956946, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.053629328, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.08380588, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.057200383, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.08260904, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.07094234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.094634846, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.094934605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18700, training loss= 0.06363324, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.0742914, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.059251346, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.09295925, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.05365724, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.09259347, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.07439038, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.10478439, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19500, training loss= 0.10290852, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.083414525, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.07773998, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.07170536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.09931735, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.06595301, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.0862209, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.09667324, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.073248245, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.057216603, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.059394486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.08403852, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.079501346, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.082226194, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.06776144, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.121488646, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.05323557, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.06528502, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.06383752, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.09724523, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.085665025, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.09887976, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.086558774, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.121660374, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.07781172, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.04603573, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.1021601, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.06865879, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.07798681, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.097441934, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.11463133, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.04755888, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.09706625, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.06720807, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.07838058, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.12850547, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.05156312, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.0967683, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.1000212, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.07105939, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.078589395, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.05592655, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.105595164, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.062287323, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.09426845, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.051419117, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.08022824, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.07461628, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.10427689, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.09173498, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.07911275, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.07995009, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.06277043, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.0570518, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.100234956, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.083719514, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.04230603, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.08010243, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.07731507, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.09419862, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.06544067, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.059514243, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.07515345, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.06428802, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.06528287, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.078191504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.07341065, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.06875535, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.03516876, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.06605572, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.079927005, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.03942529, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.076552555, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.07013579, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.11495002, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.06997191, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.09939908, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.0734339, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.076618135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.07036495, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.06632029, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.06157872, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.066217475, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.055139296, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.05473991, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.046483774, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.08647647, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.07265164, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.07688425, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.06255689, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.03929146, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.0744704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.1093717, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.07314793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.09996804, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.044037465, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.10090347, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.06605272, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.07282928, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.07141604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.04909436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.06894021, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.067530446, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.06565458, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.06416331, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.35142, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.2560321, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.2395348, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.26324478, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.14352614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.12159403, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.23858292, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.21305683, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.16255336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.15219359, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1000, training loss= 0.12830123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.12289168, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.15888679, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.11473428, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.103445224, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.12887733, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.12320122, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.14589402, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.08867555, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.13114354, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.13212042, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.11801827, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.12546775, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.07661833, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.09738722, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.14906496, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.17628048, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.108463645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.075908065, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.04962301, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.13872801, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.09544788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.07489017, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.08265606, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.16621049, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.088028714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.11424646, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.10565705, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.11562714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.11608865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.08665941, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.07601379, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.06997224, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.12684569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.070561096, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.11820254, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.0882841, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.08080963, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07624342, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.07835094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.06308511, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.116757974, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.08353779, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.071390145, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.12815881, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.07088574, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.09351747, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.09095206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.07165877, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.07754926, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.09600882, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.08683923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.055618614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.12845698, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.101984896, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.09902842, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.11002859, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.07447372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.10142533, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.056855716, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.09936431, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.10234819, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.074907206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.08048105, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.077062525, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.09239548, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.123687275, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.08532267, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.08899715, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.110377334, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.10131666, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.0758123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.06987283, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.08901373, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.06514724, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.07018473, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.100747064, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.097966604, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.080016874, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.09453613, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.067626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.10742949, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.10489551, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.071118675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.08466937, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.080507115, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.058358204, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.1394568, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.089099206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.054413863, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.080462836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.06584213, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.07440213, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.068900466, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.08609113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.04443846, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.049865052, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.06573507, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.067149244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.051542327, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.059406105, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.09377314, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.11357376, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.0752183, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.0625423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.058483962, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.08170571, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.065304905, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.06890938, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.1396394, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.06622186, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.09623281, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.07396768, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.08382503, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.111959, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.07963079, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.08775058, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.079840355, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.0754657, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.07884984, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.118734136, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.06439753, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.08712064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.05695094, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.05114824, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.082040384, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.060218923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.086438075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.07460578, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.110435285, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.07282036, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.08562766, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.06286175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.062486872, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.1209327, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.10702737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.10555181, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.060935654, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.07055015, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.04952047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.08031705, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.07109013, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.08615648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.08392666, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.07453331, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.14322278, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.07656004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.05433161, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.07431827, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.061540112, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.06546256, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.04560166, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.09484508, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.0866277, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.07498081, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.07123392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.069609925, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.07663932, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.05446779, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.09713222, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.058026556, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.066598825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.07840142, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.043495025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.09228603, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.083408006, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.055691782, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.09471468, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.0458501, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.09430733, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.0595042, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.06512302, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.08136465, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.05404191, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.0792328, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.046848394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.0791986, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.056333877, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.08583704, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.045021664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.080133244, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.10473733, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.06642108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.070723124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.07268572, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.09341465, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.051489916, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.088696145, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.03724863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.087017335, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.088340335, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.06703262, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.0764658, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.08956574, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.092815556, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.069475494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.09123994, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.070451714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.06869583, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.08641689, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.0446268, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.047774874, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.045858417, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.100300945, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.08302866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.048758406, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.072264686, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.05724393, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.061931167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.098510966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.08175726, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.07147395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.061231665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.056350835, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.0822498, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.0444797, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.058922082, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.108083695, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.09138794, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.06955166, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.10861118, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.050187603, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.07796238, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.067288786, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.0730475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.06860213, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.08299177, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.082636, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.046254907, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.07736337, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.07149758, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.085545905, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.06824352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.06522141, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.059181314, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.05600949, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.059872877, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.082928695, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.051526908, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.09621988, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.058802787, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.050823417, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.05950291, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.055795077, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.08899091, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.07616064, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.07005348, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.07075189, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.07106284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.062323228, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.06341469, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.06068794, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.07299587, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.060676046, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.08062816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.068078555, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.06973155, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.06344081, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.044368424, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.042152032, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.050858364, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.094413295, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.049587183, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.06457506, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.063307196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.08995183, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.12148136, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.05659037, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.049750015, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.059618406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.07101107, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.10472209, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.07784411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.08567705, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.07049757, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.074727505, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.06600985, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.08134802, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.057546176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.08407501, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.06644245, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.07647017, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.04366239, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.064554274, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.03848391, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.07232605, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.0852243, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.06817929, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.03584943, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.04872108, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3391647, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.22034019, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.28774437, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.41875446, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.2197108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.2160888, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.2383812, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.09272513, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.20505844, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.27768636, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.19875477, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.16709448, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.21796992, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.12366888, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.13227718, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.18588942, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.111810215, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.18515876, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.08322786, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.2115282, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.1508871, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.09251824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.16533743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.16143665, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.17690943, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.155609, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.17682943, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.17113987, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.15510029, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.11380904, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.1908062, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.113693595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.12340698, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.08378807, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.08548524, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.14217846, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.12584923, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.11282505, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.16404809, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.14136705, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4000, training loss= 0.09784837, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.123629645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.10147424, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.056660816, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.115217745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.07328855, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.10608651, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.10983473, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.1219946, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.06225207, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.11428797, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.10075806, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.16316257, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.06431519, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.08253434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.13510151, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.08823794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.070244744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.077508956, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.052775174, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.14786491, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.06102233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.07510523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.091747686, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.07238945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.06739804, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.11157633, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.10598251, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.089112595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.0988487, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.10931217, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.12069796, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.04087294, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.08104602, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.109071344, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.06278898, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.08829413, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.17067322, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.06915107, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.15954578, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.08762425, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.10903393, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.052993834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.094943054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.06442428, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.07940515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.07951914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.072453186, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.050515637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.08922627, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.10063541, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.09281435, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.08070922, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.11198254, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.11381295, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.08193797, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.075729474, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.09946311, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.08732017, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.09268524, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.059262823, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.105633505, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.0863904, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.111156955, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.08296795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.09475869, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.04749862, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.07741466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.11523206, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.09139775, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.08395953, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.08904901, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.055242356, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.10796983, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.1291304, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.09021739, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.08598224, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.08829849, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.06286011, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.05994909, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.10866493, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.07872939, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.09343528, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.09270102, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.05719911, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.11222779, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.06776702, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.06476413, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12800, training loss= 0.063985564, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12900, training loss= 0.0700799, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13000, training loss= 0.084510945, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.07927158, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13200, training loss= 0.06939987, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.06673114, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.107128434, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13500, training loss= 0.05406811, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.073363885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13700, training loss= 0.041720234, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.09377233, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.10077392, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.12281316, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.055793982, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.061922587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14300, training loss= 0.08037388, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.04836025, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.07727068, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.0856265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.07391161, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.12777038, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.054146446, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.046966076, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.05866775, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.08006984, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.09617151, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.11342656, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.059603572, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.094586104, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.051603295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.0778325, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.06337908, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.080542125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.083581485, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.10964539, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.065408394, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.070548125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.14972639, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.054152273, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.06470068, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.10166817, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.05508066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.0898356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.089801, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.06258448, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.10856849, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.05893704, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.057323035, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.07648378, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.09553288, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.12315816, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.0652065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.055675443, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.054308653, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.07025657, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.049629785, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08752311, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.045048334, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.07279574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.069830075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.07392767, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.086674295, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.120893545, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.095482334, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.08167978, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.08444487, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.06954493, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.09107377, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.07838898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.098753646, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.078791544, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.054773957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07512111, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.09001762, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.09794303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.0423496, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.08049126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.0648285, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.11488952, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.113338664, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.0643726, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.08873914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.08879307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.043524235, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.07125572, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.05715978, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.045583934, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.08640317, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.059278786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.06358673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.07315093, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21900, training loss= 0.052046664, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22000, training loss= 0.10762557, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.076451175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22200, training loss= 0.037849344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22300, training loss= 0.051379878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.08680477, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22500, training loss= 0.04323762, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22600, training loss= 0.047407087, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22700, training loss= 0.07575613, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.06648125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22900, training loss= 0.052131128, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.08566364, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.05836936, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.06911321, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.057959646, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23400, training loss= 0.056465298, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23500, training loss= 0.07440758, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23600, training loss= 0.06460267, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23700, training loss= 0.05763112, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23800, training loss= 0.06688798, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23900, training loss= 0.09082387, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24000, training loss= 0.102223076, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.061946798, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24200, training loss= 0.05173171, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.07858275, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24400, training loss= 0.057518713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24500, training loss= 0.07100479, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.035732556, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24700, training loss= 0.06846688, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24800, training loss= 0.07126931, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24900, training loss= 0.09408734, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25000, training loss= 0.07173926, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.06926938, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25200, training loss= 0.10370595, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25300, training loss= 0.054904185, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25400, training loss= 0.060190674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25500, training loss= 0.07857229, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25600, training loss= 0.063677, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25700, training loss= 0.05646132, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25800, training loss= 0.056215085, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25900, training loss= 0.050833434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26000, training loss= 0.05432462, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26100, training loss= 0.050479792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26200, training loss= 0.05886473, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.030154223, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26400, training loss= 0.09125614, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26500, training loss= 0.0951162, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26600, training loss= 0.03522609, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26700, training loss= 0.08572575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26800, training loss= 0.049925413, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26900, training loss= 0.06891775, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27000, training loss= 0.055094823, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27100, training loss= 0.05481352, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27200, training loss= 0.06784019, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27300, training loss= 0.07648337, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27400, training loss= 0.07297811, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.04772454, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27600, training loss= 0.044180624, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27700, training loss= 0.045987464, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27800, training loss= 0.07410576, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27900, training loss= 0.050650414, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28000, training loss= 0.041811317, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.045655064, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28200, training loss= 0.06791382, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28300, training loss= 0.045348715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28400, training loss= 0.06703813, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28500, training loss= 0.05303307, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28600, training loss= 0.06520518, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28700, training loss= 0.056107122, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28800, training loss= 0.047795527, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.06668889, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29000, training loss= 0.07743818, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29100, training loss= 0.05178531, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29200, training loss= 0.06399537, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29300, training loss= 0.077196896, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29400, training loss= 0.041921914, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29500, training loss= 0.064664684, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29600, training loss= 0.09120708, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29700, training loss= 0.06567043, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29800, training loss= 0.060641587, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29900, training loss= 0.07367441, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4188408, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.26090047, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.32407916, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.21514244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 400, training loss= 0.21632013, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.22385639, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.3213212, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.18260708, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.14612651, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.3089174, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.26286557, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.12810206, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1200, training loss= 0.14841385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1300, training loss= 0.19537415, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.12780458, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1500, training loss= 0.1510507, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1600, training loss= 0.082845405, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.09873176, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.1324048, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.111067645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.11582292, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.12977809, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.12625027, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.06695545, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.11822983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.1468103, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.16987807, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.08871192, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.06241899, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.08235346, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.09174745, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.07902825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.09872959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.053741727, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.088222936, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.12567589, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.086929396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.09433122, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.10715752, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.1389978, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.10045935, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.13357955, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.10621266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.086093076, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.10624742, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.055996187, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.1203652, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.09826739, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.12039936, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.08320559, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.0912803, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.07624261, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.10601083, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.11961154, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.07470246, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.08155185, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.08361867, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.087013006, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.08941328, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.09211696, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.1130553, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.11298241, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.08061634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.10661352, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.11570071, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.09092553, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.093116835, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.08885999, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.08501182, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.10917721, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.09515382, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.13193858, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.049994133, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.064423524, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.09369359, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.09195844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.086861044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.08063668, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.065088905, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.07647496, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.0646999, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.10626739, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.048981104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.08741788, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.08422561, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.06951336, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.0520744, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.12094098, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.08268727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.0870252, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.06591456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.06369375, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.06606718, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.06609368, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.07558371, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.06275113, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.051529095, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.037943985, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.04393971, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.09808259, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.07418266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.11779186, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.073442906, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.06597631, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.04684495, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.08007087, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.029383682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.08664033, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.09732752, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.051665675, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.084416226, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.09898992, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.060525704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.07544819, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.04986582, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.072761506, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.058979075, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.062545456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.077933416, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.08272466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.079502836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.13833526, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.057220384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.08207558, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.10939036, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.047605187, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.048783757, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.05617549, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.056234993, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.08604212, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.07205138, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.07443856, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.06526659, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.08800508, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.08600384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.07136856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.085156396, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.071549, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.037074707, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.09369853, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.04492654, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.084488176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.0782442, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.05922946, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.07803971, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.04339661, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.04960589, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.08728629, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.084447995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.07558422, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.073113546, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.0705492, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.04871888, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.0608142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.12189148, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.061269213, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.05863848, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.0927238, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.05745361, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.080290124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.08386569, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.07813223, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.062572636, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.08194706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.04785123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.06379029, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.05902377, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.05407036, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.036381003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.07884282, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.07303416, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.08599035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.051380567, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.11852762, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.05001413, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.059385724, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.09495096, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07201118, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.05979225, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.03474105, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.08665696, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.05138032, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.101411805, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.09021661, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.047195558, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.050169103, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.050353304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.052945875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.048006527, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.068553545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.08009168, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.069524884, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.066910505, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.12690553, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.046387173, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.04821542, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.051542737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.09102392, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.054944202, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.045059364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.056662798, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.063502885, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.057680987, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.06293434, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.08109773, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.052342772, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.10150346, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.04567823, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.05627971, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.06399121, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.0794096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.06472856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.05003702, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.037987918, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.07976584, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.09232621, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.05889474, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.051038075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.070689276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.056069322, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.05356237, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.033909414, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.074778676, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.052853554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.06336836, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.05963994, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.041407302, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.067985795, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.07701413, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.058376294, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.06291197, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.06517246, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.047944706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.055111304, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.09245518, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.053594865, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.083536476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.06702211, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.08834364, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.05578879, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.055126812, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.052680384, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.10551804, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.052561913, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.04230205, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.063239805, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.05120266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.05293337, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.06963484, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.07776973, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.07013814, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.06956388, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.07260886, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.08259741, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.046963293, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.091021836, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.06802545, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.044406738, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.05563888, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.06779991, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.076852955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.047665264, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.081330605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.058862604, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.033398632, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.06478377, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.0794173, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.0764594, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.067078955, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.062298607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.052227363, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.06732321, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.08665475, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.06134683, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.06012099, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.09556797, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.069792815, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.06773095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.05602591, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.042036258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.06147345, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.06658985, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.04503615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.0315348, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.063171476, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.08557806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.061269633, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.06755557, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.05696308, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.067901276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.065933675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.042092115, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.102220625, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.07174507, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.04858143, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.0667107, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.06867831, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.048730485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.06766479, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.06333122, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.5287936, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.52529794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.29411566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.3373748, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.32386562, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.20834126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.16844255, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.23470566, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.1392735, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.20368144, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.18171449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.17004517, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.27765903, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.13608843, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.13779703, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.20783111, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.11828971, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.17302053, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.056963034, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.14877239, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.17033978, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.08307545, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.09310463, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.15460607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.13255288, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.16728793, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2600, training loss= 0.093952626, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2700, training loss= 0.11880582, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2800, training loss= 0.16161284, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2900, training loss= 0.11483863, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.072114386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.14450303, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.11093683, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.06326926, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.097979926, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.08746648, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.06085362, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.12297363, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.12004142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.08734874, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.14209121, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.15799536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.11002222, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.07547299, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.08340361, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.04780906, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.12241624, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.07580362, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.11161742, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.13523944, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.09215341, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.091852054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.03220247, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.047825873, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.08780382, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.14584501, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.13879994, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.08488913, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.094868384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.08583393, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.11571196, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.075560406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.114609085, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.06881073, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.12950873, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.052039556, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.091707624, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.08594217, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.113696605, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.119293384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.11392776, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.0813805, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.114371605, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.11527722, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7400, training loss= 0.09400837, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.08804757, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.129249, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.098808445, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.087413065, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.08942903, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.08085475, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.14081803, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.069688916, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.040977214, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.0858064, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.13686062, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.1351773, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.057395272, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.084741816, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 8900, training loss= 0.1042335, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.083882935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9100, training loss= 0.07491415, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9200, training loss= 0.0722004, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9300, training loss= 0.040140856, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9400, training loss= 0.119916946, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9500, training loss= 0.08126102, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.074240476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9700, training loss= 0.107203044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.081935205, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.074870646, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.06422482, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.08960101, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.064930744, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.10606713, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.115342, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.11174139, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.09261615, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.060848705, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.09445771, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.14024119, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.03826064, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.07792735, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.06731614, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.06477644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.09728634, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.09447541, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.08609932, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.16005221, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.0926861, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.071770035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.114077725, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.098472, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.058919113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.10282165, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.06474213, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.090828046, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.08227163, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.117129005, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.10036758, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.049241915, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.057614427, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.07678121, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.11902695, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.087214656, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.09967204, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.08240501, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.077272475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.08335687, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.08075734, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.11020437, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.07923563, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.055119965, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.06427049, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.1033651, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.03222733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.09768508, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.07981551, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.064038664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.09008092, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.09632866, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.09293252, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.07471257, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.07385599, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 0.052634887, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.05563642, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 0.120447904, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.049850184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.07948808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.079642825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.06227322, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.09164698, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.066667475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.06252294, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.083357796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.08106702, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.068692304, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.081547, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.06326661, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.07206353, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.054403882, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.065387554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.09954352, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.05594898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.043836575, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 0.07283739, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.07205388, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.07325607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.069650024, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.10004111, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.057590604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.07974691, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.09630948, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.08038672, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.113292724, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08865065, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.070984915, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.09223013, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.112003595, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.057275083, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.052111175, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.05987374, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.06493637, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.05314479, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.087261066, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.078872, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.06645719, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.08110401, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.048138693, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.08895917, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.07501316, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.080466636, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.056703515, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.0708249, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.053875107, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.1173374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.07094789, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.06299351, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.047279663, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.051146865, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.05579416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.101518415, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.08166897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.052333187, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.06430205, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.070352174, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.070632786, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.055433445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.045823637, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.08734725, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.079276435, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.052457403, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.10287866, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.040820625, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.06319742, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.09715749, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.03603628, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.06825061, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.066388965, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.053095456, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.09272281, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.06295967, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.09025233, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.053031035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.10057133, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.07132048, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.049719848, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.031972602, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.07515894, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.05463641, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.07461073, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.05625986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.10020844, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.07551939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.079886064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.10016776, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.07007403, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.064813405, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.07266048, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.08451074, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.08221131, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.065493494, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.07756005, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.09598231, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.05237179, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.075144865, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.048197187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.08342748, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.09282707, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.0927402, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.055718098, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.052200116, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.07072604, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.084621705, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.04977684, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.08395634, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.062434077, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.07234019, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.063671306, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.032632403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.10357129, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.07180318, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.061877124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.034074403, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.036818016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.060991414, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.064943194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27600, training loss= 0.0743834, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.036961347, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.04469531, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.071045995, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.07154727, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.059535436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.059310723, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.06695506, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.064372994, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.07604587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.07984745, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.07451737, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28800, training loss= 0.05827178, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.06404812, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29000, training loss= 0.054748554, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29100, training loss= 0.054958403, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29200, training loss= 0.07501327, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.04568668, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29400, training loss= 0.05644285, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.036396407, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.049322728, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.04015061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.09089617, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.04868599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.5430123, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.277408, training acc= 92.5000011920929%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.23575383, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 300, training loss= 0.1993526, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 400, training loss= 0.13387837, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.14681236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.13494405, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.12176308, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.17322695, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.11218576, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.14582716, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.0930364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.12548015, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.15290555, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.1511687, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.07611717, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.09572049, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.107265435, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.07724794, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.1162374, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.09379242, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.13444267, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.14929298, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.051807933, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.081517495, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.11428316, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.10617578, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.10989797, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.09665304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.09802012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.10778364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.1546096, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.07705492, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.12905066, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.07429184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.10270431, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.13413362, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.0818661, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.09112858, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.12542534, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.10156461, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.10774709, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4200, training loss= 0.12549105, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.10287161, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.11713575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.12404287, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.07308732, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.11818133, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.06774917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.08955898, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.074590445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.10463907, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.11033754, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.11106803, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.07767771, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.09801864, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.11764213, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.082328126, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.11268209, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.12710352, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.08779438, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.09449669, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.11770986, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.076340064, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.10232338, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.08997538, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.11436932, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.09138783, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.13618784, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.11071142, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.074401945, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.12910464, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.10889375, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.06663413, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.14477848, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.07572869, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.10336285, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.069289155, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.07259853, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.0756872, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.08902055, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.06628897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.09238973, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.09567117, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.09290584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.11848819, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.07000311, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.10684928, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.14308544, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.104216635, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.052888915, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.103198975, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.09060374, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.05681061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.11171064, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.067130916, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.11554506, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.084838554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.0899899, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.07984167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.0880331, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.07826203, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.08451115, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.11840632, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.11336157, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.096792065, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.07469854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.08339261, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.11917864, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.04001516, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.096341416, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.08136975, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.075126, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.11322801, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.09224864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.07833718, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.11648436, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.072450824, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.10382083, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.081077516, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.10263115, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.06139653, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.11350027, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.09634504, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.068688214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.08248866, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.07654554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.06895551, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.118521705, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.09834139, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.08305977, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.08842111, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.08397853, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.09765573, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.07982014, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.1268184, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.08261937, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.08829151, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.09320622, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.09162666, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.09344374, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.1079128, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.106937125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.10706416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.114791535, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.06897254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.07166863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.08225684, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.09218605, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.07267656, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.08954428, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.070125274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.079356335, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.09036627, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.13268381, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15500, training loss= 0.06851819, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.09797689, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.07952404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.047898725, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.08214121, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.072086215, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.082986236, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.09212252, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.064323865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.074767925, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.054431297, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.1058501, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.07701113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.04780374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.06823392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.050546788, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.08276536, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17200, training loss= 0.07656342, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.073084824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.10610658, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.08127355, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.09268745, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.09444355, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.07892004, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.05819076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.056781005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.078456566, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.05560052, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.11520522, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.050753303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.10705834, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.093668334, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.0767381, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.07463373, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.12976983, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.06248182, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19100, training loss= 0.10935681, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.107009254, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.05959928, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.1027941, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.08425552, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.12507248, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.08458903, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.10170816, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.08179526, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.104920775, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.08314176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.076157555, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.09045142, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.07660562, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.09463035, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.11090895, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.07756801, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.11987551, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.11189546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.07689008, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.082387984, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.069710076, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.08885214, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.071597464, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.111055814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.07753688, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.07640811, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.10930899, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.077118106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.08298415, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.066205986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.059107102, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.101859674, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.06828995, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.10782176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.07283218, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.07965443, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.05535474, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.09318655, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.080712035, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23100, training loss= 0.06824431, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.11005539, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.11059664, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23400, training loss= 0.048697542, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.07273865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23600, training loss= 0.06823391, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.08202317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.089129254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.10458513, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24000, training loss= 0.07812183, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24100, training loss= 0.06995757, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.08161866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24300, training loss= 0.09784809, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.09101608, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.08504104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.08435085, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.089667074, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.067673154, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.118895404, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.06794218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.09659308, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.07992678, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.10946441, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25400, training loss= 0.08464895, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.089460686, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.06650518, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25700, training loss= 0.104089454, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25800, training loss= 0.08040594, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.12632978, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26000, training loss= 0.08783808, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.10033423, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.06045664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.083831005, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.0922343, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.09070808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.10138749, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.1045226, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.07742761, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.08297969, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.07494139, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.080653705, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.07996707, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.117437705, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.13169338, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.08635239, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.084926985, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27700, training loss= 0.10115578, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.06621938, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.093067184, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.08538519, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.06977411, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0846511, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.048535444, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.101315975, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.08096945, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.06876069, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.078495406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.07637267, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.087632746, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.089031324, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.091506526, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.07852903, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.0916681, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.09289485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.06542027, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.07187159, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.09871225, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.065327644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.08954832, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.250179, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.38621405, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.17054535, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.27347434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.113556035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 500, training loss= 0.2636048, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.1649452, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.14459279, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.12746641, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.17622557, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.094268754, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.17869936, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.14330123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.14199989, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.14395353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.0975173, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.14494535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.11975006, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.23048344, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.23874685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.15797412, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.12871027, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.06864022, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.12454659, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.17100567, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.1403421, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.11941827, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.15399678, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2800, training loss= 0.1087388, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.14933562, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.15247817, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.10613304, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.1551941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.16025767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.08528109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.15255152, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.17679326, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.11969153, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.12089604, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.093547024, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.17410532, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.14913066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.13632837, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.108946055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.1407876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.10886152, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.1011535, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.14036998, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.16156879, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.09425471, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.08327305, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.10691469, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.14778766, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.11122642, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.12625855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.12211064, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.1618337, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.10193414, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.12277003, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.10354009, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.14173985, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.104392625, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.12255005, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.119476266, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.123388715, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.08884653, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.05711083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.16086212, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.07025789, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.15406582, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.1512667, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.1354181, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.12589018, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.056775674, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.10575197, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.13278489, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.091836385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.114197694, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.04751525, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.065965995, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.13186222, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.12203018, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.12685683, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.08785521, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.123730674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.08526687, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.089289464, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.12026491, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.08591641, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.053685203, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.12281567, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.11332841, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.077047825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.07082039, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.09499981, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.07222157, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.11541159, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.09994445, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.09529293, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.10273734, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.08068961, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.06902352, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.068211496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.13789342, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.1051509, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.08981188, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.10984939, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.10301153, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.077196054, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.08163545, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.1060039, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.116691425, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.11049475, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.078881316, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.12853794, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.094216965, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.0951307, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.09809781, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.1331558, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.07700733, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.08561767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.1057655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.06726694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.123748906, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.10394092, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.12795106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.13174695, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.14294711, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.10684899, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.12190029, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.084659, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.052692812, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.06846534, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.080462456, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.07381171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.09685696, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.06256267, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.13701773, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.12420031, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.0658549, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.14779907, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.08088383, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.074623786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.042212375, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.073554896, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.08916588, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.08182293, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.12275507, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.0710635, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.09636199, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.09201164, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.110286206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 0.13609841, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.12036711, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.11560156, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.12235336, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.084959835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.09078235, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.09432224, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.06673403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.07221067, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.13045664, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16200, training loss= 0.09216856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.08400846, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.10412577, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.08603936, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.08092823, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.08753722, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.111601785, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.06812568, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.07750066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.07982308, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.087335266, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.051073126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.09586814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.10611877, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.0737637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.09028094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17800, training loss= 0.0773605, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.108428925, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.13467154, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.09719203, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18200, training loss= 0.1029155, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.07206933, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.07570074, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.10922164, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.09754053, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.09230958, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.08706679, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.12294005, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.06235289, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 0.078419, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.11235522, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.107234746, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.09185033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.0994611, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.06486192, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.054009054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.09934289, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.12187988, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20000, training loss= 0.07211086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.13378553, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.09122728, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.09322383, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.08161249, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.11296111, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.10823117, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.07704, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.06858337, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.05592362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.0862913, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.07592427, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.06809601, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.07760692, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.07877471, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.10771644, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.117397405, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.08042722, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.08310777, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.061126728, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.12394822, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.13575552, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.074821696, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.072340876, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.06773303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.08668287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.12535846, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.10526834, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.063028626, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.08616991, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.07682832, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.15613708, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.14257227, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.07883358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.07434218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.12633064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.096078105, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.11871824, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.11177185, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.061727457, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.10770151, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.09938553, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.06297956, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.1031112, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.08167707, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.13565564, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.057534978, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.09694931, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.063499644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.07182929, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.08757646, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.07040955, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.07348748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.09069768, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.082462, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.088364676, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.08384325, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.053821474, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.07104844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.07202639, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.13950929, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.087133676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.07830318, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.10735923, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.062333357, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.097883776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.09630512, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.10256605, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.08489413, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.105505995, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.0844075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.07393634, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.1310411, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.1180591, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.10156215, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.10712438, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.067946784, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.08409641, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.06821482, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.06719218, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.09737226, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.09611717, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.11903988, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.049111996, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.11025269, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.12099006, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.0748022, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.10042849, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.08021777, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.051158275, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.08110645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.078865126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.08547475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.099412344, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.09381406, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.08726981, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.069247395, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.09105795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.067454, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.082990244, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0500925, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.2723576, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.19919874, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.21554439, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.18915688, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.20182604, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.11198898, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.13551426, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.15424338, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.081851, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.15727697, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.17981316, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.109224476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.124295026, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.1220148, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.120262995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.14628425, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.08940002, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.1159022, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.06700229, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.103925996, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.115454644, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.080442026, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.08397232, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.11427258, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.12164963, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.08336187, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.113459125, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.13889761, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.11149348, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.11770118, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.13259192, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.048462983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.078076534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.09715971, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.1071369, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.10046746, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.07180746, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.15155123, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.12617184, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.06912654, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.06267335, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.11902519, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.10207907, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.08132817, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.115518115, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.08509617, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.08433273, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.09756933, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.09872752, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.09855208, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.11208998, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.101038806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.07043006, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5400, training loss= 0.119390644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.108782314, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.13924052, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.11149082, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.09879604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.09747971, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.08735139, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.088857755, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.111460656, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.08124772, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.12278265, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.093422525, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.08196131, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.052546386, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.10393124, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.07452975, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.082121834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.13934952, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.07569992, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.08606193, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.11740111, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.04617793, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.1006455, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.062782176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.090897135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.09336915, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.06318574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.063428454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.11242857, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.049423918, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.1357579, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.10281594, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.052677147, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.07668374, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.1210595, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.07327877, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.08874807, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.059613276, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.1404215, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.10476312, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.07821504, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.09007457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.06385995, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.08925416, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.059868127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.06735337, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.08294024, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.073932335, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.099997975, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.07543062, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.07510245, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.08827198, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.079184644, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.102818735, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.09088432, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.10274085, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.069232196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.07066994, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.1118758, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.08592503, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.11656687, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.06910971, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.11803095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.09498914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.06764969, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.077980064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.065972686, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.07488063, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.1074843, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.124155596, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.09551752, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.06254362, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.0752326, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.058039445, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.08697105, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.073569275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.05805365, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.099787936, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.06241097, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.11483355, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.09624254, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.059018336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.11919893, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.056786865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.072649084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.1023593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14000, training loss= 0.08042314, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.06957438, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.084370635, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.12920296, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.08128458, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.1038244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.14188942, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.106036924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.09420039, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.093853556, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.09751453, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.08633854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.07086803, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.09288695, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.10956761, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.072421044, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.07436367, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.10105677, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.061184622, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.08306411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.07320563, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.07294555, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.0836855, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.079594724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.03683264, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.067149036, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.08114439, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.07256382, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.106034145, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.08531998, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.09824409, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.058928482, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.08735922, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.08602672, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.07774474, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.07557819, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.09389541, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.1277557, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.042706374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.056446467, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.07909361, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.0647557, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.092827655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.090229616, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.085965365, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.11540359, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.059554666, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.11906018, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.08882268, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.11192416, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.056039512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.058974694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.099420466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.15451394, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.086582705, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.07466467, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.07179641, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.0688618, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.07676615, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.07740059, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07295488, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.0881518, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.074973494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.105037555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.09445696, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.09908157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.076364085, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.14559297, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.0716372, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.105741225, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.114705145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.064422175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.11721027, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.058898494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.06611565, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.113702856, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.08407566, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.04587455, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.06272992, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.08261795, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.058148693, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.068418354, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.07645082, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.0939288, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.07046264, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.08358871, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.066132866, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.068803996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.08546637, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.057923567, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.08554011, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.100799575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.088931, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.07218741, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.08171305, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.078223825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.1089388, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.07787577, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.0874067, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.0539129, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.08519948, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.07741058, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.09529902, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.07557849, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.13033369, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.08083656, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.10444884, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.11605454, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.09075614, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.07499671, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.11342007, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.09538834, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.06941991, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.049176406, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.118217416, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.1059688, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.053775046, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25700, training loss= 0.10456093, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.05811637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.07707226, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26000, training loss= 0.098096475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.053959925, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.064316615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.06802776, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.07775899, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.08923883, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.06542308, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.09933571, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.078877196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.1147418, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.08145438, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.065429814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.06018118, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.10962084, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.09541948, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.07083872, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.060595915, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.06490501, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.06560403, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.054211967, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.09897029, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.12143012, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0750278, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.078290604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.068940535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.06818395, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.11442239, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.1293044, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.082036875, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.08590438, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.052579455, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.07527914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.0711316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.06570147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.0852185, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.058311254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.07609102, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.052081678, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.061397534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.08838875, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9283379, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.309247, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.40168917, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.22367117, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.25548375, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 500, training loss= 0.16650905, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.14936134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.26423627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.17342606, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.20262337, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.15229087, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.22503336, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.19091636, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.18470937, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.16955616, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.096897386, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.12887643, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.07396151, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.10359256, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.16337869, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.21086872, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.10620792, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.21532586, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.19089401, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.16856267, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.10856615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.09523519, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.10511105, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.12318123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.17300388, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.101851046, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.06902708, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.1250358, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.09910371, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.14858681, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.10298828, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.13213456, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.15709114, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.07203843, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.09268566, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4000, training loss= 0.13276051, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.074458025, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.102101326, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.1577707, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.15924743, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.10531993, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.079179704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.10179947, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.15781884, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.065080196, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.12387772, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.124102704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.10450665, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.11244246, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.08652672, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.11161648, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.10590706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.1018088, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.11417007, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.10917882, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.11939123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.079418585, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.1351836, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.14149702, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.08574575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.08436677, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.06570086, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.113938786, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.06957168, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.10615124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.1327824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.077026, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.079297364, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.07886295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7400, training loss= 0.09648174, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.07876953, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.10310886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.09323897, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.14957602, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.061105266, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.07611149, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.06631886, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.08453208, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.14681254, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.11685111, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.1260218, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.06246046, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.11437448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.07625746, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.090685464, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.11312558, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.10342224, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.10636048, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.07482036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.07952058, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.085158765, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.0993077, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.06946607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.13015188, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.09423394, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.14704104, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.060856365, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.17139962, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.08079694, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.10552175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.054134697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.15505193, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.06382209, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.08794709, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.081749864, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.07632145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.06399745, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.055760812, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.1018994, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.10922065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.09387716, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.09574433, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.09126222, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.073794544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.09787448, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.056232486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.1340872, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.098531805, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.11513492, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.1056785, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.10880054, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.09055562, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.072530106, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12800, training loss= 0.08164631, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.09646277, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.110589, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.05001845, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.08911577, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.093486466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.09161779, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.096196614, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.05397534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.108981825, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.07653215, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.07242568, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.10716709, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.077974945, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.05085174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14300, training loss= 0.06994204, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.07789537, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.093033046, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.045678694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.069802254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.06285575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.05043722, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.10508547, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.05334149, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.06945744, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.08821085, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.0821194, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.06692074, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.07397953, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.035778712, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.12259288, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.07346643, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.093204245, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.10986788, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.08323447, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.06207505, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.08460592, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.06502127, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.093400106, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.08872128, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.066445574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.09024408, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.068157636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.084775314, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.07580928, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.05501596, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.067416646, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.090580344, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.10832414, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.060300667, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.06667439, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.07479008, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.06651423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.048364174, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.0760878, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.07132819, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.067500584, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.06348661, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.06729373, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.06362052, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.06363014, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.06902515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.0610315, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.08324674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.053748466, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.060387477, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.06964546, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19500, training loss= 0.12613654, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.069787264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.05811118, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.10055007, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.09527595, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20000, training loss= 0.074326366, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.10814854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.063529834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.056882784, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20400, training loss= 0.06612967, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.092946574, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.101176426, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.09798867, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20800, training loss= 0.09870943, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.077716514, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21000, training loss= 0.070934065, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21100, training loss= 0.07040009, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21200, training loss= 0.08632028, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.07281976, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21400, training loss= 0.07822739, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.05354113, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.07214278, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.09611504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.0458336, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.0856178, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.11470854, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.09507956, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.07028851, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.060681637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.075843014, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.06616005, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.073006034, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.090257734, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.07545709, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.09633267, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.06418517, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.059390403, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.09227753, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.071980715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.04587938, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.08187488, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.082496524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.06515261, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.07927129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.10883353, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.10240263, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.11101004, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.061829563, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.07180085, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.074404314, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.074076824, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.086238615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.06887367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.06586689, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.06845017, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.078130096, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.126499, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.072001025, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.09020049, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.05679142, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.03728598, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.10835783, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.08545572, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.06488475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.065173276, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.07543724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.054081876, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.08142882, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.064490445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.043112427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.08129113, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.10304825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26700, training loss= 0.06475255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.08152497, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.053536057, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.08887314, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27100, training loss= 0.057204522, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27200, training loss= 0.06062994, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.094619766, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.08333627, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.08593024, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.050624847, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.095116824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27800, training loss= 0.04906113, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27900, training loss= 0.059932437, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28000, training loss= 0.0762663, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.08283443, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.05710948, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.04173845, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.034294415, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.07303793, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.09799015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.06492079, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.06527614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.0593074, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.05993589, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.07101553, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.07321561, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.051328957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.08847275, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29500, training loss= 0.06854161, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.08774589, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.108247176, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.0899601, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.074787915, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.3282421, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.20640923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.2374717, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.24312721, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.05701104, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.09533881, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.14796416, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.15180601, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.2835068, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.18008636, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.19031166, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.10504623, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.1391199, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1300, training loss= 0.07328795, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.14662182, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.16874447, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.15073594, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.09650331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.13836482, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.13036624, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.11547835, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.19068453, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.111204065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.09907274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.08611421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.12389919, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.14658785, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.11122891, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.086914405, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.12057084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.07247742, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.115966395, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.12853378, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.16056615, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.13522911, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.20846014, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.13191849, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.1317325, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.0926069, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.099193744, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.16937244, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.1285572, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.07204009, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.084681585, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.13482855, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.069125235, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.07799621, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.114194185, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.12549782, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.1471275, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.13100068, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.08092317, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.10836691, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.07905002, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.10182324, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.09453307, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.089767866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.11692642, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.118686095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.07653334, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.0830185, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.108196445, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.11242179, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.095383435, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.10698597, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.10194147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.098125584, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.08635447, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.12533486, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.086385876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.09519121, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.06124154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.10740025, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.082895406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.062972486, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.074057326, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.07275215, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.07218563, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.077409156, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.07791917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.07733731, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.12006835, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.0874282, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.07448188, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.11386779, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.083640605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.11501405, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.087508984, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.05852468, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.06902461, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.07600706, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.122811824, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.07409033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.09199619, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.08961937, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.09084953, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.072132304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.070729494, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.047780618, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.07872468, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.04870388, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.07665415, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.08896179, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.08277374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.10527273, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.0778036, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.07123755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.09605017, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.07793367, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.09746781, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.06946185, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.09230289, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.06547336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.115052246, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.10492281, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.045839615, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.10047771, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.0374051, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.07186338, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.12101066, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.121732295, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.055630032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.065594755, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.08028087, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.08397129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.06873436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.120412186, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.08566033, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.07720035, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.07268512, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.1249568, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.072076455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.075325236, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.09658316, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.08921762, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.13052115, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.07309131, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.10772997, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.071435176, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.10187175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.09718348, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.085260585, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.06995098, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.062817335, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.08894861, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.09490482, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.099327564, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.1182325, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.08254109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.061470848, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.09185715, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.04872597, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.09122652, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.07929273, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.093220904, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.065212354, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.074956365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.066339634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.07684203, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.1309748, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.07864649, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.10156333, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.07544171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.09039897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.068570375, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.08686436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.08367216, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.062071882, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.12869398, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.104587436, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.06340136, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.09969824, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.07926846, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.054740645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.108348764, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.097440496, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.103466965, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.059006184, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17800, training loss= 0.099458694, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.07365271, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.056866158, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.11973147, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.05091341, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.09384377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.09223115, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.06576973, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.0712852, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.06360471, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.075045794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.048857857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.07278635, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.07915005, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.088942856, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.073489435, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.06847651, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.066045694, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.048353937, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.08970942, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.06956106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.04852294, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.07535401, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.08630365, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.079358175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.061242543, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.08654806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.100470245, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.07091623, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.10660206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.095095426, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.07596017, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.06834152, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.10634253, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.09229593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.06330385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.03832764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.07752746, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.05180536, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.059761275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.106511235, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.048021592, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.055697493, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.07423859, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.121846214, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.0983178, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.09350783, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.13018212, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.09065637, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.1093449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.05325993, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.07188014, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.074442655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.04946367, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.0763195, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.09019496, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.07434243, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.044926405, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.087671, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.06732896, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.039077148, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.080855936, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.08424184, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.07120556, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.07694744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.07493439, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.08334726, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.06181003, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.05377567, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.10230887, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.0630983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.06788117, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.06420806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.039757647, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.06722948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.098342836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.09452378, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.09224819, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.058553956, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.082825065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.0813701, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.05090761, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.07292921, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.0761466, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.09913735, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.08416303, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.08566077, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.056475207, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.069798805, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.07051552, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.07067264, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.062392212, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.042730868, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.06947229, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.092021555, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.060422234, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.08156623, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.06278161, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.06208607, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.075422615, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.10926739, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.06528305, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.050462678, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.058964025, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.07487051, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.080301344, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.06981699, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.054870527, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.07041754, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.08292941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.08166951, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.04721964, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.06378732, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.07620634, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.10938648, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.07849895, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.065249056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.064514466, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.10312778, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.1082906, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.097645566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.06795539, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.548671, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.3256759, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.31437826, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.23208806, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.21930623, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.15919055, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.17390814, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.113171, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.31304014, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.12187719, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.23782264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.17443387, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.1001116, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.19481018, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.20165679, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.1649134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.13773263, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.13035281, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.1417421, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.12015145, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.16328375, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.15608294, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2200, training loss= 0.12291302, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.20681453, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.1324485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.0718766, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2600, training loss= 0.16589542, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2700, training loss= 0.1799823, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.1370533, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.16628988, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.06148341, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.09931569, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.17287737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.078103125, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.11345153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.09408041, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.10213724, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.12284507, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.08398258, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.09454942, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.089299306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.10069826, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.14474587, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.15389255, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.09909337, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.08473838, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.07975278, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.13209963, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.14945783, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.15794922, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.1254062, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.09614966, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.05401492, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.14529797, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.100753985, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.098582074, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.093397036, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.09799671, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.06663503, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.11128603, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.05239169, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.07400809, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.09928228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.0860472, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.05833422, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.16248333, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.10076053, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.10262447, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.04852419, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.07924377, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.09885315, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.075505786, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.098019965, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.10366056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.12404042, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.099294834, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.12632659, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.08421391, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.07451423, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.13385256, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.13346583, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.0763756, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.10470645, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.11892751, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.065349445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.11059406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.12254683, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.08260476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.09872385, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.06361329, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.09805477, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.08221771, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.06896165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.07367855, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.10145118, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.08270884, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.07931093, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.09289974, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.07399099, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.16335973, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.11124318, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.105610155, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.0955523, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.10759443, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.07085599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.09741994, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.12449878, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.106094554, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.08694935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.045372784, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.06929262, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.12760207, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.095518835, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.10149684, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.0569822, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.05918703, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.07800845, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.10727542, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.11133839, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.08000548, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.09242262, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.082701005, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.06292745, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.1026662, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.06780724, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.086575136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.058096766, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.08093369, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12800, training loss= 0.060520675, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.06341869, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.11614561, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.08122061, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.11149266, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.10322358, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.09499414, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13500, training loss= 0.07675848, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.08879354, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.060927767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.06237711, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.091431335, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14000, training loss= 0.05418902, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.04889587, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.072812095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14300, training loss= 0.09294778, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14400, training loss= 0.06765738, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.112945236, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.08150064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14700, training loss= 0.083572336, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14800, training loss= 0.062499512, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.06841568, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.053148616, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15100, training loss= 0.08848193, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15200, training loss= 0.09724514, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.03728765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.061022032, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.110082656, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.052625902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.092613325, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.084546015, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.04982715, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.09993079, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.070815496, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16200, training loss= 0.09632305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.08101014, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.063746214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.10523721, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.057160955, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16700, training loss= 0.08704984, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.097993635, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.049965557, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.038405318, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.060738795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.1020383, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.045929864, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.07193406, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.07319272, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.06903519, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.05224111, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17800, training loss= 0.10247449, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.074136265, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.09493651, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.06872743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.102591574, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.0376434, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.09325504, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.073847495, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.08097513, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18700, training loss= 0.04361101, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18800, training loss= 0.07643762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.050838977, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.050440844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.074359514, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.076332904, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.08423405, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.073693715, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.08235538, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.074435756, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.041213065, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.05918846, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.045014344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.05036859, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.062519565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.07007807, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.049700845, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20400, training loss= 0.048998564, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.09825571, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.06973609, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.0716537, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20800, training loss= 0.085516885, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.09246222, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21000, training loss= 0.059729185, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21100, training loss= 0.10199227, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21200, training loss= 0.074922524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.112831645, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21400, training loss= 0.08476597, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21500, training loss= 0.068297625, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21600, training loss= 0.11200457, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.07085801, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21800, training loss= 0.05526571, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21900, training loss= 0.060386613, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22000, training loss= 0.06505491, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.056395665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.07630852, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.0756071, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.06883075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22500, training loss= 0.06550645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22600, training loss= 0.052690882, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22700, training loss= 0.061288696, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.09388713, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22900, training loss= 0.08328439, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.058140006, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.09170787, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.07415267, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.06672376, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23400, training loss= 0.056812815, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23500, training loss= 0.10067091, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23600, training loss= 0.03410101, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23700, training loss= 0.054757867, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23800, training loss= 0.09419299, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23900, training loss= 0.07204858, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.07229358, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.049785614, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.09787944, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.06433009, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.037916288, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.07002876, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.10310976, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.05532963, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24800, training loss= 0.08974484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.099395074, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25000, training loss= 0.04745533, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.0770438, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.09557862, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.09862684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.06072008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.09390614, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.06903981, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.045319106, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.1085384, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.0721866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.07081681, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.090461336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.06745589, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.11888974, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.08339305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.051213957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.056030262, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.04721267, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.06788977, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.06199193, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.100119986, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.080152735, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.08648073, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.073635146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.08200374, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.08283813, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.06795217, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.056466877, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.069566995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.06847816, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.04127761, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28100, training loss= 0.08290382, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.056186114, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.04709699, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.060867038, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.063356854, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.10005186, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.088627286, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.09165098, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.059629817, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.08263155, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.026574168, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.0556535, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.06680938, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.069075115, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.073688366, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.0851954, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.062477283, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.028478, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.09736288, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.5459721, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.18679024, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.26328745, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.25629458, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.1454288, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.25644866, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.27523753, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.16281144, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.15647806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.12538262, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.10308436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.08897255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1200, training loss= 0.18214808, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.21097054, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.09789377, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.15036216, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.21723782, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.12183911, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1800, training loss= 0.12315489, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.094018064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.09319355, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.11291274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.11487169, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.086041264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.119116545, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.0806295, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.1348985, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.09480039, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.13764997, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.13635097, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3000, training loss= 0.11219495, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.13466997, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.1039052, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.057963822, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.07724539, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.08265584, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.13478577, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.07363157, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.19174506, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.07316879, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.15682994, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.13426699, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.10544263, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.1124523, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.06934198, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.074693836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.067956075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.083275, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.12318066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.11483148, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.09460476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.12602949, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.1630825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.13545318, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.073223196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.095985055, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.045713868, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.094499774, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.13948247, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.06639862, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.08995407, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.13815157, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.10573415, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.10927795, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.1149818, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.09869288, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.06808078, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.101354696, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.14478935, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.06238083, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.10899882, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.08512778, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.07514732, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.09147314, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.08915881, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.059687138, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.07370062, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.07376039, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.07767876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.12013825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.06361625, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.08633021, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.07103954, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.05206061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.09994686, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.11495879, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.11051663, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.06853843, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.071106315, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.066117145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.07828036, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.0698257, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.040947456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.076118864, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.04368487, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.057214864, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.051287524, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.04940228, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.10158942, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.088828504, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.056836564, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.076590925, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.09306926, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.059692767, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.06471476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.084051795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.095938034, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.06327387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.103947856, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.08157546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.08327671, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.07112597, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.061536066, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.09481101, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.074300535, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.08715394, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.11892676, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.0859838, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.055855937, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.053972136, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.070347704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.08912633, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.06719397, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.044860914, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.07727341, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.077023484, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.08436476, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.086319424, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.076789536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.054984193, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.052883234, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.064012565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.047499467, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.043403186, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.06945857, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.07466432, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.06408849, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.058121614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.078137755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.124771886, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.0746229, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.07104242, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.09926864, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.07502369, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.08183686, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.06522232, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.0661423, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.06072039, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.091306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.07701371, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.06658195, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.08748535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.10580749, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.09482685, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.0770552, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.046929963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.07087133, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.06863778, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.05772428, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.059666447, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.08188713, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.07210244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.07745202, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.101470694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.08007825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.08776353, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.059951227, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.07809094, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.07806275, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.039269533, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.082744606, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.0677778, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.11230246, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.06675306, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.10334516, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.07373788, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.09278269, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.071813054, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.07658125, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.07008753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.08496394, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.08960084, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.07732387, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.057509534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.07947551, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.08420596, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.07474486, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.11396546, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.051646605, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.06552243, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.08737705, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.06296676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.067813836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.074784875, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.059492238, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.062097583, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.05740914, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.06543128, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.043861397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.056832306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.0492388, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.09175217, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.082220264, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.06493539, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.07072999, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.057239812, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.06257329, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.08946524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.071681425, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.08009786, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.07116331, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.06741801, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.07784458, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.082964756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.08563441, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.0536425, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.05105049, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.05643024, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.059996307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.054323304, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.07393936, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.06171429, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.1000819, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.07680787, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.062062103, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.08744264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.060025685, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.03845793, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.07692539, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.03980543, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.082723394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.06886295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.12053251, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.039998475, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.08112202, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.08498053, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.06862336, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.073249154, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.08381323, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.051437344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.08233926, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.07974718, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.041365016, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.079576954, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.08324466, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.06901749, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0559793, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.031514168, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.07195864, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.06799855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.059830826, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.065834485, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.0639471, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.06173603, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.07918316, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.07488457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.061740022, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.07440223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.0639012, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.06691052, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.04427954, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.08338127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.04577785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.054481108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.10198154, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.058865786, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.09338832, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.08267653, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.07940673, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.04510752, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.057880156, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.06348827, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.063368365, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.08831864, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.080484435, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.0744628, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.083515935, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.05417775, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.067040615, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.06758735, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.050709616, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.06805946, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.052007876, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.049423438, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.029669281, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.054873902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.06541096, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.085235134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.08154106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.08629053, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.0954554, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0548323, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.06354613, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.07095694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.05115468, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.07432328, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.050608158, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.07652854, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.08561395, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.059081163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.2286394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.2698653, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.22328405, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.34855413, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.37335622, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.22095494, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.20778337, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.27122214, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.25651678, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.18829742, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.20972502, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.21216677, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.1181063, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.11894424, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.2650311, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.13973485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.1159233, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.12574339, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.13031924, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.10714833, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.086082205, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.10960021, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.06983525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.083056524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.14970979, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.09686873, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.056223672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.17167284, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.11224776, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.13123877, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3000, training loss= 0.124519244, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.12718977, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.12838157, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.10789134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3400, training loss= 0.10620812, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.16928296, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.17547117, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.08411183, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.1586399, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.15567969, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4000, training loss= 0.1195262, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.11214329, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.13424748, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.20749798, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.1349519, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.0700076, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.06599486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.14534973, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.06883199, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.09065517, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.18521672, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.11934741, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.12017826, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.13071965, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.1844946, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.16117533, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.10093822, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.14206073, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.06887372, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.08184582, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.14102595, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.089194916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.07379505, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.15609543, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.089389645, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.11588842, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.09849588, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.14598967, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.07826341, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.06358779, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.092404135, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.07714632, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.10294825, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.08850262, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.08007122, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.06702325, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.094943486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.08621726, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.110902466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.06882912, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.09066225, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.07294769, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.08224434, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.09777104, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.07920479, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.064125635, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.060570635, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.09460845, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.1333851, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.055721708, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.09191626, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.07947495, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.070158504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.116267584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.06196564, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.11693946, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.060219165, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.041969016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.07068027, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.1060155, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.057749875, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.10308533, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.06111442, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.077096686, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.07416813, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.13440137, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.0850755, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.07990106, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.07474511, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.103187166, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.065657094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.08867952, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.117000796, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.10036361, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.106789015, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.04423043, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.08766972, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.06732077, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.13762395, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.10500558, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.102508046, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.11314453, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.054656565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.05641187, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.07807608, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.07889389, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.09799509, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.052127194, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.11625458, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.060519855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.103452586, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.072581224, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.07327074, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.08507148, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.15194085, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.05496762, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.08955079, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.07365166, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.05339226, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.08263298, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.043034293, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.07302059, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.095472336, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.06974626, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.10996349, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.056743007, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.11832279, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.08590143, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.08827159, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.10065287, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.08297348, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.06967925, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.088596374, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.13827531, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.07934969, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.057683527, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.075698845, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.09927671, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.07243169, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.06328523, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.09202922, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.07853921, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.045024376, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.11288495, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.08761756, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.067203104, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.099945426, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.07652373, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.052186914, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.057992596, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.08861295, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.049367078, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.075886354, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.06883183, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.050494045, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.087628655, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.06572359, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.08183452, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.085675575, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.088324994, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.059601407, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.059946906, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.04716667, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.062125564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.04647094, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.09591071, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.03865922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.09862618, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.11086116, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.066586055, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.044563837, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.079133846, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.07337212, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.06580801, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.07923943, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.059302997, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.04637773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.10206325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.089492634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.09932066, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.03219461, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.08293297, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.06886671, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.08558536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.04414347, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.035221495, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.05810448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.06928351, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.06539839, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.07192026, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.07957743, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.1141441, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.06807666, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.055651475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.066403665, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.06604607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.08809514, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.053400617, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.075386465, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.049864825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.047708567, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.07738508, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.07988616, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.077824384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.0667757, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.06793956, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.06191213, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.056939095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.086532824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.07043942, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.09256007, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.062689885, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.038594168, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.055740744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.109684624, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.060630154, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.106404535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.069285594, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.06956859, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.0790714, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.040921208, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.045633666, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.033820692, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.09019483, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.091396786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.08113416, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.06620676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.07618251, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.039651554, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.093146764, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.040241476, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.073033415, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.06488261, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.05362451, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.06779551, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.053162295, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.053930342, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.081419945, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.058839083, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.057274897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.07255392, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.08013311, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.057678115, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.06710065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.083465055, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.108230114, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.06643621, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.06691576, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.06126331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.057409417, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.075781785, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.06194536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.05765741, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.07780231, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.050946455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.0609061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.07785194, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.12567171, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.045720946, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.06921541, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.06714608, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.051763196, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.06072064, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.059143055, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.041267633, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.09514017, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.05364097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.049421996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.06193309, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.10334859, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.04400083, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.05946623, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.066644624, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.077563755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.05290992, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.051330924, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.06385373, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.08484028, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.04548793, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.047129568, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.8951279, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.3891404, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.18374506, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.14092866, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 400, training loss= 0.16725847, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.1515618, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.13886254, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.21072216, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.16249487, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.11797703, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.1554865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.099857084, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.086744174, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.11757154, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.20940542, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.1293419, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.09882218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.10961872, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.13455549, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.11247495, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.11416441, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.10020317, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.13523124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.103572264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.10769289, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.16733861, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.1414504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.044533968, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.076679125, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.12079336, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.13727595, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3100, training loss= 0.15609844, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.09510568, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.11181902, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.052355267, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.07576457, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.0633412, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.11879805, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.1263703, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.082968295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.13044965, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.0974288, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.09819397, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.087400764, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.09296456, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.10189382, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.059530996, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.08018047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07210334, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.064177275, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.0624111, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.087948725, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.07046799, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.12159391, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.13815555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.06712817, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.08451378, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.07307277, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.06165749, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.0743014, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.051706284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.08585691, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.06252146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.07105777, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.07574816, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.105361156, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.037018795, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.062383793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.09197897, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.07767996, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.06500443, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.065361924, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.08007618, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.08009711, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.047377728, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.08337, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.046790075, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.07348193, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.08767587, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.07126935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.11442599, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.09905824, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.093763, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.059511192, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.06756107, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.07249137, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.073582634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.06840637, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.07462302, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.10276414, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.0742707, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.062351715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.06966607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.11463208, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.09919843, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.093820006, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.093723655, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.089185834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.10324003, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.084673725, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.099116966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.045000367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.07794298, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.070080616, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.09369786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.043688588, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.042259447, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.096641004, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.061655536, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.050758287, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.08942227, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.1008977, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.061864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.08411838, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.06947921, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.053482987, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.07740778, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.054887023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.06898023, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.058857005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.10705981, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.076548494, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.11909245, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.06006153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.07400137, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.11464016, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.05382876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.08776394, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.08090929, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.05499524, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.0665105, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.10224436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.07558117, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.053548727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.091098435, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.08805846, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.056045387, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.12710078, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.08855411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.10574438, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.071743086, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.043313514, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.09485163, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.068723075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.08286508, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.052900627, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.1261528, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.08393095, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.07364045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.06850408, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.07639369, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.08772732, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.08251615, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.076368675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.07729009, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.055625193, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.05993429, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.11452967, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.0479609, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.05813923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.0907975, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.08165268, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.09246185, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.06379452, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.088444054, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.09088644, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.05876486, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.049717247, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.08933562, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.09445107, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.07027529, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.090206735, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.044676602, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.10249471, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.07397174, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.06729363, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.04974482, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.07072864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.08139451, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.08686501, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.058462378, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.0943581, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.11629142, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.077669434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.104738064, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.056471325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.062237635, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.05586736, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.05544485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.07363175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.09487964, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.058776956, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.054581963, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.058917627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.07786875, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.05555637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.07814271, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.039086863, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.09454009, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.09028268, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.093459494, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.101480156, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.08999781, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.05284186, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.08361177, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.087233804, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.036507323, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.073840484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.07564324, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.083625585, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.08382643, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.08216311, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.05176516, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.06559424, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.06861858, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.06743713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0632131, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.065437004, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.058674917, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.058172498, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.049753856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.07286741, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.0677585, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.09338188, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.076682836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.07298915, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.06813598, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.075133085, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.073401764, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.04211708, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.04706507, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.059835777, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.060612738, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.04523612, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.06636097, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.07968187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.05209884, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.040679272, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.05661078, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.06603274, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.059298247, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.06474328, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.06577398, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.05798768, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.049336445, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.08962071, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.05952897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.10019542, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.059353895, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.036496922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.07309025, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.06798017, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.037344556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.08995877, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.057814077, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.055317968, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.06308471, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.06425758, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.051440533, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.0773181, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.068754785, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.05325543, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.0550046, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.06466454, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.07908138, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.047623254, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.047981683, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.06840287, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.046508648, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.058145553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.061802365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.09966029, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.051208153, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.076144904, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.068694964, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.07059617, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.059141792, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.073855564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.050936196, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.053399146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.05682406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.07477044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.057153925, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.06283173, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.02740672, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.06399094, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.08048116, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.098641835, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.057145596, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.06800988, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.07696354, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.047362335, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.04848297, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.08174117, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.05246892, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.057172224, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0471452, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.050056234, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.0790531, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.068318084, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9906211, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.39644685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.17542371, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.33671987, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.18858373, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.23298314, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.10763292, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.1648902, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.20508048, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.10677754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.12709454, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.15647157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.120682225, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.19252805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.07975912, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.0951868, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.12926033, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.21207254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.103764534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.13778628, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.11886726, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.1359977, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.17614481, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.094013564, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.12250962, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.1462367, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.11182734, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.093110576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.093387954, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.05904734, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.110759996, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.11173283, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.114165686, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.06543041, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.12898372, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.14062253, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.107394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.09278933, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.11034841, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.07834923, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.12562867, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.0922043, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.073543355, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.10692178, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.07643817, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.0997738, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.06694807, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.04277715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.095399044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.103113286, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.1138391, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.12258379, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.13115872, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.059778206, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.1248554, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.09291699, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.14449668, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.060480744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.111458674, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.08159236, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.15144973, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.06559779, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.08783358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.060307607, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.12842567, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.079973675, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.055520497, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.11436437, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.06923278, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.076232344, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.08940605, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.15822603, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.10882973, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.07362513, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.06475287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.12531957, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.06989492, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.09827703, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.15068066, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.11356932, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.0981315, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.07245292, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.05635187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.081139825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.122036204, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.065716356, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.07934064, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.11507394, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.06729837, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.09404375, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.05165816, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.06629851, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.09758169, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.07275865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 0.05666719, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.078797996, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.09068634, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.055255968, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.07897975, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.115821354, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.071499266, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.06331258, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.09371406, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.066384256, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.09138154, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.07652655, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.11003383, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.12369239, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.10575919, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.09185624, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.09011983, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.07026191, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.08108584, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.079831146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.07725147, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.050538313, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.08642302, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.06983951, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.078413725, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.066748805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.0784356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.08391365, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.0828728, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.054610644, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.09382244, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.082431, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.075835645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.0561272, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.06675428, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.08156917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.106009245, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.08521294, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.13701549, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.08079174, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.08513345, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.051818, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.07076244, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.1081659, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.10785302, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.06897763, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.10467325, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.05835143, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.06805357, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.09072846, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.097661294, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.08877928, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.07939263, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.087643184, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.13289678, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.045598347, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.065791324, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.06780028, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.085745454, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.023015164, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.08633689, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.050162464, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.05463053, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.0645513, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.092430875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.045905255, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.062702835, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.056968186, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.055521842, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.09140863, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.08804502, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.06695731, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.07009585, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.075253606, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.059714157, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.090284504, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.051282603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.054331884, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.09345805, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.06071279, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.078760184, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.064169995, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.07874288, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.06321732, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.055529185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.07757923, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.06712274, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.091526955, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.079135634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.090727724, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.08553153, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.060858868, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.060140893, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.04588577, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.04311491, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.10027542, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.045555253, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.042241257, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.123927206, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.050238557, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.07981557, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.11671373, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.0432326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.05881382, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.06435744, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.06223307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.060485322, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.056796107, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.0421131, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.069176316, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.047675155, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.06487658, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.077368826, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.075806886, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.052927136, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.06685487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.06506424, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.08562196, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.062140305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.06655991, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.06289588, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.07994578, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.09705831, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.0863446, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.08278179, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.07094206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.084080756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.07084574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.06681478, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.07675141, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.056366704, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.061219208, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.058954965, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.061460964, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.05024068, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.10320269, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.096600406, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.08530407, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.057107564, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.06509148, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.08400309, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.038804874, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.08902859, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.06619171, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.038686644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.07875357, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.076812536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.057744917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.036502294, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.06021362, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.054620214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.120423265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.07552868, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.07222582, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.07964932, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.05117054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.11079743, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.07006142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.072105736, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.05870515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.08933868, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.05958204, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.054513883, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.057679545, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.057925157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.034879815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.070758, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.0951513, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.055488836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.07447104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.057777625, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.042325556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.06449725, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.038522184, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.076772764, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.09489123, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.058414947, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.046772204, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.05859114, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.11605283, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.06134487, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.09205669, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.0523825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.072263956, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.06307132, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.06735444, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.08159628, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.051139373, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.072440095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.070938595, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.084774934, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.069147825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.032831494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.06366438, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.059920084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.08246482, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.05173746, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.0787663, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.066489235, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.037889607, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.07179268, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.049761854, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.0695249, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.05077425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.05725993, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.07131916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.08157348632812 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.6325437, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.23383877, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.20475508, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 300, training loss= 0.1473465, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 400, training loss= 0.19376938, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.22738521, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.13452782, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.13887835, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.1759774, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.1444548, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.25829697, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.09143875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.10327122, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.14932561, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.14395213, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.16109979, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.12217904, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.09906669, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.103590995, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.117102504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.11041037, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.09152465, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.11778625, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.06835182, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.10458399, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.07637842, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.09264553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.14784107, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.086014375, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.11044244, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.11034992, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.12123042, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.16822746, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.10479515, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.1360092, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3500, training loss= 0.085014604, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.1400874, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.10751796, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.098263405, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.09270857, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.08085707, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.10240532, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.11007323, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.09814673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.10408275, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.0975773, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.112097174, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.061595023, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.12036815, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.078296125, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.1315559, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.09500874, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.08579485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.08115821, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.09704285, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.14272141, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.08496601, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.12248315, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.075615555, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.12004094, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.057636842, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.075295165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.07731744, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.09410889, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.10675016, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.1023297, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.068307534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.07557036, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.094351836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.088604, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.10263267, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.14501181, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.061800316, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.087386936, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.07619271, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.076047316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.12098802, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.09481391, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.08456924, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.095276095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.08069109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.057334483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.108992934, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.058468413, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.078739494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.08669392, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.088264994, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.06311065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.108021185, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.09294244, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.097904794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.102302, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.09649051, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.08120708, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.14573422, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.059224524, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.07713948, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.093709856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.0760621, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.09842303, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.09929895, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.10873598, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.0638829, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.10522826, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.09832174, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.075626306, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.105254464, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.08278297, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.09970876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.05922584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.1064719, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.0529441, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.10637706, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.08195549, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.09417866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.07890216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.08577662, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.05366008, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.11966002, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.04417659, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.062668905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.09499489, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.094372526, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.10616198, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.10732023, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.11395733, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.06983097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.07032016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.0877545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.060132522, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.12991744, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.108734295, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.07986221, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.08488388, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.091688104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.058003075, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.10013291, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.103509516, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.07161721, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.063859686, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.08761011, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.104490794, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.11682201, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.114926934, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.11346465, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.10932054, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.06984767, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.095954575, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.0527136, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.09116336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.08771556, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.12470067, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.10510794, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.06133384, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.073581144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.09121632, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.089066826, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.12249101, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15800, training loss= 0.057328943, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.092048004, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.072767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.08210702, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.050967816, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.09669974, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.06536546, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.055978198, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.08596127, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.07572062, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.0832608, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.11052545, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.088186644, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.10277652, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.104132645, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.107907146, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.07527907, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.09362903, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.07904086, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.077728316, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.07855537, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.061285354, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.06864255, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.0696055, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.085118674, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.063247494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.07472743, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.055354986, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.061951682, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.104733, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.10403236, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.09661869, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.09361432, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.09360301, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19200, training loss= 0.07823241, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.09052659, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.090597816, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.06333975, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.07397058, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.08957257, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.06511471, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.07116931, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20000, training loss= 0.124183305, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20100, training loss= 0.048914988, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.11853896, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20300, training loss= 0.06471037, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.09811049, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.08231194, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.07867747, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20700, training loss= 0.12149384, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.05990285, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.06669791, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.0846565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.060522787, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.07378518, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.08021727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.07719139, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.1034699, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.09141191, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.059948966, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.07777941, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.09783621, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.06821462, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22100, training loss= 0.084771425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.08558622, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.06419629, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.10813214, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.059790317, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.07348462, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.08923759, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.06357788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.08729209, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.075933695, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.08444546, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.04639521, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.070707284, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.09896882, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.08323087, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.112565555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23700, training loss= 0.09659114, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.10227029, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.07631272, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.078997135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.10677867, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.08378618, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24300, training loss= 0.0702466, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24400, training loss= 0.09662192, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24500, training loss= 0.081811465, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.081851326, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24700, training loss= 0.119136415, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.08796931, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.12452528, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.0937211, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.11174723, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.10315674, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.063811444, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.10913607, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.076883964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.10448261, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.074710764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.081959605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.08001672, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26000, training loss= 0.056756925, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.06977809, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.11573194, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.08008691, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.09172575, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.11371877, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26600, training loss= 0.13348448, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.11921174, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26800, training loss= 0.064074986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.08780808, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.13050327, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.10806133, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.052250497, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27300, training loss= 0.055061936, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.058493298, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.07170675, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.11889313, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.09125439, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27800, training loss= 0.045417447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.10687134, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.11139629, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.06753619, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0890591, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.10150538, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.096288964, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.121939495, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.07450457, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.09897319, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.048985835, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.101040885, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.08681223, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.089856714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.074040264, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.07901806, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.09039576, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.08946581, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.08352605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.09513219, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.066997066, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.1251017, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7041212, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.3594011, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.3591708, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.18232927, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.31082255, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 500, training loss= 0.27610648, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.14513291, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.19377424, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.124913536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.13207617, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.21685408, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.21914367, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.06571856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.23254693, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.10855091, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.17180598, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.07809792, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.1265864, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.18230942, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.12471868, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.108570665, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.13197328, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.14921592, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.14310814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.11632921, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.09201276, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.13051638, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.105572276, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.110763215, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.14376855, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.19048186, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3100, training loss= 0.13271503, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.12134756, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.09779556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.10230787, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.16181773, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.13291892, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.10000603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.12579092, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.08380905, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.12560278, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.1405007, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.14000791, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.073219866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.1470134, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.10518419, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.059736464, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.045301426, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.12604266, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.09238838, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.13569377, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.106962636, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.102307096, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.12470165, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.14002767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.14038907, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.10915968, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.09175942, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.08642385, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.100528285, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.124638356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.10207745, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.05927057, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.104500495, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.0713699, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.10560305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.12197909, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.079180345, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.15466413, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.1262119, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.0823933, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.13483728, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.07531309, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.09874361, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.103465356, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.09011921, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.12494273, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.082462355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.09121427, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.08811703, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.07259826, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.12570551, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.18331613, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.07966866, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.07032487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.14438082, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.13089725, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.0935998, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.11371748, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.055755086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.1063008, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.104322396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.09301678, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.091256864, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.06762564, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.10926132, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.12758823, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.08629505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.12211108, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.12172918, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.09078654, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.079503424, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.10521236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.12778427, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.07322568, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.114344954, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.06883965, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.09904402, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.093671225, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.11772123, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.09985899, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.12315679, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.10072408, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.106450066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.09416854, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.087881655, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.08709344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.086982526, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.050242476, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.115828656, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.064163476, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.09820268, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.08882435, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.081354074, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.10681258, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.08209328, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.06775896, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.06944573, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.09315756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.06480583, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.15490231, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.06087106, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.073625185, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.0804865, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.06616959, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.08766027, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.09513849, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.07423892, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.07366158, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.11964229, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.10994463, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.09849178, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.1061338, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.06794335, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.10951111, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.07756116, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.09958198, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.08992975, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.091351, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.08992759, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.11089541, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.05859241, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.058710724, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.090093195, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.114658386, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.12995926, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.13627163, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.06873711, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.073865086, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.087256, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.10608598, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.07507046, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.09259424, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.12681699, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.100410804, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.10604751, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.081070274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.05526438, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.08341888, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.10189681, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.0579901, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.07295163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.09538716, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.09110011, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.1261724, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.0632766, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.12169714, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.103345424, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.08032772, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.13078132, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.062837526, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.06560793, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.09633704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.091305465, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08007056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.071816824, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.08344013, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.11295288, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.0943059, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.085613444, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.101640455, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.12074279, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.07477636, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.046788033, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.12789752, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.07835208, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.07488192, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.09840833, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.087726355, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.08489817, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.06551945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.10600568, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.079957545, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.08169511, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.10698615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.12324329, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.07031539, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.09251954, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.077414855, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.07849531, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.06758699, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.079013094, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.10243478, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.075260505, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.07833627, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.115184054, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.06800796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.107638724, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.07767634, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.095287904, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.08139442, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.11992551, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.0668544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.11357001, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.102110036, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.08764534, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.082554325, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.10044286, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.10059985, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.0919818, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.1337339, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.07149996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.07034986, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.10239645, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.09816536, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.068017304, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.09014654, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.099417426, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.080434605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.09481572, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.06758548, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.06450172, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.07090644, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.0706689, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.08942201, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.049453698, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.093830675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.06726952, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.0809245, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.0910893, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.06611873, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.06709023, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.066024035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.1046859, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.08294581, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.10934064, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.12167743, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.092801146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.090811044, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.07751342, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.086805485, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.1479472, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.094836324, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.06677495, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.06258715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.055748448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.07988393, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.058365833, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.0732632, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.07315813, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.10681031, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.08016163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.09544718, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.104331635, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.101991154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.08715983, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.0980685, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.08320778, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.09747377, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.09358898, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.07107576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28100, training loss= 0.11756886, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.103515096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.06923964, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.09093167, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.08895196, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.0932814, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.10275576, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.08359374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28900, training loss= 0.06719415, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.07019281, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.07509191, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.090394825, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.0665386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.08988383, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.060345177, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.0974954, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.1157805, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.0446922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.1020858, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7071765, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.23905064, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.1916103, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.2172452, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.15386084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.17297657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.20466805, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.2246489, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 800, training loss= 0.14209008, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.0720543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.12057187, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.14404652, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.17851317, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.23137446, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.08772847, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.09885873, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.09586382, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.130959, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.14952558, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.10429616, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.16418341, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.114334345, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.12543039, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.07476654, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.08270453, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.059708416, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.120879084, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.18424386, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.12011464, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.086988606, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.12294108, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3100, training loss= 0.08829324, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.08910563, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3300, training loss= 0.09415932, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.10791175, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.084403664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.08982429, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.08319768, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.09352384, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.1634379, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.07680197, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.10679194, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.121058345, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.08396506, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.083667785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.105293125, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.09820746, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.103536606, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.109782696, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.096964195, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.111799836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.1287392, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.14187698, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.091581784, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.12305033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.12882568, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.09614092, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.101080924, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.0640367, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.11026235, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.08694343, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.09465194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.073065996, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.10396881, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.120127834, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.07309614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.101479426, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.13618864, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.08893352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.08591698, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.102378786, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.07743494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.1353892, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.117406026, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.10787486, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.07995214, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.085696764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.08716567, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.0741705, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.105213575, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.063305005, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.058286756, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.095482394, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.053195477, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.09100586, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.08746049, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.08896663, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.09490018, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.09266165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.14489153, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.09560255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.08570884, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.08094206, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.08816618, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 0.0477635, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.082770616, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.080370024, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.14578018, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.09843205, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.12671211, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.11189146, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.065990336, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.08666404, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.06073989, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.080694914, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.058127128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.06127384, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.07309161, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.08828056, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.07214813, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.09634128, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.06493075, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.09577261, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.07418458, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.09167163, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.09983274, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.093198754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.09077652, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.10213571, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.0731809, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.12406793, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.07390142, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.0938129, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.07454283, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.06377338, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.10305039, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.09340404, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.07057698, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.09523441, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.08857347, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13000, training loss= 0.05904265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.08599731, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.07339236, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.13446848, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.061075956, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.05055625, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.122640446, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13700, training loss= 0.083808295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13800, training loss= 0.06657916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.07494019, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14000, training loss= 0.093919456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.10225189, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.10987489, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.066442475, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14400, training loss= 0.0597264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.051074278, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14600, training loss= 0.06851565, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.112652004, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.0667364, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.065727405, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.070730686, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.09681693, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.0798389, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.11367162, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.08925638, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.08205301, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.10357031, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.0659292, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.09937118, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.05582442, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.06564439, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.071443416, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.11129583, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.05195228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.08389424, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.064120285, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.099516675, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.08534201, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.08329287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.09957536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.07986415, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.06860213, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.062769696, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.09271163, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.064010434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.079630606, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.05881612, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.08491944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.05289026, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.102791704, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.101790786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.07751389, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.07620348, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.10710261, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08171126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.118739046, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.10178261, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.05066865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.07214584, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.063523404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.06708856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.0730753, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.05104591, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.06434226, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.09952335, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.08192752, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.08579757, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.08087213, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.047008973, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.10662862, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.087049484, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.07969273, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.049053628, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.10109438, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.069816664, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.09277431, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.07397812, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.08086422, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.054289024, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.103520654, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.0741269, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.06834524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.097304665, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.06737905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.081945986, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.059371345, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.093985625, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.0889632, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.101537004, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.08619742, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.07140281, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.08747627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.09926689, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.09909686, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.08767359, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.0903545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.067155555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.06277242, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.07564706, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.072341576, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.08929781, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.06900189, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.066086456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.10709587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.067164056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.090413675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.09256646, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.08196544, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.07206775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.07214361, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.09067246, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.09441896, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.07078712, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.08556199, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.066612706, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.0955483, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.06327323, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.077602684, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.10803133, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.0777705, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25000, training loss= 0.0517941, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.060820963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25200, training loss= 0.09365113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.076807916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.10068173, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.088253565, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.088028885, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.10764145, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.080085956, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.039467536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.08354521, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.083465494, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.063759804, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.09168186, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.086835705, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.068612635, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.06493713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.0474736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.074026644, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.11463173, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.08605966, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.061313413, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27200, training loss= 0.10449551, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.09250131, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.09175195, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.128678, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.05381697, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.07870325, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27800, training loss= 0.052218646, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.064587496, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.07494232, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.074808374, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.10880375, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.076337956, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28400, training loss= 0.0652606, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.06252806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.0797633, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.06295075, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.0651332, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.057343762, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.08593416, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.1038911, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.0378374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.08925572, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.06247798, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.07794793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.07853702, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.072499335, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.07592707, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.08202523, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.8007385, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.3759109, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.20905583, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.1674849, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.33519498, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.25357112, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.1565032, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.08490523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 800, training loss= 0.25469038, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.116465025, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.14704633, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.13417418, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.1380908, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.1860589, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.14376275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.08153872, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.09496165, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.12089518, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.13368754, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.12938969, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.09012919, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.09028092, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.14882943, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.13358699, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.1857601, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.14289974, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2600, training loss= 0.119661026, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.1460846, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.095798604, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.15071897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.12963599, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.12162483, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.10759297, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.109735765, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.10568822, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.15752816, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.10113952, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.11751113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.09914979, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.09962737, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.10020591, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.11973139, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.10458379, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.1198569, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.11441044, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.1734084, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.123625256, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.12409597, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.082016654, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.10386048, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.0814955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.11569134, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.11202162, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.11299004, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.188599, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.16338049, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.07005872, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.101876624, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.070486225, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.114452995, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.17929162, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.13988858, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.116920814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.069822736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.12839389, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.13109668, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.055628333, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.12451926, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.07882215, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.070731476, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.08384029, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.08165151, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.14072408, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.09203512, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.09484894, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.099999055, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.097273275, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.082231574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.13505603, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.15643528, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.11620115, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.10579467, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.06523996, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.11163759, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.049878146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.05845005, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.096014306, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.15916975, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.09900855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.059134874, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.11578626, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.0980182, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.093398996, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.09766762, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.10830362, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.113393545, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.091555834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.09615897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.10076954, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.094881594, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.047556154, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.09169613, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.0731968, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.12379236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.08043078, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.1134875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.07950563, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.11523485, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.10675679, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.06924971, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.076022014, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.0869757, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11200, training loss= 0.08040551, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.07120169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.13750455, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.11581271, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.08648283, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.10303984, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.0959478, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.09148775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.11716904, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.06288498, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.093298435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.092294574, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.11003726, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.15033123, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.074149705, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.08893981, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.0809698, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.10564541, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.12640004, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.06954855, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.09309581, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.07224391, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.08428562, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.12717025, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.09656931, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.060756207, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.102386095, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.061249197, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.06837966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.099285364, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.05821808, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.069351904, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.08177761, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.085886545, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.110501096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.10329443, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.123032995, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.11782604, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.10329809, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.11270131, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.089047216, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.079174906, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.102473274, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.09154939, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.077237844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.07902743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.11783234, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.07342983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.0833019, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.04723865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.10764056, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.13213544, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.13261934, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.10004524, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.0765302, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.07742168, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.06936813, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.10053554, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.056599896, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.100434445, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.06990232, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.12785593, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.08064134, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.05491634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.0708004, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.04948948, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.07582959, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.10747389, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.059248745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.08142445, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.05922844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.09760169, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.087320514, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.07963157, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.10555503, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.088060334, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.09631395, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.061631814, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.061076164, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.06484745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.05690158, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.051061045, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.085481524, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.05836324, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.062028628, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.07746806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.07385567, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.07816724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.07455064, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.119624056, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.12109031, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.06882152, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.10757916, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.12242854, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.09894148, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.06584994, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.11004988, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.06930033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.09823172, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.09302592, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.06565306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.10488013, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.09845261, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.08726898, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0830123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.071017265, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.056445614, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.04028839, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.03976198, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.09628457, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.1228261, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.11659634, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.060078297, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22500, training loss= 0.0947008, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.09812685, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.05293412, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.056007743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.05847432, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.063937284, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.070133306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.076857485, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.06530064, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.08265392, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23500, training loss= 0.0822566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.05275803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.07412028, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.07322452, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.0791523, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24000, training loss= 0.061948944, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.067056, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.07557861, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.095548496, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.12004055, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.09326736, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.06903211, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.09360014, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.04309369, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.08119069, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.0862108, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.053807285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.08172788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.12172789, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.078652, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.08312382, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.05934092, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.06556875, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.052777875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.13803323, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.09125602, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.10792716, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.11198686, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.072649814, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.11029397, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.045793254, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.073165044, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.08349662, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.0796192, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.08254373, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.0775663, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.08658799, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.07987376, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.089593306, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.07824769, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.07008099, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.0774736, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.054560013, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.055779234, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.06426854, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.09358931, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.050491057, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.10627834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.06330772, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.06728957, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.100262165, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.07795589, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.064498186, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.064569876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.069215536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.077539146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.07055109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.0845669, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.057347577, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.082003, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.056976285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0979707, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.090430476, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.07042348, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.05002766, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0709616, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.29111066, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.27851135, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.16252993, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.14311846, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.118486166, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.19025141, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.1590406, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.25083113, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.10260371, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.10929673, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.15518342, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.14230104, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.17243166, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.1879757, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.13217884, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.1365946, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.22315031, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.09774865, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.10617661, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.10748326, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.11242195, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.13561827, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.113558784, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.118818365, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.1081197, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.15117235, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.08830021, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.11580584, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.12951334, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.111506514, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.14205447, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.08380531, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.09292834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3400, training loss= 0.056032438, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.07122354, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.14085238, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.13154292, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.12539554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.13672253, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.05083784, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.12675734, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.16194895, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.077838555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.09667676, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.07454236, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.06988637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.11435522, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07377047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.104041934, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.07008325, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.10001603, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.123287715, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.11348644, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.12854268, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.06487288, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.10912982, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.09791374, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.107378826, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.10625221, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.0932411, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.09134723, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.06571013, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.09203808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.12553473, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.08146616, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.06582311, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.10979714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.08539767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.08718432, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.11424189, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.10560571, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.11671914, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.06595565, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.069552325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7500, training loss= 0.09596147, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.07120241, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.1083851, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.07859487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.091084145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.0858413, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.09789929, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.05758558, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.09393976, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.078454174, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.09924754, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.08349538, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8700, training loss= 0.124507666, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.08073299, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.072999, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.08330671, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9100, training loss= 0.13675043, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.053394873, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9300, training loss= 0.057073023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.11108432, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.09413057, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.113380395, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.044346903, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.08720137, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.12039942, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.10678972, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.075748, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.078512534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.053527683, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.08819311, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10500, training loss= 0.06598578, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10600, training loss= 0.09204786, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.12229255, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.033907197, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10900, training loss= 0.04984189, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11000, training loss= 0.060982812, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.09176934, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.099394575, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.11994503, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.061814588, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.13299477, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.08402106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.107531324, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.10010096, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.115449086, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.070026815, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.07092691, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.070952125, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.1057923, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.09803232, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.06813324, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.068443805, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12700, training loss= 0.10109569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.095891535, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.058832236, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.048116613, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.08035528, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.07600709, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.07130214, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.10099488, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.08742868, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.067457065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.11670897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.07158119, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.06724142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.06292888, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.091158316, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07820896, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.11375482, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.07021543, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.056987956, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.10850399, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.12034651, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.061341193, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.095951766, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.093666896, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.08575565, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.062029097, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.112302504, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.10418576, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.0638159, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.06998252, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.068231866, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.1090055, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.06559339, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.06880096, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.08511644, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.06821284, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.11354754, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.11269079, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.07916269, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.06918279, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.07144951, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.0602163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16900, training loss= 0.0651411, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.1282574, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.094090715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.07364641, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17300, training loss= 0.072914496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.06391642, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.052532904, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.1496299, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.08552625, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.074128285, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.08364929, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.08399713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.08821931, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18200, training loss= 0.08210654, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.08326241, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.07345573, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.06431724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.1008716, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.062430765, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.037235405, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.083976254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.083517686, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.09266524, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.08069195, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.086093225, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.044626646, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.09370758, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.07148144, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.122458376, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.10715208, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.08801688, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.07544152, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.064316384, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.048695277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.084540896, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.052671526, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.123235755, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.10305647, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.101677805, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.076172434, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.055294663, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.07104323, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.06928707, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.06122068, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.09454688, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.07958829, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.112558804, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.03491822, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.08419748, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.055274516, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.07064866, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.077544995, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.051675733, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.06871084, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.055654097, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.09309967, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.07872988, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.07797416, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22700, training loss= 0.10492554, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22800, training loss= 0.06412629, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.07727657, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.12638159, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.12078357, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.103613034, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.08519021, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.062763736, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.060363512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.06866411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.11769591, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.08909009, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.09484886, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.09985089, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.08199743, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.09187712, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.09273415, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.063192226, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.062153704, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.079042144, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.05011357, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.057748854, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.08899619, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.056292135, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.08337821, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.08164905, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.09371454, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.09469272, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.046394747, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.07105397, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.095387965, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.063331604, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.07674999, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.06859882, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.05945192, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.074595176, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.074987955, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.09708761, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.08267436, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.11445705, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.07417063, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.05990215, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.07002159, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.12339866, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.07171236, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.078175284, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.09784472, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.058076873, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.06958663, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.08335447, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.06782533, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.07416364, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.08596823, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.09455555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.07845953, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.057740416, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.067905545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.04942957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.115105376, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.0941839, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.07531813, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.08331175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.051405575, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.111941576, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.08506981, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.062639534, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.07268871, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.11364565, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.079811774, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.075551875, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.07404411, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.054517914, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.072124146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.8233639, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.35962006, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.14823107, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.39453042, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.25894234, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.13243505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.28338525, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.19290887, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.14428948, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.1692244, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.14353454, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.17800987, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.20471683, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.17470591, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.13230573, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.16075432, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.15768512, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.12710193, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.14802836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.11825621, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.13469687, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.18066113, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.07839801, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.11192987, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.1673444, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.12982395, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.105474606, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2700, training loss= 0.14192274, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2800, training loss= 0.15267117, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.1874366, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3000, training loss= 0.1873631, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3100, training loss= 0.07983803, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3200, training loss= 0.07241885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.10933518, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.1466732, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.06330055, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.10846192, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.19436045, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.086336836, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.11704133, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.098959126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.076386966, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.18940365, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.10549366, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.13002928, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.1238844, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.10142722, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.12388136, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.103033006, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.104923606, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.09794328, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.08268328, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.10798787, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.07586991, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.1097628, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.111829005, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.12822048, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.069213614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.09505858, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.11134906, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.12680809, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.08380236, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.13940595, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6300, training loss= 0.1164931, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6400, training loss= 0.11989772, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6500, training loss= 0.12617813, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6600, training loss= 0.123149894, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.10088443, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6800, training loss= 0.09930837, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.0866871, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.08102595, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.14221041, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.08389231, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.09110137, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.0652363, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.11156111, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7600, training loss= 0.11439735, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.092870794, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.12260624, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.19096556, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8000, training loss= 0.04381941, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.13853632, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.088640235, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.108648874, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.102003455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.16292536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.12191825, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.084669426, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.05072477, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.059231944, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.109928824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.115285076, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.07734525, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.07743191, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.10350662, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.04973743, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.09246179, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.11639897, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.057676304, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.0887283, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.17894287, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.08014852, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.06686588, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.06560654, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.048818123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.11823382, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.09727647, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.15789323, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.098794125, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.0745201, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.07914054, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.04942448, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.1283292, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.07982587, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.054755248, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.1004137, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.103192985, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.11511002, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.08698948, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.05742106, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.08653845, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.09110712, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.07297209, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.06839466, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.06984448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.07562844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.047838893, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.10201603, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.06727088, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.088781156, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.08689314, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.062822856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.04381452, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.07420884, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.07573175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.1015439, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.10026176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.06968337, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.062244434, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.05395825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.0813512, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.10256984, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.08275776, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.06805604, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.08081507, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.09233816, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.07962608, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.11702285, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.067623965, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.07452057, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.093137816, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.08815644, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.085783355, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.10033708, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.051513743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.08473863, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.0913555, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.087292336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.13556205, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.09084966, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.124340296, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.06900171, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.100892045, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.081990205, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.13394618, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.099716894, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.08090953, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.05561742, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.064247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.09655825, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.10775884, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.08154001, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.060312875, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.05167904, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.049134985, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.10152457, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.06301048, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.06383967, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.100428455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.06759488, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.12297558, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.12092091, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.106149696, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.06041568, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.06888816, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.054062456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.08041274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.06161275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.077277526, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.059485514, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.07577035, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.082466975, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.063910924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.089319006, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.08989257, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.08428838, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.08188011, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.05560387, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.08689709, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.063697666, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.09921243, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.08863894, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.04665177, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.07056519, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.058714755, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.0698519, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.08587855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.08062037, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.11958659, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.071780704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.07592922, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.051830377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.06229052, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.069024056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.084340505, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.0704888, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.05811876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.0844473, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.12757571, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.070596226, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.08381747, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.053283136, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.045670986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.078157306, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.06788013, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.04972767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.05076548, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.054969724, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.08456423, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.10061156, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.06872226, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.08071911, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.06802923, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.10422194, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.07048604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.08372269, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.08814063, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.08437844, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.09414265, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.111627914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.05702305, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.09220454, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.07143589, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.0728122, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.05975076, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.06937852, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.06675934, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.07195142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.094158344, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.071765, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.10026812, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.079507925, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.13532524, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.049533058, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.07513517, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.050593983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.092249475, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.0795094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.07647156, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.06091087, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.09824531, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.11034913, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.07008618, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.08269354, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.070918374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.10009052, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.07397982, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.053986695, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.06716655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.09016045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.10375377, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.071637474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.064253405, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.08920061, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.04114233, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.10152487, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.07973173, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.055053182, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.0576393, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.077598505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.04355753, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.06496754, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.06566192, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.07013395, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.06494465, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.07176416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.08894961, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.068479516, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.09722053, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.10513683, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.06618881, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.06784272, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.1019569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.1279144, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.044826154, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.08266377, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.07539267, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.07046729, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.08456004, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.06416359, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.99417776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.37815148, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.20807038, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.3167445, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.13228917, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.07761877, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.19240265, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.28171784, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.072039545, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.13629891, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.16299795, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.10890444, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.17287278, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1300, training loss= 0.15287119, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1400, training loss= 0.1490074, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1500, training loss= 0.110101126, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1600, training loss= 0.115815535, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1700, training loss= 0.13755675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.13208048, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.16848277, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.08146113, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.11654045, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.11735799, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.18551712, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.14342518, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.14192866, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.091512874, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.1038713, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.107678354, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.10897279, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.16180383, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.13056736, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.16503394, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.10839095, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.052679628, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3500, training loss= 0.15121834, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.09618663, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.0918625, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.071058765, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.088095665, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.06734126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.100995205, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.092386305, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.10817629, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.11889732, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.17325042, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.08352583, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.106198825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.14196973, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.09482396, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.057905924, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.117806755, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.072338514, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.11798372, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.09062453, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.08372969, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.10262437, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.115513384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.05730307, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.047813084, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.105816655, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.08025736, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.07112456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.08026868, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.1234776, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.09559498, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.121857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6700, training loss= 0.06586941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.08910876, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.11097548, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.08507854, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.09914974, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.08918456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.10966387, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.1085056, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.09167736, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.04151333, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.091596544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.08449439, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7900, training loss= 0.071940996, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.07594998, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.07708952, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.08469422, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.09757496, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.086468756, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8500, training loss= 0.076341234, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.08809273, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.061160255, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.072912894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.10417121, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.06066307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.07453885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.07397729, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.046883, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.057790514, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.0722585, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.10248237, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.116728544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.09576523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.087204605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.074055016, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.067341, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.07975351, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.066182874, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.10977539, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.0743986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.10096645, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.101467125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.065900296, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.13709572, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.066573255, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.063806646, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.060398694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.07715563, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.062226802, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.09027411, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.09008171, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.05853462, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.057217717, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.07666037, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.1007046, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.129628, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.05845012, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.058223166, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.08457759, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.09214151, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.070758305, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.07009607, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.0611596, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.089012384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.07308795, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.1081594, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.092979066, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.07733482, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.09483649, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.063234285, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.07237154, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.06956824, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.06433012, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.08058051, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.09759809, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.07850835, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.08630504, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.09640558, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.040221103, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.09223636, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.057309806, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.10393365, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.08701482, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.06681465, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.08080773, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.07009444, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.07504319, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.08606105, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.095921755, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.07144928, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.09560861, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.09940896, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.09412859, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.08164407, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.1022225, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.09131526, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.09233594, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16300, training loss= 0.079641126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.07052597, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.07267556, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.06447631, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.06833187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.086290665, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.074043095, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.08137077, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.065399185, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.120056346, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.09423983, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.053126503, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.08310912, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.079784326, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.052604835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.11560786, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.081651315, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.05838086, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.06155723, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.083254054, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.034259904, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.08395425, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.122429505, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.06394335, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.06434953, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.06945069, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.06174289, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.08566785, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.07596179, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.052959073, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.05787867, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.09716655, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.03975615, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.083415784, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.057278067, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.087794386, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.07953211, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.07781674, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.0739571, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.07180704, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.061009623, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.059386928, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.061071344, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.06593185, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.054756235, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.061715897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.12043076, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.08237188, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.050473828, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.069728546, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.08563191, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.07589161, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.053382423, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.094909705, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.057582863, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.06291473, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.06781167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.068117015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.09103253, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.09400872, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.047788456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.089353584, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.07039058, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.064028196, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.07158259, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.08518752, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.0824963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.07458096, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.08682646, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.06955553, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.087683015, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.07715796, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.122816026, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.03981123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.08137949, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.06508264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.049777407, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.06434102, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.080853835, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.0638253, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.049905352, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.047240384, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.08602887, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.05231882, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.08442967, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.056598973, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.11896999, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.057381656, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.11311766, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.058018245, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.07303666, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.062427606, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.054008313, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.075479664, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.06098873, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.070324376, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.061569, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.06663314, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.06215025, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.049898442, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.04557711, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.05908955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.06734982, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.064567566, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.061701532, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.054275822, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.06739159, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.08552916, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.05304096, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.07539248, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.061168768, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.092546046, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.051858265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.07817796, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.072052546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.0718569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.09065211, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.07769733, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.04489098, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.088302486, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.08504224, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.059127677, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.06550082, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.05325365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.07931054, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.07241253, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.09498202, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.07841005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.096154325, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.08884191, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.07152255, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.09150489, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.05534637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.058395803, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.068683855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.08795939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.0975325, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.07576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.28416055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.47142705, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 300, training loss= 0.12424256, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.17597339, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.30604893, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.24683075, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 700, training loss= 0.24552155, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 800, training loss= 0.15063776, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.15388623, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1000, training loss= 0.21195759, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.15746292, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.10182802, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.16427334, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.19412822, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.18526152, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.09005332, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.16492319, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.09558568, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.15268101, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.17497815, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.11652945, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.13989985, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.14975472, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.1249876, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.20532206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.14156681, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.16912214, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.14371844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.11192928, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.24032998, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.09845338, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.09911469, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.075746626, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.14202718, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.073646426, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.10119228, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.1402379, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.10509162, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.11006254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.12082369, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.07420029, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.05232733, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.12740898, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.084227055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.09804708, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.14802007, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.16468453, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07456611, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.082219146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.117998905, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.06533397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.054079246, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.10934639, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.11018726, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.08345761, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.10333511, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.117320485, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.073329784, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.11779674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.08863317, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.1089685, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.04951626, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.0721437, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.15209673, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.12948437, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.10909511, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.14952971, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.052235216, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.093669094, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.041645855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.08987246, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.13556042, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.10455946, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.088684455, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.0742332, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.0949002, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.16644222, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.068382286, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.08086055, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.055019543, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.09609126, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.06315327, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.10563271, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.09103789, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.08921402, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.07744408, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.10267002, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.12063869, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.06703646, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.060319085, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.119271815, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.1607791, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.12009739, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.106209695, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.0577923, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.06681462, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.069487706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.053773027, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.12800443, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.06615745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10100, training loss= 0.07367886, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.119701885, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.102549516, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.1003549, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.083338715, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.046785604, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.09544839, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.092076994, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.10849552, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.07131956, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.06149522, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.120303385, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.1457731, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.09966997, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.070185944, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.07982942, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.057913285, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.06369455, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.063213274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.12637375, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12100, training loss= 0.07773583, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.07691778, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.10642078, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.1160684, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12500, training loss= 0.092410654, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.11237575, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.106388055, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.09691822, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12900, training loss= 0.09184164, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.09307896, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.07822062, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.039126106, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13300, training loss= 0.08394144, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.09096903, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.09991073, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.12164609, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.09749389, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.077672, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.09747755, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.085558675, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.049113113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.07907612, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.051198296, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.07677119, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.06761582, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.07628194, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.07985944, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.088180155, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.076822236, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.038829386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.08747149, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.050909147, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.08193915, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.07491825, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.10683082, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.04431674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.0968462, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.056888036, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.13603692, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.094129644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.10578069, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.086631574, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.062067077, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.08094469, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.09392318, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.08115141, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.099566646, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.068139434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.05558621, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.09719646, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.09271916, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.048884887, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.055162627, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.057923477, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.067897655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.09592187, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.093272746, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.121501006, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.054560922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.09980027, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.06128462, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.08727306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.06965334, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.09240296, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.067557216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.094737686, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.06947543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.16796438, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.044979144, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.05902872, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.053794257, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.07819093, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.05402106, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.15395857, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.07425962, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.047196742, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.10513863, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.056374714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.07406206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.11782161, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.068954535, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.048698492, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.057856094, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.058102332, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.09573587, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.051156316, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.07626452, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.11497785, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.06941567, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.07778019, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.0652794, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.05687558, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.07613685, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.06731024, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.09440193, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.07905251, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.09787738, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.077900276, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.1115991, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.07668715, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.10479981, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.06780145, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.058824215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.094088756, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.053386398, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.051690005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.07417865, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.077663824, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.08399536, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.06642512, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.066682726, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.082186125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.109710544, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.052835725, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.0916755, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.046667825, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.07854075, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.10026414, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.04345294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.058976386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.06389897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.056193195, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.0658965, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.06788025, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.0635218, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.06638203, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.06767697, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.07610414, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.068432085, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.052392274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.066910684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.05965912, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.078182735, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.08157699, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.06689526, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.049787723, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.060982816, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.074374914, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.077645496, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.08109778, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.0890857, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.09310793, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.058013923, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.05705058, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.06917721, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.048214655, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.055536315, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.05780406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.09101857, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.052410647, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.06552569, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.077844515, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.045013975, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.10714216, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.097228505, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.06717624, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.09318358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.070364274, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.07655486, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.09118569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.048440296, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.059148345, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.09873282, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.058044646, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.07391129, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.06025638, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.06452244, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.05536122, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.086140946, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.0535155, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.08953205, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.068575576, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.08174569, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.047025472, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.080529034, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.113589324, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.06379039, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.062257856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.070162475, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.444587, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.24958147, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.2821079, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.2922485, training acc= 93.00000071525574%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.23400988, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.23902696, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.2142823, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.18388884, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.21011114, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.12348028, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.14387687, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1100, training loss= 0.1222828, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1200, training loss= 0.14157857, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.123819396, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.20692694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.13767052, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.1095966, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.116878375, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.14692695, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.10495939, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.08305101, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.114583895, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.12068703, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.08558004, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.106653295, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.104667425, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.13183004, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.07038483, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.1547243, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.07463188, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.08831853, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.07672007, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.07668165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.07958934, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.16444933, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.114535496, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.06322326, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3700, training loss= 0.1051592, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3800, training loss= 0.09109637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3900, training loss= 0.13132519, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.102663465, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4100, training loss= 0.09454463, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.109995455, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4300, training loss= 0.105483055, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4400, training loss= 0.06253496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.05728689, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4600, training loss= 0.083051026, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4700, training loss= 0.062358256, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.07145834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.10257095, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5000, training loss= 0.14157704, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.083421685, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.073906936, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5300, training loss= 0.07003178, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5400, training loss= 0.08782961, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5500, training loss= 0.093881465, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.11897792, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5700, training loss= 0.08521638, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5800, training loss= 0.09582589, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.06578866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.10322801, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.07350995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.08304135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.07715782, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.08330047, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.0764495, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.11043641, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.07898243, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.11844301, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.073869064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.11053934, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.0949121, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.09243324, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.08147559, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.14719515, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.10149862, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.12004661, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.089448296, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.053536065, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.11295661, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.14358515, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.05067737, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.04955791, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.075963706, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.0502084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.07737148, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.06569947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.071233526, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.05827735, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.11672404, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.068798475, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.10474752, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.09545207, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.11101721, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.08325382, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.09612414, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.07208564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.12311071, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.067050874, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.07240005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.10007913, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.05450229, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.06150559, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.05844746, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.08830949, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.055649836, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.10979124, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.06582486, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.07644254, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.08979325, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.07753466, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.08129381, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.07017345, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.061698135, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.063023895, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.07080419, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.043299895, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.07464838, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.06560139, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.06974299, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.10956113, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.08987146, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.07833315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.065616146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.0806219, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.13260166, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.07349078, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.085967965, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.061259862, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.0811097, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.0703905, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.063314095, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.05730663, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.055115614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.11055483, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.06311753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.060449753, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.05627485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.08426258, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.0582144, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.07453507, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.101463, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.10192869, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.06584574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.058470856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.078918934, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.06081372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.073382676, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.05703219, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.08884728, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.0519206, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.08368224, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.070205644, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.06182103, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.044556115, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.072891094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.07123548, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.0506523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.08997122, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.049106035, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.0847522, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.06547852, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.057765972, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.09052712, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.096845925, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.107387066, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.0467225, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.11629216, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.063957214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.07487399, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.053218063, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.074712396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.0770904, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.06437246, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.04840631, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.059449535, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.05895872, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.060819387, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.0497545, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.061031587, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.07120464, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.07490389, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.06710715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.100512095, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.05455827, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.07878462, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.10979847, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.06550182, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.07546369, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.084362276, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.06750146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.08688013, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.06377131, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.0685987, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.06291701, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.082763754, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.080643825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.06039403, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.09733529, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.084288955, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.052270006, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.06454462, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.07934531, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.05636847, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.0899474, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.076763034, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.052161463, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.09621369, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.050016195, training acc= 99.00000095367432%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tB8zakGK3Zzp"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### --\n",
        "#### Valid acc= 98.5 %\n",
        "#### Validation Accuracy Test 98.08917236328125 ...\n",
        "==================================================\n",
        "W1 = 5 ...\n",
        "W2 = 4 ...\n",
        "W3 = 0 ...\n",
        "**************************************************\n",
        "==================================================\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DysvlYK_3UuW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bFyJSL6Yx7Dt"
      },
      "cell_type": "markdown",
      "source": [
        "## contd from above different start point"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oOV5_7Er2qmC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "splt.plot(ValidAccuracy_Track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QFb2ZTPYk0_K"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WOMNr2hxk1Py"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xClVvxq_hQ50",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YmTBX6sTqm6m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tXZ8K7a_qm2Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
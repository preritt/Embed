{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "95p08of HARfeedbackFullDatasetEpochBased0430_Test94p88.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/95p08of_HARfeedbackFullDatasetEpochBased0430_Test94p88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "e7b7a038-6441-486e-8435-97faac0c09e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.031224</td>\n",
              "      <td>0.052527</td>\n",
              "      <td>0.115961</td>\n",
              "      <td>-0.875200</td>\n",
              "      <td>-0.957705</td>\n",
              "      <td>-0.900766</td>\n",
              "      <td>-0.868209</td>\n",
              "      <td>-0.959311</td>\n",
              "      <td>-0.903576</td>\n",
              "      <td>-0.871754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868067</td>\n",
              "      <td>-1.420373</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>0.041417</td>\n",
              "      <td>-0.618447</td>\n",
              "      <td>1.179824</td>\n",
              "      <td>0.885911</td>\n",
              "      <td>-0.877134</td>\n",
              "      <td>0.056712</td>\n",
              "      <td>0.119820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.176101</td>\n",
              "      <td>0.356526</td>\n",
              "      <td>-0.417228</td>\n",
              "      <td>0.311962</td>\n",
              "      <td>0.450204</td>\n",
              "      <td>0.852550</td>\n",
              "      <td>0.306335</td>\n",
              "      <td>0.367644</td>\n",
              "      <td>0.888266</td>\n",
              "      <td>0.245780</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.124388</td>\n",
              "      <td>0.568143</td>\n",
              "      <td>0.749813</td>\n",
              "      <td>0.297311</td>\n",
              "      <td>0.234130</td>\n",
              "      <td>1.557127</td>\n",
              "      <td>1.772883</td>\n",
              "      <td>-0.028307</td>\n",
              "      <td>0.797992</td>\n",
              "      <td>1.281095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.401526</td>\n",
              "      <td>-0.255999</td>\n",
              "      <td>-0.227483</td>\n",
              "      <td>0.724607</td>\n",
              "      <td>1.012197</td>\n",
              "      <td>0.537364</td>\n",
              "      <td>0.702820</td>\n",
              "      <td>1.059839</td>\n",
              "      <td>0.485615</td>\n",
              "      <td>1.002515</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247473</td>\n",
              "      <td>1.222819</td>\n",
              "      <td>1.111675</td>\n",
              "      <td>-1.753009</td>\n",
              "      <td>-0.472243</td>\n",
              "      <td>1.453390</td>\n",
              "      <td>0.416217</td>\n",
              "      <td>-0.390767</td>\n",
              "      <td>0.767157</td>\n",
              "      <td>0.638829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.241090</td>\n",
              "      <td>0.149696</td>\n",
              "      <td>0.354921</td>\n",
              "      <td>-0.829910</td>\n",
              "      <td>-0.829986</td>\n",
              "      <td>-0.777500</td>\n",
              "      <td>-0.821882</td>\n",
              "      <td>-0.817905</td>\n",
              "      <td>-0.772262</td>\n",
              "      <td>-0.844885</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025308</td>\n",
              "      <td>-0.373414</td>\n",
              "      <td>-0.461477</td>\n",
              "      <td>-0.076678</td>\n",
              "      <td>-0.191304</td>\n",
              "      <td>0.185464</td>\n",
              "      <td>-0.753572</td>\n",
              "      <td>-0.179145</td>\n",
              "      <td>0.956654</td>\n",
              "      <td>0.816782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.509378</td>\n",
              "      <td>0.598757</td>\n",
              "      <td>1.235366</td>\n",
              "      <td>1.671994</td>\n",
              "      <td>1.222057</td>\n",
              "      <td>2.101020</td>\n",
              "      <td>1.609877</td>\n",
              "      <td>1.248976</td>\n",
              "      <td>1.892042</td>\n",
              "      <td>1.919040</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105242</td>\n",
              "      <td>0.009285</td>\n",
              "      <td>-0.345760</td>\n",
              "      <td>0.989375</td>\n",
              "      <td>1.564256</td>\n",
              "      <td>-0.593559</td>\n",
              "      <td>0.870385</td>\n",
              "      <td>-0.557192</td>\n",
              "      <td>0.373064</td>\n",
              "      <td>0.783913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  0.031224  0.052527  0.115961 -0.875200 -0.957705 -0.900766 -0.868209   \n",
              "1 -0.176101  0.356526 -0.417228  0.311962  0.450204  0.852550  0.306335   \n",
              "2  0.401526 -0.255999 -0.227483  0.724607  1.012197  0.537364  0.702820   \n",
              "3  0.241090  0.149696  0.354921 -0.829910 -0.829986 -0.777500 -0.821882   \n",
              "4 -0.509378  0.598757  1.235366  1.671994  1.222057  2.101020  1.609877   \n",
              "\n",
              "        7         8         9    ...       551       552       553       554  \\\n",
              "0 -0.959311 -0.903576 -0.871754  ...  0.868067 -1.420373 -1.031076  0.041417   \n",
              "1  0.367644  0.888266  0.245780  ... -0.124388  0.568143  0.749813  0.297311   \n",
              "2  1.059839  0.485615  1.002515  ...  0.247473  1.222819  1.111675 -1.753009   \n",
              "3 -0.817905 -0.772262 -0.844885  ... -0.025308 -0.373414 -0.461477 -0.076678   \n",
              "4  1.248976  1.892042  1.919040  ... -0.105242  0.009285 -0.345760  0.989375   \n",
              "\n",
              "        555       556       557       558       559       560  \n",
              "0 -0.618447  1.179824  0.885911 -0.877134  0.056712  0.119820  \n",
              "1  0.234130  1.557127  1.772883 -0.028307  0.797992  1.281095  \n",
              "2 -0.472243  1.453390  0.416217 -0.390767  0.767157  0.638829  \n",
              "3 -0.191304  0.185464 -0.753572 -0.179145  0.956654  0.816782  \n",
              "4  1.564256 -0.593559  0.870385 -0.557192  0.373064  0.783913  \n",
              "\n",
              "[5 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "2c6cfb5c-9a39-45b7-d8fe-770d30dd399e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  3\n",
              "1  1\n",
              "2  0\n",
              "3  4\n",
              "4  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "e79cdc9a-461e-437c-c297-afa7d9f5c346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "2a077205-f5a0-4277-bae3-e97babed62b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1471, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "4013e253-a798-42c8-bbaa-08579443b998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDOMf8vCQFNW"
      },
      "source": [
        "## without using vaidation data for fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "222fea38-eb4b-47d4-a9ed-22d0ca76b87d",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4794
        }
      },
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(374, ), max_iter=500, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.01)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52720526\n",
            "Iteration 2, loss = 0.15379691\n",
            "Iteration 3, loss = 0.11074311\n",
            "Iteration 4, loss = 0.08947817\n",
            "Iteration 5, loss = 0.07609836\n",
            "Iteration 6, loss = 0.06703077\n",
            "Iteration 7, loss = 0.06092138\n",
            "Iteration 8, loss = 0.05482786\n",
            "Iteration 9, loss = 0.05074759\n",
            "Iteration 10, loss = 0.04820633\n",
            "Iteration 11, loss = 0.04462717\n",
            "Iteration 12, loss = 0.04117033\n",
            "Iteration 13, loss = 0.03949230\n",
            "Iteration 14, loss = 0.03816921\n",
            "Iteration 15, loss = 0.03526902\n",
            "Iteration 16, loss = 0.03338227\n",
            "Iteration 17, loss = 0.03256753\n",
            "Iteration 18, loss = 0.03047405\n",
            "Iteration 19, loss = 0.02924046\n",
            "Iteration 20, loss = 0.02849386\n",
            "Iteration 21, loss = 0.02730756\n",
            "Iteration 22, loss = 0.02559763\n",
            "Iteration 23, loss = 0.02459467\n",
            "Iteration 24, loss = 0.02391017\n",
            "Iteration 25, loss = 0.02354070\n",
            "Iteration 26, loss = 0.02216005\n",
            "Iteration 27, loss = 0.02149137\n",
            "Iteration 28, loss = 0.02112266\n",
            "Iteration 29, loss = 0.02016297\n",
            "Iteration 30, loss = 0.01943691\n",
            "Iteration 31, loss = 0.01848743\n",
            "Iteration 32, loss = 0.01833975\n",
            "Iteration 33, loss = 0.01734477\n",
            "Iteration 34, loss = 0.01683132\n",
            "Iteration 35, loss = 0.01656447\n",
            "Iteration 36, loss = 0.01629328\n",
            "Iteration 37, loss = 0.01554519\n",
            "Iteration 38, loss = 0.01475836\n",
            "Iteration 39, loss = 0.01461295\n",
            "Iteration 40, loss = 0.01419653\n",
            "Iteration 41, loss = 0.01353610\n",
            "Iteration 42, loss = 0.01370225\n",
            "Iteration 43, loss = 0.01320427\n",
            "Iteration 44, loss = 0.01308621\n",
            "Iteration 45, loss = 0.01274597\n",
            "Iteration 46, loss = 0.01203195\n",
            "Iteration 47, loss = 0.01174829\n",
            "Iteration 48, loss = 0.01125364\n",
            "Iteration 49, loss = 0.01074622\n",
            "Iteration 50, loss = 0.01062621\n",
            "Iteration 51, loss = 0.01044433\n",
            "Iteration 52, loss = 0.01012032\n",
            "Iteration 53, loss = 0.00998317\n",
            "Iteration 54, loss = 0.00957855\n",
            "Iteration 55, loss = 0.00919682\n",
            "Iteration 56, loss = 0.00903952\n",
            "Iteration 57, loss = 0.00882828\n",
            "Iteration 58, loss = 0.00842398\n",
            "Iteration 59, loss = 0.00830306\n",
            "Iteration 60, loss = 0.00800349\n",
            "Iteration 61, loss = 0.00785930\n",
            "Iteration 62, loss = 0.00785182\n",
            "Iteration 63, loss = 0.00758100\n",
            "Iteration 64, loss = 0.00740849\n",
            "Iteration 65, loss = 0.00748268\n",
            "Iteration 66, loss = 0.00716864\n",
            "Iteration 67, loss = 0.00700393\n",
            "Iteration 68, loss = 0.00692167\n",
            "Iteration 69, loss = 0.00658257\n",
            "Iteration 70, loss = 0.00648939\n",
            "Iteration 71, loss = 0.00624277\n",
            "Iteration 72, loss = 0.00612378\n",
            "Iteration 73, loss = 0.00603359\n",
            "Iteration 74, loss = 0.00594559\n",
            "Iteration 75, loss = 0.00585920\n",
            "Iteration 76, loss = 0.00570434\n",
            "Iteration 77, loss = 0.00561283\n",
            "Iteration 78, loss = 0.00554028\n",
            "Iteration 79, loss = 0.00541069\n",
            "Iteration 80, loss = 0.00524976\n",
            "Iteration 81, loss = 0.00527214\n",
            "Iteration 82, loss = 0.00516337\n",
            "Iteration 83, loss = 0.00497239\n",
            "Iteration 84, loss = 0.00485493\n",
            "Iteration 85, loss = 0.00490756\n",
            "Iteration 86, loss = 0.00467278\n",
            "Iteration 87, loss = 0.00460029\n",
            "Iteration 88, loss = 0.00454493\n",
            "Iteration 89, loss = 0.00442256\n",
            "Iteration 90, loss = 0.00432667\n",
            "Iteration 91, loss = 0.00433931\n",
            "Iteration 92, loss = 0.00421722\n",
            "Iteration 93, loss = 0.00419655\n",
            "Iteration 94, loss = 0.00406313\n",
            "Iteration 95, loss = 0.00407564\n",
            "Iteration 96, loss = 0.00401053\n",
            "Iteration 97, loss = 0.00392400\n",
            "Iteration 98, loss = 0.00386804\n",
            "Iteration 99, loss = 0.00379496\n",
            "Iteration 100, loss = 0.00373337\n",
            "Iteration 101, loss = 0.00365417\n",
            "Iteration 102, loss = 0.00360392\n",
            "Iteration 103, loss = 0.00356796\n",
            "Iteration 104, loss = 0.00349700\n",
            "Iteration 105, loss = 0.00347712\n",
            "Iteration 106, loss = 0.00346129\n",
            "Iteration 107, loss = 0.00341398\n",
            "Iteration 108, loss = 0.00332927\n",
            "Iteration 109, loss = 0.00332159\n",
            "Iteration 110, loss = 0.00330862\n",
            "Iteration 111, loss = 0.00318258\n",
            "Iteration 112, loss = 0.00317291\n",
            "Iteration 113, loss = 0.00313192\n",
            "Iteration 114, loss = 0.00312075\n",
            "Iteration 115, loss = 0.00306214\n",
            "Iteration 116, loss = 0.00303800\n",
            "Iteration 117, loss = 0.00300883\n",
            "Iteration 118, loss = 0.00297746\n",
            "Iteration 119, loss = 0.00287678\n",
            "Iteration 120, loss = 0.00285229\n",
            "Iteration 121, loss = 0.00280417\n",
            "Iteration 122, loss = 0.00281288\n",
            "Iteration 123, loss = 0.00279715\n",
            "Iteration 124, loss = 0.00272476\n",
            "Iteration 125, loss = 0.00271742\n",
            "Iteration 126, loss = 0.00268767\n",
            "Iteration 127, loss = 0.00261441\n",
            "Iteration 128, loss = 0.00265474\n",
            "Iteration 129, loss = 0.00261967\n",
            "Iteration 130, loss = 0.00256700\n",
            "Iteration 131, loss = 0.00249650\n",
            "Iteration 132, loss = 0.00251667\n",
            "Iteration 133, loss = 0.00249242\n",
            "Iteration 134, loss = 0.00244083\n",
            "Iteration 135, loss = 0.00249760\n",
            "Iteration 136, loss = 0.00237943\n",
            "Iteration 137, loss = 0.00237679\n",
            "Iteration 138, loss = 0.00234850\n",
            "Iteration 139, loss = 0.00232762\n",
            "Iteration 140, loss = 0.00229602\n",
            "Iteration 141, loss = 0.00230112\n",
            "Iteration 142, loss = 0.00225280\n",
            "Iteration 143, loss = 0.00222079\n",
            "Iteration 144, loss = 0.00221551\n",
            "Iteration 145, loss = 0.00218910\n",
            "Iteration 146, loss = 0.00220109\n",
            "Iteration 147, loss = 0.00214222\n",
            "Iteration 148, loss = 0.00212741\n",
            "Iteration 149, loss = 0.00211983\n",
            "Iteration 150, loss = 0.00208963\n",
            "Iteration 151, loss = 0.00208430\n",
            "Iteration 152, loss = 0.00205445\n",
            "Iteration 153, loss = 0.00202581\n",
            "Iteration 154, loss = 0.00201077\n",
            "Iteration 155, loss = 0.00198594\n",
            "Iteration 156, loss = 0.00201227\n",
            "Iteration 157, loss = 0.00197451\n",
            "Iteration 158, loss = 0.00197394\n",
            "Iteration 159, loss = 0.00191715\n",
            "Iteration 160, loss = 0.00191562\n",
            "Iteration 161, loss = 0.00192284\n",
            "Iteration 162, loss = 0.00191362\n",
            "Iteration 163, loss = 0.00187164\n",
            "Iteration 164, loss = 0.00184135\n",
            "Iteration 165, loss = 0.00183465\n",
            "Iteration 166, loss = 0.00182088\n",
            "Iteration 167, loss = 0.00180899\n",
            "Iteration 168, loss = 0.00180355\n",
            "Iteration 169, loss = 0.00177716\n",
            "Iteration 170, loss = 0.00176685\n",
            "Iteration 171, loss = 0.00175030\n",
            "Iteration 172, loss = 0.00175049\n",
            "Iteration 173, loss = 0.00171984\n",
            "Iteration 174, loss = 0.00171184\n",
            "Iteration 175, loss = 0.00170115\n",
            "Iteration 176, loss = 0.00169457\n",
            "Iteration 177, loss = 0.00166902\n",
            "Iteration 178, loss = 0.00166703\n",
            "Iteration 179, loss = 0.00163954\n",
            "Iteration 180, loss = 0.00163217\n",
            "Iteration 181, loss = 0.00163243\n",
            "Iteration 182, loss = 0.00162558\n",
            "Iteration 183, loss = 0.00159687\n",
            "Iteration 184, loss = 0.00164311\n",
            "Iteration 185, loss = 0.00157965\n",
            "Iteration 186, loss = 0.00155642\n",
            "Iteration 187, loss = 0.00156807\n",
            "Iteration 188, loss = 0.00153528\n",
            "Iteration 189, loss = 0.00155032\n",
            "Iteration 190, loss = 0.00152579\n",
            "Iteration 191, loss = 0.00152152\n",
            "Iteration 192, loss = 0.00152949\n",
            "Iteration 193, loss = 0.00149234\n",
            "Iteration 194, loss = 0.00149090\n",
            "Iteration 195, loss = 0.00149407\n",
            "Iteration 196, loss = 0.00146058\n",
            "Iteration 197, loss = 0.00146076\n",
            "Iteration 198, loss = 0.00144024\n",
            "Iteration 199, loss = 0.00146338\n",
            "Iteration 200, loss = 0.00143834\n",
            "Iteration 201, loss = 0.00144446\n",
            "Iteration 202, loss = 0.00140414\n",
            "Iteration 203, loss = 0.00139807\n",
            "Iteration 204, loss = 0.00139003\n",
            "Iteration 205, loss = 0.00138725\n",
            "Iteration 206, loss = 0.00138091\n",
            "Iteration 207, loss = 0.00136549\n",
            "Iteration 208, loss = 0.00136043\n",
            "Iteration 209, loss = 0.00136405\n",
            "Iteration 210, loss = 0.00134716\n",
            "Iteration 211, loss = 0.00133971\n",
            "Iteration 212, loss = 0.00133517\n",
            "Iteration 213, loss = 0.00133948\n",
            "Iteration 214, loss = 0.00131070\n",
            "Iteration 215, loss = 0.00130429\n",
            "Iteration 216, loss = 0.00129578\n",
            "Iteration 217, loss = 0.00129759\n",
            "Iteration 218, loss = 0.00128454\n",
            "Iteration 219, loss = 0.00127488\n",
            "Iteration 220, loss = 0.00127705\n",
            "Iteration 221, loss = 0.00125503\n",
            "Iteration 222, loss = 0.00125035\n",
            "Iteration 223, loss = 0.00124939\n",
            "Iteration 224, loss = 0.00123950\n",
            "Iteration 225, loss = 0.00124269\n",
            "Iteration 226, loss = 0.00122294\n",
            "Iteration 227, loss = 0.00121358\n",
            "Iteration 228, loss = 0.00121795\n",
            "Iteration 229, loss = 0.00121993\n",
            "Iteration 230, loss = 0.00120013\n",
            "Iteration 231, loss = 0.00120214\n",
            "Iteration 232, loss = 0.00118955\n",
            "Iteration 233, loss = 0.00119117\n",
            "Iteration 234, loss = 0.00117541\n",
            "Iteration 235, loss = 0.00118291\n",
            "Iteration 236, loss = 0.00115907\n",
            "Iteration 237, loss = 0.00115156\n",
            "Iteration 238, loss = 0.00115538\n",
            "Iteration 239, loss = 0.00113846\n",
            "Iteration 240, loss = 0.00114294\n",
            "Iteration 241, loss = 0.00113441\n",
            "Iteration 242, loss = 0.00113424\n",
            "Iteration 243, loss = 0.00113737\n",
            "Iteration 244, loss = 0.00112972\n",
            "Iteration 245, loss = 0.00111104\n",
            "Iteration 246, loss = 0.00111092\n",
            "Iteration 247, loss = 0.00110113\n",
            "Iteration 248, loss = 0.00109721\n",
            "Iteration 249, loss = 0.00108678\n",
            "Iteration 250, loss = 0.00108536\n",
            "Iteration 251, loss = 0.00108186\n",
            "Iteration 252, loss = 0.00108212\n",
            "Iteration 253, loss = 0.00107221\n",
            "Iteration 254, loss = 0.00105986\n",
            "Iteration 255, loss = 0.00105490\n",
            "Iteration 256, loss = 0.00106770\n",
            "Iteration 257, loss = 0.00104865\n",
            "Iteration 258, loss = 0.00105722\n",
            "Iteration 259, loss = 0.00104949\n",
            "Iteration 260, loss = 0.00104859\n",
            "Iteration 261, loss = 0.00103729\n",
            "Iteration 262, loss = 0.00102181\n",
            "Iteration 263, loss = 0.00102176\n",
            "Iteration 264, loss = 0.00101276\n",
            "Iteration 265, loss = 0.00100853\n",
            "Iteration 266, loss = 0.00100495\n",
            "Iteration 267, loss = 0.00100003\n",
            "Iteration 268, loss = 0.00100249\n",
            "Iteration 269, loss = 0.00099136\n",
            "Iteration 270, loss = 0.00099639\n",
            "Iteration 271, loss = 0.00098411\n",
            "Iteration 272, loss = 0.00097758\n",
            "Iteration 273, loss = 0.00097843\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(374,), learning_rate='constant',\n",
              "       learning_rate_init=0.01, max_iter=500, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "73ac5174-9ba2-494c-a2ad-6995e1e76299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "660b3319-8a4e-4bd5-d8cd-58da8a14d369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.982324949014276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "62b88ce6-d08f-4c68-97be-59342009a54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9463861554122837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "12e61392-891c-4526-c58a-264f5dd07a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "source": [
        "#### 561 -> 374 -> 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "8ae2d17e-3e74-41b6-8c1a-412dfff048e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5881, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "colab": {}
      },
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "source": [
        "#### Rerun the same thing in tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# ## Building the graph - Best!\n",
        "# saver = tf.train.Saver()\n",
        "# learning_rate = 0.001\n",
        "# hid_neuron = [374]\n",
        "# num_steps = 20000\n",
        "# batch_size = 200\n",
        "# train_losses = []\n",
        "# test_acc = []\n",
        "# X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "# Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "# def neural_net(x,train = True):\n",
        "#     layer_outputs = []\n",
        "#     layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "#     layer_1 = tf.nn.relu(layer_1)\n",
        "# #     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "# #     layer_2 = tf.nn.relu(layer_2)\n",
        "#     out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_outputs.append(out_layer)\n",
        "#     return out_layer\n",
        "\n",
        "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "# train_op = optimizer.minimize(loss)\n",
        "# correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "#   ### Initialization and running the model\n",
        "# with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     best_accuracy_valid = 0\n",
        "#     for step in range(0, num_steps):\n",
        "#         batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "#         if step % 1000 == 0:\n",
        "#             train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "#             train_losses.append(train_loss)\n",
        "#             validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "#             if step%1000 == 0:\n",
        "#               print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "#               print()\n",
        "#               if (validation_accuracy >= best_accuracy_valid):\n",
        "#                 best_accuracy_valid = validation_accuracy\n",
        "#                 saver.save(sess, './statlog_letter')\n",
        "#                 test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#     print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "#     print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "#     print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UpCtcB9hQFPI",
        "outputId": "d2a4205f-d2a0-4610-92dd-3eba99a80688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1471, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mT7SryMuQFPO"
      },
      "source": [
        "## Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K-zBUEuGwV98",
        "colab": {}
      },
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E91ru7-owV5i",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 374\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlDkpoIzcLL3",
        "colab_type": "code",
        "outputId": "3dfb6382-502a-413b-dc83-9dfc32fe2db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5881, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqw9g6e-cL3l",
        "colab_type": "code",
        "outputId": "896d9678-73d6-423a-9d77-568bbda03353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "5881/200"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUH5tpXwcUdm",
        "colab_type": "code",
        "outputId": "db2020fe-0128-4c23-9993-4480e4c284fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "100000/30"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3333.3333333333335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dqcFndAcZyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 3333"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXzaScAbcaj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle  #train_data, train_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIJshIO5b1w6",
        "colab_type": "text"
      },
      "source": [
        "# Train using epoch based methos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crEGEj10b4k_",
        "colab_type": "code",
        "outputId": "59d3db18-720d-4fac-eec8-f45548fa098b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17187
        }
      },
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 4112\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 10\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = train_data.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 3\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(train_data, train_label_one_hot)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "              saver.save(sess, './HarFull')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/3333, training loss= 13.493498, training acc= 79.6633243560791%\n",
            "Validation Accuracy 79.33378601074219 ...\n",
            "\n",
            "Epoch 10/3333, training loss= 1.6857285, training acc= 94.04863119125366%\n",
            "Validation Accuracy 94.08565521240234 ...\n",
            "\n",
            "Epoch 20/3333, training loss= 0.3384957, training acc= 97.02431559562683%\n",
            "Validation Accuracy 96.4649887084961 ...\n",
            "\n",
            "Epoch 30/3333, training loss= 0.13230404, training acc= 98.26560020446777%\n",
            "Validation Accuracy 96.7369155883789 ...\n",
            "\n",
            "Epoch 40/3333, training loss= 0.08856975, training acc= 98.53766560554504%\n",
            "Validation Accuracy 96.80489349365234 ...\n",
            "\n",
            "Epoch 50/3333, training loss= 0.063261144, training acc= 98.87773990631104%\n",
            "Validation Accuracy 96.6009521484375 ...\n",
            "\n",
            "Epoch 60/3333, training loss= 0.049065556, training acc= 99.09879565238953%\n",
            "Validation Accuracy 96.66893768310547 ...\n",
            "\n",
            "Epoch 70/3333, training loss= 0.03969408, training acc= 99.25183057785034%\n",
            "Validation Accuracy 97.07682037353516 ...\n",
            "\n",
            "Epoch 80/3333, training loss= 0.03411312, training acc= 99.30284023284912%\n",
            "Validation Accuracy 97.1447982788086 ...\n",
            "\n",
            "Epoch 90/3333, training loss= 0.02931125, training acc= 99.37085509300232%\n",
            "Validation Accuracy 97.21277618408203 ...\n",
            "\n",
            "Epoch 100/3333, training loss= 0.026140315, training acc= 99.47288036346436%\n",
            "Validation Accuracy 97.28076171875 ...\n",
            "\n",
            "Epoch 110/3333, training loss= 0.023567796, training acc= 99.52389001846313%\n",
            "Validation Accuracy 97.4167251586914 ...\n",
            "\n",
            "Epoch 120/3333, training loss= 0.020932533, training acc= 99.59190487861633%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 130/3333, training loss= 0.018936004, training acc= 99.62591528892517%\n",
            "Validation Accuracy 97.4167251586914 ...\n",
            "\n",
            "Epoch 140/3333, training loss= 0.016185008, training acc= 99.69393014907837%\n",
            "Validation Accuracy 97.4167251586914 ...\n",
            "\n",
            "Epoch 150/3333, training loss= 0.014488693, training acc= 99.74493980407715%\n",
            "Validation Accuracy 97.4167251586914 ...\n",
            "\n",
            "Epoch 160/3333, training loss= 0.0135869235, training acc= 99.74493980407715%\n",
            "Validation Accuracy 97.4167251586914 ...\n",
            "\n",
            "Epoch 170/3333, training loss= 0.011441911, training acc= 99.84696507453918%\n",
            "Validation Accuracy 97.48470306396484 ...\n",
            "\n",
            "Epoch 180/3333, training loss= 0.010205541, training acc= 99.89797472953796%\n",
            "Validation Accuracy 97.48470306396484 ...\n",
            "\n",
            "Epoch 190/3333, training loss= 0.009161863, training acc= 99.94899034500122%\n",
            "Validation Accuracy 97.34874725341797 ...\n",
            "\n",
            "Epoch 200/3333, training loss= 0.007884925, training acc= 100.0%\n",
            "Validation Accuracy 97.48470306396484 ...\n",
            "\n",
            "Epoch 210/3333, training loss= 0.00714425, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 220/3333, training loss= 0.006883608, training acc= 100.0%\n",
            "Validation Accuracy 97.55268859863281 ...\n",
            "\n",
            "Epoch 230/3333, training loss= 0.005953017, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 240/3333, training loss= 0.0049327444, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 250/3333, training loss= 0.004652584, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 260/3333, training loss= 0.003877026, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 270/3333, training loss= 0.0035559502, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 280/3333, training loss= 0.0033300396, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 290/3333, training loss= 0.0031042844, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 300/3333, training loss= 0.0027903754, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 310/3333, training loss= 0.002590838, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 320/3333, training loss= 0.002423374, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 330/3333, training loss= 0.0022760755, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 340/3333, training loss= 0.0021421744, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 350/3333, training loss= 0.0020105755, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 360/3333, training loss= 0.0018980666, training acc= 100.0%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 370/3333, training loss= 0.0017979903, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 380/3333, training loss= 0.001698222, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 390/3333, training loss= 0.0015987793, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 400/3333, training loss= 0.0015118219, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 410/3333, training loss= 0.0014665782, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 420/3333, training loss= 0.0013621909, training acc= 100.0%\n",
            "Validation Accuracy 97.68864440917969 ...\n",
            "\n",
            "Epoch 430/3333, training loss= 0.0013034274, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 440/3333, training loss= 0.0012323416, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 450/3333, training loss= 0.0011767929, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 460/3333, training loss= 0.0011220991, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 470/3333, training loss= 0.001075352, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 480/3333, training loss= 0.0010236911, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 490/3333, training loss= 0.0009786017, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 500/3333, training loss= 0.0009401081, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 510/3333, training loss= 0.0008992031, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 520/3333, training loss= 0.0008633974, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 530/3333, training loss= 0.0008291821, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 540/3333, training loss= 0.0007978594, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 550/3333, training loss= 0.00076774316, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 560/3333, training loss= 0.00073616125, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 570/3333, training loss= 0.00070796977, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 580/3333, training loss= 0.00068143546, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 590/3333, training loss= 0.0006567661, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 600/3333, training loss= 0.00063227327, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 610/3333, training loss= 0.000605623, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 620/3333, training loss= 0.0005811204, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 630/3333, training loss= 0.0005610286, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 640/3333, training loss= 0.0005419069, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 650/3333, training loss= 0.0005237031, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 660/3333, training loss= 0.00050624006, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 670/3333, training loss= 0.0004896212, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 680/3333, training loss= 0.00047409412, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 690/3333, training loss= 0.0004589547, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 700/3333, training loss= 0.00044490525, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 710/3333, training loss= 0.00043088675, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 720/3333, training loss= 0.0004176779, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 730/3333, training loss= 0.0004052758, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 740/3333, training loss= 0.0003929045, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 750/3333, training loss= 0.00038130704, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 760/3333, training loss= 0.00037038786, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 770/3333, training loss= 0.00035959523, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 780/3333, training loss= 0.00034946133, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 790/3333, training loss= 0.0003398447, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 800/3333, training loss= 0.00033048936, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 810/3333, training loss= 0.00032139517, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 820/3333, training loss= 0.00031308492, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 830/3333, training loss= 0.00030423194, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 840/3333, training loss= 0.00029601983, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 850/3333, training loss= 0.00028878244, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 860/3333, training loss= 0.00028085808, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 870/3333, training loss= 0.00027359225, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 880/3333, training loss= 0.00026650916, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 890/3333, training loss= 0.0002596993, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 900/3333, training loss= 0.00025325685, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 910/3333, training loss= 0.00024682085, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 920/3333, training loss= 0.00024088431, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 930/3333, training loss= 0.00023486259, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 940/3333, training loss= 0.00022937296, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 950/3333, training loss= 0.0002237694, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 960/3333, training loss= 0.00021848155, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 970/3333, training loss= 0.0002133182, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 980/3333, training loss= 0.000208322, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 990/3333, training loss= 0.00020345059, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1000/3333, training loss= 0.00019871263, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1010/3333, training loss= 0.00019418726, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1020/3333, training loss= 0.00018978152, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1030/3333, training loss= 0.00018545018, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1040/3333, training loss= 0.00018123066, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1050/3333, training loss= 0.00017704268, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1060/3333, training loss= 0.00017284782, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1070/3333, training loss= 0.00016923083, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1080/3333, training loss= 0.00016554669, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1090/3333, training loss= 0.00016209204, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1100/3333, training loss= 0.00015858676, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1110/3333, training loss= 0.00015531303, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1120/3333, training loss= 0.00015200638, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1130/3333, training loss= 0.00014888043, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1140/3333, training loss= 0.0001459085, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1150/3333, training loss= 0.00014282629, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1160/3333, training loss= 0.00013980141, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1170/3333, training loss= 0.00013688335, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1180/3333, training loss= 0.000134155, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1190/3333, training loss= 0.00013148073, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1200/3333, training loss= 0.0001288213, training acc= 100.0%\n",
            "Validation Accuracy 97.75662994384766 ...\n",
            "\n",
            "Epoch 1210/3333, training loss= 0.00012625763, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1220/3333, training loss= 0.00012378613, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1230/3333, training loss= 0.0001213847, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1240/3333, training loss= 0.00011897439, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1250/3333, training loss= 0.00011665412, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1260/3333, training loss= 0.00011434973, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1270/3333, training loss= 0.00011221476, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1280/3333, training loss= 0.000110011315, training acc= 100.0%\n",
            "Validation Accuracy 97.8246078491211 ...\n",
            "\n",
            "Epoch 1290/3333, training loss= 0.000107992055, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1300/3333, training loss= 0.00010598974, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1310/3333, training loss= 0.000103898135, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1320/3333, training loss= 0.00010200229, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1330/3333, training loss= 0.00010005899, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1340/3333, training loss= 9.824407e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1350/3333, training loss= 9.6457974e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1360/3333, training loss= 9.468313e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 1370/3333, training loss= 9.296755e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1380/3333, training loss= 9.12877e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1390/3333, training loss= 8.96471e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1400/3333, training loss= 8.794455e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1410/3333, training loss= 8.631121e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1420/3333, training loss= 8.47319e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1430/3333, training loss= 8.327981e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1440/3333, training loss= 8.181263e-05, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 1450/3333, training loss= 8.035169e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1460/3333, training loss= 7.893634e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1470/3333, training loss= 7.758438e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1480/3333, training loss= 7.625041e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1490/3333, training loss= 7.493235e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1500/3333, training loss= 7.367322e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1510/3333, training loss= 7.240357e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1520/3333, training loss= 7.123894e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1530/3333, training loss= 6.999591e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1540/3333, training loss= 6.8851834e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1550/3333, training loss= 6.763491e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1560/3333, training loss= 6.652955e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1570/3333, training loss= 6.553068e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 1580/3333, training loss= 6.430606e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1590/3333, training loss= 6.3222345e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1600/3333, training loss= 6.2184365e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1610/3333, training loss= 6.121634e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1620/3333, training loss= 6.0140326e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1630/3333, training loss= 5.915526e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1640/3333, training loss= 5.814864e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1650/3333, training loss= 5.7195808e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1660/3333, training loss= 5.6271332e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1670/3333, training loss= 5.53188e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1680/3333, training loss= 5.4425735e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1690/3333, training loss= 5.355196e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1700/3333, training loss= 5.269875e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1710/3333, training loss= 5.1854993e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1720/3333, training loss= 5.1047562e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1730/3333, training loss= 5.0245013e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1740/3333, training loss= 4.945956e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1750/3333, training loss= 4.8682978e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1760/3333, training loss= 4.7987298e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1770/3333, training loss= 4.716376e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1780/3333, training loss= 4.6454436e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1790/3333, training loss= 4.5724366e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1800/3333, training loss= 4.5036686e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1810/3333, training loss= 4.432155e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1820/3333, training loss= 4.3634907e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1830/3333, training loss= 4.2972068e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1840/3333, training loss= 4.2321677e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1850/3333, training loss= 4.168713e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1860/3333, training loss= 4.1047446e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1870/3333, training loss= 4.0446852e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1880/3333, training loss= 3.9831728e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1890/3333, training loss= 3.9218772e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1900/3333, training loss= 3.864149e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1910/3333, training loss= 3.8065293e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1920/3333, training loss= 3.749699e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1930/3333, training loss= 3.693218e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1940/3333, training loss= 3.6372894e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1950/3333, training loss= 3.583936e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1960/3333, training loss= 3.530654e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1970/3333, training loss= 3.4793666e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 1980/3333, training loss= 3.42797e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 1990/3333, training loss= 3.378617e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2000/3333, training loss= 3.3329517e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2010/3333, training loss= 3.280955e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2020/3333, training loss= 3.2337353e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2030/3333, training loss= 3.189077e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2040/3333, training loss= 3.1402444e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2050/3333, training loss= 3.0948097e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2060/3333, training loss= 3.0509811e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2070/3333, training loss= 3.0062074e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2080/3333, training loss= 2.963965e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2090/3333, training loss= 2.9229548e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2100/3333, training loss= 2.8803128e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 2110/3333, training loss= 2.8384848e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2120/3333, training loss= 2.7981267e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2130/3333, training loss= 2.7583523e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2140/3333, training loss= 2.7202454e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2150/3333, training loss= 2.6815906e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2160/3333, training loss= 2.6430605e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2170/3333, training loss= 2.606551e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2180/3333, training loss= 2.5700661e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2190/3333, training loss= 2.534205e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2200/3333, training loss= 2.4980145e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2210/3333, training loss= 2.4635414e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2220/3333, training loss= 2.4293447e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2230/3333, training loss= 2.3961247e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2240/3333, training loss= 2.3628563e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2250/3333, training loss= 2.3312223e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2260/3333, training loss= 2.2992139e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2270/3333, training loss= 2.2677606e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2280/3333, training loss= 2.2371987e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2290/3333, training loss= 2.2058373e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2300/3333, training loss= 2.175615e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2310/3333, training loss= 2.1463222e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2320/3333, training loss= 2.1165582e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2330/3333, training loss= 2.0883066e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2340/3333, training loss= 2.0594536e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2350/3333, training loss= 2.0313375e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2360/3333, training loss= 2.0042182e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2370/3333, training loss= 1.9765645e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2380/3333, training loss= 1.948899e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2390/3333, training loss= 1.9223637e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2400/3333, training loss= 1.896026e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2410/3333, training loss= 1.870374e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2420/3333, training loss= 1.8448274e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2430/3333, training loss= 1.8210714e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2440/3333, training loss= 1.7969245e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2450/3333, training loss= 1.7711103e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2460/3333, training loss= 1.7475564e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2470/3333, training loss= 1.7246206e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2480/3333, training loss= 1.6996612e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2490/3333, training loss= 1.6765736e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2500/3333, training loss= 1.6543425e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2510/3333, training loss= 1.6316037e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2520/3333, training loss= 1.6096787e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2530/3333, training loss= 1.5887364e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2540/3333, training loss= 1.5673526e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2550/3333, training loss= 1.5464584e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2560/3333, training loss= 1.526222e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2570/3333, training loss= 1.50652e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2580/3333, training loss= 1.4855701e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2590/3333, training loss= 1.4657387e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2600/3333, training loss= 1.4463286e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2610/3333, training loss= 1.42684385e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2620/3333, training loss= 1.4078378e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2630/3333, training loss= 1.3892971e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2640/3333, training loss= 1.3715711e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2650/3333, training loss= 1.3532378e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2660/3333, training loss= 1.3354338e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2670/3333, training loss= 1.3174881e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2680/3333, training loss= 1.300212e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2690/3333, training loss= 1.2832603e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2700/3333, training loss= 1.26641135e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2710/3333, training loss= 1.2498664e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2720/3333, training loss= 1.2335861e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2730/3333, training loss= 1.2188305e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2740/3333, training loss= 1.20211735e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2750/3333, training loss= 1.1860244e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2760/3333, training loss= 1.1704258e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2770/3333, training loss= 1.1554401e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2780/3333, training loss= 1.1409253e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2790/3333, training loss= 1.1259226e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2800/3333, training loss= 1.111874e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2810/3333, training loss= 1.0971018e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2820/3333, training loss= 1.0832104e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2830/3333, training loss= 1.0690021e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2840/3333, training loss= 1.0550283e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2850/3333, training loss= 1.0416061e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2860/3333, training loss= 1.0284929e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2870/3333, training loss= 1.0158848e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2880/3333, training loss= 1.0027055e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2890/3333, training loss= 9.898394e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2900/3333, training loss= 9.774159e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2910/3333, training loss= 9.651432e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2920/3333, training loss= 9.530247e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2930/3333, training loss= 9.409885e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2940/3333, training loss= 9.292952e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2950/3333, training loss= 9.174461e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2960/3333, training loss= 9.062263e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2970/3333, training loss= 8.944158e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2980/3333, training loss= 8.833113e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 2990/3333, training loss= 8.729265e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3000/3333, training loss= 8.619524e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3010/3333, training loss= 8.505612e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3020/3333, training loss= 8.398202e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3030/3333, training loss= 8.292766e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3040/3333, training loss= 8.18875e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3050/3333, training loss= 8.099199e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3060/3333, training loss= 7.991355e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3070/3333, training loss= 7.889498e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3080/3333, training loss= 7.791135e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3090/3333, training loss= 7.692894e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3100/3333, training loss= 7.5980242e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3110/3333, training loss= 7.503374e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3120/3333, training loss= 7.4111613e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3130/3333, training loss= 7.3204333e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3140/3333, training loss= 7.2295784e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3150/3333, training loss= 7.1425416e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3160/3333, training loss= 7.0539118e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3170/3333, training loss= 6.9653265e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3180/3333, training loss= 6.8790887e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3190/3333, training loss= 6.793731e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3200/3333, training loss= 6.7099872e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3210/3333, training loss= 6.6270836e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3220/3333, training loss= 6.544268e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3230/3333, training loss= 6.463066e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3240/3333, training loss= 6.3871385e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3250/3333, training loss= 6.305135e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3260/3333, training loss= 6.2256854e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3270/3333, training loss= 6.1509636e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3280/3333, training loss= 6.0733646e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3290/3333, training loss= 6.0002376e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3300/3333, training loss= 5.9259846e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3310/3333, training loss= 5.8513942e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3320/3333, training loss= 5.779449e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 3330/3333, training loss= 5.709205e-06, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Valid acc= 98.16452 %\n",
            "==================================================\n",
            "W1\n",
            "3\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctjgqv4OcnxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMzDOL06cnuP",
        "colab_type": "code",
        "outputId": "7618644a-6200-403d-e219-d46f82e5096b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "steps_plot =  [step for step in range(0, 3333, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),11,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),11,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt8VeWV//HPygUChHskKmiDiEVU\nQIjiXdBqRa2AtSJirVTHy9haOz+1zvTq76cz6liZWltbHEVtLcEb2o6iRYRKx4rckZuCEpX7VSBA\nAslZvz/2TgiQQEjOLft8369XXjlnn3P2Xuuck73yPPvZzzZ3R0REJCqyUh2AiIhIPKmwiYhIpKiw\niYhIpKiwiYhIpKiwiYhIpKiwiYhIpKiwiYhIpKiwiYhIpKiwiYhIpOSkOoCmKCgo8KKioiatY8eO\nHbRp0yY+AaVYVHKJSh6gXNJVVHKJSh4As2fP3ujuR8RjXc26sBUVFTFr1qwmrWPatGkMGjQoPgGl\nWFRyiUoeoFzSVVRyiUoeAGb2WbzWpa5IERGJFBU2ERGJFBU2ERGJFBU2ERGJFBU2ERGJFBU2ERGJ\nlIQVNjN72szWm9nCWss6mdlkM1sW/u4YLjcze8zMlpvZAjPrn6i4REQk2hLZYnsGuGS/ZfcCU9y9\nJzAlvA8wBOgZ/twMPJHAuEREJMISdoK2u79rZkX7LR4KDApvPwtMA34ULn/O3R1438w6mNlR7r4m\nUfHFW1XMeW3eKqYsWU/MPSUxbNhQzoSVs1Oy7XiKSh6gXNJVVHJJlzwGffUIRpx2bKrDqJHsmUcK\naxWrtUBheLsr8EWt560Mlx1Q2MzsZoJWHYWFhUybNq1JAZWVlTVpHe7OhxurePHjPXyxPUbnPCMv\nRfO5xGIx1uxYl5qNx1FU8gDlkq6ikku65NG6YhOFOz5NdRg1Ujallru7mR1208bdxwJjAYqLi72p\n08k0ZUoad+fnf17Ec7M/45hOrXhsZC8uP+UosrKsSTE1VlSm14lKHqBc0lVUcolKHvGW7MK2rrqL\n0cyOAtaHy1cBx9R6XrdwWVpa9eUuHn5zKdOXbWTzjt189+zu3DukFy1yNMhURCTVkl3Y/gx8B3gw\n/P1areXfM7MSYCCwNR2Pr325czcvzlrJY+8sY09VjMtOOZqTu7bjhrOKMEtNK01ERPaVsMJmZuMJ\nBooUmNlK4OcEBe0FM7sR+Ay4Onz6G8ClwHJgJzA6UXE1hrvzztL1/OsrH7J+ewWnd+/Ef17Vh690\njsblIkREoiSRoyJH1vPQhXU814HbExVLU8Rizt0vLeDlOSvpcUQbnry+mL7HdEh1WCIiUo9mfT22\nRNu5u5KfTFzIK3NX8b3Bx3PHhT11HE1EJM2psNVj2kdB1+PabeX8y0Un8P0LjtdxNBGRZkCFrQ4b\nyyq4Y/xcCtvl8cItZ3JaUadUhyQiIg2kwlaHX/71I3btqeKJ6/pzfJe2qQ5HREQOgw4Y7WdTWQUv\nz1nFiNOOUVETEWmGVNj2UzLzC3ZXxrjhrKJUhyIiIo2gwrafv8xfzelFndRaExFpplTYalm3rZyl\na7czuFeXVIciIiKNpMJWy/RlGwE474SCFEciIiKNpcJWy7sfb6AgvyUnHtku1aGIiEgjqbCFyvdU\nMWXJOi7odUTKLjsjIiJNp8IWmrp0PTt2V3FF366pDkVERJpAhS30xsK1FOS34IzjNMuIiEhzpplH\nQp9t2sFJR7cnJ1u1XuLAHWKVwe/K3ZCdC1V7gt+7tkBua8jNg52bYdErMPsZaNUJvvYLWL8EPnwR\nBv8bdDoOVvwN3vt1sJ5kMoNel8Fp/wRm5O7eCjs21v/8qj0w/RGoLIdB/wo5ecmL9TAdMpdmIm3y\nyGkJLdPnFCkVttCWnbs5rkDXV5PDsOkTWD0XuvSGFm1g5cxgucfgg7GwpZRTszvBzI3Q+XjY8FHw\n3M/fg5bt4Ki+UDo9eE3XAUFBe3JwcD8rF566aO+2uvQOilwylW+Fvz0U/ABnA7x3qBcZWBbM/WOC\ng2uahuWS/tImj9Nvhkv/M9VR1FBhC23ZsYeObVqkOgxJtapK+OD30K4rnDQsWBaLwexxsHrOvs9b\n/GrQOrHs4D/WPTv3Pt6yPbQ9kjZbPodORbB2IXQsCgrh+ffCp1Phixlw7l1BgTvxG8F/3kv/Annt\nofv5sPR/glZQXns4aXjQ2ku2T6bCpuUAfLzsY07oecLBn390/yDOL2YkIbjGa1AuzUDa5NGld6oj\n2IcKG7C7MkZZRSUdW0egsO3cHHR1NUXV7uC/dMuGc+4MusH27Aq7l1rGJ85qee2hTZzOGyzbABXb\n9l2WlQ0dvhK8J/W9L+VbYcr/DVpglbtgx4Zg+Vtdg/egqgLK1kF+IWTV+pM5/mtw3t0w4/ewa3PQ\ndZjbOngsvxByW/OPqW9x7uCvw54d0CIfKrZDqw5w/o+gYiu06rh3fflHQPF3994fcEOT35Im6zE4\n+AFW75zGCacPatjrjuqTuJji4LBySWNRySPeVNiAL3cFxy7SqsVWWQGLXg2O0/QeGhSUxa8FO+F6\nFK14H6Z/KyhMTZXdIjg+tPClYGdu2bDkz01f7/4sC868HTp2r1l09KqPYeYnh7eezZ/C+78NugH3\nd/SpsG7Rwd+Xlu2h16WAQc+vwbY1wWuqdT8X+o4Mjjvtb/gT9a62KqcNZOdAdvtgQavw6utZWfsW\nNRGJGxU2gm5IgI6t49DVs34JLJoI590T7ND298UHsGACnH0ndDjmwMc3fAR/HwOr5sDGj4Jl7z4c\n/Le/buFBN10EcMKQoNuqqboOAK+C1fOC/76zW8DKWU1f7/6WTw5ahLWcALCsEevqMwJ6XLjvsu2r\n4W8PQ48L4KQr636dGRSdA+2ObsRGRSTdqLARDBwBDt0V+b+/gtK/w7Uv1P2fO8AbdwcDAkr/DusX\nB8dnaqvYBjjMfnZvt1Vtu8uCItb5OBjxx2BQwtR/D1obV/43dD+v/vD+8T5nXzz04DkcriO+uvd2\n5x7xXTdA3xEw5OHgWFLovffe46yzzjq89WTnQut6TtU445/j34UqImlLhQ3YsqMBha18K/ztP2H3\ndlg+JeiuAti4DJa+HhSA/C5BUWvTBT77XzjximAQQm2tOsAJl8DCl/fZmdfIbQUDb4G2R+5d1uOC\nBuWxp0X7Bj0v7exXkHa37AhtC+O3fhU1kYyiwgZs2Rl2RbY5SFfkB08GRS2vPfzlDijoGRyD+uKD\nYMABQPtjg3OR/vn9oAvsyFPqX9/R/eKYgYiIVNPZyDSgK3LDx/Duf8JXL4Vv/AradwtGCVaWw4mX\nwx3zoMtJsPVzuPxRaNP54EVNREQSRi02gq7IVrnZ5OVmH/jg8ikw8dbgeNjlY4IuwroGZ1w7AVbN\nis/ADRERaTQVNoKuyANGRFbuhin3wT8ehyNOhKue3ve41/46HFP3KEcREUkqFTaCrsgDzmGbdE8w\n20TxjfD1B4JBHSIikvZU2IBtu/bQLm+/FtuyvwYnRl/+aGqCEhGRRtHgEaCiMkZeblZwzlnVHvjy\nC9i2Cr5ydqpDExGRw6QWG1BRWcXxVZ/Cr28OzjsrHh08cMzA1AYmIiKHTYWNoMU2esODULkKtqwI\nZgfJbQOFJ6c6NBEROUzqigS6Vqzg6IoVcMFPoXUBrF0Afa6ue65HERFJa9pzA4MrpxMji6y+I+HI\nk4OZ3ftdm+qwRESkEVTYgFN9Mavze9Mt/wjIb9i8jCIikp7UFQnkeTkVLTqkOgwREYmDjC9sVTGn\nFRXEsnUCtohIFGR8YdsTgzzbTSwnL9WhiIhIHKiwxaAVFXhdF/0UEZFmR4Ut5rRiN56jrkgRkShQ\nYauM0cp2Qwu12EREoiDjC1usKrh6tqkrUkQkEjK+sHllOQDWQl2RIiJRoMJWWQFAVos2KY5ERETi\nIeMLGzWFTV2RIiJRoMIWFrbslipsIiJRkPGFzaqCwpaTp65IEZEoSElhM7MfmNlCM1tkZneGy35h\nZqvMbF74c2lSYqkubGqxiYhEQtJn9zezk4F/Ak4HdgNvmtn/hA+PcfdHkhpPOCoyp2V+MjcrIiIJ\nkorL1pwIzHD3nQBm9jfgyhTEAUBWLGix5bZSV6SISBSYuyd3g2YnAq8BZwK7gCnALGATcAOwLbz/\nf9x9Sx2vvxm4GaCwsHBASUlJk+JZO+fPXLPtKaad9hS0KWjSulKtrKyM/Pzm3/KMSh6gXNJVVHKJ\nSh4AgwcPnu3uxfFYV9ILG4CZ3Qj8M7ADWARUAP8BbAQc+H/AUe7+3YOtp7i42GfNmtWkWCaO+QHD\ntz5D5V0ryMnv1KR1pdq0adMYNGhQqsNosqjkAcolXUUll6jkAWBmcStsKRk84u5PufsAdz8P2AJ8\n7O7r3L3K3WPAkwTH4BIuO7Yb0KhIEZGoSNWoyC7h72MJjq/9ycyOqvWU4cDCZMSSHSunyg2yWyRj\ncyIikmCpGDwC8LKZdQb2ALe7+5dm9msz60fQFVkK3JKMQHJiuym3lrQxS8bmREQkwVJS2Nz93DqW\nfTsVseTEKqigJeqIFBGJhoyfeSTHK6iwlqkOQ0RE4iTjC1turILdKmwiIpGhwua7qcjStdhERKIi\n4wtbC69gj1psIiKRkfGFLccriWWlanCoiIjEW8YXNsNxy051GCIiEicqbMQAncMmIhIVGV/YAFwn\nZ4uIREbGF7YsHLXYRESiI+MLmxHDLePfBhGRyNAe3cHVYhMRiYyML2xZGjwiIhIpGV/YwNUVKSIS\nIRm/R8/C1RUpIhIhGV/YDMc03F9EJDJU2NQVKSISKRm/RzedxyYiEikZX9iy1GITEYkU7dHVYhMR\niZSML2xBi02FTUQkKjK+sAUtNr0NIiJRkfF7dB1jExGJlozfowfXYxMRkahQYXNALTYRkcjI+D26\nEQMNHhERiYyML2w6xiYiEi0Zv0fXzCMiItGiwobrGJuISIRk/B49Sy02EZFIyfjCptn9RUSiJeP3\n6EFXpFpsIiJRocKmY2wiIpFyyD26mX3fzDomI5hU0DE2EZFoaUhTpRCYaWYvmNklZtHqt1OLTUQk\nWg65R3f3nwA9gaeAG4BlZvbvZtYjwbElhemyNSIikdKgpoq7O7A2/KkEOgIvmdnDCYwtKbJwTC02\nEZHIyDnUE8zsB8D1wEbgv4G73X2PBdVgGXBPYkNMLM0VKSISLYcsbEAn4Ep3/6z2QnePmdnliQkr\neQxwDQ4VEYmMhuzRJwGbq++YWTszGwjg7ksSFViyZBEjYuNhREQyWkMK2xNAWa37ZeGySDDQqEgR\nkQhpyB7dwsEjQNAFScO6MNOex2Jkmc5jExGJkoYUtk/N7A4zyw1/fgB8mujAkiFWXa/VYhMRiYyG\n7NFvBc4CVgErgYHAzYkMKlk8Fgtu6BibiEhkHLJL0d3XA9ckIZaki9UUNrXYRESioiHnseUBNwIn\nAXnVy939uwmMKylisarghlpsIiKR0ZCmyh+AI4GvA38DugHbm7JRM/uBmS00s0Vmdme4rJOZTTaz\nZeHvJEy8XH2MLTvxmxIRkaRoSGE73t1/Cuxw92eBywiOszWKmZ0M/BNwOtAXuNzMjgfuBaa4e09g\nSng/oWpabCIiEhkNKWx7wt9fhkWpPdClCds8EZjh7jvdvZKgFXglMBR4NnzOs8CwJmyjQWKxsMWW\npRabiEhUWK1T1Op+gtlNwMvAKcAzQD7wU3f/faM2aHYi8BpwJrCLoHU2C/i2u3cIn2PAlur7+73+\nZsJRmYWFhQNKSkoaEwYAu8t3cvH7I3m94/W06fvNRq8nXZSVlZGfn5/qMJosKnmAcklXUcklKnkA\nDB48eLa7F8djXQcdPBJOdLzN3bcA7wLHNXWD7r7EzB4C/grsAOYBVfs9x82szorr7mOBsQDFxcU+\naNCgRsey9ctN8D50LjiCM5qwnnQxbdo0mvJ+pIuo5AHKJV1FJZeo5BFvB+2KDGcZifvs/e7+lLsP\ncPfzgC3Ax8A6MzsKIPy9Pt7bPUA43N+yNNxfRCQqGrJHf9vM7jKzY8KRi53MrFNTNmpmXcLfxxIc\nX/sT8GfgO+FTvkPQXZlQNSdoa0otEZHIaMicjyPC37fXWuY0rVvyZTPrTDAw5XZ3/9LMHgReMLMb\ngc+Aq5uw/gbZex6bWmwiIlHRkJlHusd7o+5+bh3LNgEXxntbB6O5IkVEoqchM49cX9dyd38u/uEk\nl3vQYtP12EREoqMhXZGn1bqdR9CqmgM0+8JWPfGIWmwiItHRkK7I79e+b2YdgMafPJZGqo+xqcUm\nIhIdjWmq7ADiftwtFVyz+4uIRE5DjrH9hb2ddllAb+CFRAaVLMFpeqiwiYhESEOOsT1S63Yl8Jm7\nr0xQPEmlFpuISPQ0pLB9Dqxx93IAM2tlZkXuXprQyJLAw0mQdYxNRCQ6GtJUeRGI1bpfFS5r9vZ2\nRaqwiYhERUMKW467766+E95ukbiQkqdmVKTmihQRiYyG7NE3mNkV1XfMbCiwMXEhJZOuoC0iEjUN\nOcZ2K/C8mT0e3l8J1DkbSXOjSZBFRKKnISdofwKcYWb54f2yhEeVJNXH2NQVKSISHYfco5vZv5tZ\nB3cvc/cyM+toZvcnI7hEqx4VqeH+IiLR0ZA9+hB3/7L6Tng17UsTF1Ly7J0EOcWBiIhI3DSksGWb\nWcvqO2bWCmh5kOc3G7GaE7Q1eEREJCoaMnjkeWCKmY0jGGVxA/BsIoNKGtcJ2iIiUdOQwSMPmdl8\n4GsE4+PfAr6S6MCSoXpUpOkYm4hIZDR0j76OoKh9C7gAWJKwiJKoZuYRjYoUEYmMeltsZnYCMDL8\n2QhMAMzdBycptoTz6q5InccmIhIZB+uKXApMBy539+UAZvbDpESVJNWjItViExGJjoPt0a8E1gBT\nzexJM7uQiE3RUXOCto6xiYhERr17dHd/1d2vAXoBU4E7gS5m9oSZXZysABOq5gTtSNVrEZGMdsim\nirvvcPc/ufs3gG7AXOBHCY8sCfZOqaXz2EREouKw+uDcfYu7j3X3CxMVUDLtHe6vFpuISFRk9MGl\n6lGRGf42iIhESmbv0XWhURGRyMnoPXp1iy0rS12RIiJRkdGFDaonQc7wt0FEJEIyeo8eqz7Gptn9\nRUQiI6MLm4fH2LI0KlJEJDIyurBZdYtNg0dERCIjo/foe6fUUotNRCQqMruwhSdoZ2nmERGRyMjo\nwkbYYvNoze0sIpLRMrqwxWrOY8vot0FEJFIye49ePVekCpuISGRk+B69+graGf42iIhESEbv0fde\ntkbH2EREokKFDV2PTUQkSjK6sFWPitQVtEVEoiOzC1tMoyJFRKImo/fo7uH12DS7v4hIZGT2Hr16\ncn8VNhGRyMjoPXp1i03XYxMRiY7M3qNXzzySndlvg4hIlKRkj25mPzSzRWa20MzGm1memT1jZivM\nbF740y/hgVQP99dckSIikZGT7A2aWVfgDqC3u+8ysxeAa8KH73b3l5IWTNhi03lsIiLRkao+uByg\nlZnlAK2B1akIovoE7SzNPCIiEhnm1VeRTuZGzX4APADsAv7q7qPM7BngTKACmALc6+4Vdbz2ZuBm\ngMLCwgElJSWNjmPrwjcYuvH3vNn/v8lrd0Sj15MuysrKyM/PT3UYTRaVPEC5pKuo5BKVPAAGDx48\n292L47Iyd0/qD9AReAc4AsgFXgWuA44CDGgJPAv87FDrGjBggDfFPyY87P7zdr5xzWdNWk+6mDp1\naqpDiIuo5OGuXNJVVHKJSh7u7sAsj1OdSUVX5NeAFe6+wd33AK8AZ7n7mjC/CmAccHqiA/HqUZGa\nUktEJDJSUdg+B84ws9ZmZsCFwBIzOwogXDYMWJjwSKpHReo8NhGRyEj6qEh3n2FmLwFzgEpgLjAW\nmGRmRxB0R84Dbk1CMIDmihQRiZKkFzYAd/858PP9Fl+Q/DjCFptO0BYRiYyM3qNb9YhQdUWKiERG\nRu/RnfA8NhU2EZHIyOw9uq7HJiISOZm9R68+xqbCJiISGRm+Rw/nitR5bCIikZHZhS28HluWJkEW\nEYmMDC9sarGJiESNChtqsYmIRElGFzbX4BERkcjJ8D16dVdkhr8NIiIRktF7dAtbbJp5REQkOjJ7\nj15T2DR4REQkKjK8sDkxV1ETEYmSjC5s7k4MFTYRkSjJ6MJmHsNV2EREIiWjCxu4CpuISMRkdmHz\nmLoiRUQiJsMLm1psIiJRk9mFDbXYRESiJqMLW3CCtgqbiEiUZHRh03B/EZHoyejCZjrGJiISORld\n2NB5bCIikZPZhQ11RYqIRE1GFzYjhmf2WyAiEjkZvVd39/CKbCIiEhUZXdjMY8R0LTYRkUjJ7L26\nq70mIhI1mV3YcGKZ/haIiERMTqoDSCVdtkYkMfbs2cPKlSspLy9PdSh1at++PUuWLEl1GE3WHPPI\ny8ujW7du5ObmJmwbKmwqbCJxt3LlStq2bUtRURFm6fc3tn37dtq2bZvqMJqsueXh7mzatImVK1fS\nvXv3hG0no/vhHFTYRBKgvLyczp07p2VRk9QxMzp37pzwlnxGFzbT9dhEEkZFTeqSjO9FRhe2oM2m\nPz4RkSjJ6MKmFptING3atIl+/frRr18/jjzySLp27Vpzf/fu3Q1ax+jRo/noo48Oe9uXX34555xz\nzmG/TuInowePqMUmEk2dO3dm3rx5APziF78gPz+fu+66q+bxioqKYOYhd7Ky6v7/fty4cYe93c2b\nN7NgwQLy8vL4/PPPOfbYYxuXwCFUVlaSk5Phu++DyOh3xnQ9NpGEu+8vi1i8eltc19n76Hb8/Bsn\nHfbrli9fzhVXXMHJJ5/MwoULmTx5Mvfddx9z5sxh165djBgxgp/97GcAnHPOOTz++OOcfPLJFBQU\ncOuttzJp0iRat27Na6+9RpcuXQ5Y/0svvcSwYcNo3749JSUl3HPPPQCsXbuWW265hRUrVmBmjB07\nloEDBzJu3DjGjBmDmdG/f3/GjRvHddddx1VXXcWwYcMAyM/Pp6ysjLfffpv777+f/Px8PvnkE5Ys\nWcLVV1/N+vXrKS8v54c//CE33XQTAK+//jo//elPqaqqorCwkDfffJMTTjiBDz74gE6dOlFVVUXP\nnj2ZNWsWnTp1auzHkLYyuisSTYIsknGWLl3K7bffzuLFi+natSsPPvggs2bNYv78+UyePJnFixcf\n8JqtW7dy/vnnM3/+fM4880yefvrpOtc9fvx4Ro4cyciRIxk/fnzN8ttvv52LLrqIBQsWMHv2bE48\n8UTmz5/PQw89xLRp05g/fz6//OUvDxn7rFmz+O1vf1tz7trvfvc7Zs+ezcyZM3n00UfZsmULa9eu\n5bbbbmPixInMnz+fkpISsrKyGDlyJH/6058AeOuttzjttNMiWdQg41tsMVwNNpGEakzLKpF69OhB\n//79a+6PHz+ep556isrKSlavXs3ixYvp3bv3Pq9p1aoVQ4YMAWDAgAFMnz79gPWuXr2azz//nDPP\nPBOAWCzG0qVL6dWrF9OmTaOkpASAnJwc2rVrxzvvvMOIESNqiktDisyZZ565T/fmb37zG9566y0g\nOHfwk08+4YsvvmDw4MF85Stf2We9N954I9/61rf43ve+x9NPP13TuouijG+uqMUmklnatGlTc3vZ\nsmX86le/4p133mHBggVccskldZ5j1aJFi5rb2dnZVFZWHvCcCRMmsHHjRoqKiigqKuLzzz/fp9XW\n0GHuOTk5xGIxAKqqqvbZVu3Y3377bd577z3ef/995s+fT58+fQ56flhRUREdO3Zk6tSpzJ07l4sv\nvrhB8TRHGb1X18wjIplt27ZttG3blnbt2rFmzZqa1k9jjB8/nrfffpvS0lJKS0v54IMPagrb4MGD\n+d3vfgcExWrbtm1ccMEFTJgwgc2bNwPU/C4qKmL27NkATJw4kaqqqjq3t3XrVjp27EirVq1YtGgR\nM2fOBOCss85i6tSpfPbZZ/usF4JW26hRo7jmmmvqHTQTBdHNrEFchU0kg/Xv35/evXvTq1cvrr/+\nes4+++xGreeTTz5hzZo1FBcX1yzr2bMneXl5zJ49m8cff5y33nqLU045heLiYpYuXUrfvn255557\nOO+88+jXrx933303ALfccguTJ0+mb9++zJ07l5YtW9a5zcsuu4ydO3fSu3dvfvKTnzBw4EAACgsL\neeKJJxg6dCh9+/Zl1KhRNa8ZPnw4W7du5YYbbmhUns1G9ZDX5vgzYMAAb4o5/3Gxf/SLvk1aRzqZ\nOnVqqkOIi6jk4Z65uSxevDhxgcTBtm3bUh1CXBxuHv/4xz980KBBCYqm4er6fgCzPE61IbMHj6Cu\nSBHJDA888ABjx46tGcQSZeqKVGETkQzw4x//mM8++6xm1GaUpaSwmdkPzWyRmS00s/Fmlmdm3c1s\nhpktN7MJZtbi0GtqYhwaPCIiEjlJL2xm1hW4Ayh295OBbOAa4CFgjLsfD2wBbkx4LGqxiYhETqq6\nInOAVmaWA7QG1gAXAC+Fjz8LDEt4FO64Lq0hIhIpSR884u6rzOwR4HNgF/BXYDbwpbtXn4m4Euha\n1+vN7GbgZgiGtU6bNq3RsbSv3I25NWkd6aSsrCwSuUQlD8jcXNq3b8/27dsTG1ATVFVVpXV8DdVc\n8ygvL0/s30W8hlc29AfoCLwDHAHkAq8C1wHLaz3nGGDhodbV1OH+H95/jn943+lNWkc6icrQ8qjk\n4Z65uaR6uP+gQYP8zTff3GfZmDFj/NZbb3X3+ofJt2nTxt3dV61a5d/85jfrfM7555/vM2fOPOj2\nx4wZ4zt27Ki5P2TIEN+yZUuD4z+Uvn37+ogRI5rtaQuJHu6fiq7IrwEr3H2Du+8BXgHOBjqEXZMA\n3YBViQ9Fs/uLRNHIkSMPGNZeUlLCyJEjG/T6o48+mpdeeunQT6zHf/3Xf7Fz586a+2+88QYdOnRo\n9PpqW7JkCVVVVUyfPp0dO3bEZZ11qWvasOYiFeexfQ6cYWatCboiLwRmAVOBq4AS4DvAa4kOxIih\n67GJJNike2Hth/Fd55GnwJAH6334qquu4ic/+Qm7d++mRYsWlJaWsnr1as4991zKysr4xje+wbZt\n29izZw/3338/Q4cO3ef1paVQ5mzjAAANFElEQVSlXH755SxcuJBdu3YxevRo5s+fT69evdi1a1fN\n82677TZmzpzJrl27uOqqq7jvvvt47LHHWL16NYMHD6agoICpU6dSVFTErFmzKCgo4NFHH625OsBN\nN93EnXfeSWlpKUOGDOGcc87hvffeo2vXrrz22mu0atXqgNzGjx/Pt7/9bZYsWcLrr7/OjTcG4+yW\nL1/OrbfeyoYNG8jOzubFF1+kR48ePPTQQ/zxj38kKyuLIUOG8OCDDzJo0CAeeeQRiouL2bhxI8XF\nxZSWlvLMM8/wyiuvUFZWRlVVFa+//jpDhw5ly5YtB7xXzz33HI888ghmRp8+ffjtb39Lnz59+Pjj\nj8nNzWXbtm307du35n4ypeIY2wwzewmYA1QCc4GxwOtAiZndHy57KtGxtMrJohxP9GZEJMk6derE\n6aefzqRJkxg6dCglJSVcffXVmBl5eXk8//zzdO3alY0bN3LGGWdwxRVX1DtJ8RNPPEHr1q1ZsmQJ\nCxYs2OfKAA888EDN9c0uvPBCFixYwB133MGjjz7K1KlTKSgo2Gdds2fPZty4ccyYMQN3Z+DAgZx/\n/vl07NiRZcuWMX78eJ588kmuvvpqXn75Za677roD4pkwYQKTJ09m6dKljBkzpqawjRo1invvvZfh\nw4dTXl5OLBZj0qRJvPbaa8yYMYPWrVvvM29kfebMmcOCBQvo1KkTlZWVTJw4kXbt2u3zXi1evJj7\n77+f9957j4KCAjZv3kzbtm0ZNGgQr7/+OsOGDaOkpIQrr7wy6UUNUnTZGnf/OfDz/RZ/CpyezDiO\nK2jN5rL6Z8MWkTg4SMsqkaq7I6sL21NPBf8ruzv33Xcf77//PllZWaxatYp169Zx5JFH1rmed999\nlzvuuAOAPn360KdPn5rHXnjhBcaOHUtlZSVr1qxh8eLF+zy+v7///e8MHz68Zpb+K6+8kunTp3PF\nFVfQvXt3+vXrBwSXxiktLT3g9dWtvmOPPZauXbsyevRoNm/eTG5uLqtWrWL48OEA5OXlAcEVAEaP\nHk3r1q2Bhl0a56KLLqp5nrvzb//2b7z77rv7vFfvvPMO3/rWt2oKd/Xzb7rpJh5++GGGDRvGuHHj\nePLJJw+5vUTI7JlHXF2RIlE1dOhQpkyZwpw5c9i5cycDBgwA4Pnnn2fTpk3Mnj2befPmUVhYeNDL\nvdRnxYoVPPLII0yZMoUFCxZw2WWXNWo91WpPdlzfpXHGjx/P0qVLKSoqokePHmzfvp2XX375sLdV\n+9I4+8dc+9I4zz//PBs2bGjwe3X22WdTWlrKtGnTqKqq4uSTTz7s2OIhwwubo8ImEk35+fkMHjyY\n7373u/sMGtm6dSsFBQXk5ubuc3mX+px33nk1V55euHAhCxYsAIJL3rRp04b27duzbt06Jk2aVPOa\ntm3b1jkM/9xzz+XVV19l586d7Nixg4kTJ3Luuec2KJ9YLMYLL7zAhx9+WHNpnPHjxzN+/Hjatm1L\nt27dePXVVwGoqKhg586dXHTRRYwbN65mIEtdl8Y52CCZrVu30qVLlwPeqwsuuIAXX3yRTZs27bNe\ngOuvv55rr72W0aNHNyivRMjswnb+PXxxTOLPAxeR1Bg5ciTz58/fp7CNGjWKuXPncsopp/Dcc8/R\nq1evg67jtttuo6ysjBNPPJGf/exnNS2/vn37cuqpp9KrVy+uvfbafS55c/PNN3PJJZcwePDgfdbV\nv39/brjhBk4//XQGDhzITTfdxKmnntqgXKZPn07Xrl05+uija5adffbZLF68mDVr1vCHP/yBxx57\njD59+nDWWWexdu1aLrnkEq644gqKi4vp168fjzzyCAB33XUXTzzxBKeeeiobN26sd5ujRo1i1qxZ\nB7xXJ510Ej/+8Y85//zz6du3L//yL/+yz2u2bNnS4BGoCRGv8wZS8dPU89jcM/c8o3QWlTzcMzeX\nVJ/HdijN9fyv/aVjHi+++KJfd911B32OLlsjIiLNwve//30mTZrEG2+8kdI4VNhERCQufv3rX6c6\nBCDTj7GJSMIEvUsi+0rG90KFTUTiLi8vj02bNqm4yT7cnU2bNtWcZ5co6ooUkbjr1q0bK1euZMOG\nDakOpU7l5eUJ37kmQ3PMIy8vj27duiV0GypsIhJ3ubm5dO/ePdVh1GvatGkNHmafzqKSR7ypK1JE\nRCJFhU1ERCJFhU1ERCLFmvOoJTPbABx8ordDKwDqn1OmeYlKLlHJA5RLuopKLlHJA+Cr7t42Hitq\n1oNH3P2Ipq7DzGa5e3E84km1qOQSlTxAuaSrqOQSlTwgyCVe61JXpIiIRIoKm4iIRIoKG4xNdQBx\nFJVcopIHKJd0FZVcopIHxDGXZj14REREZH9qsYmISKSosImISKRkbGEzs0vM7CMzW25m96Y6noYw\ns1Iz+9DM5lUPjTWzTmY22cyWhb87hsvNzB4L81tgZv1THPvTZrbezBbWWnbYsZvZd8LnLzOz76RR\nLr8ws1XhZzPPzC6t9di/hrl8ZGZfr7U8pd9BMzvGzKaa2WIzW2RmPwiXN7vP5SC5NMfPJc/MPjCz\n+WEu94XLu5vZjDCuCWbWIlzeMry/PHy86FA5pjiPZ8xsRa3PpF+4PH7fr3hdirs5/QDZwCfAcUAL\nYD7QO9VxNSDuUqBgv2UPA/eGt+8FHgpvXwpMAgw4A5iR4tjPA/oDCxsbO9AJ+DT83TG83TFNcvkF\ncFcdz+0dfr9aAt3D7112OnwHgaOA/uHttsDHYbzN7nM5SC7N8XMxID+8nQvMCN/vF4BrwuW/A24L\nb/8z8Lvw9jXAhIPlmAZ5PANcVcfz4/b9ytQW2+nAcnf/1N13AyXA0BTH1FhDgWfD288Cw2otf84D\n7wMdzOyoVAQI4O7vApv3W3y4sX8dmOzum919CzAZuCTx0e+rnlzqMxQocfcKd18BLCf4/qX8O+ju\na9x9Tnh7O7AE6Eoz/FwOkkt90vlzcXcvC+/mhj8OXAC8FC7f/3Op/rxeAi40M6P+HJPiIHnUJ27f\nr0wtbF2BL2rdX8nB/wjShQN/NbPZZnZzuKzQ3deEt9cCheHt5pDj4cae7jl9L+xCebq6+45mkkvY\nfXUqwX/Vzfpz2S8XaIafi5llm9k8YD3BjvwT4Et3r6wjrpqYw8e3Ap1Jg1z2z8Pdqz+TB8LPZIyZ\ntQyXxe0zydTC1lyd4+79gSHA7WZ2Xu0HPWi3N8vzN5pz7KEngB5AP2AN8MvUhtNwZpYPvAzc6e7b\naj/W3D6XOnJplp+Lu1e5ez+gG0Erq1eKQ2qU/fMws5OBfyXI5zSC7sUfxXu7mVrYVgHH1LrfLVyW\n1tx9Vfh7PTCR4Au/rrqLMfy9Pnx6c8jxcGNP25zcfV34RxwDnmRvl09a52JmuQSF4Hl3fyVc3Cw/\nl7pyaa6fSzV3/xKYCpxJ0DVXPb9v7bhqYg4fbw9sIo1yqZXHJWG3sbt7BTCOBHwmmVrYZgI9w1FG\nLQgOuP45xTEdlJm1MbO21beBi4GFBHFXjxL6DvBaePvPwPXhSKMzgK21upfSxeHG/hZwsZl1DLuU\nLg6Xpdx+xy+HE3w2EORyTThyrTvQE/iANPgOhsdhngKWuPujtR5qdp9Lfbk008/lCDPrEN5uBVxE\ncMxwKnBV+LT9P5fqz+sq4J2wpV1fjklRTx5La/3TZATHCWt/JvH5fjV2xEtz/yEYgfMxQd/1j1Md\nTwPiPY5ghNN8YFF1zAR96VOAZcDbQCffOyLpN2F+HwLFKY5/PEFX0B6CPvIbGxM78F2Cg+DLgdFp\nlMsfwlgXhH+gR9V6/o/DXD4ChqTLdxA4h6CbcQEwL/y5tDl+LgfJpTl+Ln2AuWHMC4GfhcuPIyhM\ny4EXgZbh8rzw/vLw8eMOlWOK83gn/EwWAn9k78jJuH2/NKWWiIhESqZ2RYqISESpsImISKSosImI\nSKSosImISKSosImISKSosIkkiZlV1ZrRfJ7FceZ4MyuyWlcbEMlkOYd+iojEyS4PphcSkQRSi00k\nxSy4zt7DFlxr7wMzOz5cXmRm74STxU4xs2PD5YVmNtGC61zNN7OzwlVlm9mTFlz76q/hbA8iGUeF\nTSR5Wu3XFTmi1mNb3f0U4HHgv8Jlvwaedfc+wPPAY+Hyx4C/uXtfguvCLQqX9wR+4+4nAV8C30xw\nPiJpSTOPiCSJmZW5e34dy0uBC9z903Ai37Xu3tnMNhJMAbUnXL7G3QvMbAPQzYNJZKvXUURwWZCe\n4f0fAbnufn/iMxNJL2qxiaQHr+f24aiodbsKHUOXDKXCJpIeRtT6/Y/w9nsEs8sDjAKmh7enALdB\nzYUc2ycrSJHmQP/RiSRPq/BqwtXedPfqIf8dzWwBQatrZLjs+8A4M7sb2ACMDpf/ABhrZjcStMxu\nI7jagIigY2wiKRceYyt2942pjkUkCtQVKSIikaIWm4iIRIpabCIiEikqbCIiEikqbCIiEikqbCIi\nEikqbCIiEin/H559wQhBI725AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiak3L46dJA2",
        "colab_type": "code",
        "outputId": "cd18a66a-817a-4ab3-893c-0d5d259f66ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "steps_plot =  [step for step in range(0, 3333, plot_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1CaNdeDc_9p",
        "colab_type": "code",
        "outputId": "dd2c958b-9db7-40a8-d7e1-5815adfead7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.16452\n",
            "160\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQiZpMXVc_6P",
        "colab_type": "code",
        "outputId": "f0da4956-c211-4bf4-d7ab-570c9994f9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.16452\n",
            "160\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AenHvoY8c_3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY1cF8ZQb1l2",
        "colab_type": "text"
      },
      "source": [
        "## Now retrain till 1900  epoch with complete data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk4b9AoviHXG",
        "colab_type": "code",
        "outputId": "689b319e-720f-4b13-d617-d525ba297e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 6)\n",
            "(7352, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeoQbuFiHTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dSoVofcifpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1910"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMrVBWxFiTse",
        "colab_type": "code",
        "outputId": "362584a4-a84a-4c15-f113-fbea6ced127a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2142
        }
      },
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 4112\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.0001\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 3\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(combined_train_valid, combined_train_valid_label)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "    saver.save(sess, './HArFullBest')\n",
        "    G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1910, training loss= 0.038889285, training acc= 99.42864775657654%\n",
            "Validation Accuracy 97.62066650390625 ...\n",
            "\n",
            "Epoch 50/1910, training loss= 0.0027638515, training acc= 99.91837739944458%\n",
            "Validation Accuracy 99.59211730957031 ...\n",
            "\n",
            "Epoch 100/1910, training loss= 0.0014243348, training acc= 99.98639822006226%\n",
            "Validation Accuracy 99.93202209472656 ...\n",
            "\n",
            "Epoch 150/1910, training loss= 0.0011546826, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 200/1910, training loss= 0.0009938759, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 250/1910, training loss= 0.0008778551, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 300/1910, training loss= 0.0007857877, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 350/1910, training loss= 0.00070962025, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 400/1910, training loss= 0.00064526976, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 450/1910, training loss= 0.0005893623, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 500/1910, training loss= 0.0005404174, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 550/1910, training loss= 0.0004972765, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 600/1910, training loss= 0.00045864854, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 650/1910, training loss= 0.0004240286, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 700/1910, training loss= 0.00039282846, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 750/1910, training loss= 0.0003644216, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 800/1910, training loss= 0.00033861463, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 850/1910, training loss= 0.0003150697, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 900/1910, training loss= 0.000293397, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 950/1910, training loss= 0.00027358893, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1000/1910, training loss= 0.00025541533, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1050/1910, training loss= 0.00023860007, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1100/1910, training loss= 0.00022300461, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1150/1910, training loss= 0.00020857563, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1200/1910, training loss= 0.00019520582, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1250/1910, training loss= 0.00018275817, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1300/1910, training loss= 0.00017120955, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1350/1910, training loss= 0.00016049427, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1400/1910, training loss= 0.00015048501, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1450/1910, training loss= 0.00014118908, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1500/1910, training loss= 0.00013245973, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1550/1910, training loss= 0.00012432421, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1600/1910, training loss= 0.000116742944, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1650/1910, training loss= 0.000109654524, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1700/1910, training loss= 0.00010303795, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1750/1910, training loss= 9.6831354e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1800/1910, training loss= 9.104213e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1850/1910, training loss= 8.561608e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1900/1910, training loss= 8.0520185e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Valid acc= 100.0 %\n",
            "==================================================\n",
            "W1\n",
            "3\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2mxHqJHiTqL",
        "colab_type": "code",
        "outputId": "6508dd26-455c-4bff-b5c1-8d31307e8a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './HArFullBest')\n",
        "    train_accuracy = sess.run(accuracy*100, feed_dict={X: X_train,Y: y_train})\n",
        "    print(\"Train acc=\",str(train_accuracy), \"%\")\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./HArFullBest\n",
            "Train acc= 100.0 %\n",
            "ValidValid acc= 100.0 %\n",
            "Test acc= 95.07974 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFeVzG-_iTnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbc1-WviiTkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "source": [
        "## Best Tuned, Use W1 = 4, W2 =2, W3 = 1 from best validation accuracy found below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W5Fa3AIQ5n8N",
        "colab": {}
      },
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [374]\n",
        "num_steps = 100000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY5Bt2EM3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwd9EKfLM3Z9",
        "colab_type": "code",
        "outputId": "82535c54-6378-4f17-f5b2-987d3de0fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEYCAYAAAA06gPTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpHiEL6VM3aB",
        "colab_type": "code",
        "outputId": "2d03f9be-d0d6-4a16-aecf-a242575ce7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.64704\n",
            "485\n",
            "24250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_l2RRE0M3aE",
        "colab_type": "code",
        "outputId": "8ad5cca4-e098-4fa4-bd62-f5f537063401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 6)\n",
            "(7352, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaKv7GnsM3aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRpkJTtqM3aJ",
        "colab_type": "text"
      },
      "source": [
        "#### Now retrain on this appended test data till 24300 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Uifa_UHiM3aK",
        "colab_type": "code",
        "outputId": "d8ba0e2b-73ee-415a-c457-940391c94d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8432
        }
      },
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 24300\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "    \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 0.45379114, training acc total= 93.14671754837036%\n",
            "step 50, training loss Total= 0.039833248, training acc total= 99.64147806167603%\n",
            "step 100, training loss Total= 0.045330588, training acc total= 99.3381142616272%\n",
            "step 150, training loss Total= 0.019238897, training acc total= 99.79315996170044%\n",
            "step 200, training loss Total= 0.013733287, training acc total= 99.86210465431213%\n",
            "step 250, training loss Total= 0.021557797, training acc total= 99.7380018234253%\n",
            "step 300, training loss Total= 0.15683196, training acc total= 98.17981123924255%\n",
            "step 350, training loss Total= 0.016487077, training acc total= 99.86210465431213%\n",
            "step 400, training loss Total= 0.04703603, training acc total= 99.32432174682617%\n",
            "step 450, training loss Total= 0.01743794, training acc total= 99.82073903083801%\n",
            "step 500, training loss Total= 0.009342014, training acc total= 99.91726279258728%\n",
            "step 550, training loss Total= 0.014104057, training acc total= 99.94484186172485%\n",
            "step 600, training loss Total= 0.056876045, training acc total= 99.46221709251404%\n",
            "step 650, training loss Total= 0.023242952, training acc total= 99.75179433822632%\n",
            "step 700, training loss Total= 0.039095264, training acc total= 99.64147806167603%\n",
            "step 750, training loss Total= 0.01313867, training acc total= 99.90347623825073%\n",
            "step 800, training loss Total= 0.0052991095, training acc total= 99.97242093086243%\n",
            "step 850, training loss Total= 0.0073110424, training acc total= 99.94484186172485%\n",
            "step 900, training loss Total= 0.0054948954, training acc total= 100.0%\n",
            "step 950, training loss Total= 0.0026818907, training acc total= 100.0%\n",
            "step 1000, training loss Total= 0.005416252, training acc total= 99.95863437652588%\n",
            "step 1050, training loss Total= 0.0029244383, training acc total= 99.98621344566345%\n",
            "step 1100, training loss Total= 0.009015584, training acc total= 99.91726279258728%\n",
            "step 1150, training loss Total= 0.0047110305, training acc total= 99.97242093086243%\n",
            "step 1200, training loss Total= 0.0025466764, training acc total= 100.0%\n",
            "step 1250, training loss Total= 0.011902557, training acc total= 99.90347623825073%\n",
            "step 1300, training loss Total= 0.0025260278, training acc total= 100.0%\n",
            "step 1350, training loss Total= 0.02453232, training acc total= 99.82073903083801%\n",
            "step 1400, training loss Total= 0.01409426, training acc total= 99.82073903083801%\n",
            "step 1450, training loss Total= 0.023859076, training acc total= 99.80695247650146%\n",
            "step 1500, training loss Total= 0.03329613, training acc total= 99.6690571308136%\n",
            "step 1550, training loss Total= 0.009649995, training acc total= 99.86210465431213%\n",
            "step 1600, training loss Total= 0.003689609, training acc total= 99.98621344566345%\n",
            "step 1650, training loss Total= 0.0005480611, training acc total= 100.0%\n",
            "step 1700, training loss Total= 0.0006046851, training acc total= 100.0%\n",
            "step 1750, training loss Total= 0.002250957, training acc total= 100.0%\n",
            "step 1800, training loss Total= 0.0011101604, training acc total= 99.98621344566345%\n",
            "step 1850, training loss Total= 0.000708361, training acc total= 99.98621344566345%\n",
            "step 1900, training loss Total= 0.00043114158, training acc total= 99.98621344566345%\n",
            "step 1950, training loss Total= 0.00029356795, training acc total= 99.98621344566345%\n",
            "step 2000, training loss Total= 0.0003990697, training acc total= 100.0%\n",
            "step 2050, training loss Total= 0.0002397307, training acc total= 100.0%\n",
            "step 2100, training loss Total= 0.0001829968, training acc total= 100.0%\n",
            "step 2150, training loss Total= 0.00016412513, training acc total= 100.0%\n",
            "step 2200, training loss Total= 0.00016021628, training acc total= 100.0%\n",
            "step 2250, training loss Total= 0.00015052022, training acc total= 100.0%\n",
            "step 2300, training loss Total= 0.00014221712, training acc total= 100.0%\n",
            "step 2350, training loss Total= 0.00013628391, training acc total= 100.0%\n",
            "step 2400, training loss Total= 0.0001313389, training acc total= 100.0%\n",
            "step 2450, training loss Total= 0.0001279928, training acc total= 100.0%\n",
            "step 2500, training loss Total= 0.00012342617, training acc total= 100.0%\n",
            "step 2550, training loss Total= 0.00011975322, training acc total= 100.0%\n",
            "step 2600, training loss Total= 0.00011516353, training acc total= 100.0%\n",
            "step 2650, training loss Total= 0.000115180126, training acc total= 100.0%\n",
            "step 2700, training loss Total= 0.00010938619, training acc total= 100.0%\n",
            "step 2750, training loss Total= 0.000107229935, training acc total= 100.0%\n",
            "step 2800, training loss Total= 0.00010414702, training acc total= 100.0%\n",
            "step 2850, training loss Total= 0.00010170599, training acc total= 100.0%\n",
            "step 2900, training loss Total= 9.9578305e-05, training acc total= 100.0%\n",
            "step 2950, training loss Total= 9.720049e-05, training acc total= 100.0%\n",
            "step 3000, training loss Total= 9.5185576e-05, training acc total= 100.0%\n",
            "step 3050, training loss Total= 9.3388655e-05, training acc total= 100.0%\n",
            "step 3100, training loss Total= 9.1292364e-05, training acc total= 100.0%\n",
            "step 3150, training loss Total= 9.0570175e-05, training acc total= 100.0%\n",
            "step 3200, training loss Total= 8.810865e-05, training acc total= 100.0%\n",
            "step 3250, training loss Total= 8.655106e-05, training acc total= 100.0%\n",
            "step 3300, training loss Total= 8.511055e-05, training acc total= 100.0%\n",
            "step 3350, training loss Total= 8.30821e-05, training acc total= 100.0%\n",
            "step 3400, training loss Total= 8.2190854e-05, training acc total= 100.0%\n",
            "step 3450, training loss Total= 7.991048e-05, training acc total= 100.0%\n",
            "step 3500, training loss Total= 7.9128265e-05, training acc total= 100.0%\n",
            "step 3550, training loss Total= 7.738369e-05, training acc total= 100.0%\n",
            "step 3600, training loss Total= 7.606571e-05, training acc total= 100.0%\n",
            "step 3650, training loss Total= 7.4599535e-05, training acc total= 100.0%\n",
            "step 3700, training loss Total= 7.394822e-05, training acc total= 100.0%\n",
            "step 3750, training loss Total= 7.243282e-05, training acc total= 100.0%\n",
            "step 3800, training loss Total= 7.1066104e-05, training acc total= 100.0%\n",
            "step 3850, training loss Total= 7.007496e-05, training acc total= 100.0%\n",
            "step 3900, training loss Total= 6.9149006e-05, training acc total= 100.0%\n",
            "step 3950, training loss Total= 6.789845e-05, training acc total= 100.0%\n",
            "step 4000, training loss Total= 6.752289e-05, training acc total= 100.0%\n",
            "step 4050, training loss Total= 6.586513e-05, training acc total= 100.0%\n",
            "step 4100, training loss Total= 6.472743e-05, training acc total= 100.0%\n",
            "step 4150, training loss Total= 6.4207445e-05, training acc total= 100.0%\n",
            "step 4200, training loss Total= 6.291922e-05, training acc total= 100.0%\n",
            "step 4250, training loss Total= 6.2562474e-05, training acc total= 100.0%\n",
            "step 4300, training loss Total= 6.151337e-05, training acc total= 100.0%\n",
            "step 4350, training loss Total= 6.0053877e-05, training acc total= 100.0%\n",
            "step 4400, training loss Total= 5.98447e-05, training acc total= 100.0%\n",
            "step 4450, training loss Total= 5.832744e-05, training acc total= 100.0%\n",
            "step 4500, training loss Total= 5.7690355e-05, training acc total= 100.0%\n",
            "step 4550, training loss Total= 5.6781522e-05, training acc total= 100.0%\n",
            "step 4600, training loss Total= 5.579446e-05, training acc total= 100.0%\n",
            "step 4650, training loss Total= 5.5062155e-05, training acc total= 100.0%\n",
            "step 4700, training loss Total= 5.510753e-05, training acc total= 100.0%\n",
            "step 4750, training loss Total= 5.3011812e-05, training acc total= 100.0%\n",
            "step 4800, training loss Total= 5.2269887e-05, training acc total= 100.0%\n",
            "step 4850, training loss Total= 5.1641724e-05, training acc total= 100.0%\n",
            "step 4900, training loss Total= 5.0703253e-05, training acc total= 100.0%\n",
            "step 4950, training loss Total= 5.019182e-05, training acc total= 100.0%\n",
            "step 5000, training loss Total= 5.0755316e-05, training acc total= 100.0%\n",
            "step 5050, training loss Total= 4.9589915e-05, training acc total= 100.0%\n",
            "step 5100, training loss Total= 4.7938887e-05, training acc total= 100.0%\n",
            "step 5150, training loss Total= 4.7407844e-05, training acc total= 100.0%\n",
            "step 5200, training loss Total= 4.6303157e-05, training acc total= 100.0%\n",
            "step 5250, training loss Total= 4.5708e-05, training acc total= 100.0%\n",
            "step 5300, training loss Total= 4.47868e-05, training acc total= 100.0%\n",
            "step 5350, training loss Total= 4.4157092e-05, training acc total= 100.0%\n",
            "step 5400, training loss Total= 4.3727534e-05, training acc total= 100.0%\n",
            "step 5450, training loss Total= 4.2848886e-05, training acc total= 100.0%\n",
            "step 5500, training loss Total= 4.2399846e-05, training acc total= 100.0%\n",
            "step 5550, training loss Total= 4.15261e-05, training acc total= 100.0%\n",
            "step 5600, training loss Total= 4.097614e-05, training acc total= 100.0%\n",
            "step 5650, training loss Total= 4.076816e-05, training acc total= 100.0%\n",
            "step 5700, training loss Total= 3.970181e-05, training acc total= 100.0%\n",
            "step 5750, training loss Total= 3.933144e-05, training acc total= 100.0%\n",
            "step 5800, training loss Total= 3.898717e-05, training acc total= 100.0%\n",
            "step 5850, training loss Total= 3.7689042e-05, training acc total= 100.0%\n",
            "step 5900, training loss Total= 3.6948193e-05, training acc total= 100.0%\n",
            "step 5950, training loss Total= 3.6885023e-05, training acc total= 100.0%\n",
            "step 6000, training loss Total= 3.5781293e-05, training acc total= 100.0%\n",
            "step 6050, training loss Total= 3.5292782e-05, training acc total= 100.0%\n",
            "step 6100, training loss Total= 3.5001445e-05, training acc total= 100.0%\n",
            "step 6150, training loss Total= 3.4707784e-05, training acc total= 100.0%\n",
            "step 6200, training loss Total= 3.333456e-05, training acc total= 100.0%\n",
            "step 6250, training loss Total= 3.2890694e-05, training acc total= 100.0%\n",
            "step 6300, training loss Total= 3.268921e-05, training acc total= 100.0%\n",
            "step 6350, training loss Total= 3.1813724e-05, training acc total= 100.0%\n",
            "step 6400, training loss Total= 3.1175947e-05, training acc total= 100.0%\n",
            "step 6450, training loss Total= 3.06217e-05, training acc total= 100.0%\n",
            "step 6500, training loss Total= 2.9924515e-05, training acc total= 100.0%\n",
            "step 6550, training loss Total= 2.9368362e-05, training acc total= 100.0%\n",
            "step 6600, training loss Total= 2.9557104e-05, training acc total= 100.0%\n",
            "step 6650, training loss Total= 2.8611234e-05, training acc total= 100.0%\n",
            "step 6700, training loss Total= 2.7806207e-05, training acc total= 100.0%\n",
            "step 6750, training loss Total= 2.8191218e-05, training acc total= 100.0%\n",
            "step 6800, training loss Total= 2.6764219e-05, training acc total= 100.0%\n",
            "step 6850, training loss Total= 2.6985621e-05, training acc total= 100.0%\n",
            "step 6900, training loss Total= 2.5748674e-05, training acc total= 100.0%\n",
            "step 6950, training loss Total= 2.5859163e-05, training acc total= 100.0%\n",
            "step 7000, training loss Total= 2.4881081e-05, training acc total= 100.0%\n",
            "step 7050, training loss Total= 2.4454004e-05, training acc total= 100.0%\n",
            "step 7100, training loss Total= 2.4397496e-05, training acc total= 100.0%\n",
            "step 7150, training loss Total= 2.3464538e-05, training acc total= 100.0%\n",
            "step 7200, training loss Total= 2.3243449e-05, training acc total= 100.0%\n",
            "step 7250, training loss Total= 2.2654332e-05, training acc total= 100.0%\n",
            "step 7300, training loss Total= 2.2294273e-05, training acc total= 100.0%\n",
            "step 7350, training loss Total= 2.1747077e-05, training acc total= 100.0%\n",
            "step 7400, training loss Total= 2.1405414e-05, training acc total= 100.0%\n",
            "step 7450, training loss Total= 2.1371805e-05, training acc total= 100.0%\n",
            "step 7500, training loss Total= 2.0714097e-05, training acc total= 100.0%\n",
            "step 7550, training loss Total= 2.0047093e-05, training acc total= 100.0%\n",
            "step 7600, training loss Total= 1.9721607e-05, training acc total= 100.0%\n",
            "step 7650, training loss Total= 1.9668209e-05, training acc total= 100.0%\n",
            "step 7700, training loss Total= 1.9357909e-05, training acc total= 100.0%\n",
            "step 7750, training loss Total= 1.8505072e-05, training acc total= 100.0%\n",
            "step 7800, training loss Total= 1.8325072e-05, training acc total= 100.0%\n",
            "step 7850, training loss Total= 1.7988601e-05, training acc total= 100.0%\n",
            "step 7900, training loss Total= 1.7382707e-05, training acc total= 100.0%\n",
            "step 7950, training loss Total= 1.7103308e-05, training acc total= 100.0%\n",
            "step 8000, training loss Total= 1.676944e-05, training acc total= 100.0%\n",
            "step 8050, training loss Total= 1.6405153e-05, training acc total= 100.0%\n",
            "step 8100, training loss Total= 1.6218299e-05, training acc total= 100.0%\n",
            "step 8150, training loss Total= 1.5685093e-05, training acc total= 100.0%\n",
            "step 8200, training loss Total= 1.5637701e-05, training acc total= 100.0%\n",
            "step 8250, training loss Total= 1.5384174e-05, training acc total= 100.0%\n",
            "step 8300, training loss Total= 1.5263153e-05, training acc total= 100.0%\n",
            "step 8350, training loss Total= 1.4749183e-05, training acc total= 100.0%\n",
            "step 8400, training loss Total= 1.4942148e-05, training acc total= 100.0%\n",
            "step 8450, training loss Total= 1.3973641e-05, training acc total= 100.0%\n",
            "step 8500, training loss Total= 1.5342941e-05, training acc total= 100.0%\n",
            "step 8550, training loss Total= 1.352159e-05, training acc total= 100.0%\n",
            "step 8600, training loss Total= 1.3141211e-05, training acc total= 100.0%\n",
            "step 8650, training loss Total= 1.2816561e-05, training acc total= 100.0%\n",
            "step 8700, training loss Total= 1.2515919e-05, training acc total= 100.0%\n",
            "step 8750, training loss Total= 1.2235865e-05, training acc total= 100.0%\n",
            "step 8800, training loss Total= 1.194812e-05, training acc total= 100.0%\n",
            "step 8850, training loss Total= 1.1650202e-05, training acc total= 100.0%\n",
            "step 8900, training loss Total= 1.18395465e-05, training acc total= 100.0%\n",
            "step 8950, training loss Total= 1.1626804e-05, training acc total= 100.0%\n",
            "step 9000, training loss Total= 1.09505445e-05, training acc total= 100.0%\n",
            "step 9050, training loss Total= 1.0693775e-05, training acc total= 100.0%\n",
            "step 9100, training loss Total= 1.0483288e-05, training acc total= 100.0%\n",
            "step 9150, training loss Total= 1.0218528e-05, training acc total= 100.0%\n",
            "step 9200, training loss Total= 1.0311115e-05, training acc total= 100.0%\n",
            "step 9250, training loss Total= 1.0391344e-05, training acc total= 100.0%\n",
            "step 9300, training loss Total= 9.610909e-06, training acc total= 100.0%\n",
            "step 9350, training loss Total= 9.3115705e-06, training acc total= 100.0%\n",
            "step 9400, training loss Total= 9.170817e-06, training acc total= 100.0%\n",
            "step 9450, training loss Total= 8.87041e-06, training acc total= 100.0%\n",
            "step 9500, training loss Total= 8.703654e-06, training acc total= 100.0%\n",
            "step 9550, training loss Total= 8.5080765e-06, training acc total= 100.0%\n",
            "step 9600, training loss Total= 8.317578e-06, training acc total= 100.0%\n",
            "step 9650, training loss Total= 8.11799e-06, training acc total= 100.0%\n",
            "step 9700, training loss Total= 7.88519e-06, training acc total= 100.0%\n",
            "step 9750, training loss Total= 7.749754e-06, training acc total= 100.0%\n",
            "step 9800, training loss Total= 7.5953894e-06, training acc total= 100.0%\n",
            "step 9850, training loss Total= 7.3588785e-06, training acc total= 100.0%\n",
            "step 9900, training loss Total= 7.3093056e-06, training acc total= 100.0%\n",
            "step 9950, training loss Total= 7.02444e-06, training acc total= 100.0%\n",
            "step 10000, training loss Total= 6.8462446e-06, training acc total= 100.0%\n",
            "step 10050, training loss Total= 6.649202e-06, training acc total= 100.0%\n",
            "step 10100, training loss Total= 6.5015815e-06, training acc total= 100.0%\n",
            "step 10150, training loss Total= 6.4178876e-06, training acc total= 100.0%\n",
            "step 10200, training loss Total= 6.4071637e-06, training acc total= 100.0%\n",
            "step 10250, training loss Total= 6.3303687e-06, training acc total= 100.0%\n",
            "step 10300, training loss Total= 5.9762883e-06, training acc total= 100.0%\n",
            "step 10350, training loss Total= 6.5979016e-06, training acc total= 100.0%\n",
            "step 10400, training loss Total= 6.0262655e-06, training acc total= 100.0%\n",
            "step 10450, training loss Total= 5.6011913e-06, training acc total= 100.0%\n",
            "step 10500, training loss Total= 5.4835136e-06, training acc total= 100.0%\n",
            "step 10550, training loss Total= 5.374652e-06, training acc total= 100.0%\n",
            "step 10600, training loss Total= 5.1238726e-06, training acc total= 100.0%\n",
            "step 10650, training loss Total= 4.988756e-06, training acc total= 100.0%\n",
            "step 10700, training loss Total= 5.152259e-06, training acc total= 100.0%\n",
            "step 10750, training loss Total= 4.868415e-06, training acc total= 100.0%\n",
            "step 10800, training loss Total= 4.6311525e-06, training acc total= 100.0%\n",
            "step 10850, training loss Total= 4.490116e-06, training acc total= 100.0%\n",
            "step 10900, training loss Total= 4.3844657e-06, training acc total= 100.0%\n",
            "step 10950, training loss Total= 4.347875e-06, training acc total= 100.0%\n",
            "step 11000, training loss Total= 4.3009345e-06, training acc total= 100.0%\n",
            "step 11050, training loss Total= 4.264303e-06, training acc total= 100.0%\n",
            "step 11100, training loss Total= 4.0137693e-06, training acc total= 100.0%\n",
            "step 11150, training loss Total= 3.863273e-06, training acc total= 100.0%\n",
            "step 11200, training loss Total= 3.8003948e-06, training acc total= 100.0%\n",
            "step 11250, training loss Total= 3.825282e-06, training acc total= 100.0%\n",
            "step 11300, training loss Total= 3.6556785e-06, training acc total= 100.0%\n",
            "step 11350, training loss Total= 3.543266e-06, training acc total= 100.0%\n",
            "step 11400, training loss Total= 3.4455707e-06, training acc total= 100.0%\n",
            "step 11450, training loss Total= 3.3386596e-06, training acc total= 100.0%\n",
            "step 11500, training loss Total= 3.3748452e-06, training acc total= 100.0%\n",
            "step 11550, training loss Total= 3.1914726e-06, training acc total= 100.0%\n",
            "step 11600, training loss Total= 3.084842e-06, training acc total= 100.0%\n",
            "step 11650, training loss Total= 2.993544e-06, training acc total= 100.0%\n",
            "step 11700, training loss Total= 2.931459e-06, training acc total= 100.0%\n",
            "step 11750, training loss Total= 2.865205e-06, training acc total= 100.0%\n",
            "step 11800, training loss Total= 2.795469e-06, training acc total= 100.0%\n",
            "step 11850, training loss Total= 2.874802e-06, training acc total= 100.0%\n",
            "step 11900, training loss Total= 1.0209057, training acc total= 94.60838437080383%\n",
            "step 11950, training loss Total= 0.07255421, training acc total= 99.37947988510132%\n",
            "step 12000, training loss Total= 0.0339027, training acc total= 99.86210465431213%\n",
            "step 12050, training loss Total= 0.014941098, training acc total= 99.97242093086243%\n",
            "step 12100, training loss Total= 0.021021731, training acc total= 99.94484186172485%\n",
            "step 12150, training loss Total= 0.0063558845, training acc total= 99.97242093086243%\n",
            "step 12200, training loss Total= 0.0075750193, training acc total= 100.0%\n",
            "step 12250, training loss Total= 0.005658201, training acc total= 99.98621344566345%\n",
            "step 12300, training loss Total= 0.0025600367, training acc total= 100.0%\n",
            "step 12350, training loss Total= 0.01002537, training acc total= 99.94484186172485%\n",
            "step 12400, training loss Total= 0.0026108145, training acc total= 100.0%\n",
            "step 12450, training loss Total= 0.0064419555, training acc total= 100.0%\n",
            "step 12500, training loss Total= 0.0029203158, training acc total= 100.0%\n",
            "step 12550, training loss Total= 0.002632146, training acc total= 100.0%\n",
            "step 12600, training loss Total= 0.00075261656, training acc total= 100.0%\n",
            "step 12650, training loss Total= 0.000614577, training acc total= 100.0%\n",
            "step 12700, training loss Total= 0.00038471568, training acc total= 100.0%\n",
            "step 12750, training loss Total= 0.0002161647, training acc total= 100.0%\n",
            "step 12800, training loss Total= 0.00012398882, training acc total= 100.0%\n",
            "step 12850, training loss Total= 0.000118790806, training acc total= 100.0%\n",
            "step 12900, training loss Total= 9.826971e-05, training acc total= 100.0%\n",
            "step 12950, training loss Total= 8.907376e-05, training acc total= 100.0%\n",
            "step 13000, training loss Total= 8.240566e-05, training acc total= 100.0%\n",
            "step 13050, training loss Total= 7.578769e-05, training acc total= 100.0%\n",
            "step 13100, training loss Total= 7.1960305e-05, training acc total= 100.0%\n",
            "step 13150, training loss Total= 6.774983e-05, training acc total= 100.0%\n",
            "step 13200, training loss Total= 6.53275e-05, training acc total= 100.0%\n",
            "step 13250, training loss Total= 6.2719664e-05, training acc total= 100.0%\n",
            "step 13300, training loss Total= 6.3502426e-05, training acc total= 100.0%\n",
            "step 13350, training loss Total= 5.8850674e-05, training acc total= 100.0%\n",
            "step 13400, training loss Total= 5.8054902e-05, training acc total= 100.0%\n",
            "step 13450, training loss Total= 5.750559e-05, training acc total= 100.0%\n",
            "step 13500, training loss Total= 6.4130785e-05, training acc total= 100.0%\n",
            "step 13550, training loss Total= 5.6682693e-05, training acc total= 100.0%\n",
            "step 13600, training loss Total= 5.308215e-05, training acc total= 100.0%\n",
            "step 13650, training loss Total= 5.2863226e-05, training acc total= 100.0%\n",
            "step 13700, training loss Total= 4.9961112e-05, training acc total= 100.0%\n",
            "step 13750, training loss Total= 4.8936126e-05, training acc total= 100.0%\n",
            "step 13800, training loss Total= 4.7082147e-05, training acc total= 100.0%\n",
            "step 13850, training loss Total= 4.624399e-05, training acc total= 100.0%\n",
            "step 13900, training loss Total= 4.534407e-05, training acc total= 100.0%\n",
            "step 13950, training loss Total= 4.3765842e-05, training acc total= 100.0%\n",
            "step 14000, training loss Total= 4.3111228e-05, training acc total= 100.0%\n",
            "step 14050, training loss Total= 4.7520767e-05, training acc total= 100.0%\n",
            "step 14100, training loss Total= 4.28178e-05, training acc total= 100.0%\n",
            "step 14150, training loss Total= 4.1930125e-05, training acc total= 100.0%\n",
            "step 14200, training loss Total= 4.179911e-05, training acc total= 100.0%\n",
            "step 14250, training loss Total= 4.1090072e-05, training acc total= 100.0%\n",
            "step 14300, training loss Total= 3.924191e-05, training acc total= 100.0%\n",
            "step 14350, training loss Total= 3.9495477e-05, training acc total= 100.0%\n",
            "step 14400, training loss Total= 3.9067312e-05, training acc total= 100.0%\n",
            "step 14450, training loss Total= 3.712748e-05, training acc total= 100.0%\n",
            "step 14500, training loss Total= 3.9845294e-05, training acc total= 100.0%\n",
            "step 14550, training loss Total= 3.5955298e-05, training acc total= 100.0%\n",
            "step 14600, training loss Total= 3.5604637e-05, training acc total= 100.0%\n",
            "step 14650, training loss Total= 3.8322854e-05, training acc total= 100.0%\n",
            "step 14700, training loss Total= 3.435951e-05, training acc total= 100.0%\n",
            "step 14750, training loss Total= 3.4393794e-05, training acc total= 100.0%\n",
            "step 14800, training loss Total= 3.3091106e-05, training acc total= 100.0%\n",
            "step 14850, training loss Total= 3.2454176e-05, training acc total= 100.0%\n",
            "step 14900, training loss Total= 3.198538e-05, training acc total= 100.0%\n",
            "step 14950, training loss Total= 3.2053125e-05, training acc total= 100.0%\n",
            "step 15000, training loss Total= 3.1777246e-05, training acc total= 100.0%\n",
            "step 15050, training loss Total= 3.0407202e-05, training acc total= 100.0%\n",
            "step 15100, training loss Total= 2.995752e-05, training acc total= 100.0%\n",
            "step 15150, training loss Total= 3.0806186e-05, training acc total= 100.0%\n",
            "step 15200, training loss Total= 2.9611158e-05, training acc total= 100.0%\n",
            "step 15250, training loss Total= 2.8551924e-05, training acc total= 100.0%\n",
            "step 15300, training loss Total= 2.8678187e-05, training acc total= 100.0%\n",
            "step 15350, training loss Total= 2.8250133e-05, training acc total= 100.0%\n",
            "step 15400, training loss Total= 2.7691269e-05, training acc total= 100.0%\n",
            "step 15450, training loss Total= 2.7365511e-05, training acc total= 100.0%\n",
            "step 15500, training loss Total= 2.687747e-05, training acc total= 100.0%\n",
            "step 15550, training loss Total= 2.6238273e-05, training acc total= 100.0%\n",
            "step 15600, training loss Total= 2.5903539e-05, training acc total= 100.0%\n",
            "step 15650, training loss Total= 2.5482948e-05, training acc total= 100.0%\n",
            "step 15700, training loss Total= 2.487454e-05, training acc total= 100.0%\n",
            "step 15750, training loss Total= 2.4458062e-05, training acc total= 100.0%\n",
            "step 15800, training loss Total= 2.473055e-05, training acc total= 100.0%\n",
            "step 15850, training loss Total= 2.3969742e-05, training acc total= 100.0%\n",
            "step 15900, training loss Total= 2.6466554e-05, training acc total= 100.0%\n",
            "step 15950, training loss Total= 2.834014e-05, training acc total= 100.0%\n",
            "step 16000, training loss Total= 2.6482347e-05, training acc total= 100.0%\n",
            "step 16050, training loss Total= 2.4651712e-05, training acc total= 100.0%\n",
            "step 16100, training loss Total= 2.3973747e-05, training acc total= 100.0%\n",
            "step 16150, training loss Total= 2.3076702e-05, training acc total= 100.0%\n",
            "step 16200, training loss Total= 2.2449334e-05, training acc total= 100.0%\n",
            "step 16250, training loss Total= 2.2098344e-05, training acc total= 100.0%\n",
            "step 16300, training loss Total= 2.1766302e-05, training acc total= 100.0%\n",
            "step 16350, training loss Total= 2.1222e-05, training acc total= 100.0%\n",
            "step 16400, training loss Total= 2.080561e-05, training acc total= 100.0%\n",
            "step 16450, training loss Total= 2.090354e-05, training acc total= 100.0%\n",
            "step 16500, training loss Total= 2.0370742e-05, training acc total= 100.0%\n",
            "step 16550, training loss Total= 2.0760885e-05, training acc total= 100.0%\n",
            "step 16600, training loss Total= 1.9534786e-05, training acc total= 100.0%\n",
            "step 16650, training loss Total= 1.9427054e-05, training acc total= 100.0%\n",
            "step 16700, training loss Total= 1.87044e-05, training acc total= 100.0%\n",
            "step 16750, training loss Total= 1.8716624e-05, training acc total= 100.0%\n",
            "step 16800, training loss Total= 2.2635626e-05, training acc total= 100.0%\n",
            "step 16850, training loss Total= 1.8225313e-05, training acc total= 100.0%\n",
            "step 16900, training loss Total= 1.7550552e-05, training acc total= 100.0%\n",
            "step 16950, training loss Total= 1.7222199e-05, training acc total= 100.0%\n",
            "step 17000, training loss Total= 1.697274e-05, training acc total= 100.0%\n",
            "step 17050, training loss Total= 1.6750691e-05, training acc total= 100.0%\n",
            "step 17100, training loss Total= 1.6436534e-05, training acc total= 100.0%\n",
            "step 17150, training loss Total= 1.598548e-05, training acc total= 100.0%\n",
            "step 17200, training loss Total= 1.5796219e-05, training acc total= 100.0%\n",
            "step 17250, training loss Total= 1.5340629e-05, training acc total= 100.0%\n",
            "step 17300, training loss Total= 1.565426e-05, training acc total= 100.0%\n",
            "step 17350, training loss Total= 1.46872935e-05, training acc total= 100.0%\n",
            "step 17400, training loss Total= 1.4296611e-05, training acc total= 100.0%\n",
            "step 17450, training loss Total= 1.5036277e-05, training acc total= 100.0%\n",
            "step 17500, training loss Total= 1.508462e-05, training acc total= 100.0%\n",
            "step 17550, training loss Total= 1.4147187e-05, training acc total= 100.0%\n",
            "step 17600, training loss Total= 1.3512053e-05, training acc total= 100.0%\n",
            "step 17650, training loss Total= 1.4053218e-05, training acc total= 100.0%\n",
            "step 17700, training loss Total= 1.3120511e-05, training acc total= 100.0%\n",
            "step 17750, training loss Total= 1.3031911e-05, training acc total= 100.0%\n",
            "step 17800, training loss Total= 1.3263974e-05, training acc total= 100.0%\n",
            "step 17850, training loss Total= 1.2188266e-05, training acc total= 100.0%\n",
            "step 17900, training loss Total= 1.2318173e-05, training acc total= 100.0%\n",
            "step 17950, training loss Total= 1.1965285e-05, training acc total= 100.0%\n",
            "step 18000, training loss Total= 1.1512229e-05, training acc total= 100.0%\n",
            "step 18050, training loss Total= 1.1250276e-05, training acc total= 100.0%\n",
            "step 18100, training loss Total= 1.1044826e-05, training acc total= 100.0%\n",
            "step 18150, training loss Total= 1.2330011e-05, training acc total= 100.0%\n",
            "step 18200, training loss Total= 1.0683701e-05, training acc total= 100.0%\n",
            "step 18250, training loss Total= 1.0797374e-05, training acc total= 100.0%\n",
            "step 18300, training loss Total= 1.0438748e-05, training acc total= 100.0%\n",
            "step 18350, training loss Total= 1.00635125e-05, training acc total= 100.0%\n",
            "step 18400, training loss Total= 9.913598e-06, training acc total= 100.0%\n",
            "step 18450, training loss Total= 1.0549147e-05, training acc total= 100.0%\n",
            "step 18500, training loss Total= 1.0018655e-05, training acc total= 100.0%\n",
            "step 18550, training loss Total= 1.0534897e-05, training acc total= 100.0%\n",
            "step 18600, training loss Total= 9.481535e-06, training acc total= 100.0%\n",
            "step 18650, training loss Total= 9.153038e-06, training acc total= 100.0%\n",
            "step 18700, training loss Total= 8.9223395e-06, training acc total= 100.0%\n",
            "step 18750, training loss Total= 8.7094795e-06, training acc total= 100.0%\n",
            "step 18800, training loss Total= 8.681695e-06, training acc total= 100.0%\n",
            "step 18850, training loss Total= 8.363177e-06, training acc total= 100.0%\n",
            "step 18900, training loss Total= 8.277223e-06, training acc total= 100.0%\n",
            "step 18950, training loss Total= 8.2033885e-06, training acc total= 100.0%\n",
            "step 19000, training loss Total= 7.806901e-06, training acc total= 100.0%\n",
            "step 19050, training loss Total= 7.658677e-06, training acc total= 100.0%\n",
            "step 19100, training loss Total= 7.775378e-06, training acc total= 100.0%\n",
            "step 19150, training loss Total= 7.3148403e-06, training acc total= 100.0%\n",
            "step 19200, training loss Total= 7.185485e-06, training acc total= 100.0%\n",
            "step 19250, training loss Total= 7.5392913e-06, training acc total= 100.0%\n",
            "step 19300, training loss Total= 7.0234905e-06, training acc total= 100.0%\n",
            "step 19350, training loss Total= 6.9441194e-06, training acc total= 100.0%\n",
            "step 19400, training loss Total= 6.727451e-06, training acc total= 100.0%\n",
            "step 19450, training loss Total= 6.7591345e-06, training acc total= 100.0%\n",
            "step 19500, training loss Total= 6.681769e-06, training acc total= 100.0%\n",
            "step 19550, training loss Total= 6.309461e-06, training acc total= 100.0%\n",
            "step 19600, training loss Total= 6.2060367e-06, training acc total= 100.0%\n",
            "step 19650, training loss Total= 6.0697666e-06, training acc total= 100.0%\n",
            "step 19700, training loss Total= 5.915979e-06, training acc total= 100.0%\n",
            "step 19750, training loss Total= 5.7332577e-06, training acc total= 100.0%\n",
            "step 19800, training loss Total= 5.637579e-06, training acc total= 100.0%\n",
            "step 19850, training loss Total= 5.9968793e-06, training acc total= 100.0%\n",
            "step 19900, training loss Total= 5.424773e-06, training acc total= 100.0%\n",
            "step 19950, training loss Total= 5.447223e-06, training acc total= 100.0%\n",
            "step 20000, training loss Total= 5.1735146e-06, training acc total= 100.0%\n",
            "step 20050, training loss Total= 5.4999823e-06, training acc total= 100.0%\n",
            "step 20100, training loss Total= 5.0290687e-06, training acc total= 100.0%\n",
            "step 20150, training loss Total= 4.842328e-06, training acc total= 100.0%\n",
            "step 20200, training loss Total= 4.793106e-06, training acc total= 100.0%\n",
            "step 20250, training loss Total= 4.73369e-06, training acc total= 100.0%\n",
            "step 20300, training loss Total= 4.645777e-06, training acc total= 100.0%\n",
            "step 20350, training loss Total= 4.8547076e-06, training acc total= 100.0%\n",
            "step 20400, training loss Total= 4.9739415e-06, training acc total= 100.0%\n",
            "step 20450, training loss Total= 3.5053017, training acc total= 89.68560099601746%\n",
            "step 20500, training loss Total= 0.10172338, training acc total= 99.25537705421448%\n",
            "step 20550, training loss Total= 0.037739296, training acc total= 99.86210465431213%\n",
            "step 20600, training loss Total= 0.018938145, training acc total= 99.94484186172485%\n",
            "step 20650, training loss Total= 0.020598738, training acc total= 99.8896837234497%\n",
            "step 20700, training loss Total= 0.03055688, training acc total= 99.79315996170044%\n",
            "step 20750, training loss Total= 0.007804987, training acc total= 99.95863437652588%\n",
            "step 20800, training loss Total= 0.008381491, training acc total= 99.98621344566345%\n",
            "step 20850, training loss Total= 0.0035855577, training acc total= 100.0%\n",
            "step 20900, training loss Total= 0.0026489256, training acc total= 100.0%\n",
            "step 20950, training loss Total= 0.002648671, training acc total= 100.0%\n",
            "step 21000, training loss Total= 0.0011988437, training acc total= 100.0%\n",
            "step 21050, training loss Total= 0.0006779384, training acc total= 100.0%\n",
            "step 21100, training loss Total= 0.0006692555, training acc total= 100.0%\n",
            "step 21150, training loss Total= 0.00031337776, training acc total= 100.0%\n",
            "step 21200, training loss Total= 0.00023146188, training acc total= 100.0%\n",
            "step 21250, training loss Total= 0.00017637269, training acc total= 100.0%\n",
            "step 21300, training loss Total= 0.00017985937, training acc total= 100.0%\n",
            "step 21350, training loss Total= 0.00014176367, training acc total= 100.0%\n",
            "step 21400, training loss Total= 0.00013669221, training acc total= 100.0%\n",
            "step 21450, training loss Total= 0.00012420192, training acc total= 100.0%\n",
            "step 21500, training loss Total= 0.00012334884, training acc total= 100.0%\n",
            "step 21550, training loss Total= 0.00011904327, training acc total= 100.0%\n",
            "step 21600, training loss Total= 0.00011099148, training acc total= 100.0%\n",
            "step 21650, training loss Total= 0.00010931609, training acc total= 100.0%\n",
            "step 21700, training loss Total= 9.824542e-05, training acc total= 100.0%\n",
            "step 21750, training loss Total= 9.387492e-05, training acc total= 100.0%\n",
            "step 21800, training loss Total= 9.347381e-05, training acc total= 100.0%\n",
            "step 21850, training loss Total= 8.649283e-05, training acc total= 100.0%\n",
            "step 21900, training loss Total= 8.3630344e-05, training acc total= 100.0%\n",
            "step 21950, training loss Total= 8.3775325e-05, training acc total= 100.0%\n",
            "step 22000, training loss Total= 8.0197606e-05, training acc total= 100.0%\n",
            "step 22050, training loss Total= 7.768636e-05, training acc total= 100.0%\n",
            "step 22100, training loss Total= 7.589365e-05, training acc total= 100.0%\n",
            "step 22150, training loss Total= 7.506433e-05, training acc total= 100.0%\n",
            "step 22200, training loss Total= 7.6290264e-05, training acc total= 100.0%\n",
            "step 22250, training loss Total= 7.0420145e-05, training acc total= 100.0%\n",
            "step 22300, training loss Total= 7.1476854e-05, training acc total= 100.0%\n",
            "step 22350, training loss Total= 6.6403634e-05, training acc total= 100.0%\n",
            "step 22400, training loss Total= 6.638282e-05, training acc total= 100.0%\n",
            "step 22450, training loss Total= 6.378655e-05, training acc total= 100.0%\n",
            "step 22500, training loss Total= 6.2599196e-05, training acc total= 100.0%\n",
            "step 22550, training loss Total= 6.110889e-05, training acc total= 100.0%\n",
            "step 22600, training loss Total= 6.026148e-05, training acc total= 100.0%\n",
            "step 22650, training loss Total= 5.981463e-05, training acc total= 100.0%\n",
            "step 22700, training loss Total= 5.8371283e-05, training acc total= 100.0%\n",
            "step 22750, training loss Total= 5.8286798e-05, training acc total= 100.0%\n",
            "step 22800, training loss Total= 5.529193e-05, training acc total= 100.0%\n",
            "step 22850, training loss Total= 5.9883594e-05, training acc total= 100.0%\n",
            "step 22900, training loss Total= 5.393805e-05, training acc total= 100.0%\n",
            "step 22950, training loss Total= 5.3223517e-05, training acc total= 100.0%\n",
            "step 23000, training loss Total= 5.308398e-05, training acc total= 100.0%\n",
            "step 23050, training loss Total= 5.040383e-05, training acc total= 100.0%\n",
            "step 23100, training loss Total= 4.928916e-05, training acc total= 100.0%\n",
            "step 23150, training loss Total= 4.815358e-05, training acc total= 100.0%\n",
            "step 23200, training loss Total= 4.786538e-05, training acc total= 100.0%\n",
            "step 23250, training loss Total= 4.7190108e-05, training acc total= 100.0%\n",
            "step 23300, training loss Total= 4.5908808e-05, training acc total= 100.0%\n",
            "step 23350, training loss Total= 4.485738e-05, training acc total= 100.0%\n",
            "step 23400, training loss Total= 4.4378958e-05, training acc total= 100.0%\n",
            "step 23450, training loss Total= 4.341851e-05, training acc total= 100.0%\n",
            "step 23500, training loss Total= 4.2810032e-05, training acc total= 100.0%\n",
            "step 23550, training loss Total= 4.1852305e-05, training acc total= 100.0%\n",
            "step 23600, training loss Total= 4.5016805e-05, training acc total= 100.0%\n",
            "step 23650, training loss Total= 4.016359e-05, training acc total= 100.0%\n",
            "step 23700, training loss Total= 3.920151e-05, training acc total= 100.0%\n",
            "step 23750, training loss Total= 3.94171e-05, training acc total= 100.0%\n",
            "step 23800, training loss Total= 3.7841815e-05, training acc total= 100.0%\n",
            "step 23850, training loss Total= 3.707498e-05, training acc total= 100.0%\n",
            "step 23900, training loss Total= 3.61458e-05, training acc total= 100.0%\n",
            "step 23950, training loss Total= 3.5822e-05, training acc total= 100.0%\n",
            "step 24000, training loss Total= 4.2347845e-05, training acc total= 100.0%\n",
            "step 24050, training loss Total= 3.7062808e-05, training acc total= 100.0%\n",
            "step 24100, training loss Total= 3.4290773e-05, training acc total= 100.0%\n",
            "step 24150, training loss Total= 3.290595e-05, training acc total= 100.0%\n",
            "step 24200, training loss Total= 3.183751e-05, training acc total= 100.0%\n",
            "step 24250, training loss Total= 3.128255e-05, training acc total= 100.0%\n",
            "ValidValid acc= 99.93202 %\n",
            "ValidTest acc= 99.0 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft97oy5cM3aN",
        "colab_type": "code",
        "outputId": "c0b2db3c-1b5b-463d-c3ec-ba640046fa73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./Pendigit\n",
            "ValidValid acc= 99.93202 %\n",
            "Test acc= 94.876144 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWblrxpgM3aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihtQRjvnM3aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LUJzvaHZ6B3v",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "best_weights = {'G_W1': G_W1np, 'G_b1': G_b1np,'G_W2': G_W2np, 'G_b2': G_b2np}\n",
        "scipy.io.savemat('HarFullDataset03212019_Adam', best_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9WWYbkum6Kl4"
      },
      "source": [
        "## Verify handover works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-2ER5pNw6JCz",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "x = loadmat('HarFullDataset03212019_Adam.mat')\n",
        "G_W1np, G_b1np, G_W2np, G_b2np= x['G_W1'],x['G_b1'], x['G_W2'],x['G_b2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n1lIoTcq6N43",
        "outputId": "752fc367-a7c3-4399-af51-abc1718ffe58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1np), G_b1np)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2np) + G_b2np\n",
        "    layer_outputs.append(out_layer)\n",
        "    return layer_outputs\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"Valid acc=\",str(validation_accuracy), \"%\")\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid acc= 98.64038 %\n",
            "Test acc= 95.38514 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZiy1Lgx0b4",
        "colab_type": "code",
        "outputId": "c50c4a28-0265-45ac-d260-812a62ee940a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i-MLbTOJQFQJ"
      },
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-BkroR_XQFQK",
        "outputId": "d0e538bd-2766-47d7-bebb-c4691f6506c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278830
        }
      },
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,5):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 1.9857837, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 87.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.008144151, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.0006294729, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0005400359, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 400, training loss= 0.1527065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 500, training loss= 0.0013683734, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00021194252, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00032862485, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00025341622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.00028031622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00020475077, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0003020033, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00024354778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00014706065, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00029177137, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.0001350425, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00016606697, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00018623672, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00015216254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 0.00011072023, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 0.00014188612, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00023836568, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.0001355805, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001233557, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00016521299, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.00019633351, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.00010483772, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2700, training loss= 0.00014303994, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.586293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.609259e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 9.8155026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 3.3604018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 9.2597256e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 6.721567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 7.687432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.780202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 8.004801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.1782518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.9696853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 6.810024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.636981e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5683905e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.8620117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.8458773e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 5.265702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 8.7179935e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.327066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 5.9413127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.1775235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 1.39963295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.2185797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.6216587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 2.6288237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.5653866e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.2123731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3709934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 1.8652794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.2361822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.9032594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.2012822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.6528496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.1033039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.5385518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5541144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 2.489545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 9.935381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.3722548e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.4826099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3191649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.5937192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.5124231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.579236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0794279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2980037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1881518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0636356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 4.5980264e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.622366e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 1.09407665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.1238885e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.4111827e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.7718606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.1832344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 2.6180458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.5346616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 6.9588204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 6.3365137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 6.0044563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.809996e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 2.5300678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.2133055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.3530669e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1355425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.349093e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 3.9301335e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.0649427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.6249492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.645543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 2.8087782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.811128e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.698381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.818887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 2.8230727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.6247938e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.3677005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.494359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.8569029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 2.545933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 1.9594595e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.4409051e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.8693646e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.000875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.2531683e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0448554e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 1.5181027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 1.1676285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 9.0001987e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 9.393475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 8.669367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 5.629609e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 9.915129e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 6.344809e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 8.430959e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 7.560755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.3955247e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 5.1885485e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 2.8520526e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 7.706814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 5.3196766e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.519351e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.3104553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.1064213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 2.6166344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 3.2424703e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 4.398789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.7252724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 2.2113223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 4.348137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.085874e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.302084e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.1202762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.3454369e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.3543713e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.8954229e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 2.3066919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.632889e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.8328382e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.0132776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.5331883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 2.3394738e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.9802197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.4156079e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7911132e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 1.5228956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.8358172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.2308327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 9.477127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.296399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 7.7187906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.5169358e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 8.493651e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 5.394215e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.5963244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.463851e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.2904381e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.1980514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 4.172321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.1557972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.387722e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.755089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.9935088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.169074e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 6.228681e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2750053e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 4.79817e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 4.2617295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 4.023311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.0829136e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 3.308056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 4.2021256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.3378583e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 4.053114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.2351736e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.264975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.2218949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1590442e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 2.1457668e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.3113018e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.609325e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.0132787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.1026856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.1324881e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.1622901e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.2814996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.344648e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1026857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.8545334e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.278255e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23800, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24100, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24500, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.08719349, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 28000, training loss= 0.025652321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28100, training loss= 0.04324808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28200, training loss= 0.0004310665, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.643979e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 1.3230393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.007661752, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 6.094262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 8.180307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 2.5535144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.176015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 1.8676748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.7169636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 7.167124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 8.642062e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 2.030267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1825708e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.7748385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 5.291539e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.22399315e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 1.7870418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.7662272, training acc= 81.99999928474426%\n",
            "Validation Accuracy valid 86.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.008894306, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.001817639, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.01971873, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.010990087, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0014096084, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.0018062931, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00828336, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 800, training loss= 0.00034360992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0011482139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.0004452518, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00033666857, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 7.3411196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00016483082, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.00013365646, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00012015406, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.989801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014627678, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 9.896378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00013707647, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 9.413417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.0002904884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.071585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.000113107744, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 6.5728214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 7.467509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 7.47882e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00014493043, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 4.986713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 8.715366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 8.345896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3100, training loss= 8.374644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 9.8462915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.850093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.7121793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.1049865e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 6.073701e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 4.474434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.698458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 4.537524e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.7783116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 2.1114298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.4028376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 7.428725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 4.9455317e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 6.0670907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 3.9265742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.3787823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 2.222307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 2.7888911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.6384652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 4.268808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 1.8342535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 3.640592e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.675147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.0683655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 5.7309517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 5.3059237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1050517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 2.9001272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 2.1682825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 2.4490568e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.6777477e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 1.206457e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.8631803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 2.8394177e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 2.064755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 1.9105793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3473336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.6770351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 3.8086808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.083156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 2.8561692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.1495483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 2.2305263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7590653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.8775003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7700, training loss= 1.7969975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.1573217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3541719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.2924986e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.8286872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 2.0161868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.9373725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 8.702997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1870059e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 2.1714874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 8.531334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3683234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 6.9569533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 1.028602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 1.446362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 4.9309697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2126831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 1.1932704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.1256293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 9.782787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.105736e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 4.566323e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 7.683178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 6.630302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.8557586e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.638747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 7.2090293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 3.390549e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 7.0846722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.3014383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 5.559007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 3.6495085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 4.144894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11000, training loss= 3.8692833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 5.5646865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 2.6532234e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 1.5492373e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.8420288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.52481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.1986982e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 1.4946331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 3.4738641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.394339e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 4.213718e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 2.7818019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.381144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.0114609e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.7353825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.762105e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.6738297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 2.8655863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12900, training loss= 2.7352635e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.059733e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.0988865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.3960894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.2538417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13400, training loss= 8.654316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 1.0774263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.4088228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 5.956388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13800, training loss= 8.853005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.6378345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.4510845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 5.1637033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.2424226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.027154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 7.955074e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14500, training loss= 8.4458196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.847785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 4.841795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 7.291442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.635848e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15000, training loss= 5.25106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 8.404123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.2722545e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15300, training loss= 3.5067077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 3.798765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 4.0987763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 2.0086694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 3.762983e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15800, training loss= 2.8808694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15900, training loss= 2.2212514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16000, training loss= 3.1888223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 2.1119722e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16200, training loss= 3.977578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3801812e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.8927866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 3.0517435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.6152802e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.3523779e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16800, training loss= 1.7642911e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16900, training loss= 1.9152844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 3.4709578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 9.1790945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 8.821453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17300, training loss= 2.3503938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.5795172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.5830486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.8744806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.0907608e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 1.13049815e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 9.457251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.5755424e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.59624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 9.735403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 1.007316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18400, training loss= 1.140433e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 8.0664805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.4108236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 6.3975506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18800, training loss= 8.920804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.410739e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 2.6027344e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 9.6161976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 4.0928494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 19300, training loss= 4.649158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 3.2981205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 6.099537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 4.9670483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 4.4902137e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.655749e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.801416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.3577265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 4.549816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.9140343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 3.4769357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20500, training loss= 2.3841842e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 3.2186488e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20900, training loss= 1.7881387e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.529852e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21100, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.854431e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21300, training loss= 2.423921e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21400, training loss= 1.76827e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21500, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21700, training loss= 1.8278751e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.8874797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 22100, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 1.2914334e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 1.17222445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 7.351239e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.2318289e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 6.159146e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.9736423e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 7.9472855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 2.5828677e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.9802318e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 4.569689e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.3775964e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7636182, training acc= 89.49999809265137%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0014524448, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.002393889, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.13864827, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 400, training loss= 0.0029713945, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0051878896, training acc= 100.0%\n",
            "Validation Accuracy valid 96.5 ...\n",
            "\n",
            "step 600, training loss= 0.00075327273, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.006071425, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0008636887, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00034359877, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00020992127, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017444276, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 8.93537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00022914476, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 8.4610336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00015365804, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 4.266093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00011484732, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 0.00010020897, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 8.292834e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.0001145257, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00012196603, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 8.1921855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.842964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 4.8611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 8.0116275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 5.582913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.1031668e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 7.064959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 7.517244e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.7207286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 4.1879233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.4186698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.4159504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.5968543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 5.0703657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.340508e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.7673002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.251103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.7012665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 4.6962698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.385241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 3.4974462e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.0854018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.690291e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 2.8908937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 1.7610624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.1664196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.5627796e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.0464651e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.517009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.759404e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 1.9673145e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 8.960804e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9765514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.2240092e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.668813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.8317649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.8910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.2009532e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.2012475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.0280283e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8704028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.3285839e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.5801768e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.552519e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 9.762813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.0695344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 8.8103625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2685976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 8.348381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.0402509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.683439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 5.94079e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.603427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.2821643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 8.822334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 6.4213345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 4.3542923e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 9.515376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.848005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.077483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 5.8962605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 7.2099474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 4.577006e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.092034e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.700421e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.8339763e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.2160867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 6.3622447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.250631e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.6400797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 4.893738e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.439866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 3.4113343e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.594419e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.8299346e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.3984117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.6114793e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.7841119e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.3087333e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.2500294e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.2367042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8166952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.9553854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.6409862e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.9424567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.595777e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.4432038e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.4477749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.4052541e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7197599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8244617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.4058462e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.3106868e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.1147757e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.229424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0220067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.4116162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.997535e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 9.590278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 6.083603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.042517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 8.2849544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 4.5060912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 5.114039e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.9815674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.0842294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.445209e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 2.5073595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.2061374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.1391636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 4.6511127e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.153072e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 3.576264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 3.7729563e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.797439e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13700, training loss= 4.525961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.9470808e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 4.7206638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 2.4855063e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 3.4570587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.1934457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.7596883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.8331965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 1.7603206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.9192649e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.4557033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.9669483e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 1.1920912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.331169e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8993967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7444259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.1761971e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 2.1656297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 9.675813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.4781924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.1344734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.6053491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 7.6691165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0391059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 7.232023e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1404347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.00334404e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.563096e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.0068816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.2516956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 4.7286328e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 8.583061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 4.4703462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.0133777e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.7352223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 9.179109e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2054688e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.6160138e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.3246787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 3.6557505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.7815496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 3.8345647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 3.2981234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.741813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.66234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6291928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.5033946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.8080073e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.5099841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.6623402e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.9073484e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.88748e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.2516974e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.11261995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.735425e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 4.3710067e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.7617817e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.12636083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 1.5009055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 4.5446195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 0.00019335095, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 2.0004713e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28000, training loss= 0.00024587451, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 5.17878e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.8015188e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2475813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.16426875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.2762443e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 2.4796489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.874821e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.9667257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 1.3271837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.1669373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 5.0436165e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 3.8146922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 2.386263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 8.116291e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.4715047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 3.1947408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.6322995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 8.512951e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 6.2739383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7304913, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.024764434, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.00072215847, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0033973714, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.0005037752, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0030435477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.0022072683, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.0008827405, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00044512466, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0021594528, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0021753563, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.000990368, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1200, training loss= 0.0021206276, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00036779614, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.0037439256, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.00082475785, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1600, training loss= 0.00024784182, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.000190548, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.000101983955, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00021216992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 0.00011386407, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 0.00011138018, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 8.63583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 5.57357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 5.417957e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000108176755, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.0001890949, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.0819992e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 6.838632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 5.6099372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 5.2011772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 2.472774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 6.274405e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.713733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 9.317016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.7877868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 2.8687671e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 5.5696095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.441774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.780889e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.309848e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5136407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.2342344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.198066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 4.228693e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 4.623733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 5.259833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.8154747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 2.9219354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 4.8661506e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.720072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.737663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 3.3301876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 1.9597674e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.303492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.149919e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.0326766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 3.693348e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.0893876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.4200576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.0393646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.36700555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 2.2173379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 2.4110748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 2.927052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 2.1804688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 3.3416698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 1.1375284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 3.0013467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.5185645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 1.9262208e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 7.24648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.9320647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.0112638e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.3421217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.6355956e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 2.1810254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 9.434999e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3208644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3258212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.6602802e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.3406531e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 8.6087675e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.1284631e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.3691073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1275537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 1.0726529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 5.316216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3310492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 7.1013837e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 7.122497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.4317516e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 5.995298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 6.4786645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 8.058474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 4.1793282e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 5.9965755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.325073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 5.3627527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 8.09692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 3.2421524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 7.312679e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.890297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.465615e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 3.6471156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 3.6296326e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.547755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 3.7599389e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 3.9908955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.801147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.700158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.3630324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 5.625648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 5.4111997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.9192797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 4.2606243e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.0359045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.8398329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 2.0259854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 3.4805132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 1.8117825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.1677497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 2.0436332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 2.1751746e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8606397e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.8549617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.8841043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.5198765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.0305584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.3752001e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 1.1393081e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.4402093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 13200, training loss= 1.4075287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.7976179e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 1.3381026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.8223251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 7.575585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.0067002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 1.0707812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.2458647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 14000, training loss= 5.9276107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.170657e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 4.3049062e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 8.118035e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.939553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 6.636888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 5.1080553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.84716e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 4.2199778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.5060816e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 4.944158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.769806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 7.1345886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 6.8634006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.6373513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 2.7134763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.5032457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.5778866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.583847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.2739103e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.7374686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 4.950135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.00433624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3543706e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 3.3408233e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16500, training loss= 2.539148e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 3.71484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 2.3931165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 3.0442934e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 2.3037137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.3798397e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.6525345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.548226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.136021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.15632865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1725819e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 1.2189115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.6591824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.6128566e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 9.909255e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.18911075e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 8.0764195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.3362352e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 9.626133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.2442453e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.09672335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 8.314835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 7.8976015e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 8.821478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 5.6624362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.6656832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 7.733698e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 4.529949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 4.202125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 4.1723204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 5.2303033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.7699913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 4.4256414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 4.52995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 3.4272656e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 2.8610216e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 2.9057254e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 3.2782513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 3.5762767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 2.473592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.9371504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 3.576277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21200, training loss= 1.8477435e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 2.7716155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 2.4139867e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.130865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.4901157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.9837765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.2814995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748602e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 9.089707e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 7.0035444e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.6391276e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 5.960464e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28100, training loss= 0.14615121, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 0.16133761, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 0.00042809127, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 0.02816139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 5.3594245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 6.424133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 8.930463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0064306515, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 0.0013593932, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 0.00028876038, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 2.99408e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 3.9986888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 1.6156795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 2.3464807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29500, training loss= 7.012028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 1.301896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 8.8096385e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3575656e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.338141e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.5094995, training acc= 87.99999952316284%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.039435677, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0029222893, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0010214503, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.00034394336, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0002726078, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0003874169, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00024444636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 800, training loss= 7.78137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0002793996, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0002509097, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00022534527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.0002431607, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00015126858, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00026668172, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00020671163, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011088938, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0002102695, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00024402318, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00014018922, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.000118058495, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 0.000169405, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 9.5967356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00018843854, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.619639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00017519623, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010826914, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 6.3557294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 5.8655984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 0.000116522075, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.6885975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 6.175657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.320747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.7774046e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.00010348646, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.05501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 7.633815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 5.044512e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 5.3543514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 7.600165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 3.658233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 7.516591e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 3.8953043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 5.268231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.604312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 5.693039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 4.1753025e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 5.882939e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 4.570583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 5.954526e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.8352653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.220578e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 4.9572915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 1.7886814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.347068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.200028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6758515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.4645338e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.7491753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.890632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.0029758e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 9.767324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.4392694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9938734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1649712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.1366663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 1.15115445e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.627149e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 9.4102315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.18667695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 7.315959e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 9.4693305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.999106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.817514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.0087821e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 1.0298888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.0137086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.0302095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 7.774598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.379647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 8.708265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 4.684891e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 5.9717368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 4.1632193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 4.3086106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 8.625295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8600, training loss= 9.096246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.021494e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8800, training loss= 3.964501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2560058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9000, training loss= 5.396032e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9100, training loss= 4.86689e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9200, training loss= 2.7238436e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 4.746905e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 2.6210175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.1935015e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.127882e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 1.8012137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 1.9081392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.85567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.2672803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9290576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.8781066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.990749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3388204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.5172055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.0706204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 1.0570711e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.8903185e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10900, training loss= 1.1977398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.3911481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1804457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.5905444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.422006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.308879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.456476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 1.1220336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0493231e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 7.1763264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.869385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 7.119715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 8.287952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.593852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 6.6249885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 4.0590544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 7.5786664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.2961245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 7.1971675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.3836154e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 4.0024162e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.42427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.3289052e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.1872093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.1083673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 4.392842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 4.8160257e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.007029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.453785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8119763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.086158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.9265803e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.5570313e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1980515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.9341665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 2.306693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.596335e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.4036873e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.3977251e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 1.9669494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.14142715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.5944207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.0728818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.6629673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 9.775151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.5914415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.4960735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.3351398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.09672364e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 1.0997041e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 7.331364e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.4871326e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.1682496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1116253e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.84125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 9.685743e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 8.791676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.1557983e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.9008553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.6028327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 8.136025e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.172323e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 5.0365898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.245204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 4.7683695e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.5464744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.9935095e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 3.039836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 2.026557e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.2649758e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7716151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.3709066e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.3245805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 2.1159643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.400709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.0430811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 9.238718e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.49011585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.025566172, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 95.5 ...\n",
            "\n",
            "step 26400, training loss= 0.0034496982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26500, training loss= 0.0040100445, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26600, training loss= 0.00511861, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26700, training loss= 4.1705647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.0001831693, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 5.6671648e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27000, training loss= 0.0001770996, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 4.699156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.5728401e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 7.700904e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 7.4260447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 5.681718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 7.393381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.2465034e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.3613008e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 3.1198968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 2.7861872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.3089022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 3.7146718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.1053833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 3.186115e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.283511e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.856783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3570617e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 1.779635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 2.4203371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 7.957782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 1.8808056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.6190117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.5169241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.2388602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 2.2471556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.6563006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.2319857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.8784289e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.952098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7491051, training acc= 91.00000262260437%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 100, training loss= 0.034846384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0027968925, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.00047345422, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.00033690428, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0034412623, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 600, training loss= 0.0007994493, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.06041136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.031878598, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 900, training loss= 0.00096669135, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0003687142, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.00053446105, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00048036771, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00012743808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0001659477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001688339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00016108585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 8.44349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 7.4442396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00014246671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.0271857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 8.8449226e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 6.683565e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 9.433382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 3.48266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 9.452199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 3.536197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.962503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.5803066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 5.3583466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 0.00011115102, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 4.639947e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 8.055888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3300, training loss= 2.217185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 7.468372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3500, training loss= 5.611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3600, training loss= 7.5111566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3700, training loss= 5.248479e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.4966724e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3900, training loss= 3.2931985e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 3.0140853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 5.587737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4200, training loss= 4.4394117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 2.7067463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 5.3845055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4500, training loss= 4.7568883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 2.760794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4700, training loss= 2.4561949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 3.833233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4900, training loss= 2.414298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5000, training loss= 3.2821878e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.6419088e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 3.0928026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5300, training loss= 3.172096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5400, training loss= 2.9084766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.960324e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 1.702319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5700, training loss= 3.1217234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1078644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 1.9665416e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.102241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.3703633e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.190164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.925997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.682143e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.8846249e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.1859872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 2.855706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5393258e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 2.198239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.3099368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.3651934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 3.332225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2504407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.4693432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1715385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.0993313e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.3868442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.0447887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.3118067e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.5397375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.0527187e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.1633114e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0775805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.407657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 8.719276e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.2441643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 9.942413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8800, training loss= 9.356401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.113451e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.2375984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0537907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 3.4513328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 3.542377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 4.840788e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 7.922656e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 4.8024226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 3.311136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 6.2441645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.7440457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.286357e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 4.602099e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 3.6908616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 5.3517865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 4.891503e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10500, training loss= 3.3034005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10600, training loss= 5.554033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 4.325919e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.3685297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 3.9670913e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.1605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.5436977e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.1449933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.311484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.1916028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5230588e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.415313e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 2.6025407e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 1.3350995e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 11900, training loss= 2.8675822e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12000, training loss= 1.9370934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.328794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12200, training loss= 1.3141361e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.3128187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2933568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 2.231692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.8400432e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 9.240939e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12800, training loss= 7.4671203e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.9659087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 8.5793647e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13100, training loss= 1.4408387e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 5.378687e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 5.118801e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.263327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.0149259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.2730089e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 7.9726226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 6.0366494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.989159e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14000, training loss= 7.107143e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14100, training loss= 8.423157e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14200, training loss= 5.671921e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 7.487463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 4.2795787e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 8.196721e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.985288e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 6.4455566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.2506367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 4.1126978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 4.2056612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 3.104176e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15200, training loss= 4.6896585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.0877617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 4.868468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 5.917487e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 4.039961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15700, training loss= 2.9337158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.3078768e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.5497163e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 2.0933044e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 3.00406e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.6331612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.1290678e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.7954385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.1362237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.7249492e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.0170113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 1.561638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 7.200231e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 1.635547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.4829605e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.1563275e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.0514238e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1396386e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 1.01327714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17600, training loss= 1.04665524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 5.8412436e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.7962746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 1.5044178e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.022774e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 8.65458e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 6.9379645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 5.3286477e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 5.078311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 8.225427e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.747238e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.6014744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 3.838537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 5.292885e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 5.531306e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 7.414811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8610183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 3.0517565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.8875773e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 4.756447e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8610211e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 4.3392152e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 1.740455e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 3.0517562e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 2.431868e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.454353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 2.7179704e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.0027157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.0980828e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 3.6001182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.7404552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 2.5629987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 2.1457662e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.9311898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.704692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 9.53674e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1444089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.1444088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 1.3709062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 9.77516e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.821486e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 7.867811e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.4373005e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.814697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 7.3909754e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 7.629394e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.0994411e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.7418137e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.112007275, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.11103656, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 0.0005116432, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 9.75468e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 0.008496265, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 5.7019173e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27600, training loss= 0.0004373042, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27700, training loss= 1.1850859e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 2.3806272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 2.7104883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28000, training loss= 9.759002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 2.3935432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28300, training loss= 2.4006331e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 2.4710875e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 6.238008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 3.3717086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28700, training loss= 1.6770267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28800, training loss= 1.710619e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28900, training loss= 1.4606363e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 2.031028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 8.3561845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29200, training loss= 1.5126936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 3.6813908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 1.4453636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 2.6563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 1.6650685e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 1.752893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6865813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 5.1087663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.14847247, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 94.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.0007601454, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0062709516, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00041410883, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.018620707, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00094815134, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.00047243008, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.00019986519, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 800, training loss= 0.0002234125, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00031657013, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00017952269, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00015443658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00014692658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00018098918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00023744153, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.000103558945, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00012654845, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0001302577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 9.935229e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 9.933386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 9.201987e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 9.5115174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 0.00012162826, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 8.828254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 0.00011542862, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 9.615535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 7.242731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 3.2542845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.252827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 2.7502243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 7.2430645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.4835316e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 8.825268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 5.4219643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 3.3850585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.0782274e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 5.4826043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.1017585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.276399e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.4302393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 3.2332002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.6150792e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.4243556e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 1.4400564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.9570925e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 3.4416033e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 2.4489924e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.7464997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 1.7821938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.6904687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.1947513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.062126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 1.6229103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 2.0709907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.3617691e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 1.1845765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.5679694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.5038126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 7.5704993e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.5022351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.8019406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.6936581e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.232541e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.18999815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 1.0497903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.4213764e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7636456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 4.6242885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.18226235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 6.5555055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 4.8518627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 7.4627187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 8.263121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 7.917012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 5.2882624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 5.1350253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.0090554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 9.185651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.505415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.2839044e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.9021405e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 3.8857816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 3.6776676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 6.341853e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.4922955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 5.8767273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 4.4723574e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 3.2225844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.149103e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 1.452396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.3337114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 2.3051564e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 1.9564932e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2847678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.717753e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.6361012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 1.6295547e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 1.9295053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 1.1090625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.2548023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1157888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.5792895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 1.6151013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.0733162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.2195002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 7.308938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.4850286e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.0086438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 9.4815323e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.3936844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.3254976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 7.3089427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.5289888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0713821e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 9.028518e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 6.645876e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 7.389442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 4.5358885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 5.552135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 4.231914e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 6.581788e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 4.9665243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 6.696544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 4.8502847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.1958747e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 4.793684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 4.1261177e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.39121e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 2.6509105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 6.4640886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 1.6719059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.591442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.792468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 1.3768653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.3379826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.829859e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.710514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.8118396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8522104e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.6525361e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.384181e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.0950999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1667598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.799919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 1.5869719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.164205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.12354655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2963997e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.2278537e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 8.0913225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.00880754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 7.599584e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.374445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.230305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 5.677339e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 4.4256417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 6.7949244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 5.364415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 7.7933024e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 6.213781e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.7453466e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.1856006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 3.21865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 3.933906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 6.73532e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 6.7502235e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.409118e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.919003e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.7997946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.664061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 2.8610218e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 3.7103877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.096195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1010626e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 4.306434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.0116564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 1.5646217e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 2.0563599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 1.2665984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.0877846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.0563597e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.877546e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 1.02818e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.1622903e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 7.897615e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 8.791685e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 7.3015682e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20400, training loss= 1.2069938e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20700, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20900, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.9371509e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21100, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21400, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.0233132e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 2.8312204e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0430813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.1794868, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 91.19999694824219 ...\n",
            "\n",
            "step 24900, training loss= 0.05283235, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.024460968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 25100, training loss= 0.0011026246, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 0.0037383218, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25300, training loss= 0.007821645, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25400, training loss= 2.9168423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 0.00014622895, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 25600, training loss= 5.9074697e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25700, training loss= 4.7847083e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25800, training loss= 7.369522e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 2.8571852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26000, training loss= 3.942655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26100, training loss= 3.220571e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 3.3161654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26300, training loss= 2.0020156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26400, training loss= 8.432376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26500, training loss= 4.895209e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 4.6962043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 3.5029458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26800, training loss= 6.3240573e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 2.9128441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27000, training loss= 4.7755293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 2.4796074e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 7.1433337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27300, training loss= 2.4853827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 2.1829412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 2.6021942e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.898441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 1.9363055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.187242e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 1.2992667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 3.7369962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.6083064e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.2791265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2738248e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.0155272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 1.7903318e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 8.328605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 7.0235537e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 2.1747273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 6.9265398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 1.7684783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 8.7655435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.4506243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.0134418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 5.924403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.476949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.2289474e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 7.034543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 9.128639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 1.083224e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.4625556, training acc= 86.50000095367432%\n",
            "Validation Accuracy valid 84.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.009873457, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.009675698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.06272699, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.4000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.009281827, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0023525394, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.000796955, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.007612922, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.008417513, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.04200749, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0010823058, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.011957829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.005447494, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00016969378, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00025642803, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 0.00018994625, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00011148728, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 0.0001519523, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 5.1344472e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.000114705, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 0.00017647487, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.00016669072, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 7.0707545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 0.00014605207, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 0.00019520438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00012533748, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 9.3231065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00013419885, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 0.00015070809, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 6.698415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 7.4300464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 7.788869e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 6.204043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 6.954175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 0.000101137164, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 0.00014247942, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 3.9282517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 6.19493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 0.00012098811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 7.959501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 2.0376454e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.5651745e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.053907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 5.738453e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 6.5646214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 7.19845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 4.2279626e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.0300577e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.6554233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.9958282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 4.414931e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 8.059281e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 4.4121003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0030613e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.980649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.2697437e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 1.987078e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3039963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 2.044901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.324795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 3.006205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.0659782e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.8798682e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 3.736447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.926903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9375326e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.0508218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 3.2549677e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 4.4712488e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 2.3236962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 2.9457082e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 2.1961814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 2.5960593e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.216319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.39927015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7645887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.9442721e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.262071e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.6021906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.5504424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.5671989e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.2741196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.2926779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0557667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.09657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.4000293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.5243709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 1.6457901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 5.975668e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 6.3747534e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.679973e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 7.3154283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 6.9534776e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.8046176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 1.2720513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.6647705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 9600, training loss= 4.9250134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 7.0780306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 8.165239e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.324812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 5.124565e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.060113e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10200, training loss= 4.5891775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.454139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10400, training loss= 2.5667296e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 5.3375766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.954761e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 2.921967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10800, training loss= 3.5418911e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 1.7839251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 1.8321765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.414253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 2.3481068e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.809641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.2566621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 2.5879533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 6.2190503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.6484897e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.7702238e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11900, training loss= 1.532734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0999341e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.556374e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5289532e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.3946088e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.0038367e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.5996262e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.4872192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.2217483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3159212e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.6888064e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.1527846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.5043951e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.5712758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.8937896e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.5219156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 8.4899415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 5.999765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.1037449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 8.475642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 8.4673076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 5.1891465e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.828087e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.5517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 6.4861297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 6.718564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 5.9866505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.3917927e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 4.3785363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.6476286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 4.5418423e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 5.5074395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.99484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.7215384e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 5.357237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.60352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.181685e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.888267e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.650015e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.8192883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.7215398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.4734239e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.7739915e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.3446785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 2.1207283e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 2.4998124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.6214005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.3554077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 1.8143614e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 2.2244394e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 9.5844165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 2.2160962e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.2016282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.3518307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.1193731e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.6307804e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 9.798988e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 8.690347e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 6.830686e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.108645e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 8.904927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.878368e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 7.59362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.731249e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 7.009502e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 4.386899e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 9.310237e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.079671e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.8146947e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.9696673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.5537924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 4.684922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 5.3644158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 5.2809664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 4.6014765e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.7564487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.0279143e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.3603434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.2530552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2305703e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 2.2172927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.8596644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.7523764e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.7537338e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.28746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.4175325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.323223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.4662741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.2636183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.466274e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.602837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.106231e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.026558e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 1.6689301e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.2649764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 0.10768938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.008793372, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 0.012823711, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27000, training loss= 1.2324063e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.012677136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.3485197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 3.1230695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27400, training loss= 1.0392901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 2.1648111e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 2.415332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.8522265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 1.8608886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.7186818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 3.8044805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 7.1837685e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.2715481e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 1.637915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3154365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.0271192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 4.4160174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 1.5864213e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 7.2442067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.9943133e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.6809759e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 3.192872e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 4.392033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 7.865176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 2.9069377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 2.593819e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.3062578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.8372024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 3.7867183e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.836629e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.19013658, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 95.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00093026174, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0026277967, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.001492311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0024322432, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0055890502, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.00030306313, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.003100828, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0011220517, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0055018878, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0009811673, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.0002756448, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.00011071658, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00025124694, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00016421286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00011190099, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00010541811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 9.068278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1800, training loss= 0.00010285259, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.00011336279, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 9.543807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 6.598983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 0.0001048186, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 6.791052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 8.446564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 0.00012669193, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 5.7286346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 7.6599514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.583943e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 7.213351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3000, training loss= 8.483188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 0.0001235103, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 5.7044235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.213048e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3400, training loss= 8.943349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.9132086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.019669e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 5.190742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 7.3327596e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.2594657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 3.1536434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 6.0016704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.3755753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.8125934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.6538997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 3.681976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 5.190695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.0097595e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 4.829544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 2.4251223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 3.4608584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.0206395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.1829377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 2.141725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.593269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3686447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.7244552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 2.9091678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.3514032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.6609652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.596803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.2894791e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 1.3850272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.3748465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 9.598098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.5380698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.3717976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.531126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0051459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2853964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.0743887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.392279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 1.1115343e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 8.731065e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.3423013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 8.573937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 5.6051285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 8.959563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1156192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.093328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.699008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.97865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 6.377527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.442519e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 5.4422085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.3331244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 3.4193479e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.3501954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 3.2585556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 4.601866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.73484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 8.332201e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 2.6594612e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.3757423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.614429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.3148297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 2.994404e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.5207094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.716661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 4.0560403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.5897298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.4749584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 4.7529043e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 3.8448393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3756274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.9698388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.7610328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.5251676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.6350413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.833491e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 2.583909e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7254063e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.9528363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.3899358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.7905795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.4260626e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.2743261e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1824178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.1075607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 5.171254e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.1026717e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.1557121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.0965964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.4981807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.1550235e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.5883385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.0082405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 5.1855665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 8.489946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 7.6567466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 3.2830022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.02304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 5.7720746e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 4.4345572e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.407294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.266953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.4785123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.2138655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 3.6835488e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 1.8632356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 4.3189343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.278083e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.2780837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 4.6551006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 3.9064693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 2.9325346e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.4519667e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 2.8550505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.778759e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.5878642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 1.6975366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 2.5105408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.7237619e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.3150396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.052776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.5532946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.3518297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.9955564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.4519672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.7869435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 8.475768e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.0335435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.976452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 8.618823e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.3113002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.0228137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 6.866446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.5061068e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 4.8637357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 9.822834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 9.691693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 4.2080853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 5.8174063e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.8293296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 3.5762763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 5.7101204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 4.935263e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.5180297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 6.759163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 4.577633e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 5.340574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.2530555e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 3.1828865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.7656545e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.8252591e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.4318684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.076955e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 4.25577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.5047517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.8715854e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.9431107e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.7523762e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 2.3126592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 9.298322e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.0967251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.823902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.1086461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.1086463e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 7.0333472e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.4570693e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.3113021e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 0.00049628475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.0487039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.0063560284, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27400, training loss= 6.09169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27500, training loss= 1.2766516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 4.756465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 2.0138152e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 1.1392219e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 3.7247166e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 6.1270885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 2.4826218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.4615197e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.3096518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 8.548321e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 1.4721978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28600, training loss= 8.3002915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 1.2625357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 1.3777887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28900, training loss= 7.742751e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 3.521224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.1625331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.0342712e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 2.7950875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 4.9842947e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 7.2881144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29600, training loss= 4.0344307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29700, training loss= 4.7630215e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29800, training loss= 1.17057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 8.4733865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7141365, training acc= 90.49999713897705%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0074453596, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0009144604, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0011556392, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0052687093, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0003429781, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.00025804708, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.049575698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 800, training loss= 0.0019488088, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.051701337, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.030002326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.0077472776, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00019876577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 9.024233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 8.974371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 8.9546375e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00014210286, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.00018890618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 9.702795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00010099527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00014198791, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 8.03155e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 9.9710735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00011535117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 8.077585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 9.9031706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 6.20196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.8977676e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 0.00010070081, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.108279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.5106906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.9841175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 5.907393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.209719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 6.7312016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 2.7272741e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 7.707601e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3700, training loss= 7.978093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.3837307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.3424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 5.4274147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 4.5890218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.3613356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 4.9521983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.7869322e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 6.9451555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.733818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.57006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.3307286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 6.0959308e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 6.312785e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.731221e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.9706269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 6.433572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.619432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 4.91137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.5674917e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.2786286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.6947797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.9430896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 2.134277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.6391627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.103963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 2.3596955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 3.065319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9957584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 3.1795567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 2.6485766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 2.0281239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 3.579099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.2436634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.4378545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.882001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.7350767e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1065293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1154377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 8.33703e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2613851e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3134572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.0364819e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 1.6570779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 9.424848e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.5135257e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 1.4990833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 1.2265535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.0599004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0820388e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 7.829222e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 1.0707916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.348662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 1.2290646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0312282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 1.2390558e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 9.838934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 6.499245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 5.473657e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 5.8741857e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.9230167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 3.375192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.2452206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.903218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.590292e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.589014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 6.082514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.6260811e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.906372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 2.5236131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 3.7562318e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.0008514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 4.632992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.2223502e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.8740915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.948306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 3.1749946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.0445693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.8900785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 3.6731817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 5.078464e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 2.6606458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.9680439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0738598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.815725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5706449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.1089242e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8578164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.6621826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 1.0975984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 9.974736e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3866722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.7796442e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 5.230249e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 9.995538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 1.6169129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.1837301e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 8.383242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.2278381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 1.0618398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.879924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.5805797e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.61637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 7.9690517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 7.887602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 4.4285986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 4.8756146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.196464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 3.2712842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 3.811684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 3.6259286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.9279186e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 3.4153206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 5.820335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 3.9487844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.1500858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.0563522e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.0374756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 4.0828968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.0149823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.42292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.0503948e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.316978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.189471e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 2.6851794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.1248985e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.6341573e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.4384551e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.0281785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.7871415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.1056644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.56653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.04307986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.1553338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.3261976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.0838093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.493643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.987011e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.0758597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.3023586e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 1.23282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.8975078e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 7.957209e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.82472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 7.8181316e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.695486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 9.248642e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 7.450572e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.2518944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.6358806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 5.9604613e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.619353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.947182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.010033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 4.3511363e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.9603624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.904102e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 2.831219e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8908236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.4437892e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 4.410741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.8676117e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 3.5862115e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.8908243e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.0398354e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.9206262e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.1258987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 1.4603133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.976887e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.834764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.238717e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 6.854533e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 7.4505797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.854534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 6.2584866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.066395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.021732664, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.0 ...\n",
            "\n",
            "step 26000, training loss= 4.065458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 0.010269502, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.6831855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00021952903, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 3.9125225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 1.5004598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.082927e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.876794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 4.683961e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.6893438e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 5.7578727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 3.5213143e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 3.8073863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27300, training loss= 9.285785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 7.257216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27500, training loss= 1.18348635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.3288599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 3.6785648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27800, training loss= 5.0734984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27900, training loss= 2.892303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28000, training loss= 5.3037293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.8159358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28200, training loss= 4.5573865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.9036553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 7.1590184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.5684889e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 1.2261452e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 2.853986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 6.2794925e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 7.1493105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 6.7924702e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 2.631013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 6.1907673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.7757769e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 2.6626967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.6199251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 2.8669488e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.0942198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 1.1702637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 2.7612755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.240357, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 87.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00072087307, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.010604541, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0005547491, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00061997864, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.00030061085, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.0002527497, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 700, training loss= 0.00042292374, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.000133779, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00021847297, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0001858882, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0002035335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00022087155, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00020502399, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.000119573524, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00016135925, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00023241036, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00013802794, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00020564668, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00017970696, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00012806633, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2100, training loss= 0.00013740644, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.000104741404, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00010557528, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.0001370245, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 9.642969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010056618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 0.000101965255, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012939224, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00010101048, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.3418385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 0.00011470896, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 4.7746402e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.00010684254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 6.681612e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.1465045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 6.3796884e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.478265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.8874266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.422483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 6.0372688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 8.1153245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 8.310058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4300, training loss= 2.6912525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 3.9985393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 4.7254805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4600, training loss= 2.5460518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4700, training loss= 4.8057296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.1858537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 3.2272234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 4.7587422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.9853529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.3146597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.8194277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 4.5807366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 2.5900312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6406013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.2266395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 4.1245698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5900, training loss= 4.01718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.9558687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.2121938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8255998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9564624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.4104778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.2817856e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 7.790083e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.7202658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.4445213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.091918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7000, training loss= 7.1219297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7100, training loss= 1.0965941e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0558951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6640362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7400, training loss= 7.5274647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 9.91309e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7600, training loss= 1.48251465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.1687644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1087876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 8.414353e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 7.6496835e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.232028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 8.863616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8300, training loss= 9.999422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 5.7980305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.5095164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.231801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.1509533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.6448375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2739158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.7755434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 5.1879542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.6441028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.9093198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.9708538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 2.632359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.777344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 3.3987578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9800, training loss= 3.0161123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9900, training loss= 2.442489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.0720563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9975748e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 2.16029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 2.178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10400, training loss= 1.8458895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.4912632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 1.4972244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.0454469e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.9919305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.8130879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.2424379e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 8.29984e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8092544e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 5.6533764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.5353871e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.0657184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 9.366682e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0514067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 8.5352207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 7.1584344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0949204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.008199e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 1.1461756e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 8.240231e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 5.2094146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.6521106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 7.8498266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 6.6428674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 5.0902077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 5.0663544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 6.5355965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.9981007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 6.991501e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.0427992e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 4.7891893e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 2.7358405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 4.3451462e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.6494146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.7954454e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 2.616635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 1.388782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.2023836e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 2.056353e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 2.7328596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 1.5824993e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.6583552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 2.226224e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.81333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 2.3543718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 2.3126496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 2.0772136e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.7583338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.096723e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.3619629e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.2516955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.4811727e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 8.2552326e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 1.0311588e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0460595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.2516952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 7.927403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.05798065e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.1557933e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.344645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 5.7816422e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 5.602831e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.261727e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 4.3213337e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 7.301559e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 5.2750064e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 6.25848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.9769824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.0365866e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 3.665684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 2.801417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 3.457067e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.1888472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.5629989e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 1.639127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.682208e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.8179412e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 2.6822077e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.2947784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.341104e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.2516973e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 8.3446485e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 0.07618469, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 0.079483144, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.7620423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 0.0008994444, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3940243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 3.0558513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 6.925167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 8.874664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 4.0461928e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.7967077e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 3.2079129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 9.0263875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 8.843295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 6.6778966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 8.88847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.1153843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.066351e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.5637835, training acc= 88.49999904632568%\n",
            "Validation Accuracy valid 83.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.009219123, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.028671242, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0339968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.000744403, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0017800194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0066021285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0035789192, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0008883609, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0006055735, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00017274884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00033500823, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0002683743, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.0001676285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00014868894, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00016313572, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00017124631, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 9.40735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1800, training loss= 5.2675383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00015923165, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00010941772, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2100, training loss= 5.985739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.000118150616, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001165792, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00013586287, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2500, training loss= 4.287825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2600, training loss= 3.3790533e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2700, training loss= 7.964137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2800, training loss= 5.701467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2900, training loss= 9.243786e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3000, training loss= 7.799166e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3100, training loss= 9.340639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3200, training loss= 3.677304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 3300, training loss= 8.6567816e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3400, training loss= 6.0278806e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3500, training loss= 7.397346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3600, training loss= 6.843914e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3700, training loss= 8.776783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3800, training loss= 5.9543127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3900, training loss= 9.175373e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4000, training loss= 4.402351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4100, training loss= 2.2397937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4200, training loss= 3.2885026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4300, training loss= 4.080262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4400, training loss= 4.5756886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4500, training loss= 5.9554888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4600, training loss= 2.0483687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4700, training loss= 4.8015147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4800, training loss= 1.8999515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4900, training loss= 5.000678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5000, training loss= 3.1390948e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5100, training loss= 4.341062e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5200, training loss= 3.5542293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5300, training loss= 3.29073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 5400, training loss= 3.0748364e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 2.1142372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 3.6396024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5700, training loss= 1.8799263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5800, training loss= 5.672108e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5900, training loss= 2.0149058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.615231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6100, training loss= 1.8298879e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.1910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.066327e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.1439587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.9743922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.909969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6700, training loss= 9.895275e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6800, training loss= 1.8217193e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.8964653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.850747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7100, training loss= 1.2582383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 1.5819525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.94874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.5780653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.0326659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.5469042e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.6382518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.649186e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.1612133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.3358386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.200997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 9.97935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.5963342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.4736417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.2384781e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0966139e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 1.2153874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 6.3762327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 1.3212799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.370498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.599305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 7.3170618e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 7.3944047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 5.7985617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 1.0688096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 7.312641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 4.737663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.357037e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 4.169524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.464946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 2.616641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 7.613475e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.946591e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 6.5175204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 4.156245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.4063607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 2.643734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 4.840908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.0164205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.8086952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.1595501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 3.9890697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.7695444e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.1670805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4616354e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.8973368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 2.654517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.6394304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 1.4092485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.1499834e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.6281841e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.0322422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.531545e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12400, training loss= 2.2337817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12500, training loss= 1.1781003e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.0956027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.8034227e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.0394018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.2493897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 7.139658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.3696742e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 8.603279e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.1339162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.2074739e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 7.863428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 6.8152826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.515626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 7.3005623e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 5.674273e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 8.7864754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 6.411636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 5.2187596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 6.15794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 4.2395635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.7564095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 4.6976615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.61982e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.1113345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.4260295e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.5621335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.2506082e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.933879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 3.5430352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.1496637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.7755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 2.9478602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.725621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.6285505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.405113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.2377196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.8060149e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.0120724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 1.6859549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.0725307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 1.901383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9184115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.6476366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 1.1980512e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.7140543e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 9.340883e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.9873822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.7029862e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.1546246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1111979e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.148793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 8.685232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.1355174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.276517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.1818729e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.16228854e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.3463742e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 6.616106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18400, training loss= 5.7475837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 5.6964954e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.2148958e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.734308e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 2.2479462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 3.474097e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.371918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0994396e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 2.0691315e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.8572693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7370493e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.0142907e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 2.6311184e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.4778494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.627366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 2.3671552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.8647734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 1.5326908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.9924979e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.0435873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.3538767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1495181e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.592295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.8818033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 7.4080053e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 9.451592e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 7.663454e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.619866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 3.5762788e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.8099332e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.172325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.087176e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.150531e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.11982353, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 5.7371297e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 0.002606958, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 0.0016902818, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 0.00011953538, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.005635671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 0.0002883323, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.0006777974, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 0.00031814972, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 3.1952416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 1.09939165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.8625235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 2.4129022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3158775e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 1.640398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.3519716, training acc= 87.00000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.0009528943, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.003006239, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.014029461, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 400, training loss= 0.0015689554, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 500, training loss= 0.0003099327, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00030536676, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.03523389, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00039316947, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00039418964, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0010337114, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.00062609004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00021209747, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1300, training loss= 0.0001306783, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1400, training loss= 4.746507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 9.367379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.05381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 4.580253e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 4.2583804e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 5.3734188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 7.2573726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 5.3641164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 3.843553e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 4.4612098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 6.1662984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000104323626, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.348726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.2048243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 3.371978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.642993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 2.5509988e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 6.684009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3200, training loss= 2.5878713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 3.7779122e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.2883649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 4.758754e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 3.0657113e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 2.8887041e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3800, training loss= 3.2864176e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 3.732585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 5.088799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.419403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 2.3272509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 2.7392243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.9352435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 2.3834718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 2.0721232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.4677913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.049585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 1.9331095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.1888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.3766056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 2.1681566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.500228e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.5583608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 1.6841575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.7202525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.7157108e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.0916995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.6099933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.2681335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 9.948798e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 7.475171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5907854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 9.327078e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.026643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 6.4742485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 6.6350053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 3.7976392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 6.5302593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 6.3062303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 7.660167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.4459723e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 9.755237e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 5.9006593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.1660866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 7.315005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.629828e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.098802e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 4.431427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.212194e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.3657767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.108661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 4.8544553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 2.3476496e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 3.904682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 5.2775117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 2.5992967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.197542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.4326245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.1559794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 2.4537435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.9838131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.6144287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1462056e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.8924104e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9600, training loss= 2.1578867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 1.3227204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 1.8188492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.0837114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.441226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 1.2795639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 9.5056566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.4546888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.684517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 8.5973164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.1005285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.1821861e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.025697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.3952018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 5.631402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.1376029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 9.2362524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.362464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.1725314e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.162041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.846139e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 5.8638676e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 5.9258434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 6.313289e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 7.460071e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 3.0612864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.589695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 3.8528333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.052225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 6.7758185e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 6.645871e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 4.2009188e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.8301724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.587864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.4558644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.4926575e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.5513897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13300, training loss= 3.0469775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 2.2900056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 1.9466829e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8812818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.3269595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.0170174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 2.499814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 2.6416683e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.950421e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 1.5592553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.0108937e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.776216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 1.5032272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.6486621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.6164756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.3364976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.1205658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 8.583062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.3136845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.10268495e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 15300, training loss= 9.810914e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 1.1301029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 7.092948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 8.726113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 9.21487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 5.781647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.388256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 7.748599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 7.450577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 5.14984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 8.058544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 4.1961655e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 4.3153747e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 3.671645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 5.6743563e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 6.580348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.6597246e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.8756586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.3365017e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 3.0040734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 3.5166725e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.099441e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 2.8252595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.6702873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.3841855e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.4199483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.0623204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6212462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.7762183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.5258788e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0251998e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 9.655952e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.503395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 4.8875806e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.1988827e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 4.4107433e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 1.0728836e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.1729553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 95.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.0031946634, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 0.00025052714, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25200, training loss= 0.0047556064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25300, training loss= 0.00039012992, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0019254637, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25500, training loss= 0.0009243777, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25600, training loss= 0.0037950636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 25700, training loss= 0.0002131526, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25800, training loss= 0.00033333493, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 9.50662e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26000, training loss= 5.5164932e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26100, training loss= 6.2116036e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 0.00012879116, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00013183773, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26400, training loss= 6.066161e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26500, training loss= 5.828503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26600, training loss= 0.00014434585, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26700, training loss= 6.5723725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.00013109639, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26900, training loss= 5.679692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.4003347e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27100, training loss= 5.0567993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27200, training loss= 5.742894e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27300, training loss= 3.3297933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27400, training loss= 4.2237552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27500, training loss= 4.8522703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27600, training loss= 2.9742963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 2.129703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27800, training loss= 2.1666032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27900, training loss= 2.1551958e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28000, training loss= 2.329084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28100, training loss= 2.5134379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28200, training loss= 4.9698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28300, training loss= 2.1453234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.6060341e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28500, training loss= 3.4785953e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28600, training loss= 4.0305527e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 1.1208098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28800, training loss= 1.6175867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28900, training loss= 2.3721153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29000, training loss= 1.4099831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29100, training loss= 2.7127657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29200, training loss= 1.2386997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29300, training loss= 1.923202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29400, training loss= 9.747781e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29500, training loss= 8.271617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29600, training loss= 1.8319597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29700, training loss= 1.1474658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29800, training loss= 7.541031e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29900, training loss= 1.7230459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.08917236328125 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.4353279, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.0023052054, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.00817067, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0012017189, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.0019304784, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0011654797, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0024550452, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.0019152034, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00040729338, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0037700261, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00527143, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00017237726, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0004813281, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.0001397225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00024952108, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1500, training loss= 8.417386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1600, training loss= 0.0001752477, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1700, training loss= 7.580368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1800, training loss= 7.096267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1900, training loss= 7.655546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00012819025, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2100, training loss= 0.00011084802, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2200, training loss= 6.95028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00013003117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2400, training loss= 7.066823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 6.038435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 4.9352657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2700, training loss= 5.35837e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 9.045679e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 6.712659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 4.825196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.356384e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 3.754795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.1368664e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.7147125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 6.498417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 2.2050423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.576332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 6.4594205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 4.001712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 2.3424298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 5.2356507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 5.2146053e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.7952497e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 2.306709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 3.150861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 3.2143907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 2.27654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.046918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 4.7465153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 3.2441218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 2.1702464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.487742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.9062137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9037901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.4690544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 4.4863158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3629243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.814534e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.1962673e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.4901772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.1438396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.518539e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 2.2726628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1718959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 9.16725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.37141205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 2.3904355e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.6641432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.3209275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.00211855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 2.0758102e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.8091861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6848642e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 7.1548e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 8.754681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.1048828e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.08617705e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.0820899e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.431282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 6.1394758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.1510084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 1.0234857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 5.8081164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 1.210195e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.71322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 7.745655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 8.386487e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 1.3572065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.234663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.9971045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.239033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 5.749447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.9238816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 5.477398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 7.675773e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 6.401778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.8150787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.910181e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.831391e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 5.557418e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.475434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.9240425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 2.0966415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.087136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.2135805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.9673515e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.2271935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.4433057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.468637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.3491589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 3.3168315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 1.9718705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.0837392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.718139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4965427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.7829245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1739949e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.3384041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.0300517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.5389562e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.0319427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.730026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 9.278356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2689695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 1.2989624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 7.994861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.5140245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.133902e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.0366132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 6.3339417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.1051603e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 6.069677e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.9170665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.586867e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.9775966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 6.5167114e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.963399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 7.6730606e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.405814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 4.330259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 4.85476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.5947725e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 3.2663172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 3.8742775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.190822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.8888243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.634515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.8530624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.2852564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2017493e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8715814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.912668e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 2.6186208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.499417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 1.6887945e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.6967428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.8517133e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.3609709e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.3788525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 1.8993961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.581865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.622237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.13646045e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 7.480377e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.056988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9192672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 1.2000373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 9.53673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 7.3909696e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 7.867805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.0995376e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 7.192287e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.4041514e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.1603026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 7.867807e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.427454e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.1155994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.5101795e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 5.6425677e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.622797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 3.496804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.688897e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.708666e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 4.4504784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 4.837909e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 3.9736413e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.4570675e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 5.0663935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 2.622604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.2981227e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 1.8278755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 1.986821e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.1822574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.536541e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.9868212e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.9470848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.4305112e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20700, training loss= 2.1855035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.2020268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.2318291e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21900, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 2.8808909e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.9670534e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.4835267e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 0.13311927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.046874475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 0.05061221, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.0041597537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27100, training loss= 0.014204321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 27200, training loss= 0.001146232, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.021358844, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 0.0018947971, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 0.0047540064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 0.0003114235, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27700, training loss= 3.8776663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 6.4117994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 5.7206264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 1.6581589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.1862379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.3297419e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 6.852968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.608867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.1707627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 4.0452374e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.984698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 3.1582522e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.5353715e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 6.449117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.8671493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 5.4049688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 1.6709346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 1.3321171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.6156073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 9.45316e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 3.602549e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 7.384754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 1.2332417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.0955105, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0028113748, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.020106887, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0075765625, training acc= 100.0%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.0030207026, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.02076395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0071594287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00045671416, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00037344565, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0012458521, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00021473918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00014760095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00013677847, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00013461121, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00021795194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001313438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011562832, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014888095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013140295, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00010066957, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.000112738475, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 7.613995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 5.3595628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 7.152121e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.671476e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 0.00010096761, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 3.564369e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.1420422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 6.614269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.349897e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 5.164496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.2876585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 6.37733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 6.556921e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.9869544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.2773994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.1103998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 5.787611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.1437328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 2.4311628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 1.4565001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4100, training loss= 4.5023902e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 1.8875788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 4.076463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 4.7788562e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 3.184429e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.972469e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.776609e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 2.9440813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 2.2038916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 1.7966004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5100, training loss= 2.8320275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.2405575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.2988037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.3130415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 1.32359055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.247483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 9.296824e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 2.4153762e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.7385415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.9255198e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.8501427e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6200, training loss= 2.1512398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.6649432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.2661908e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.1631276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.2810624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 9.034132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0652611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 9.76632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.1188107e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 8.573692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 7.988838e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.1142546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.05885265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0540736e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 5.203169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.0639708e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7800, training loss= 7.1809513e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 8.578989e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 7.4236045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.1001803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 7.1308214e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.7187563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 3.943845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.446505e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 7.254146e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8700, training loss= 2.8082854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.5589026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8900, training loss= 2.1234277e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 5.221008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.047283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.692058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9300, training loss= 2.9169641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9400, training loss= 3.8244416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.2935446e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.1042814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.504906e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.1706138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.9283163e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.862589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.6190272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 3.1757636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8427322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 9.73531e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10500, training loss= 2.3000148e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.8012147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.5653662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.2071681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.250008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11000, training loss= 1.4086252e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1070438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.923374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.9851818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 8.7855835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5202958e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.004134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.613352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 4.3312525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.9220255e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0176362e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 5.42e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.64523e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.833968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 2.9762452e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 6.8067965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 6.9895714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.9497866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.608102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 12900, training loss= 6.8504954e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 7.2200305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 4.1345547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.960347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 4.4723112e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 2.8510783e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 3.1669754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 4.6769503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.496794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 1.8318434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 3.3060525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.6530316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.7219292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 1.5536901e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.0980772e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.1537078e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.3643126e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.1497372e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 1.4861402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.345076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.0609617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.6947558e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15100, training loss= 1.8358199e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.1603023e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 1.18414334e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 1.7444272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15500, training loss= 9.695676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 7.311496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 8.6227956e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.4563365e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 1.0728823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.0609615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16100, training loss= 6.119405e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.0689081e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 8.9009504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 8.066485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 6.715452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 9.83476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 6.7154524e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16800, training loss= 6.735318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 5.205467e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 5.5829645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 6.635977e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 5.5034924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.2716643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.1657317e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 2.9206268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 3.5365403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.715453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 4.8279738e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 4.5895558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 5.7021744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 4.450478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 3.337859e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 2.8411542e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 1.4305108e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.3047125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18700, training loss= 2.2053715e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.5894567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 2.8212858e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.589457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.1060302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 3.283803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27600, training loss= 8.750192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27700, training loss= 0.00017802311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 2.1196429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.8985592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 7.8763205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 3.546847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.6731125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 7.883992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3357021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.3983502e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 1.2783901e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 3.0526621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.755123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 8.7105955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 7.6139836e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 5.894734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 2.29254e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 9.097336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.9656381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 4.0238247e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.581168e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.5255363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 7.185875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.3462383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 97.87686157226562 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.043932762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.00346537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.0011190585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0012442004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.021783786, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.022612568, training acc= 100.0%\n",
            "Validation Accuracy valid 96.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.008526753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0036731793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0003066097, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00044239248, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.027541004, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.0022008778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00021435294, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1300, training loss= 0.05735776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0005141321, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.0004150997, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00011833411, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 4.3463686e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00013469311, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.000113486225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.763822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00010155505, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 0.00011534586, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2300, training loss= 7.263035e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 6.118358e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00011097876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.573861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 8.1907354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 4.1220737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 8.37911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 4.5873494e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.979296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 5.355815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.9706516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.9243054e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 3.6681795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.558105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 9.076852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 3.5366185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.0052702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 8.139999e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.2944783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.6386212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.4070846e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 2.7786818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 5.3323733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.0305944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.0987096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4800, training loss= 4.204507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 4.7204703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.7862954e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.3337867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 3.93738e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0123836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.8250397e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.340844e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.3037133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.379435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.8580007e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 4.6972276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.1531753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.5730778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.2070937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.26575305e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 1.646893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.3563857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.4728784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.9740706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.0944378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.7237191e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.6347589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.3372672e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.1593232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.873226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 8.970844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.86823e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.35795835e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2734335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 7.63589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.1472493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.64973e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.3011335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.2727216e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 8.41922e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 6.9051134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.3500094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 8.619766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 9.1507845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 9.704187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.358283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 7.530288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 7.376592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1223903e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 4.9204627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 7.2851317e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.7224943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 6.3660896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.853605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.0799845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.673084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.6151978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 5.018778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 4.3387704e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 5.035393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.0998478e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 4.3450655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 5.868524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 2.5312145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.5855664e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.039097e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 3.6719402e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11100, training loss= 1.6627401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 2.246681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 2.751994e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 4.0859622e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11500, training loss= 2.403876e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 2.1279636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 2.2112338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.9876795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.718517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 2.0409645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 1.9794986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12200, training loss= 2.0122852e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 1.121226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.3376744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 1.1521322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 1.9483273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 1.361175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 1.4165066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.2780766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 1.3518024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.2564403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 9.152626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 6.0864096e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13400, training loss= 4.3545228e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 9.839789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 9.414007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13700, training loss= 1.3303458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 6.7667764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 5.490398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 7.271686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 4.870499e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 4.795587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 7.9358546e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 4.965891e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14500, training loss= 8.1325726e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14600, training loss= 4.7334325e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.7792632e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 5.359276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14900, training loss= 3.4170236e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 2.9121003e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 3.382125e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.8153827e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15300, training loss= 3.7056924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 2.8235408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 2.861861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 1.743858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15700, training loss= 3.4749345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15800, training loss= 2.6021596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 2.9597865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.66552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.3998549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16200, training loss= 1.8221955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 1.5667482e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 1.963542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 1.7540755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16600, training loss= 3.3625395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 1.1035363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.2642516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 1.449242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 7.901864e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17100, training loss= 9.2131664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 1.3436569e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.2568047e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17400, training loss= 1.1886851e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 6.505416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 8.1743444e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 8.4127585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.03967366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 7.629383e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 8.21692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 5.1600544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 8.8385086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 4.8364875e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 6.7438336e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 7.322849e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 6.556505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 6.003037e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 2.997261e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18900, training loss= 3.3889485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 3.5081577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19100, training loss= 3.8487553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 3.0483513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.8269621e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 2.758841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 2.3501252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 2.929141e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 2.4182446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 2.4948793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 3.193105e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 2.7588428e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 1.7029896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 2.0095277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.452305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.6518996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20600, training loss= 1.958438e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 1.7370494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.5326904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21100, training loss= 1.4645709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 1.3623916e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 1.4986309e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1239731e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.328332e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 9.621892e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 1.2261526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 8.429799e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 6.8119594e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 8.8555465e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22400, training loss= 4.598072e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 6.130763e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 8.514948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22900, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 5.449567e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23300, training loss= 6.2159122e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23500, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23600, training loss= 4.0871755e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 4.5980726e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24000, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24100, training loss= 1.4475414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25200, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25300, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26400, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 2.2138869e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.08700258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28200, training loss= 0.0010462438, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 0.007788537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 0.0002787191, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.03819514, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 0.0005042283, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.009254003, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 0.00053602253, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 4.780922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.00015877286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 6.313633e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.1946026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 1.9100013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 3.2852473e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1920068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.3221739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 3.518542e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.7654147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.6732978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9243863, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0024209036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0068702064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00035379876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00045177506, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00038027472, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00036243335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00017564422, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.00029733498, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00027954616, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.000161541, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017748478, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00022369123, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.000344609, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00015815801, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00012104943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.0002594582, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.00018366707, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013618838, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 7.929951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00015742778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00018521569, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.00021373876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.9257304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.3261504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.000116200856, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 9.615918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 9.446045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012584943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00011829853, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.00011489536, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 8.699955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.80409e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.161969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 5.5696393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 3.2970627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 8.763576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.7847116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 6.593805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.6044188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 4.8277332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.8972863e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.126466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.9542392e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.5367608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 1.985223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 5.5880606e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 3.2430893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 3.910794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 2.018158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.5018284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.3676028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.0947302e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.6408117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 2.6051965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.1301573e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.367336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.049514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 9.990617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 8.0822365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.5722264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.2119383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.2337974e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 9.168887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.6381538e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.9810032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 7.81372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 8.688743e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.10711435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.0865252e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 5.9742338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 4.7527224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.2080694e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 8.884138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.293933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.51772e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 7.38424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 2.1105293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 6.9539697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 3.7264176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.755928e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.063937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 3.9288493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 3.2804019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 3.0751528e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.550676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 3.4777236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.084731e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 2.4777005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.0058607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 1.4986039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.1463794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.966666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 1.2074029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 1.7817259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 1.3650937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.261265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.7514195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.3318578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.5875698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1644014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.048308e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.4952833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 8.9976413e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.2329394e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.6770747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 8.1129633e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 4.567388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.5798327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 8.6085134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 9.19009e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 4.133988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.034042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 7.367038e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.0818939e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.5007466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 5.320095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.200197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 7.127799e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 8.553963e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.6966734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 6.839999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.735665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 3.3514695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 3.4425798e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.8849995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 5.039107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.1777643e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.136189e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 4.8475374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 2.1219216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 2.5544762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.1661975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.8921604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.0197416e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.7804719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8303603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.932538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.7200168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.0691259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.8562555e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 1.4168852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.4863567e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.7915418e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 9.84327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.809205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 8.617114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2568043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 8.6086054e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 7.4590886e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 6.914132e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 8.3786965e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.4979106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 6.335113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.04222835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 5.6539225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 7.833745e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 6.2669976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.006787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 4.4958913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.9982724e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 4.2489567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.8923415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 5.177086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 4.7939146e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.160056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 3.1335006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.2196604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.712516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.975468e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 2.7929026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 3.031321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 4.1552934e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 2.2138865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 1.9414083e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7247832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.1372518e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 2.656663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.29427224e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.2857571e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.4560561e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 1.5667505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.3027872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.8392285e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 8.855547e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.1239732e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.0813985e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 7.833753e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 9.196145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 4.4277733e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 3.32083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.3623918e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.24474247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 96.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.032282036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 5.73278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 0.00030204258, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 26700, training loss= 4.8327554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26800, training loss= 0.0003888717, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 8.557337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 1.0821099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27100, training loss= 9.114718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27200, training loss= 6.6440302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 2.1565978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 1.7132148e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27500, training loss= 1.2015865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 7.938417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 8.493593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 6.0402754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 1.7332968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28000, training loss= 5.8008377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 7.557258e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0585328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 3.2737814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.2189442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.4599065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 4.4164253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28700, training loss= 3.0639646e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 2.4838625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.8142007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 8.375978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.4958329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 2.5601869e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 7.4032455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 6.6567754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.7429356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 8.500388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 6.127682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6215455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29900, training loss= 1.1230701e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3563504, training acc= 89.99999761581421%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0013517543, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.046949483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.015602395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0010993601, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.00060543907, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.035742156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.02051982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 800, training loss= 0.0003255704, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.002698314, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.00090309983, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.0007421032, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00023186239, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.0002514339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.000115245464, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00015637734, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 8.212202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1700, training loss= 0.00014769404, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.00014291928, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 7.7071294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 8.413261e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 6.18306e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.244873e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 7.1835784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2400, training loss= 0.00014239793, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00011172854, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2600, training loss= 4.0016163e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 3.7728772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 4.3896995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 3.8974944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 4.320103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 6.5506516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.630137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 8.348236e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 4.6463654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 4.73913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.9050643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 3.443583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3800, training loss= 5.295749e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 2.9115756e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.7335463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.3563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 7.086432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.7008376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.1530515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 5.4621105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 3.8189406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.090024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.822282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.6192174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.9120765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.4396213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 4.3570755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.8151382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.6990412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.3288716e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.3502238e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 3.2518095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.6441714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.6492204e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.2933482e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 3.7795922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.8690403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.6910099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 4.06955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.0182362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7673021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.2118496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5177543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.828235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.4597936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.6470447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 2.1047e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.4996771e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.1297304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.5014371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.3697337e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.5776854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 2.1273268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.753624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.9416693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 1.307189e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.0839659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 7.0077126e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 7.5698817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.5104426e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.3171199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 4.5427187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.0951795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.323114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.55921e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0194833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.873782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 6.6927596e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1024396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 3.8785356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.2273388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 5.3128606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.273568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.140481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.284792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 5.9459653e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.5585815e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.6425023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 4.1130966e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 2.938506e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.3039228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 4.156696e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 2.800087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.8784414e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.6066193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.2186498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 4.17659e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 3.9410666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 3.8625662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11500, training loss= 2.8251538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 1.9006941e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.1492651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.2465964e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 9.211739e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.5813542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.2170963e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.289801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.2382616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.4377094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.1516122e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3979792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.3319154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12800, training loss= 7.256767e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.0221991e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 7.5279627e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 8.2810675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 9.0776246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 4.2489964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.548806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.855719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 8.304287e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 6.607124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 3.659695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.7520888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 6.347845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.280196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.4469117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 3.9212117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.0348688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.830923e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.755484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 2.9384975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 3.433214e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 3.611269e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2983607e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 2.479542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.9580064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 4.0672444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.3351415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 3.5554007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 3.6067885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.0205908e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.5637343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.573278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.5765391e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.2977463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.8179368e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.5884589e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 2.0980778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 9.9241525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 2.3901367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.630183e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.4473165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 1.1891107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 1.3142795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.364943e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 9.097145e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.4454085e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.8380026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.0490401e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.2606354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.884327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.039163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 7.27176e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 6.586307e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 6.288281e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 4.3287837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 8.493653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 5.692239e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.731114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 7.3760674e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 5.9306558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 3.4272652e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 3.09944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 3.6954862e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.6491586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 2.7418128e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.397464e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2186495e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 2.5033941e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.3841853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.795589e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.9744032e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 1.9147986e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 2.175569e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 1.9371505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.788139e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.4007088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.4454123e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 8.940692e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 4.2468304e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.5762782e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920928e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 1.0501016, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 94.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.00021391657, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 0.1540282, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 0.00055521145, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 3.4036017e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 0.001800267, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 0.0073885997, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0033072354, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 0.00026740984, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.0043647327, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 0.00016933345, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.00020177083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 0.0009964005, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 1.4938123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 9.6338714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.6149547e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.3622192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 0.00013764083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.4615026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9294039, training acc= 87.99999952316284%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1286d8755697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", training loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\", training acc= \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_validation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_validation_data_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mplot_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy valid {} ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BoQHpkHzQ0YO"
      },
      "source": [
        "#### Valid acc= 98.799995 %\n",
        "#### Validation Accuracy Test 98.51380157470703 ...\n",
        "W1 = 4 ...\n",
        "W2 = 1 ...\n",
        "W3 = 0 ...\n",
        "Highest validation accuracy, to brake tie Validation test accuracy was used which is highest for this combination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SeaxvipDvrKA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {}
      },
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {}
      },
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {}
      },
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SW9qZGWUQFQs",
        "colab": {}
      },
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oWFUJtzdQFQx",
        "colab": {}
      },
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5nSzdyLhJ3K-",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
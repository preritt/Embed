{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EpochBasedSatimFullDataset04202019_SGD - TBC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/EpochBasedSatimFullDataset04202019_SGD_TBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "a7ef6ca4-f4e6-4031-85be-3834d018df6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.127273</td>\n",
              "      <td>-0.095238</td>\n",
              "      <td>-0.289256</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.054545</td>\n",
              "      <td>-0.157895</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.188119</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.484375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>-0.603306</td>\n",
              "      <td>-0.096774</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.015385</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.609375</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.609375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.074380</td>\n",
              "      <td>0.354839</td>\n",
              "      <td>0.327273</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.207921</td>\n",
              "      <td>-0.010526</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.380952</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>-0.225806</td>\n",
              "      <td>-0.163636</td>\n",
              "      <td>-0.410526</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.383333</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.347368</td>\n",
              "      <td>-0.484375</td>\n",
              "      <td>0.09375</td>\n",
              "      <td>0.087379</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.218750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.1250</td>\n",
              "      <td>-0.184466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287356</td>\n",
              "      <td>-0.183333</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.267327</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>-0.03125</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6   \\\n",
              "0  0.0000  0.127273 -0.095238 -0.289256  0.032258  0.054545 -0.157895   \n",
              "1  0.0000 -0.090909 -0.571429 -0.603306 -0.096774 -0.090909 -0.494737   \n",
              "2  0.5625  0.490909  0.333333 -0.074380  0.354839  0.327273  0.052632   \n",
              "3  0.0000 -0.018182 -0.380952 -0.471074 -0.225806 -0.163636 -0.410526   \n",
              "4  0.0000 -0.018182 -0.285714 -0.471074  0.032258 -0.090909 -0.326316   \n",
              "\n",
              "         7       8         9     ...           26        27        28  \\\n",
              "0 -0.265625 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.138462   \n",
              "1 -0.562500 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.015385   \n",
              "2 -0.187500  0.1875  0.242718    ...     0.103448 -0.233333  0.200000   \n",
              "3 -0.437500 -0.3750 -0.242718    ...    -0.011494 -0.383333 -0.138462   \n",
              "4 -0.500000 -0.1250 -0.184466    ...     0.287356 -0.183333  0.230769   \n",
              "\n",
              "         29        30        31       32        33        34        35  \n",
              "0 -0.188119 -0.431579 -0.546875 -0.15625 -0.126214 -0.431579 -0.484375  \n",
              "1 -0.049505 -0.431579 -0.609375 -0.15625 -0.126214 -0.494737 -0.609375  \n",
              "2  0.207921 -0.010526 -0.312500 -0.15625  0.009709 -0.326316 -0.437500  \n",
              "3 -0.049505 -0.347368 -0.484375  0.09375  0.087379 -0.031579 -0.218750  \n",
              "4  0.267327 -0.031579 -0.281250 -0.03125 -0.126214 -0.431579 -0.546875  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "326d1506-dda9-487b-84a1-25b7eb765099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  5\n",
              "1  5\n",
              "2  5\n",
              "3  5\n",
              "4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "31caf516-7b80-4418-a3f9-f2089746d302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "c8fd3ce1-abbb-4f48-e1f0-0a084f356424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "a8492888-b66e-4038-c584-c9b8a184b539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XnBnT6NdTqyO",
        "colab_type": "code",
        "outputId": "d4dafb1e-b297-49cb-b18e-56b2a2004243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "20*90/36"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "3a76e82a-816f-471f-f5b3-bdc7a3d16bc2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(90, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.95444174\n",
            "Iteration 2, loss = 0.41361696\n",
            "Iteration 3, loss = 0.37376292\n",
            "Iteration 4, loss = 0.35310299\n",
            "Iteration 5, loss = 0.33669458\n",
            "Iteration 6, loss = 0.32397037\n",
            "Iteration 7, loss = 0.31519296\n",
            "Iteration 8, loss = 0.30943933\n",
            "Iteration 9, loss = 0.30110286\n",
            "Iteration 10, loss = 0.29639559\n",
            "Iteration 11, loss = 0.29181714\n",
            "Iteration 12, loss = 0.28519907\n",
            "Iteration 13, loss = 0.27945018\n",
            "Iteration 14, loss = 0.27446988\n",
            "Iteration 15, loss = 0.27230486\n",
            "Iteration 16, loss = 0.26854954\n",
            "Iteration 17, loss = 0.26347512\n",
            "Iteration 18, loss = 0.25999897\n",
            "Iteration 19, loss = 0.25824005\n",
            "Iteration 20, loss = 0.25456133\n",
            "Iteration 21, loss = 0.24952501\n",
            "Iteration 22, loss = 0.24607191\n",
            "Iteration 23, loss = 0.24673228\n",
            "Iteration 24, loss = 0.24442729\n",
            "Iteration 25, loss = 0.24115307\n",
            "Iteration 26, loss = 0.23827513\n",
            "Iteration 27, loss = 0.23520357\n",
            "Iteration 28, loss = 0.23354455\n",
            "Iteration 29, loss = 0.22978524\n",
            "Iteration 30, loss = 0.22810795\n",
            "Iteration 31, loss = 0.22567502\n",
            "Iteration 32, loss = 0.22661689\n",
            "Iteration 33, loss = 0.22176630\n",
            "Iteration 34, loss = 0.22185255\n",
            "Iteration 35, loss = 0.21909550\n",
            "Iteration 36, loss = 0.21857916\n",
            "Iteration 37, loss = 0.21802408\n",
            "Iteration 38, loss = 0.21273616\n",
            "Iteration 39, loss = 0.21271724\n",
            "Iteration 40, loss = 0.21180686\n",
            "Iteration 41, loss = 0.20911150\n",
            "Iteration 42, loss = 0.20824662\n",
            "Iteration 43, loss = 0.20727753\n",
            "Iteration 44, loss = 0.20444614\n",
            "Iteration 45, loss = 0.20458268\n",
            "Iteration 46, loss = 0.20322771\n",
            "Iteration 47, loss = 0.20093423\n",
            "Iteration 48, loss = 0.19972227\n",
            "Iteration 49, loss = 0.19969319\n",
            "Iteration 50, loss = 0.19881669\n",
            "Iteration 51, loss = 0.19614789\n",
            "Iteration 52, loss = 0.19417483\n",
            "Iteration 53, loss = 0.19168104\n",
            "Iteration 54, loss = 0.19479601\n",
            "Iteration 55, loss = 0.19010506\n",
            "Iteration 56, loss = 0.19106383\n",
            "Iteration 57, loss = 0.19142207\n",
            "Iteration 58, loss = 0.18865416\n",
            "Iteration 59, loss = 0.18610193\n",
            "Iteration 60, loss = 0.18574850\n",
            "Iteration 61, loss = 0.18561203\n",
            "Iteration 62, loss = 0.18429022\n",
            "Iteration 63, loss = 0.18052444\n",
            "Iteration 64, loss = 0.18136414\n",
            "Iteration 65, loss = 0.18031222\n",
            "Iteration 66, loss = 0.17744159\n",
            "Iteration 67, loss = 0.18027992\n",
            "Iteration 68, loss = 0.17645335\n",
            "Iteration 69, loss = 0.17403393\n",
            "Iteration 70, loss = 0.17429126\n",
            "Iteration 71, loss = 0.17618357\n",
            "Iteration 72, loss = 0.17183623\n",
            "Iteration 73, loss = 0.17166370\n",
            "Iteration 74, loss = 0.17217259\n",
            "Iteration 75, loss = 0.16904945\n",
            "Iteration 76, loss = 0.17088875\n",
            "Iteration 77, loss = 0.17259165\n",
            "Iteration 78, loss = 0.16779362\n",
            "Iteration 79, loss = 0.16512526\n",
            "Iteration 80, loss = 0.16614422\n",
            "Iteration 81, loss = 0.16629507\n",
            "Iteration 82, loss = 0.16287885\n",
            "Iteration 83, loss = 0.16415537\n",
            "Iteration 84, loss = 0.16234924\n",
            "Iteration 85, loss = 0.16424623\n",
            "Iteration 86, loss = 0.15978972\n",
            "Iteration 87, loss = 0.16143070\n",
            "Iteration 88, loss = 0.15866024\n",
            "Iteration 89, loss = 0.15941105\n",
            "Iteration 90, loss = 0.15681068\n",
            "Iteration 91, loss = 0.15561312\n",
            "Iteration 92, loss = 0.15621932\n",
            "Iteration 93, loss = 0.15605395\n",
            "Iteration 94, loss = 0.15510723\n",
            "Iteration 95, loss = 0.15339714\n",
            "Iteration 96, loss = 0.15174013\n",
            "Iteration 97, loss = 0.15426171\n",
            "Iteration 98, loss = 0.15044099\n",
            "Iteration 99, loss = 0.15172792\n",
            "Iteration 100, loss = 0.14968459\n",
            "Iteration 101, loss = 0.14847401\n",
            "Iteration 102, loss = 0.14847588\n",
            "Iteration 103, loss = 0.14778554\n",
            "Iteration 104, loss = 0.14824874\n",
            "Iteration 105, loss = 0.14742960\n",
            "Iteration 106, loss = 0.14452012\n",
            "Iteration 107, loss = 0.14947363\n",
            "Iteration 108, loss = 0.14322124\n",
            "Iteration 109, loss = 0.14478542\n",
            "Iteration 110, loss = 0.14181720\n",
            "Iteration 111, loss = 0.14135020\n",
            "Iteration 112, loss = 0.14072554\n",
            "Iteration 113, loss = 0.13985860\n",
            "Iteration 114, loss = 0.13897508\n",
            "Iteration 115, loss = 0.13912146\n",
            "Iteration 116, loss = 0.13914079\n",
            "Iteration 117, loss = 0.13889620\n",
            "Iteration 118, loss = 0.13568594\n",
            "Iteration 119, loss = 0.13788100\n",
            "Iteration 120, loss = 0.13676511\n",
            "Iteration 121, loss = 0.13544847\n",
            "Iteration 122, loss = 0.13301428\n",
            "Iteration 123, loss = 0.13581044\n",
            "Iteration 124, loss = 0.13166328\n",
            "Iteration 125, loss = 0.13556177\n",
            "Iteration 126, loss = 0.13061816\n",
            "Iteration 127, loss = 0.12774804\n",
            "Iteration 128, loss = 0.13414609\n",
            "Iteration 129, loss = 0.12788896\n",
            "Iteration 130, loss = 0.12703824\n",
            "Iteration 131, loss = 0.12845110\n",
            "Iteration 132, loss = 0.12680860\n",
            "Iteration 133, loss = 0.12745193\n",
            "Iteration 134, loss = 0.12698741\n",
            "Iteration 135, loss = 0.12842388\n",
            "Iteration 136, loss = 0.12634677\n",
            "Iteration 137, loss = 0.12352253\n",
            "Iteration 138, loss = 0.12330926\n",
            "Iteration 139, loss = 0.12610248\n",
            "Iteration 140, loss = 0.12203222\n",
            "Iteration 141, loss = 0.12216357\n",
            "Iteration 142, loss = 0.11924790\n",
            "Iteration 143, loss = 0.11957397\n",
            "Iteration 144, loss = 0.12033362\n",
            "Iteration 145, loss = 0.11740384\n",
            "Iteration 146, loss = 0.11871911\n",
            "Iteration 147, loss = 0.11659951\n",
            "Iteration 148, loss = 0.12022110\n",
            "Iteration 149, loss = 0.11646908\n",
            "Iteration 150, loss = 0.11516562\n",
            "Iteration 151, loss = 0.11565456\n",
            "Iteration 152, loss = 0.11418154\n",
            "Iteration 153, loss = 0.11264107\n",
            "Iteration 154, loss = 0.11497207\n",
            "Iteration 155, loss = 0.11319484\n",
            "Iteration 156, loss = 0.11410818\n",
            "Iteration 157, loss = 0.11406045\n",
            "Iteration 158, loss = 0.10999054\n",
            "Iteration 159, loss = 0.11248917\n",
            "Iteration 160, loss = 0.11442108\n",
            "Iteration 161, loss = 0.11135488\n",
            "Iteration 162, loss = 0.11127527\n",
            "Iteration 163, loss = 0.10752335\n",
            "Iteration 164, loss = 0.10901415\n",
            "Iteration 165, loss = 0.10863796\n",
            "Iteration 166, loss = 0.10790327\n",
            "Iteration 167, loss = 0.10961160\n",
            "Iteration 168, loss = 0.10851879\n",
            "Iteration 169, loss = 0.10602720\n",
            "Iteration 170, loss = 0.10630070\n",
            "Iteration 171, loss = 0.10501613\n",
            "Iteration 172, loss = 0.10583980\n",
            "Iteration 173, loss = 0.10541182\n",
            "Iteration 174, loss = 0.10096666\n",
            "Iteration 175, loss = 0.10404634\n",
            "Iteration 176, loss = 0.10221237\n",
            "Iteration 177, loss = 0.10075696\n",
            "Iteration 178, loss = 0.09931985\n",
            "Iteration 179, loss = 0.10203152\n",
            "Iteration 180, loss = 0.10096311\n",
            "Iteration 181, loss = 0.09975398\n",
            "Iteration 182, loss = 0.09955987\n",
            "Iteration 183, loss = 0.09993594\n",
            "Iteration 184, loss = 0.09770182\n",
            "Iteration 185, loss = 0.09802935\n",
            "Iteration 186, loss = 0.09803881\n",
            "Iteration 187, loss = 0.09618500\n",
            "Iteration 188, loss = 0.09616072\n",
            "Iteration 189, loss = 0.09800732\n",
            "Iteration 190, loss = 0.09534339\n",
            "Iteration 191, loss = 0.09352430\n",
            "Iteration 192, loss = 0.09372701\n",
            "Iteration 193, loss = 0.09739990\n",
            "Iteration 194, loss = 0.09370456\n",
            "Iteration 195, loss = 0.09311714\n",
            "Iteration 196, loss = 0.09235983\n",
            "Iteration 197, loss = 0.09294382\n",
            "Iteration 198, loss = 0.09261564\n",
            "Iteration 199, loss = 0.09151696\n",
            "Iteration 200, loss = 0.09206768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(90,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "54e92d1e-6c9f-4564-894b-8a1126068008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710051546391752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "d7ad0a36-87ed-4040-a145-6ba130fff0a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858001502629602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "29f638dc-8885-4a3e-b70e-bb4afd80aa21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "3b4ce84e-e8ef-4149-b616-c386c7033447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 36 -> 90 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "0ccd8192-4654-4d07-8d00-ae9030860220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "d2b300d1-0da9-405a-cc13-bde691282354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.train.GradientDescentOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "caa0ef5d-3d2f-498d-d21b-6623a8423fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "hid_neuron = [374]\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-4106bc23d37b>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.09654394, training acc= 96.49999737739563%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1000, training loss= 0.074345045, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2000, training loss= 0.0795926, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 3000, training loss= 0.09808998, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 4000, training loss= 0.07493803, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 5000, training loss= 0.095866315, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 6000, training loss= 0.07703011, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 7000, training loss= 0.074125834, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 8000, training loss= 0.099417955, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 9000, training loss= 0.09222789, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 10000, training loss= 0.08109907, training acc= 96.49999737739563%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 11000, training loss= 0.11149396, training acc= 95.49999833106995%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 12000, training loss= 0.06741232, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 13000, training loss= 0.109245956, training acc= 95.99999785423279%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 14000, training loss= 0.07493451, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 15000, training loss= 0.090577155, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 16000, training loss= 0.13477787, training acc= 94.49999928474426%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 17000, training loss= 0.07381674, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 18000, training loss= 0.07977779, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 19000, training loss= 0.102517195, training acc= 95.99999785423279%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "Test acc= 89.450005 %\n",
            "Valid acc= 88.805405 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5A_PHV3bS7ui"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G5BxkTLzUAok"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test¶"
      ]
    },
    {
      "metadata": {
        "id": "mejHTwMYhEzu",
        "colab_type": "code",
        "outputId": "6b088442-02b3-492e-8a01-b2e186521a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(validation_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1331, 36)\n",
            "(3104, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xguK-SPLUrkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgzAMkJCXVq2",
        "colab_type": "code",
        "outputId": "84257891-733b-46bf-b020-f2da5f7760a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "qT_XdektXjmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plt.scatter(np.argmax(valid_validation_data_label,axis = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RS8J8lVeXGoK",
        "colab_type": "code",
        "outputId": "595fa11c-ad3e-48bd-f5d5-99e66bcdda43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(valid_validation_data_label,axis = 1))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([262.,   0.,  89.,   0., 152.,   0., 103.,   0., 165., 229.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CWpuf8GKxxT4b3UCxMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AJtaOCHUc8Us",
        "colab_type": "code",
        "outputId": "a875245d-188d-4ea0-b13b-a0cbcfbc59b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "KrEu6ndlUZh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "id": "Q5TyGgw4Ub9n",
        "colab_type": "code",
        "outputId": "0c63af24-4893-4537-d62c-edce4875818b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220065
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "# hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 2056\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "number_of_epoch = 10000\n",
        "# learning_rate = 0.001\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "number_of_ex = train_data.shape[0]\n",
        "\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,7):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for ep in range(0,number_of_epoch):\n",
        "              if ep<5000:\n",
        "                learn = .1\n",
        "              elif ep >=5000 and ep <= 8000:\n",
        "                learn = .01\n",
        "              else:\n",
        "                learn = .001\n",
        "              for step in range(0, total_steps_for_one_pass):\n",
        "\n",
        "                if step>=number_of_ex//batch_size:\n",
        "                  batch_x, batch_y = train_data[step*batch_size:,:],train_label_one_hot[step*batch_size:,:]\n",
        "        #           print(step,'Finishing',step*batch_size )\n",
        "                  step = 0\n",
        "\n",
        "                else:\n",
        "\n",
        "                  start = step*batch_size\n",
        "                  finish = (step+1)*batch_size\n",
        "        #           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "                  batch_x, batch_y = train_data[step:finish,:],train_label_one_hot[step:finish,:]\n",
        "        #         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})              \n",
        "\n",
        "\n",
        "\n",
        "  #                 batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "  #                 sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "              if ep % plot_every == 0:\n",
        "                  train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                  print(\"epoch \" + str(ep) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                  train_losses.append(train_loss)\n",
        "                  validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                  if ep%plot_every == 0:\n",
        "                    print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                    print()\n",
        "                    if (validation_accuracy >= best_accuracy_valid):\n",
        "                      best_accuracy_valid = validation_accuracy\n",
        "                      saver.save(sess, './statimgTrack')\n",
        "                      G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-36-01c115be8035>:54: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 6.3381844, training acc= 88.35877776145935%\n",
            "Validation Accuracy valid 85.5 ...\n",
            "\n",
            "epoch 100, training loss= 0.114989124, training acc= 96.27862572669983%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.07935828, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.07430671, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.074711435, training acc= 96.66030406951904%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07354451, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.071832255, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.08842048, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.08119054, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.06672005, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.058011055, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1100, training loss= 0.22082631, training acc= 96.37404680252075%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.051522493, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.047487713, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04676085, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.048031673, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.042011358, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.058029793, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.037921194, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.060004152, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.19836871, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03514021, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03561541, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.044272836, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.0474019, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04657368, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.033455193, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03261129, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031960748, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03019393, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.031161001, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.028996848, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.029230472, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.027791891, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.02851675, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.02749328, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.026400592, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.025871878, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.027818069, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.025901755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.02542047, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.024765514, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.024327163, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.044525307, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027548071, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.028368935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.025709359, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.024841975, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.024089096, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.023645885, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.023168115, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.023167705, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.023143891, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.023119053, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.023093745, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.023063958, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.02303396, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.023004105, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.022974906, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.022945084, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.022915542, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02288571, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.022855558, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02282512, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.02279522, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02276559, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.022737024, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.022709226, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.022681769, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.022654332, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.022627538, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.022601051, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.022575079, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.02254933, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.022523709, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.022498678, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.022473559, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.022448255, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.022423524, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.022398904, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.022374643, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.022375524, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.022373457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.022371305, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.02236903, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.022366736, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.022364443, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.022362126, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.022359844, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.022357492, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.022355169, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.022352835, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.022350486, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.022348156, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.022345817, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.022343492, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.022341123, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.022338798, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.022336438, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.02233408, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.41337138, training acc= 93.98854970932007%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.07085124, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.062371984, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.059018042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 400, training loss= 0.056937005, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.057519283, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.05458059, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.054769978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.055807676, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.052687164, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05054483, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04950989, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.048938304, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.063689865, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.047108777, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04665398, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.045790233, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.045450114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.044580616, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04407546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04396823, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.042953815, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04238154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.042043313, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04138066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.041467726, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.040798705, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.039858364, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.039400786, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038973108, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.038610645, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.038200658, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03783091, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.037445106, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.037105214, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03674163, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.036399577, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03612063, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0358011, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03546503, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.035138294, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.034829948, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03451915, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.034202736, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03390496, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.033603936, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.033321764, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.033038005, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03277554, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03250795, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03222756, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03223049, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03220845, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03218641, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03216189, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03213826, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03211428, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.032089747, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.032065146, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.032038547, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.032013044, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.031987347, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.031961046, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.031935576, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03191004, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.031883672, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.031856872, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03183157, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.031805817, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.031779654, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03175257, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03172661, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.031699616, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.031673353, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03164721, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.031621613, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.031595133, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03156959, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.031543083, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.031517185, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.031491525, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.031491626, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.031489514, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03148728, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.031484924, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.031482525, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03148003, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03147753, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.031475086, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.031472478, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.031469993, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.031467453, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.031465016, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.031462498, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.031459995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.031457514, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.031454995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03145246, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.031449992, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.0314475, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 3.7447982, training acc= 89.12213444709778%\n",
            "Validation Accuracy valid 85.5 ...\n",
            "\n",
            "epoch 100, training loss= 0.094632305, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.0895618, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.06455621, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.06352434, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.09404397, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.05791143, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 700, training loss= 0.082865626, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.083406314, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.052822977, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.054745093, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.049104195, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.052221276, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.08481589, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.045655545, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.049792785, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.043895748, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.0672104, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.11622092, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.050949015, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.045856673, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.042419028, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04012445, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04124436, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03936326, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04144684, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.038583156, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037615124, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.038705215, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.036476515, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03643756, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.036164016, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03563832, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.040442955, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.046638798, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.035929434, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03574467, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.034744427, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03370943, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03315964, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.032827917, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.032543015, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.032114573, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.031593733, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.034143697, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.032304384, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03140152, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.030464433, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.029885748, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.034380656, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.042538285, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03241092, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03169867, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03121462, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.030961057, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03073862, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.030554395, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.030405158, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.030258097, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.030117096, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.030013677, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.029904185, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.029786956, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.029673634, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.029571632, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.029470364, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.029373419, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.02928593, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.029208018, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.02913693, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.029069392, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.029005393, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.028946549, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.028887318, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.028830394, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.02877553, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.028724357, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.028675385, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02862823, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.028581114, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.028532848, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.028532997, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.028528834, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.028524388, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.028519887, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02851523, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.028510539, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.028505938, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.028501172, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.028496467, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.028491732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.028486997, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.028482223, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.028477399, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.028472433, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.028467558, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.02846262, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.02845776, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.028452877, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.028448097, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 4.1065335, training acc= 89.02671933174133%\n",
            "Validation Accuracy valid 85.39999389648438 ...\n",
            "\n",
            "epoch 100, training loss= 0.109946325, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.074629664, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.068775356, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.06210794, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.061238863, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06683235, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.06245432, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 800, training loss= 0.061179567, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.054490782, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.050712295, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04471336, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04476541, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.042004045, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057913322, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.03910626, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.050722014, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.039717834, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.07565243, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.0375699, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.034955006, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034258213, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03347068, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03283687, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033605065, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.033105023, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.08949145, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.031291734, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.030764876, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.032809533, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.030160753, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.02969323, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.029258166, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.02893355, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.028515017, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.047166735, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 3600, training loss= 0.02816607, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.027634704, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.027261315, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.026928147, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.026643008, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.026316023, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.02597158, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.02568078, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.02541864, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.025160039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.024961967, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.024695322, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.024472555, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.024244623, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.02403071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.024021236, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.024003858, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.0239838, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.023962341, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.023941185, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.023919944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.02389924, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.023878578, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.023858588, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.023838926, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.023818886, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.023799207, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.023779368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.023760086, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02374044, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.023720881, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.023701569, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.023681983, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.023662472, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.023642696, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.023623198, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.023603441, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.02358373, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.023564214, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.023544425, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.023524987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.023505606, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.023486245, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.023467224, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02344769, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.023447538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.023445824, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.02344401, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.023442153, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02344027, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.023438344, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.023436459, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.023434542, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.023432646, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.023430772, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.02342887, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.023426931, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.023425007, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.0234231, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.023421204, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.023419267, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.02341727, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02341532, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.023413353, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.26754165, training acc= 95.5152690410614%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.0688425, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.06483412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.06786318, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.06043476, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.058521487, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.057204388, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.057015147, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.0553054, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.053814583, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05613976, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05241769, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.051915318, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.052389875, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04988851, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.049161244, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04884292, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.048998035, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.048436757, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04754819, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.046582047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04583321, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.045108184, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04462805, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.044156566, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04367803, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.043214973, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.0427576, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.042347707, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04190937, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04150413, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.041114412, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04072448, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.040335678, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03997088, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.039604474, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03919198, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.038814947, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.038459077, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.0381051, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.037759166, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.037420873, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03708938, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.036773615, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.036451116, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03613857, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03582745, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.035528928, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.035237744, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.034945864, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.034664307, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.0346747, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.034653645, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03462939, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03460396, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03457837, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.034551732, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.034524653, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.034497444, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03446982, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03444283, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.034415215, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.034388114, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03436055, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.034332976, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.034305673, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.034278065, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.0342503, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03422323, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03419586, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.034169298, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.034141913, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.034114487, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.034087174, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.034060203, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03403251, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.034005392, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.033977546, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03395046, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033923145, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.033895835, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033895157, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03389282, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033890307, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.033887826, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033885237, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033882592, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.033879973, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.033877406, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.033874746, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.03387208, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033869512, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.033866808, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03386415, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.0338615, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03385887, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03385618, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.033853482, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.033850826, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03384821, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.6618447, training acc= 89.88549709320068%\n",
            "Validation Accuracy valid 85.69999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.0850149, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.07473651, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.07122831, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.070761144, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.059308797, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.057689577, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.063333616, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.054949965, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.053195924, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07433883, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05424906, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.050529804, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.050091334, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04905699, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04754388, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.057895053, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.047798656, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.047778677, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04526503, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.046215337, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04423384, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.049179267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.042319212, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04181828, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.051134016, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.040637553, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04002019, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.041429877, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038837407, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03822824, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.037685737, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.07532819, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.037108522, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03658899, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.036167696, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03572761, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03530796, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0349211, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.034559097, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03421806, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03388652, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.0335405, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.033210203, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.0328879, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.032575246, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03227287, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.031984743, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.031709187, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03144488, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.031178419, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.031189824, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.031170726, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.031150222, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.031127214, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.031103343, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.031077996, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.031052684, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.031027311, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.031001357, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.030975541, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03095002, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.030924475, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.030898673, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.030873183, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.030847428, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.03082246, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.030796612, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.030771365, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.030746369, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.030721972, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03069729, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03067253, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.030647738, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.030622927, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.030597731, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.030572817, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.030547867, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.030522345, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.030497113, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03047209, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.030473283, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.030471718, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.030469878, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.030467654, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.030465418, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.030463088, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.030460728, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.030458344, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.030455945, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.030453527, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.030451078, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.030448645, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.030446202, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.030443773, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.030441318, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.030438894, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.030436477, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03043407, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.030431658, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.62539244, training acc= 93.51145029067993%\n",
            "Validation Accuracy valid 87.19999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.069033206, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.059124757, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.06003625, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.05457008, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.05303353, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.051217135, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.050144315, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.051439594, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.047793787, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.047146518, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.0471359, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04653128, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04425692, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043554153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04324923, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.042385917, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042129483, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04130441, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04064224, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.040392976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.039639182, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.039208144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.038768418, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.038784616, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.037875876, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03735457, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037035383, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.036562797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03617772, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.035813365, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03544261, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03506857, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.034759488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.034417972, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.034061562, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.033726294, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.033395287, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03308074, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.032802988, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03248556, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03222118, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.031936582, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03166562, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.0313999, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.031157916, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.030886462, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.030623237, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.030363876, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.030126, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.029879628, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.029891623, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.029874045, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.02985454, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.029832939, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.029809697, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.029786518, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.029763544, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.029739967, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.029716237, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02969235, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.029670179, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.02964721, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.029623264, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.029600749, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02957714, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.029554287, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.02953133, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.029508293, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.029485077, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.029460752, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.029438674, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.029415188, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.029391492, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.029368538, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.029346375, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.029323552, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.029300509, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.029277919, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.029254913, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.029232098, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02923252, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.029230852, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.029229006, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.029227117, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.029225105, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.029222984, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.02922088, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.029218692, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.029216474, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.029214239, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.029211996, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.029209737, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.029207453, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.029205242, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.029202988, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.029200753, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.029198414, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.029196102, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.029193936, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 3.1349902, training acc= 89.59923386573792%\n",
            "Validation Accuracy valid 85.5999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.085178, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.069275245, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.06665885, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.06017051, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.061893024, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.06267627, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.056990378, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.054673355, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.051881906, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.04797296, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.053633958, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.0487193, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.046019435, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.044573173, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.043040212, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06869373, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042731315, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.039918236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.039593857, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.03818295, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.037488155, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03691689, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03655782, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.047390923, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.035683837, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03512358, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03459893, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.034155063, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.033705443, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03337729, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.032954946, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.032604333, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.032202944, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.0318964, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.031632088, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.031214591, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03094428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03059706, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.030331846, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.029997543, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.029733066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.029472891, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.02921708, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.028930645, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.028665878, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.028414024, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.028170338, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.02791749, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.027674105, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.027436657, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.027448863, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.027445182, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.027431361, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.02740792, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.027382802, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.027359784, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.027333144, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.027303591, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.027275186, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02724783, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02722132, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.027195483, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.027169902, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.027144885, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02712108, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.027096702, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.027072255, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.027047385, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.027021807, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026994769, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026969094, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026943682, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.02691758, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.02689236, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.02686704, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026841855, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026816238, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.026791345, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026766075, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026741363, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026740706, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.02673874, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026736518, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026734216, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026731892, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026729584, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026727198, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026724856, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026722398, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026719972, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026717551, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026715137, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026712706, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026710212, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.02670775, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026705323, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026702855, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026700405, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026697997, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 3.4873948, training acc= 89.59923386573792%\n",
            "Validation Accuracy valid 85.5999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.10612183, training acc= 96.56488299369812%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.07801973, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.06330273, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.05567707, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.055399917, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.05826817, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.050383724, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.068654925, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.056680076, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.080906115, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.050127793, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.042329833, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04142075, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.042294435, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.055228133, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.040129263, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.0668901, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.040303156, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.037221212, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.03642355, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.036642518, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.043066803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03425917, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.044852115, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.032845132, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.037985038, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032018688, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031453416, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.054449804, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.030918378, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03044958, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030124847, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.029794488, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.029474849, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029189344, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03247489, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.030570425, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029825043, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.029133018, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03935768, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028574334, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028010447, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.027585613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027192818, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.026805148, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02651343, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02625308, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.025998132, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.025752386, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.025513591, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.025516871, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.025494883, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.02546933, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.025443448, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.02541886, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.025395114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.025372617, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.025350194, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.02532742, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.025303895, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02528096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.025257869, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.025235144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.025212744, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02519051, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.025168711, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.025146607, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.025124814, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.025103217, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.025081573, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.02505959, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.025038429, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.025016569, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.024994938, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.024973357, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.024951613, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.02493045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02490913, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.024888055, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.024867104, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.024867365, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.02486607, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.02486429, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.024862437, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02486052, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.02485859, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.024856608, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.024854545, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.02485246, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.02485043, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.024848383, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.024846392, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.024844335, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.024842314, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.024840262, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.024838218, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.024836158, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.024834089, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.024832023, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.22231992, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.06981021, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.06613749, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.0640125, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.062204935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.060847767, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.059871662, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.06017823, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.05755284, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.056816567, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.055665057, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.056258578, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.054801524, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05366955, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.052601077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05199008, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05134794, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05060451, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05007842, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.049630612, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04891398, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.048412044, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.047775682, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04737523, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04678909, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.046288993, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04583789, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04530345, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.044829186, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04437429, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.043921467, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.043485317, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04306263, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.042651784, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04224324, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04184442, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.041420136, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04102647, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.040648803, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040251598, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.039871156, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03950057, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03914383, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.038781602, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03843164, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038092032, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.037750382, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.03742428, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037090324, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.036768995, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.036458608, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03646899, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03644495, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036417197, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036387905, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03635722, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.036324907, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036293563, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03626144, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036229305, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036197837, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03616628, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036135014, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036103494, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.036072675, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03604191, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036010634, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.035978984, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03594825, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.035917357, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03588576, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.035854083, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.035823982, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.035792746, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03576181, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.035731558, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.035700843, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03567012, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.0356402, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03561026, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035579246, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.035579544, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035576966, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03557421, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03557143, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.0355686, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035565685, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03556276, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03555982, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03555695, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035554014, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03555103, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035548095, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035545144, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.035542157, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03553916, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03553624, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035533305, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.035530355, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03552746, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.7159097, training acc= 90.17175436019897%\n",
            "Validation Accuracy valid 86.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.08881189, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.08142664, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.063420616, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.06126083, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.05951733, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.057853427, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 700, training loss= 0.09584935, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.055321746, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.054611456, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.08574398, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.060417295, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.051429, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05107168, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04953688, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05171322, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04903814, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.04816401, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04719267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.046417937, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.045758985, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04521805, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04457601, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.044086292, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.043502532, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04303056, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04253936, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.042102203, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04161279, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.041856907, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.040700838, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.040276468, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.039814554, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.039837155, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.039080188, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.0387655, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.038157396, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03779336, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.037394356, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.036996823, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.036607336, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.036244363, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.035889134, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.035554104, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03516077, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.034830183, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03450946, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.034189027, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03386675, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.033555754, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.033262163, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.033272233, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03324977, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.033224497, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.033197172, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.033168733, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.033139393, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03310969, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.033079132, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03304897, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.033018485, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.032987982, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.032957353, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03292665, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.032896623, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.032866597, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.03283624, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.032806326, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03277621, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.032746606, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03271722, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.032687493, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.032658163, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.032628886, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03260003, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.032571558, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.032542538, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.032513283, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.032484498, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.032455344, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.032426566, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03242845, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03242705, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.032424856, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.032422166, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03241926, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.032416377, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.032413453, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03241051, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03240762, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.032404725, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.032401823, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03239892, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03239598, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03239309, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.032390203, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.032387305, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.032384444, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03238158, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.032378715, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.41337138, training acc= 93.98854970932007%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.07085124, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.062371984, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.059018042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 400, training loss= 0.056937005, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.057519283, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.05458059, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.054769978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.055807676, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.052687164, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05054483, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04950989, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.048938304, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.063689865, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.047108777, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04665398, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.045790233, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.045450114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.044580616, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04407546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04396823, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.042953815, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04238154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.042043313, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04138066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.041467726, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.040798705, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.039858364, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.039400786, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038973108, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.038610645, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.038200658, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03783091, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.037445106, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.037105214, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03674163, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.036399577, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03612063, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0358011, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03546503, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.035138294, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.034829948, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03451915, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.034202736, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03390496, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.033603936, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.033321764, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.033038005, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03277554, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03250795, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03222756, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03223049, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03220845, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03218641, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03216189, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03213826, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03211428, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.032089747, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.032065146, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.032038547, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.032013044, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.031987347, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.031961046, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.031935576, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03191004, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.031883672, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.031856872, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03183157, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.031805817, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.031779654, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03175257, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03172661, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.031699616, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.031673353, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03164721, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.031621613, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.031595133, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03156959, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.031543083, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.031517185, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.031491525, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.031491626, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.031489514, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03148728, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.031484924, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.031482525, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03148003, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03147753, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.031475086, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.031472478, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.031469993, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.031467453, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.031465016, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.031462498, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.031459995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.031457514, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.031454995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03145246, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.031449992, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.0314475, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.2172606, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.5999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.08070616, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.068368636, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.064501636, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.059992347, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.056018673, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 600, training loss= 0.092315204, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.056090534, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.051924106, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.05067625, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05039332, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.049865946, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05420108, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.050249036, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04756769, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.052147135, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.047968674, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.044110928, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04268137, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.0418546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.041151702, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04654837, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.040711608, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.039699513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03907945, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03855508, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.038109623, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037629973, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.037207868, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03675195, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.036323633, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03592654, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03553603, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.03513817, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.034802504, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.0344551, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.034129556, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03381093, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.033511333, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.033221748, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.032937314, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.032661133, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.0323741, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03209375, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.031818286, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03155737, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03130322, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.031054832, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03081078, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03055761, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03032304, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.030339515, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.030322198, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.030299664, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.030276548, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.030253492, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.030229796, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.030206949, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03018343, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.030159408, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.030136071, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03011211, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.030088069, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.030064376, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.030040344, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03001669, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.029992945, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.029969698, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.029945727, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.029922018, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.029898122, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.029874781, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.029851204, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.029827334, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.029804463, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.029781148, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.02975816, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.02973475, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.029711658, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.029688913, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02966578, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.029666357, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.029664647, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.02966254, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.029660411, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.029658215, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.029656013, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.029653782, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.029651528, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.029649293, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.029647022, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.029644713, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.029642435, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.029640134, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.02963781, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.02963555, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.029633258, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.029630966, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.029628726, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.029626437, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.8022562, training acc= 92.65267252922058%\n",
            "Validation Accuracy valid 86.69999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.07090478, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.05870407, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05708225, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.054486528, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.05563921, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.05080058, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.049502388, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.048605587, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.047924887, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.046274975, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.045548275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04439456, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.043787416, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043481078, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.042403955, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04224699, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042388536, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.050593432, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.040047653, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.040131792, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03906546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03877222, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03799957, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.038681258, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03701593, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.037093002, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03676771, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.035780378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03538753, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.034972467, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.034928344, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.052136447, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 3300, training loss= 0.03400263, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.033771005, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03328058, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.032992497, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03263386, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03223036, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.031904727, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.031682514, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.031282622, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.031048307, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03074356, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.030461343, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.030247096, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.029976802, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02971705, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.02948921, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.029253101, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.02902839, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.029036168, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.029016363, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.028994704, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.02897351, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.028951393, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.02892854, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.028905895, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.02888394, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.028862003, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.028839543, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.028817492, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.028795205, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.028772794, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.028750826, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.028728954, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.028706405, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.028684206, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.028661976, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.028639834, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.028617503, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.028594801, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.02857264, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.02855036, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.02852803, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.028506028, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.028483784, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.028461939, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.028439827, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.028417762, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.028395992, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.028396131, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.028394792, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.028392702, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.028390557, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.028388329, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.028386163, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.028383974, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.028381784, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.028379582, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.028377334, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.028375175, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.028373025, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.028370805, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.028368661, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.028366482, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.028364273, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.028362054, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02835988, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.028357662, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.6039605, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.39999389648438 ...\n",
            "\n",
            "epoch 100, training loss= 0.077925906, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.0665683, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.061213814, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.05885455, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.053882644, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.07773538, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.06415388, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05078979, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.048457652, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.04770564, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05026203, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04687717, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.048444692, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.052586854, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.046008855, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.041605957, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.04827528, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.03992481, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.040815484, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04571712, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03934485, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.036935873, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.037288945, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.036507376, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.035891097, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03547146, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.034838837, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.034331024, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03385153, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.033377673, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03292761, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.032502502, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.032106765, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.031719387, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03137666, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.031054689, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03070522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.030363498, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.030021898, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4000, training loss= 0.0296882, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.02939121, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.029069068, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028771814, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03301182, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.029320953, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.028519848, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.028084297, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027763491, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.027490417, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.027237238, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.027251178, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.027231583, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.027208496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.02718424, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.027159695, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.027135361, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.027111124, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.027086701, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.027062515, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.027038498, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.027014542, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026990775, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02696775, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026944416, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02692118, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02689782, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026874406, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026850972, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026827632, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026804347, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026781008, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026758034, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026734777, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026711933, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026689278, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026666816, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.02664483, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.026624205, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026605457, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026586583, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02658806, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026586851, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026585056, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.02658308, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026580999, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026578845, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026576618, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.02657441, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026572146, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026569914, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026567604, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026565317, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026562994, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026560687, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026558353, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026556004, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026553672, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026551362, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.02654902, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.9818926, training acc= 89.69465494155884%\n",
            "Validation Accuracy valid 85.5 ...\n",
            "\n",
            "epoch 100, training loss= 0.07975187, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.066019826, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05970667, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.06975089, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.054610696, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.06051408, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.053905845, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.048637457, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.055662613, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.045576755, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05645903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04901095, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.042853724, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.047377646, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.044202644, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.039368663, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052211236, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.046024907, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.059634585, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2000, training loss= 0.03708313, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03802259, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.042165328, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03545346, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03438063, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.033767764, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2600, training loss= 0.034626156, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03274439, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2800, training loss= 0.033507112, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03173992, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.031702697, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03129561, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030550454, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030456746, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03066612, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029432101, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029274736, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.028890083, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.028709257, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028239913, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028682083, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028195376, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.027829276, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.027009837, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027781678, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027179824, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.026829245, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.026188208, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.025794597, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.025538072, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.025298387, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.025294572, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.025277942, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.025258968, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.025239749, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.02521953, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.025199125, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.025178373, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.02515778, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.025136448, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.025115244, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.025094146, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.025072435, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02505037, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.025028558, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.025006494, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.024984593, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.024962628, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.02494103, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.024918951, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.024897281, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.024876, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.024854342, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.024833186, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.024812365, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.024790999, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.024770139, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.024749586, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02472815, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.024707772, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02468643, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02468648, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.024684852, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.024683122, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.024681399, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.024679504, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.024677638, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.024675783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.02467388, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.024671974, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.02467002, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.024668073, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.02466617, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.024664214, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.024662282, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.024660325, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.024658386, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.024656452, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02465453, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.024652552, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.0 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.19696403, training acc= 95.80152630805969%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.07078262, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.06711443, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.06511581, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.06345296, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.06204311, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.060940098, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.059934, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05901002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.058103755, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.057430916, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.056566946, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.055764165, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05503009, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.05427374, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05378975, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.052959275, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052367583, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.051771592, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.051131085, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.050516915, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.049951255, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.049416177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.048869573, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.048340634, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04783933, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.047302313, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04679337, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046319213, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04584392, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.045379654, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044920616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044462837, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04400201, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04355269, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.043117777, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.042649664, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.042208433, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04176037, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.041343383, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04093157, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04052535, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.040126175, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03974385, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.039367512, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03900053, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.038636893, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.038283683, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03793059, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037596636, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03725998, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03727712, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.037250314, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.0372224, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.037192643, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03716156, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.037129544, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.037097525, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.037064996, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.037032574, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03700099, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.036968186, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036935642, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036903277, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.036871333, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.036838178, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036806535, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03677448, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036741477, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03670974, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.036677603, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03664527, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036612988, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.036581006, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.036549024, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036517024, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036484655, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.036452692, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036420852, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.036389165, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.036357455, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03635684, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.0363543, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.036351472, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.036348574, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03634569, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.036342725, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.036339846, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.036336843, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.036333874, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.0363309, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.036327943, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03632493, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.036321923, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03631895, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.036315873, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.036312837, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.036309894, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03630682, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03630385, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.1227465, training acc= 91.60305261611938%\n",
            "Validation Accuracy valid 86.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08655701, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.06803437, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.069471285, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.06390588, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.0642184, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.062438566, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.061026786, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.05762093, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.05754745, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.054503478, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05407214, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.052318547, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.051524483, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.050835475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.051183335, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04925974, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.048703842, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.048044067, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.048333865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04743653, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.046869215, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04670637, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.045465585, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04504987, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.044419244, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.043884978, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.043411005, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04293688, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04241056, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.041922618, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.041482646, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04095745, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.040976673, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.040262174, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.039818894, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.039400946, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.038952153, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.038524892, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.038125858, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.037732147, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.037361115, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.036992796, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.036638036, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.036264725, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.035907246, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.035580352, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.035257474, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03493557, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03463424, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03431922, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.034332074, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.034308527, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.034281787, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03425415, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03422604, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.034198526, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.034170173, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03414077, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03411109, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03408189, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03405183, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.034022693, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.033992767, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.033962928, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.033931345, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.033899155, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03386609, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.033832844, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.0338, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.033767488, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03373506, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033702902, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.033670887, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033639103, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03360693, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.033575557, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03354382, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.033512488, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033481583, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.033450764, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033451565, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.033449158, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033446454, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.033443607, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033440717, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033437785, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03343486, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03343192, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03342896, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.033426005, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033422973, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.033419967, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03341695, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03341398, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03341099, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03340796, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.033404958, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03340194, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03339895, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.31493577, training acc= 94.65649127960205%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.06873354, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.06460365, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.063341804, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.060011838, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.05784519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.057270546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.058621217, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.054490153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.05476842, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05313535, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.054123856, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05040468, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.051902864, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.0512751, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04939679, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.047811672, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.047156878, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.046240892, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.046333358, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04519033, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04467704, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.044190083, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.043720473, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.043325875, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.042832814, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.042387083, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.041945234, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04151804, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.041104056, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.040695883, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.04029276, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.039910253, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.039530512, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03913779, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03874316, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.038372632, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.038003787, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.037649233, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03729858, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03695231, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.036605738, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.036268808, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03594654, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03562581, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.035307787, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0349946, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.03469127, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.034392375, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03409787, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.033812482, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.033822387, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03380066, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.033775784, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.033748385, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03372074, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.033692747, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.033665124, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.033636265, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.033608086, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.033579733, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.033551868, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03352394, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.033495784, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03346781, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03343998, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.033411436, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.033382095, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.033353046, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.033324447, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.0332956, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.033267148, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033238716, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.033210006, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033181913, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03315405, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.033125892, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.033098303, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.033070646, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033042558, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03301496, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033014257, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.033012066, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03300973, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03300729, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033004757, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033002175, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.032999624, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.032996982, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.032994296, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.032991596, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.032988925, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.032986227, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.032983545, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.032980878, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.032978155, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.032975484, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03297274, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03297006, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03296737, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.596056, training acc= 90.36259651184082%\n",
            "Validation Accuracy valid 86.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.0767528, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.06827313, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.062593415, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.061691966, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.058756493, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.057015505, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.0694579, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.05336292, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.0535194, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.052226853, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.052862268, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.050594237, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.0500422, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04868998, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.048759017, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.064215906, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.04642956, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.045441646, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04593693, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.044745054, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.043763973, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05286961, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04264329, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.042737063, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.041614413, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.041714355, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04102154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.0683119, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.040497843, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.039900616, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.039368358, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.038768563, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.03828101, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03792873, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03736721, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03693776, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.036643613, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.036118835, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.047793552, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.036078308, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03534461, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.034773234, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.034351263, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.033921234, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03352754, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03315669, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.032823037, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.032485344, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.032165278, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03187813, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.031877827, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.031856414, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03183218, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.031805918, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.031779256, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03175243, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.031725187, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03169811, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.031670686, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.031643003, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.031614546, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.031586397, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03155804, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03152954, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.031501327, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.031472344, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.031442795, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.031413082, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03138318, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03135314, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.031323534, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.031295255, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03126611, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.031237112, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.031207869, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.031177564, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.031146383, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.031114886, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.031081846, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.031048683, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.031048927, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03104628, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.031043282, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.031040333, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.031037401, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.031034399, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03103136, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.031028356, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03102531, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.031022344, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.031019313, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03101629, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.031013297, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.031010289, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.031007277, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.031004291, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.031001301, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.030998271, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.0309953, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.52340895, training acc= 93.89312863349915%\n",
            "Validation Accuracy valid 87.69999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.06717243, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.06071926, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.05722802, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.055782072, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.054644585, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.052764405, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.0519173, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.050339945, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.04948339, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.04900692, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.048020016, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.047658965, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04623068, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.045645308, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.045081034, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.044655338, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.043817323, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.0433774, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04289645, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.042418513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.042280555, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04102098, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04074397, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.039925173, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.039719682, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.039010208, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.038590845, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.03817192, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038014907, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.037567638, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.037169203, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03660205, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.036406502, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.035964753, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03547232, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03522224, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03479151, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.034390826, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.034165666, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.033819433, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.033470437, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03314769, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03294221, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.032573648, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03235165, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.032048654, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.031769972, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.031520255, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.031260483, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.031019744, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.031015951, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.030996693, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.030975886, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.030953217, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.030931128, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.030908145, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03088546, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.030861633, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.0308384, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.030815288, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.030791435, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03076824, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.030742297, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.030718, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03069434, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.030670749, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.030646339, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03062285, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.030599067, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.030575229, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.0305522, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.030527666, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.030504223, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03048096, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.030457614, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.030434323, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.030410537, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.030387446, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.030364385, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03034071, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03034127, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.030339729, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.030337589, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.030335363, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03033319, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.030331092, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03032894, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.030326765, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.030324569, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.030322423, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.030320236, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.030318042, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.030315889, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.030313706, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.030311512, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03030936, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.030307151, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.030304933, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.030302718, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.9884135, training acc= 90.07633328437805%\n",
            "Validation Accuracy valid 85.79999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.081482135, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.06606463, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.06749831, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.065037236, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.056128986, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.05770092, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.056364674, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.08216743, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.051691562, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.08138401, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06734297, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.047418624, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.061157364, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.059304874, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.050660484, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.046665885, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.0469123, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04292794, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04567301, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.0410267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.0429321, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04019863, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.040085673, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03947824, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.047684763, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.037919953, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037275113, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.03732564, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.036741786, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03598038, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.035557766, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.035847843, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050246228, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.034523007, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.033770014, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.033335347, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.032897882, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.032551464, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.032143, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03181278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.031465333, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.031135414, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.030813158, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.030498186, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.030223109, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.029945489, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.029690227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.02942669, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.02918562, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.028938718, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.028947622, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.028929505, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.028907554, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.02888447, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.028861219, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.028837016, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.028812753, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.028787931, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.028762834, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.028737469, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.028712114, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.02868643, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02866037, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.028634774, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.028607959, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02858211, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.028556807, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.028531773, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.028506795, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.028481776, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.028457174, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.028433038, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.028408574, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.028383378, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.028357957, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.028333127, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.028308282, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.028283289, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.028258473, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.028233025, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.028234025, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.028232098, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.028229866, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.028227396, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.028225025, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.02822256, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.028220147, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.028217737, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.028215285, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.028212853, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.028210396, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.028208012, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.028205557, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.028203087, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.02820065, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.028198186, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.028195709, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02819324, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.028190782, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.90713227, training acc= 92.36640930175781%\n",
            "Validation Accuracy valid 86.69999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.0640304, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.05905726, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05579553, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.054926913, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.05182961, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.05079264, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.053865395, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.047792494, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.047680933, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.045810096, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1100, training loss= 0.050667126, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04503496, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04384273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043384742, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04223445, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1600, training loss= 0.041754663, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.041153733, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04057319, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1900, training loss= 0.03988412, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.039267924, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.038891427, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03915452, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.037836105, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.037267826, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.036788173, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.036373805, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.13140339, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.035423208, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05729384, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.0346534, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.034149416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03370581, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.03350551, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03294833, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.032582536, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.032354683, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.032019738, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03167517, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.031386156, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.031118045, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.030897286, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.030591376, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.030324765, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.030095706, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.029813094, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.029569026, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02933028, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.029093163, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.028866453, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.02863481, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.02864773, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.02862889, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.02860771, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.028585458, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.028562801, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.028540112, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.028517134, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.02849461, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.028471986, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02844944, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.028427191, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.028404662, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.028382221, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.028359877, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.028337058, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.028314913, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.028292282, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.028269717, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.028247664, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.028225051, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.028203035, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.028181126, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.028159168, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.028137708, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.028115515, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.028094226, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.028071996, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.028050128, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.028027946, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.028006392, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.028007217, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.028005607, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.028003676, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.028001709, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02799967, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.02799756, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.027995395, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.027993275, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.0279912, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.027989047, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.02798691, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.027984777, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.02798264, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.027980575, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.027978424, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.027976291, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.027974153, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.027972056, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.02796995, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.3216412, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.39999389648438 ...\n",
            "\n",
            "epoch 100, training loss= 0.07263463, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.07191459, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.062422026, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.05840334, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.054499444, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.052578297, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.056358814, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.05179298, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.050195344, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05562498, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06938881, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1200, training loss= 0.045948762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04658067, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.044072174, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04531121, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04222182, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.045706667, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061096758, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.040560707, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.039519425, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.044476938, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.039403405, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.038772848, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04214405, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.036277246, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.10495496, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037730023, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.03893322, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.034372047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.033669394, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.033025794, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03777098, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.032385528, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.031792007, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03137441, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.030969312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.030636897, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.030297829, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.029978499, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.029662138, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.029362226, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.029024158, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028738251, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.028425857, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.028156219, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.027897162, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.027660891, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027420266, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.027189974, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.02697419, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.0269741, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026955945, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026935307, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026914408, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026892472, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026870346, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.02684854, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026826832, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026804984, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.026783383, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.026762009, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.02674078, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.026719142, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026697977, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026677435, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.026655901, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.02663453, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.02661303, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026591752, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026570309, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.02654912, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026527582, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026506264, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026484916, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.02646382, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026442805, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026421657, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.0264004, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026379654, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02635848, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02635776, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.02635594, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026354035, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026352122, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026350176, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026348198, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026346222, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026344195, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026342181, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026340157, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.02633811, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026336078, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026334021, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026332, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.02632992, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026327888, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026325826, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02632378, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.02632171, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.5681078, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.39999389648438 ...\n",
            "\n",
            "epoch 100, training loss= 0.098355144, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.06461848, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.0654221, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.05785243, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.074893415, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 600, training loss= 0.05134308, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05211904, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.049198557, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.060269378, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07634616, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04436178, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04281628, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.042391967, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04170135, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04118171, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03891327, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052713618, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.037020978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.036266547, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.14315954, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03523231, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03442907, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.033937186, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033582427, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03297642, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.033218786, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.031914327, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.033854157, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031959888, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.030947618, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030497948, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03230357, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.02960216, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.029169623, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.028784929, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.028396826, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029006515, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.02802531, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.027647862, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.027333077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.027033484, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.02675693, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.02647689, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.026217207, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.025979575, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02572768, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.025494782, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.025267353, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.025071422, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.024868874, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.024866376, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.02484906, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.024831733, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.024814457, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.02479618, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.024778305, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.024760013, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.024740849, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.02472053, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.024699429, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.024677942, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.024656504, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.024635112, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.024614, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02459281, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.024571722, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.024550745, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.024530087, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.024509901, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.024489695, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.024469474, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.02444925, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.024429219, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.024409292, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.024389355, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.024369327, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.024349641, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.024329465, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.024309719, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.024290048, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.024289688, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.024288148, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.024286436, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.02428464, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.024282834, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.024281029, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.0242792, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.024277383, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.02427555, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.024273703, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.024271887, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.024270058, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.024268204, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.024266372, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.024264531, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.024262697, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.024260854, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.024259048, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.024257218, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.17923857, training acc= 95.99236845970154%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.070538715, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.067426994, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.06549388, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.06399084, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.062693514, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.061624274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.060667403, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.059750743, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.058871698, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.058046203, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05726931, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05649682, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055788428, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.0550949, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05444232, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05380586, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05316414, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05255361, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.05195303, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.0513687, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.050816633, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.050266393, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04972191, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.049193505, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04869966, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04818686, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.047672648, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.047175344, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04667749, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04620172, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.045740757, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.045297254, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04485469, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.044412512, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.043927956, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.043474846, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043033484, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.042599026, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.042180054, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.041784003, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.041391965, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.040996417, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04060916, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04023584, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03986271, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.039495587, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.039133646, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03877964, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.038428362, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.038076993, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03809671, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.038069982, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03803959, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.038009074, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03797711, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03794452, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.037911642, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.037878882, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.037845846, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.037813306, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.037779696, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.037746973, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03771458, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.037681267, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03764807, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.037616145, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03758347, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.037550494, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.037517678, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.037484854, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.037452813, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.037420355, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.037387516, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.037355173, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03732267, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.037289545, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.037256937, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.0372252, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.037192143, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.037159372, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.037159182, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.037156608, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03715384, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03715106, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03714814, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03714521, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.037142273, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.037139133, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03713595, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.037132822, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03712957, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.037126362, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.037123166, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.037119944, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.037116725, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03711347, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.037110295, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.037107013, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03710383, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.8333926, training acc= 93.41602921485901%\n",
            "Validation Accuracy valid 87.19999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.07870485, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.06878078, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.068930626, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.06409112, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.062367983, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.06131119, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 700, training loss= 0.059617087, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.05835691, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.057623785, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1000, training loss= 0.056367338, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.055451028, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05452355, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05397263, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.054229077, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1500, training loss= 0.052336447, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.051752444, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.051330253, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.050578535, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.049950495, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.049385298, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.048810072, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.048360724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.047700718, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.047146246, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.046628993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.0460893, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04558459, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.045128968, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04466567, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04420059, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.043680865, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.043244954, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.042720675, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04304629, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04277154, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.042937297, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04140885, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.040709525, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040193215, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03971985, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.039307266, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.038904045, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03851143, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03811648, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03771874, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.037317842, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.036927607, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.036564283, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.036199003, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.035859194, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.035872947, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03584534, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03581302, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03577982, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.035747077, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.035713516, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.035680734, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.035647582, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03561501, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.0355828, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03555013, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.0355173, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.035484377, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.035451327, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03541856, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.035386678, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03535332, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.035321094, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03528886, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03525708, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03522461, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03519295, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03516052, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.035128824, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03509665, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.035064273, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.035032243, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03499972, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.034967612, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.034936167, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.034935676, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.034932822, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.034929853, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.034926735, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.034923635, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.034920435, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03491742, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.034914322, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03491117, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.034908045, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.034904875, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.034901712, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.034898523, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.034895334, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.034892123, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03488893, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03488573, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03488255, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03487932, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 89.9 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.26754165, training acc= 95.5152690410614%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.0688425, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.06483412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.06786318, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.06043476, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.058521487, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.057204388, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.057015147, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.0553054, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.053814583, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05613976, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05241769, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.051915318, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.052389875, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04988851, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.049161244, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04884292, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.048998035, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.048436757, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04754819, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.046582047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04583321, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.045108184, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04462805, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.044156566, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04367803, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.043214973, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.0427576, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.042347707, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04190937, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04150413, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.041114412, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04072448, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.040335678, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03997088, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.039604474, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03919198, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.038814947, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.038459077, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.0381051, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.037759166, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.037420873, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03708938, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.036773615, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.036451116, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03613857, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03582745, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.035528928, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.035237744, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.034945864, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.034664307, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.0346747, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.034653645, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03462939, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03460396, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03457837, training acc= 98.85495901107788%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.034551732, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.034524653, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.034497444, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03446982, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03444283, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.034415215, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.034388114, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03436055, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.034332976, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.034305673, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.034278065, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.0342503, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03422323, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03419586, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.034169298, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.034141913, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.034114487, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.034087174, training acc= 98.9503800868988%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.034060203, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03403251, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.034005392, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.033977546, training acc= 99.04580116271973%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03395046, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033923145, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.033895835, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033895157, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03389282, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033890307, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.033887826, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033885237, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033882592, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.033879973, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.033877406, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.033874746, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.03387208, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033869512, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.033866808, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03386415, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.0338615, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03385887, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03385618, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.033853482, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.033850826, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03384821, training acc= 99.14122223854065%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.1553932, training acc= 91.60305261611938%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.07828972, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.067840606, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.0653341, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.06847238, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.059676606, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06266943, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.05582667, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.05583673, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.058247168, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05297217, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.053344578, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1200, training loss= 0.050909214, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05424099, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04938306, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.048457544, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.048373416, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.04706724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04663526, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.046262227, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.045758728, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04508891, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2200, training loss= 0.044436943, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.0439976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.043452162, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.042988494, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.042737003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04223432, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.041783854, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.041385412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04091101, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.040522624, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04001279, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.039614383, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03924444, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.03882199, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.038457762, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.038135953, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.037757814, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03744835, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.037082095, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.036726635, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03638588, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.036047053, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03574554, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.035413742, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.035095137, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.034788024, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.034487516, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.0341961, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03389555, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.033903956, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.033880975, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.033853807, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.033825085, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.0337964, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.033767898, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.033739835, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.033710998, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.033681434, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.033652738, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.033623405, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.033595145, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03356685, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.033538405, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03351124, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.033482626, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.033455003, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03342717, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03339856, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.033370275, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03334209, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033313997, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03328609, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033258345, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03323027, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.03320269, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.033174474, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.033147063, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033119574, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03309186, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033091806, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.033089682, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033087123, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.033084538, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033081878, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033079263, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.0330766, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03307395, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.033071313, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.03306867, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033066068, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.033063345, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03306073, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.033058085, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03305541, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.033052754, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.033050127, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.033047426, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.033044763, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.4133714, training acc= 93.98854970932007%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.070851244, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.062371984, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.059018042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 400, training loss= 0.056937005, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.057519283, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.054580588, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.054769978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.055807676, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.052687168, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05054483, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.049509887, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.048938304, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.063689865, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.047108777, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.046653975, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.04579023, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.04545011, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.044580612, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04407546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.04396823, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04295381, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.042381544, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.042043317, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.041380662, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.041467726, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.040798705, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03985836, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.039400786, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038973108, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.038610645, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.038200658, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.037830908, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.037445106, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.037105214, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.036741633, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.036399577, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.036120635, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0358011, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.035465028, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.035138294, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.034829944, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03451915, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.034202736, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03390496, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.033603933, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.033321764, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.033038005, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03277554, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.032507945, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03222756, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03223049, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03220845, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03218641, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03216189, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03213826, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03211428, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.032089747, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.032065146, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.032038543, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.032013044, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.031987343, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.031961046, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.031935576, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.031910043, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.031883672, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.031856872, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.031831566, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.031805817, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.031779654, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.031752575, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03172661, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.031699616, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.031673353, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03164721, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.031621616, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.03159513, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03156959, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.031543083, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03151718, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03149152, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.031491626, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03148951, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03148728, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03148492, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03148252, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03148003, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03147753, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.031475086, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.031472478, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.031469993, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.031467453, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.031465016, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.031462498, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.031459995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.031457514, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.031455, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03145246, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.031449992, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.031447504, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.5386168, training acc= 90.45801758766174%\n",
            "Validation Accuracy valid 86.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.076447144, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.068696156, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.06187843, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.06208385, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.062446535, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.05674308, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.05491809, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.053832334, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.052327972, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.051052243, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058062833, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.049316015, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.048438527, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.050514277, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.047057785, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.046026096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.047444813, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.044875175, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.044464864, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05515757, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.04632373, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.04218925, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.052699845, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.041197, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04030783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.039679796, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03898069, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.03927081, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.038536686, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.037752483, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.037414193, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.036998123, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.037236568, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.038444094, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.0352761, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.034716096, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03423719, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0338047, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03346899, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.033134624, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.032769863, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03246054, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.032186065, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.031862225, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03157598, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03131036, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.031023944, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.0307576, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.0304974, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.030236006, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03024329, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.030223837, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.030202184, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.030178824, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.030154495, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03012967, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03010464, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.030079389, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.030053986, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.030028766, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.030003905, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.029978884, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02995351, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.029928504, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.029903403, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.029878473, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.029854342, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.029829418, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.029804477, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.02978002, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.029755855, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.029731456, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.029707422, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.029683063, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.029658461, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.029634465, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.029610474, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.029586403, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.029562742, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.029539509, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02954, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.029538492, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.029536579, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.029534612, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02953257, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.0295305, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.029528348, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.029526109, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.029523943, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.029521694, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.029519463, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.029517237, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.029515004, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.029512702, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.029510362, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.029507995, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.029505631, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.029503305, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.029501026, training acc= 98.75954389572144%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.62539244, training acc= 93.51145029067993%\n",
            "Validation Accuracy valid 87.19999694824219 ...\n",
            "\n",
            "epoch 100, training loss= 0.069033206, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.059124757, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.06003625, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.05457008, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.05303353, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.051217135, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.050144315, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.051439594, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.047793787, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.047146518, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.0471359, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04653128, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04425692, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043554153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04324923, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.042385917, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042129483, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04130441, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04064224, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.040392976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.039639182, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.039208144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.038768418, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.038784616, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.037875876, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03735457, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037035383, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.036562797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.03617772, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.035813365, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03544261, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03506857, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.034759488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.034417972, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.034061562, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.033726294, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.033395287, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.03308074, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.032802988, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.03248556, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03222118, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.031936582, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.03166562, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.0313999, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.031157916, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.030886462, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.030623237, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.030363876, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.030126, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.029879628, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.029891623, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.029874045, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.02985454, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.029832939, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.029809697, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.029786518, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.029763544, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.029739967, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.029716237, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02969235, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.029670179, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.02964721, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.029623264, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.029600749, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.02957714, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.029554287, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.02953133, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.029508293, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.029485077, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.029460752, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.029438674, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.029415188, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.029391492, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.029368538, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.029346375, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.029323552, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.029300509, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.029277919, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.029254913, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.029232098, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02923252, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.029230852, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.029229006, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.029227117, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.029225105, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.029222984, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.02922088, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.029218692, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.029216474, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.029214239, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.029211996, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.029209737, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.029207453, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.029205242, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.029202988, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.029200753, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.029198414, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.029196102, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.029193936, training acc= 98.66412281990051%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.8646029, training acc= 90.17175436019897%\n",
            "Validation Accuracy valid 85.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08948503, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.06870082, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.0659612, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.060281727, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.05971821, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07693195, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.05494748, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.050055873, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.05453968, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05370426, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.047805555, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05036409, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04548977, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04579956, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.043820724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.042824883, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042091824, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.044529706, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.04090367, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.040448762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.039727774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03974825, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.03886226, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03831906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.037862074, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03726048, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.037113406, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.036301773, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.04419789, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.036181893, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.035472386, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03491022, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.034381516, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.036374908, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.0343411, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.03371513, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03318668, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.032768067, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03226136, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.031921297, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.031507436, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.031206286, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.030825756, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.030508595, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03018495, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.029885253, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.029604087, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.02935977, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.029082064, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.028811106, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.028813038, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.028795557, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.028775493, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.028754763, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.028733304, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.028709004, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.028684482, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.02865995, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.028635804, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.028612051, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.028588122, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.028562244, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.028536892, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.02851241, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.028487628, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.028462784, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.028437793, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.028413039, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.028387442, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.028362444, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.028337216, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.028311817, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.028286777, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.02826192, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.028237525, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.028213214, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.028189246, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.028165182, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.028141191, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02811741, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.02811787, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.028116163, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.02811413, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.028112052, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.028109848, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.028107598, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.028105317, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.028103104, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.02810086, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.02809861, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.028096335, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.028094051, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.028091798, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.028089505, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.028087258, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.028084937, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.028082645, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.028080385, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.02807808, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 89.9 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.97226703, training acc= 92.17557311058044%\n",
            "Validation Accuracy valid 86.5999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.06785266, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.06116795, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.057441097, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 400, training loss= 0.054654036, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.053765126, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.05006077, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.050565325, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.054859336, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.048297893, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.048002467, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04565874, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.0461889, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.04303125, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.04406186, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.041837063, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.043129034, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03976623, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.0388539, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.038295016, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.043761455, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.03735999, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.039954387, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.037515115, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.035934657, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.035563264, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2600, training loss= 0.035331972, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.03489505, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.034457676, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.034136273, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.033796087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.03345841, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03312197, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.032791164, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03245451, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.032114945, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.031784285, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03149099, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.031227967, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03095597, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.030686019, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.03043299, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.030195324, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.029947463, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.029693063, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.029472485, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.029224264, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.029013466, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.028781518, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.028559618, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.02834616, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.028353194, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.028338175, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.02832061, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.028301552, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.028282039, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.028260922, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.028241495, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.028220449, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.02820103, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.028179264, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.028158573, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.028137045, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.028117375, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.028095182, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.028074358, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.028053582, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.028031098, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.028011033, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.027989179, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.027967509, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.02794629, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.027926113, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.027904306, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.027883165, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.027862648, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.027840909, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.027820138, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.027800044, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.027779192, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.027756866, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.027757412, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.027755618, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.027753733, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.027751869, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02774997, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.027748212, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.027746152, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.027744185, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.027742203, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.027740061, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.027738182, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.027736153, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.027734056, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.027731996, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.027730048, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.027728021, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.027726034, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.027723929, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.027721964, training acc= 98.56870174407959%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.1320171, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.79999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.07230412, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.068876415, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.07511383, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.065147206, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.05427865, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.05377598, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.049237933, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 800, training loss= 0.056082856, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.046949327, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.047855638, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.05024171, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.043889374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06265323, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043616615, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.042045064, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.043430444, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.042709604, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.043284737, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.039063886, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.038342714, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.06444571, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.036561087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.038116246, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.035379913, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.038744055, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.034340158, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.033830836, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.033680335, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.032939505, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.032559916, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.033529572, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.031756505, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.03136323, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.030981494, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.030627532, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.030329227, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.030008486, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0297126, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.029436363, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.02915816, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028915202, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028676806, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028421395, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.028183054, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.02794484, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.027719272, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02748595, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.02727443, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.027063567, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026850663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026860772, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026844276, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026826717, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026808351, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.02678994, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026770324, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.026750749, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026731407, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026711836, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.026692433, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02667309, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026653936, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02663489, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.02661515, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026596379, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.026576862, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.02655719, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026537506, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026518269, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026498526, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026479185, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026459407, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026439851, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026420541, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026400624, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026381217, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.02636162, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.026342435, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026323346, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.02630395, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.0263046, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026302949, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026301203, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026299408, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.02629762, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.02629577, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026293937, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026292056, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026290184, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026288338, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026286399, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.02628453, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026282609, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026280716, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.0262788, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.02627685, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026274923, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.02627299, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026271082, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 1.2723517, training acc= 90.74427485466003%\n",
            "Validation Accuracy valid 86.29999542236328 ...\n",
            "\n",
            "epoch 100, training loss= 0.068641186, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.061056677, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.05856128, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.056335583, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.049599793, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.051838905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.05948256, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.05096273, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.043883007, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.05406041, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.041985337, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.04175379, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.053433307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.043139197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.04001762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.03754727, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03732457, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.04014209, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.035483852, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.035755374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.034732793, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.03412, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.035076164, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.033208124, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.03337232, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.03287924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.032166976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.031848498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.031560484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.03124897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.030966228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.030660188, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.030402275, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.03015367, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.029903498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.029636439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.029397361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029159227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.028957153, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028744219, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.028520882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.028311739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.028101085, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027897177, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027684597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02748991, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.02729284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.027093986, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026895985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.026709445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.026719712, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.026706047, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.026690071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.026671963, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.026653655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.026634522, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0266156, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.026596617, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.026577944, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.02655922, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.02654039, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.026521584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.02650262, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.026482685, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.026463663, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.02644455, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.026425987, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.026406674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.026388312, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.026368791, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.026350755, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.026331889, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.026313126, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.026295094, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.026276538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.026258368, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.026240278, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.02622236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.026204493, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.026186133, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.026186898, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.026185496, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.026183888, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.026182236, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.026180616, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.026178734, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.026176933, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.026175065, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.026173227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.026171403, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.026169512, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.026167732, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.026165897, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.026164113, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.026162261, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.026160488, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.026158707, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.026156843, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.026155103, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 6 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 2.3499794, training acc= 89.9809181690216%\n",
            "Validation Accuracy valid 85.5 ...\n",
            "\n",
            "epoch 100, training loss= 0.11782895, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.094855085, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 300, training loss= 0.05683511, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.06812803, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.057404786, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.070452295, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 700, training loss= 0.054755837, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 800, training loss= 0.047893967, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.045524426, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1000, training loss= 0.049996506, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.04899197, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.045226593, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.042046923, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.058042075, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.044700015, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.039601736, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.03970852, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.03792491, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.03699094, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06841968, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.084143475, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05227479, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.1072115, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.03453978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.034095615, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.034008544, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.033208076, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.032947067, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.043856513, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.031955913, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.031567138, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.03131189, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.031196553, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.06671966, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.031872153, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.06732756, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 3700, training loss= 0.03019486, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.029891, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.029194765, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.028858267, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.02846649, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.02811527, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.027770177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.027476346, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.027192699, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.02689107, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.026645763, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.026398038, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.026154045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.025931356, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.025927993, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.02591023, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.025891835, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.02587247, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.02585337, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.025833936, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.025814641, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.02579471, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.025774242, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.025753874, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.025733456, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.025712792, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.025691923, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.025670815, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.025648786, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.025627188, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.025605379, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.025583759, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.025561687, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.025540335, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.025518538, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.025497379, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.025476674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.025456611, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.025436211, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.025415683, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.025395557, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.025374996, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.025354473, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.025333801, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.025333969, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.025332281, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.025330411, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.025328493, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.025326567, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.025324631, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.0253227, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.025320875, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.025318937, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.025316985, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.025315074, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.025313107, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.025311146, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.025309172, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.025307221, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.025305234, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.025303291, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.025301304, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.025299333, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.8 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 6 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_d9m5Qxk3nFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6ef780bf-baad-4b9b-e9ad-1a6545b31cc3"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4DQQKKVUgNNAoJRSAU4DgVJKBbj/BwoQHogoW9VFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "my-rDMMN3nvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fbada21-8889-4267-e98f-5598de83c60c"
      },
      "cell_type": "code",
      "source": [
        "print(np.max(ValidAccuracy_Track))\n",
        "print(np.argmax(ValidAccuracy_Track))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.8\n",
            "41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrkZIJvoUb6Y",
        "colab_type": "code",
        "outputId": "22e1a405-edfb-49cc-85b5-cfbf0b24d751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFXawPHfk4QWQi8BQu8lQJAA\nAUQBGyIKVrBgF9sKsq/uuvvuvq667tpX3dUVFZW1gFJVQBYLEaW3UJPQQgs9lBAg/bx/nBkIYZK5\nKTcJzPP9fPIhuXPLmcPMfU6/YoxBKaVU4Aoq7wQopZQqXxoIlFIqwGkgUEqpAKeBQCmlApwGAqWU\nCnAaCJRSKsBpIFBKqQCngUAppQKcBgKllApwIeWdACfq169vWrZsWaxjT548SfXq1Us3QRchzSfn\nNK+c0Xxyxs18WrVq1WFjTAN/+7kaCERkHPAQIMAHxpg3ReRW4C9AJ6C3MWalv/O0bNmSlSv97uZT\nbGwsAwcOLNaxgUTzyTnNK2c0n5xxM59EZKeT/VxrGhKRSGwQ6A10B4aJSFtgA3ATsNCtayullHLO\nzT6CTsAyY8wpY0w28DNwkzEm3hiT6OJ1lVJKFYGbgWADMEBE6olIKDAUaObi9ZRSShWDuLkMtYg8\nADwGnAQ2AhnGmCc9r8UCTxXURyAiY4AxAOHh4T2nTJlSrDSkpaURFhZWrGMDieaTc5pXzmg+OeNm\nPg0aNGiVMSba336udhYbYyYCEwFE5G/AniIc+z7wPkB0dLQpbmeKdlg5o/nknOaVM5pPzlSEfHJ7\n1FBDY8xBEWmO7SCOcfN6Simlis7teQTTRaQekAU8bow5JiI3Av8EGgBzRCTOGHONy+lQSilVALeb\nhgb42DYTmOnmdZVS6kKXnpXDS98l8JvBbakfVsXVa+kSE0opVQG9PC+BTxbvIH5fquvX0kCglFIV\nzC9bDvHxoh3c268lA9r5XSGixDQQKKVUBXLsVCZPTV1LmwbVeebajmVyzQti0TmllAoUf/56Iylp\nmXx4dy+qVgouk2tqjUAppSqIr+OS+XbtXp68sh1dm9Yqs+tqIFBKqQpg77HT/HnWBnq2qMMjl7cp\n02trIFBKqXKWm2t4aupasnMNb9zWnZDgsr01ayAoQ9k5ufy8+RBfrdiNm2s8BYLFWw+zbs+x8k5G\nQDLGsHrXUT76NYn0rJzyTs5F4ePFO1i8LYX/G9aZFvXK/mE+2lnsMmMMG5JTmbkmmW/W7uVwWoZ9\nQeC2aF2MtTg27U3lno+XU61SMPPHX06jWlXLO0kBIenwSWatSWZWXDI7U04BsGjrYd4b3ZNKZVyC\nvZgkn8jl5WUJXNkpnJG9yueecFEHgtxcQ05u+ZS8dx85xddxycxck8y2QyepHBzE4I4NGdGjCZ8s\n3sFz32ykb+t6NKsbWi7pu1ClZ+Xw26/iqFWtEqcyc3hq6lr+c39vgoKkvJN2UUpJy2D2un3MXJNM\n3O5jiEC/NvX4zaC2pKZn88LsTfxu2jpev7W7/h8UQ2Z2LhPWZVCjSggv3dwVkfLJw4s6EExYuJ3p\ny9NpH3WqTG64R09mMmf9PmatSWblzqMA9G5VlwcHtGZoZGNqhVYCoGvT2gz5x0LGfxnHlw/3Jbgc\nv0DGGKavTmbi8tO0iDxJq/qlVy3dfzydp6et5cpO4dzdt0WpfMhfn59Iwv4TfHxfL/YfT+cPM9Yz\nackO7uvfytHxqelZPD11LddGNmZEj4gSp8cfYwzx+04wKy6ZtbuP8fDlrRncMbzUzr/14An+NjeB\nOqGVubFHBH3b1CuVz1NuruH52Zv4dOlOcnINnRrX5I9DO3JD94hzamDpWTm8+t9EalWrxLPXdy63\nG9mFyBjD37+LZ9eJXD64u5vry0gU5qIOBBF1qpGclsvQt37hxZu6ckP3JqV+jfSsHH5KOMjMNcnE\nJh4kK8fQrmEYT1/TgeFRTWha5/wAFFG7Gs+P6ML4L9cyYeE2HhvYttTT5cTx01n878z1zF63DwHu\n+nAZ0x/tVypNLUdPZjJ64jK2HUrjly2H+XnzIV65pWQf9sXbDvPhr0ncFdOcQR0aYozhh00HeOm7\nBC5tW5924TUKPT49K4cHJ61kedIRYhMPERlRi7YN3VkHfu+x03wdt5dZa5JJPHCCkCChQY0q3P/J\nSu7t15Jnru1YojHixhi+WL6LF2ZvokpIMLm5humr99CwRhVu6N6EET0i6NKkZrFuzMYYXpwbzyeL\ndzAyuhn3XdqSjo1q+tz3sYFtOHYqkw9+SaJ2aCWevLJ9sd9ToPn3z9v4eNEOrmoRwlWdS69wUBwX\ndSC4oXsTMpITmLyjCmMnryE28SDPD48krErJ3nZurmFpUgpfr9nL3PX7OJGRTcMaVbi3X0tG9Iig\nc2P/X8ARURH8sOkg//h+M5e1a0BkRNmNGQZYseMIT06JY39qOk9f04FqqTt5Y3UWoycu46uH+1Kn\neuVinzstI5t7P1nBziOn+PzBGLYcPMFf58Qz5M1feP227lzevuhT5lPTs3jqq7W0rFedPw7tBICI\n8NLN3bjmzYU8+WUcMx/rT+UQ323VWTm5PP75albsOMKz13fm7R+3MP7LOGY81q/U2rePn85i3gbb\njLIs6QjGwCXNa/PC8C5c160JoZWDeWVeIh8tSmLJthTevr0HHRoVHrx8OXIyk99PX8f3mw4woF19\nXr+1OzWrVTpTIJm0ZAcf/ppEu4ZhjOgRwY09ImhSu5rj87+zYCsTf03i3n4t/ZbyRYQ/Du3EsVNZ\nvPnDFmpVq+S4dlYcWTm5nMzIpnZo8T+fFcHny3byyrxERkQ14Ybw8h/04OoTykpLdHS0WbnS54PM\n/IqNjeXSAZfx9k9b+ddPW2hWN5S3RvUgqlntIp8rYb+n0zduL/uOp1O9cjBDIhsXu0p+9GQm17y5\nkFrVKvHtE5eWySzC7JzcM3nRtE4ob42KokfzOsTGxlK1eVfu/mg5nRrX5PMH+xQrYKZn5XD/JytY\nlnSE9+7qeaakk7A/lXGT40g8cIIHL23F00M6UCXE+fv97ZdxfL12L9Mf7Xfe/938jfsZ8+kqHh/U\nhqevOX9Kfm6u4bdfxTErbi9/HRHJXTEtmLdhH498tponBrflf67uUKT3mPdBIpnZucQmHmRWXDI/\nxB8kMzuXVvWrMyIqghE9mvgcARKbeJCnpq4lNT2bP13XidExzpvNFm89zPiv4mwwGNKR+/u3Oq9t\nPn8TZZWQIP48rDN39mnu9zqfLt3Jn2dt4MYeEUVq98/OyeXxL1bz340HeOO27tx0SdNSf+DK+j3H\nGTtlDTtSThLTqh439ohgSNdG1KxaqdSuURa+XbuXsVPWMKhDQyaM7smiXxa69mAaEXH0hLKACATe\nTF6edITxX8ZxIDWd8Ve155HL2/i9ee87fppv4vYyc00yCftPEBwkXN6+AcOjmnB150ZUq1yym/fP\nmw9xz0fLub9/K/7v+s4lOpc/u4+c4skv41i18yg3XRJxTu3Im08/bDrAw5+tok+runx0b9GmuPu6\nGeSVnpXD3+fGM2nJTjo3rsnbt0fRtqH/EvGcdft4/IvVPHlluwKbHn4/bR1TV+3mq4f7Et2y7pnt\nxhie+3YTnyzewdPXdODxQWeb4Z6aupYZq/cw9ZF+9GxRx/H7XLBgATVadWfmmmTmrN/HsVNZ1Kte\nmes9TTLdm9bye8M9dCKDp6etJTbxEFd0bMgrt3SjXiHNZpnZubzx/WYmLNxGq/rVeXtUD0e1yJ0p\nJ/nTrA38suUwV3UO5+Wbu1G3gNre13HJPPllHFd0bMi/7yr6SKD0rBwemLSCpduPMOGunoQcjC+V\nG1xuruGDX7bz2vxE6odVYXhUBPM27GNHyikqhwRxVadwRvSI4PL2DQqsEVYUP28+xIOTVtCjeR3+\nc39vqlYKdvUJZRoIPPJn8vHTWfxx5nrmrNtH75Z16d2qrs/jDIY1u46xZHsKxkBUs9rc2COCYd0a\nF/qFLY5nv97ApCU7+fzBPvRvW9/nPulZOfwQf4CEfSeKdY3MnFwmL9sFwF9vjGR41LkdpXnzaeaa\nPYz/ci3XdAnnnTsucTS5xRjD76atY+qqPTx7fedCmwd+jD/A09PWcSozm99e1Z6bL2laYJ7uP57O\nNW8upGX96kx7pG+BN6e0jGyufWshAN+Nu+xMgPvH95t568ctPDSgFX8c2umcG/SJ9CyGvPkLIcHC\n3LEDqO6nBnQ6M4cJC7fx+aKtHDptqFopiGu6NGJEjwgubVu/yDdOYwyfLN7B3+cmUCu0Erf0bEpw\nAQHk582HWJ98nNt7N+fPwzoRWtl5bS031/DRoiRenpdA3eqVeeO2qPM+ZwsSDvLQf1bSs0UdJnlu\nUMWRlpHNnR8sJX7/Ccb3qMyjN19RrPN4HUhN57dfxbFoawpDujTipZu7Uju0MsYY1u45zqw1dkmG\nlJOZ1A6txLButoZ+SfM6jmtZubmGVbuOsn7Pce6MaV6kmmpRrNp5hLs+XE7rBtWZPCbmTE1GA4FD\npRkIwH4Bp63aw4tz4zmRnl3gsc3rhjI8qgnDoyJKdTRNfqczc7jun79wOjOHeeMuOzO6KCfXsHR7\nCrPWJPPdhv2kZWQTJBR7ZEZ0izq8dmt3nyOo8ufTx4uSeO7bTdzasymv3NKt0GsaY3hxTjwf/prE\nuCvaMf4q/x2GB1PTeWraOhZuPkSIp5Y1okcEV3YKP1PLMsZw90fLWbHjCHPHDqB1g8I7dlfuOMJt\nE5Zwa89mvHxLtzPv4bboprx8s+/3sGx7CqM+WMqoXs35+01dCzz3xr3HGTt5DdsOnSSyXjD3XxHJ\n1V0albi/CSB+Xyr/89VaEg8UHOTrVq/MC8O7MCSycbGvsyHZNq0kHT7Jw5e14bdXtadySBArdhzh\nrg+X0S48jMkPxVCjhE0tR09mctuEJexOSWPqo5cWe82c+Rv38/vp60jPyuXZ6zszslczn/+HWTm5\n/LrlMDPXJDN/037Ss3JpXjeUEVFNGN4jgjYFfG62Hkw7My9iz9HTAFwb2Yh/3XFJqY/ki9+XysgJ\nS6gfVoWvHul7zqAJDQQOlXYgqIjW7TnGTe8uZmjXxjxyeRtmxSXzdVwyB1LtGONru9qSZ59WpTM8\nMD9f+VRYaTqvdxZs5dX/JnJP3xb85YYuRQpU8ftS7Xtds5f9qef2u2w5eILnvt3ECyMiGR3TwtH5\nXpmXwLux27i9dzMmL9/tqFbz9+/imfDzdj68O5or843e8JamX5mXSO3QSrxxWxTZyRsuiM+UL6cy\ns3lhdjyTl++ia0Qt268ybR0NalRh6sN9S622u/94Otf94ydMcCW+erhvkUZnnc7M4cW5m/hs6S66\nNKnJW6N6OD4+LSOb/27Yz6y4ZBZtPUyuge5NazGiRwTDujXBYPh2re0/WZ98nCCBS9s14MYeTTiQ\nmsFL3yUwMrpZqY7p35lykpv/vYRKwcLUR/qeN5Lwog8EIjIOeAgQ4ANjzJsiUhf4EmgJ7ABuM8Yc\nLew8gRAIAP754xZe/34zACFBwsAODbmxRwRXdGroekdyQTUnb/t687qhhPgIQAY743REVBPeuC2q\n2JOKcnINy5I8tZ/1+zmRYWtqAzs04ON7ezn+UmZm53Lju4vYuDeV/m3rMfEe//0cGdk5jHhnMYdO\npDPvycvOlNYOnkjnqam21nJlp3BeucW2r19In6mCzNuwj99PX8/x01k0qVWVqY/2I6III4ucmDLn\nJ15bk0Pl4CDH54/fl8rYyWvYcjCNhwa04qlrijaoIK+Dqel8s3Yvs+KS2ZCcSnCQYIwh10C3prUY\nHhXB9d0b07DG2eHSb8xP5O2ftvLwZa35g2d0WmFycg3v/byNGav3UNCt9FBaBiFBNgj46hOrCIHA\nteGjIhKJDQK9gUxgnojMBsYAPxpjXhKRZ4BngN+7lY4LyaMD23AqK4cmtatxXdfGBXbqlRUR4f+G\ndaZ+WGUSD6QVuN91XRsz7sp2JZpZGhwk9GtTn35t6vP88Eh+SjjI0u0pPDG4XZFKZpVDgnj3zkuY\nsmI3jw9q6yiAVgkJ5s2RUVz/z1/5w4z1vD+6J7GJh3hq6lrSMrJ5YUQkdzkYcXMhGRLZmO7NavPh\nL0nc2ad5qQcBgEbVg5h0f09Gvb+U0R8uO69JJK8z/SXfJVCrWiX+c39vLivGMOO8GtasyoMDWvPg\ngNZsOXCCb9fuBRFu6N6kwBrG+Kvac+x0FhMWbqd2aGUeHVjwKqB7j53myS/jWJ50hJjWdWlQw/f8\nm0pBwgMDWjkaGFFe3JxH0AlYZow5BSAiPwM3AcOBgZ59JgGxaCAAICQ4iN8PKZsnEjkVFCT8ZnC7\nMr1m1UrBDO3amKFdi9ce3qJe9SLnY4dGNfjdkA78dU48d01cxqKtKXRsVIPJY2Jo72ei2oWqca1q\n/HmYuyPVujSpxUf39mL0xGXc+/Fyn30Qh9MyeGqq8xFUxdEuvAa/dTBMWET4y/VdOH46i5fn2aB0\nR5/m5+03d/0+/jBjPdk5ubx+a3duuiTigi4ouDnWagMwQETqiUgoMBRoBoQbY/Z59tkPlO+UOqU8\n7u/fir6t67Foawr39mvJrMf7X7RBoCz1almXf9/Zk4R9J3hw0spzViyNTTzIkDd/Ycm2FJ4f3oUP\n74ku9SBQVEFBwmu3dmdwx4b876z1zF6398xrpzKzeWb6Oh77fDUt64UyZ+wAbu7Z9IIOAuB+H8ED\nwGPASWAjkAHca4ypnWefo8aY8wZxi8gYbDMS4eHhPadMmVKsNKSlpREW5s4yAhcTzSfrdLbh0Klc\nmtcsuElJ88qZ/Pm0dG82E9Zl0L1BMI90r8KMLZnM35lN0zDhke5VaVqjYs0ByMgxvL4ynW3Hcnny\nkirUqCy8tzaDA6cM17WuxIi2lXz2mxWVm5+nQYMGlX9n8TkXEvkbsAcYBww0xuwTkcZArDGm0Dpb\noHQWlyfNJ+c0r5zxlU/emcs1qoZwIj27VNZdctPx01nc/v5Sth9OIyfXUK96Ff4xMoq+beqV2jUu\n6s5iTyIaGmMOikhzbP9ADNAKuAd4yfPv126mQSlVcYyOacHJjGw+W7qTt0ZFlepKrG6oVa0Sk+7v\nzX2fLKdFveq8OCLygl/nyBe3F52bLiL1gCzgcWPMMRF5CfjK02y0E7jN5TQopSqQRy5vU+bP5C2J\nBjWqMPuJAeWdDFe5GgiMMeflnjEmBSjZvHOllFKlpmL1ziillCpzGgiUUirAaSBQSqkAp4FAKaUC\nnAYCpZQKcBoIlFIqwGkgUEqpAKeBQCmlApwGAqWUCnAaCJRSKsBpIFBKqQCngUAppQKcBgKllApw\nGgiUUirAaSBQSqkAp4FAKaUCnAYCpZQKcBoIlFIqwLkaCERkvIhsFJENIjJZRKqKyGARWe3ZNklE\n3H5uslJKqUK4FghEJAIYC0QbYyKBYOAOYBIwyrNtJ3CPW2lQSinln9tNQyFANU+pPxQ4CWQaYzZ7\nXv8euNnlNCillCqEGGPcO7nIOOBF4DQwH7gL2AHcbIxZKSJvAYONMV19HDsGGAMQHh7ec8qUKcVK\nQ1paGmFhYcV7AwFE88k5zStnNJ+ccTOfBg0atMoYE+1vP9cCgYjUAaYDI4FjwFRgGrANeAWogg0O\nw4wxUYWdKzo62qxcubJY6YiNjWXgwIHFOjaQaD45p3nljOaTM27mk4g4CgRudtReCSQZYw55EjQD\n6GeM+QwY4Nl2NdDexTQopZTyw80+gl1AjIiEiogAVwDxItIQQESqAL8H3nMxDUoppfxwLRAYY5Zh\nm4JWA+s913ofeFpE4oF1wLfGmJ/cSoNSSin/XB3Db4x5Fng23+anPT9KKaUqAJ1ZrJRSAU4DgVJK\nBTgNBEopFeA0ECilVIDTQKCUUgFOA4FSSgU4DQRKKRXgNBAopVSA00CglFIBTgOBUkoFOA0ESikV\n4DQQKKVUgNNAoJRSAU4DgVJKBTgNBEopFeA0ECilVIDTQKCUUgHO1UAgIuNFZKOIbBCRySJSVUSu\nEJHVIhInIr+KSFs306CUUqpwrgUCEYkAxgLRxphIIBgYBfwbuNMYEwV8AfzJrTQopZTyz+2moRCg\nmoiEAKHAXsAANT2v1/JsU0opVU5ce3i9MSZZRF4DdgGngfnGmPki8iAwV0ROA6lAjFtpUEop5Z8Y\nY9w5sUgdYDowEjgGTAWmATcBLxtjlonI00AHY8yDPo4fA4wBCA8P7zllypRipSMtLY2wsLDivYkA\novnknOaVM5pPzriZT4MGDVpljIn2t59rNQLgSiDJGHMIQERmAP2B7saYZZ59vgTm+TrYGPM+8D5A\ndHS0GThwYLESERsbS3GPDSSaT85pXjmj+eRMRcgnN/sIdgExIhIqIgJcAWwCaolIe88+VwHxLqZB\nKaWUH272ESwTkWnAaiAbWIMt4e8BpotILnAUuN+tNCillPLPzaYhjDHPAs/m2zzT86OUUqoC0JnF\nSikV4DQQKKVUgNNAoJRSAU4DgVJKBTgNBEopFeA0ECilVIDTQKCUUgFOA4FSSgU4DQRKKRXgNBAo\npVSA00CglFIBTgOBUkoFOA0ESikV4PwGAhEJFpGEskiMUkqpsuc3EBhjcoBEEWleBulRSilVxpw+\nj6AOsFFElgMnvRuNMTe4kiqllFJlxmkg+LOrqVBKKVVuHAUCY8zPItICaGeM+UFEQoFgd5OmlFKq\nLDgaNSQiDwHTgAmeTRHALAfHjReRjSKyQUQmi0hVEflFROI8P3tFxO95lFJKucfp8NHHgf5AKoAx\nZgvQsLADRCQCGAtEG2MisTWIUcaYAcaYKGNMFLAEmFHcxCullCo5p4EgwxiT6f1DREIA4+C4EKCa\nZ/9QYG+ec9QEBuOgZqGUUso9TgPBzyLyR+xN/SpgKvBtYQcYY5KB14BdwD7guDFmfp5dRgA/GmNS\ni55spZRSpUWM8V+wF5Eg4AHgakCA/xpjPvBzTB1gOjASOIYNHtOMMZ95Xv8O+NAYM72A48cAYwDC\nw8N7Tpkyxel7OkdaWhphYWHFOjaQaD45p3nljOaTM27m06BBg1YZY6L97miM8fsDjHOyLd/rtwIT\n8/x9N/Cu5/f6QApQ1cn1e/bsaYprwYIFxT42kGg+Oad55YzmkzNu5hOw0ji4xzptGrrHx7Z7/Ryz\nC4gRkVAREeAKIN7z2i3AbGNMusPrK6WUckmh8whE5HbgDqCViHyT56UawJHCjjXGLBORacBqIBtY\nA7zveXkU8FJxE62UUqr0+JtQthjb0VsfeD3P9hPAOn8nN8Y8CzzrY/tA50lUSinlpkIDgTFmJ7AT\n6Fs2yVFKKVXW/DUNncD3fAEBjDGmpiupUkopVWb81QhqlFVClFJKlQ99QplSSgU4DQRKKRXgNBAo\npVSA00CglFIBTgOBUkoFOA0ESikV4DQQKKVUgNNAoJRSAU4DgVJKBTgNBEopFeA0ECilVIDTQKCU\nUgFOA4FSSgU4DQRKKRXgNBAopVSAczUQiMh4EdkoIhtEZLKIVBXrRRHZLCLxIjLWzTQopZQqnL9n\nFhebiEQAY4HOxpjTIvIV9qH1AjQDOhpjckWkoVtpUEop5Z9rgSDP+auJSBYQCuwF/grcYYzJBTDG\nHHQ5DUoppQohxvh6JHEpnVxkHPAicBqYb4y5U0RSgDeAG4FDwFhjzBYfx44BxgCEh4f3nDJlSrHS\nkJaWRlhYWDHfQeDQfHJO88oZzSdn3MynQYMGrTLGRPvbz82moTrAcKAVcAyYKiJ3AVWAdGNMtIjc\nBHwEDMh/vDHmfeB9gOjoaDNw4MBipSM2NpbiHhtINJ+c07xyRvPJmYqQT252Fl8JJBljDhljsoAZ\nQD9gj+d3gJlANxfToJRSyg83+wh2ATEiEoptGroCWAmkAoOAJOByYLOLaVBKKeWHa4HAGLNMRKYB\nq4FsYA22qaca8LmIjAfSgAfdSoNSSin/XB01ZIx5Fng23+YM4Do3r6uUUso5nVmslFIBTgOBUkoF\nOA0ESikV4DQQKKVUgNNAoJRSAU4DgVJKBTgNBEopFeA0ECilVIDTQKCUUgFOA4FSSgU4DQRKKRXg\nNBAopVSA00CglFIBTgOBUkoFOA0Eyr+MNMjJLu9UKKVcooFAFc4Y+HdfmPdMeadEKeUSDQSqcClb\n4dguWD0JThwo79QopVzgaiAQkfEislFENojIZBGpKiKfiEiSiMR5fqLcTIMqoV1L7b85mbDsvfJN\ni1LKFa4FAhGJAMYC0caYSCAYGOV5+WljTJTnJ86tNKhSsHspVKsDnW6AFRMh40R5p0gpVcrcbhoK\nAaqJSAgQCux1+XqqtO1aBs36wKVPQsZxWPVJeadIKVXKXAsExphk4DVgF7APOG6Mme95+UURWSci\n/xCRKm6lQZXQyRRI2WIDQURPaDkAlrwL2ZnlnTKlVCkSY4w7JxapA0wHRgLHgKnANOBHYD9QGXgf\n2GaMed7H8WOAMQDh4eE9p0yZUqx0pKWlERYWVqxjA4mvfKp3eBldN/yNNVF/43jtLtRNWU239c8R\n33EcBxoNLqeUlj/9TDmj+eSMm/k0aNCgVcaYaL87GmNc+QFuBSbm+ftu4N18+wwEZvs7V8+ePU1x\nLViwoOAXszKKfd5iy801Jjuz7K/rh898mv9nY56rZ0zmKft3bq4x7/Q15l99jMnJKdP0FZmL/7eF\nfqbUGZpPzriZT8BK4+B+7WYfwS4gRkRCRUSAK4B4EWkM4Nk2AtjgYhoKdiQJXmoG8d+W7XVXfQKv\ntYf01LK9bnHsWgZNoqBSNfu3CPQfB4fiYev35Zu2wsR/Cy+3hNR95Z0SpS4IbvYRLMM2Ba0G1nuu\n9T7wuYis92yrD/zVrTQUKv4byE6Hn1+xk6bKyrov4fQR2PZj2V2zOLIzYO8a2z+QV+RNULMpLHqr\nfNLlxNopkHUSEmaXd0qUuiC4OmrIGPOsMaajMSbSGDPaGJNhjBlsjOnq2XaXMSbNzTQUKPE7CKoE\n+9fB9tiyuebJw7B72dnrV2R74yAnA5rHnLs9uBL0fRx2LoLdK8onbYXJSodtP9nfK3oeK1VBBObM\nYu8Nud9vICy87Eq3m/8LJheAHUT9AAAZmElEQVQadbW/52SVzXWLY7dnIln+GgHAJXdD1dqwuALW\nCpJ+hqxTNo+TFl4YTXBKlbPADASb59kbcpcbIeZR2L4A9q11/7qJc22zymVPQ/ox2LXE/WsW165l\nULc1hDU8/7UqYdDrQYifDYe3ln3aCpMwByrXgKv/CrlZsPWH8k6RUhVeYAaCxO/sDblRN+h5n71x\nLHrb3WtmnbZNFh2uhTZXQHCVitt0YYytMTWLKXifPg9DcGVY8s+yS5c/ubk2yLe70s55qFa34uax\nUhVI4AWCvDdkEahWG6LvhY0z4egO96673dNk0eFaW6JufbktvZZlR7VTKdvg1GFo7qNZyCusIUTd\nAXGTK85idHtXQ9oB6DAUgoKh/RDYUsGb4JSqAAIvEGyPtTfkjkPPbuvzKEiQnTXrVFFv4IlzoEpN\nW1IFe7M6thMObiraecrCmf6BQmoEAP2esIvRLZ/gTjqKmscJc0CCod1V9u+OQyH9OOxcXPppu1iU\npCCSnQGZJwv+uZiUJJ9KcuzxPcU/tggCLxAkzrU35BaXnt1WKwK63Qar/2OXVfBn1SQ7F+BggrNr\n5uZC4jxoeyWEVLbbOlx7Nj1l4fNb4at7nO27a6ntDK7fvvD96rWBTtfD8g/gUGLJ05jXpq/h1ba2\nr8KpxO+gZX+7SB5Am8Fl2wQ381H4ZFjFrOX5sj3W5vHm+X53Pf/Yn+HFRvC3JgX+dN74ysXxQKOc\nLJgwAGY+Ark5RTs2eTW83gHWfln06yavgn9E2r44lwVWIPB1Q/bq9wRkn4YVHxZ+jo2zYPaTcPIg\nLHrT2XWTV9n9O+SphdRoZNfvSSiDQLB7BWyZD5tmwYGNDvb3LDQX5ODjcfULEFIVPr0Rju0ueVoB\nti2A6Q/a5qmFrzo75sh2O9Etbx5Xrg6tB9ramNs355RtsHYy7PgFdvzq7rVKQ/IqmHKnzeMFLxY9\nfxa+akfcXfW875/eY2h4aBF8O/bCCYwF2TgT9q+3/79zn3L+fg5vgc9vsc2VsX8relBc9DZUqQGt\nLit6mososAJB8kp7Q+543fmvNexk25SXT4DMU76P37YAZjwETXvDJffA+qnOqm6JcyAo5GyThVeH\nobZd2+0ZsIvfgqq1oFJ1WOync/fUETi8ufD+gbzqtITRM+zjLD+90Q7NLYk9nhtUvbbQ9zd2BvN+\nB5PPvQE1byAA2zx0bJezAFgSi/9pO89D61XsyXYAhzbDZ7dAaF24/BnYF2cDmFPJq+z+fX9jZ5r7\n+hn6Kkktb4e4z2H+ny7cYGCM/f9s0NG+r5Uf2cDpz/E98J8Rtsn5yuds/2P8N86vm7LN7h99P1St\nWezkOxVYgSBxrr0ht73S9+v9x8GpFPvhze/MDaod3DEFBvyP/ZAs/beD634HLfrbjum8vAFps4tN\nF4e32qplr4egp4Pg5Z3w5q9/IK9GXeGOL+H4bvjs5uI/s+BQoi1BVa8Pd82weVwp1H/wApvH4ZFQ\np8W529tfe/Z1t6QdhLgvIOp2iHnMefAqD8d2w6cjbGf66Fl2efHqDYoWvBa9DVVq2c9TIXa2GAm9\nx8CSfzmvPVc0236EAxug31h7Q+8x2taGCutPPJliC0UZqXDXdNvaULeNzWOnAXHJO/Ze1eeR0nkf\nfgRWIEiY6/uG7NW8LzTtZT+4eatx3htUWANb+q1Wx95wIm+yawedPlrwNVO2waGE80uqYEsZdVq6\n2zy0xFNS7fOwvUn5C167ltoZ1xGXFO06LfrCbf+xVegpd9gZvkVxbLf98gSFwOiZULOxLbFecg9s\nmFZ4s9OpI7Br8dl+l7xqhENEtK2VuWXZBNtp3vcJ6PWAs5pXeTh52HODOmEDbb02dh2pPg/b+RZO\ngpe3pNrrAdtsURgRGPIyRN4CP/zlwnyWxaK3oEZj6HqrfT/D3rT9Yv/9g13KJL+ME/ZecWwX3D4F\nGne3QbffE7bmlbTQ/zVPHraF0W4j7fegDAROIEjZBocTfTcLeYlA/yfPrcZ5b1DBlWwJqkajs/v3\nGwuZaba6WBBvZ3BHH4FABDpcZ2fDZriw0saJA3Z4Z9Qddrhn7WbQ9ZbCg9eupfbD611orijaXwMj\n/m0/7NMfcN4meuYGlWYDbb02Z1/r6yB4eWds+wq2YPN+7xpIdeG5SBlpsOID6DQM6re1hYSe9/oP\nXmXNe4M6vtvW3hp3O/tatDd4OZhLU9SSalCQ/Uy0vQpmj7eDAC4UyavtZznmsbN9isEhcNOHtt1+\n1mPn1jSzM2yrwb61cOsnduCCV/fboXpDZzWv5e/bc/UbW6pvpzCBEwi8N2Rfpca8Ogy17dOL3jr3\nBnXXDKjb6tx9G3ezk8OWvldwCThhLoR3hdrNfb/ecagtTbqxCN1yT0m13xNntxUWvLwLzeVfX6go\nuo+0pcCE2TB7nP+qcMYJ25zkvUE16nru67Wb+w9eiXNsqa1JD9+vd/AEfzeah1b/xw5R7f/k2W0x\nj9p/nTQbloXsDFtL27cObp0ELfqd+3poXRu81k+zJdmCpB2yJdXut9uallMhlW1tsWkvOwigrNb2\nKqnF3iawe8/dXqkqjPrCfv+n3muHJ+fm2PeW9DMMf+f8+0ylqhDziP2e719f8DUzT9pA0PE6aOBn\n1F4pCpxA4O+G7BUUZG+W++Lg/UG2Pf2OL6FRpO/9+4+zHdDrfFQTT6bYMfmFBZ9mMbYUWdrNQxkn\n7AioTtefW8JuFGn7SHwFL+9Cc77WFyqKmEfgst/Bms/gh2cL3i8r3d6g9q+3N4oWfX3v12+sXU10\nxUTf59iaZ4KgLw06QJ1WpT9UNyfLlpBb9IemeZ79UbuZbQ7x12xYFnJzbO0saSGMeBc6DPG9X8yj\nNv8KC15nSqpPFLxPQSqH2u9RvXa21Jy8qujnKEtHttvaS68COmur1IA7p0GtZvDFSBsQ4r+Ba/5u\n+4p8ib4fKocVvorBms/sZ6b/uFJ5G06FlOnVyov3hnzZ08727zbSjgw4sRdGTS74BgW2itg4yrYJ\n9xht2wO9tniaLHw1C3kFh0C7azwzYLPt36XhTEnVxweq/ziYdL0NXnlLO96JZCWpEXgN+qPteF/0\nlqc67Osm7akt3Pi+bVYqiDd4LXvPjlSpVPXsa0kLbZDo4KfJr+N19kaWcaLgtm1j4Pv/s0Nt75oO\ntZoW/h43zIDUPTDsjfNf6z/W5u+KiXDZU4WfpyRysuDdGNv06ZMnj4e8BN1HFXyeM8Frkv2ehNY9\n9/WMtLMl1frtipfWanVs09/Eq+2opfvn2SDtVG4uzBlvP9vFHYXU7mpb6Mj7GfLFSRNY9fpw9yyY\neI0NAgOesk2ZBfE2Gy79N1zx5/MLpTnZsPhftq+yWW/Hb6k0BEYg8C4y569ZyMtb9cvJPL8anZ/3\nYS3T7rMlzk7Xn30tYQ7UaGIDRWE6DrU3jd1LoeWlhe/rxJmS6qXnllS9Wg6wzSj5g9euZbbk7Guh\nuaISgaGvQngXOLG/4P0iehZcSs3LG7zWTobo+85uT5xjS1mtBhR+fIehdhDA1h+hywjf+yx81TYH\nSLBtErxvHlSv53vfM8MKO9n27/zCu9jtvoJXadq5GFK2Qvc7Cg5cDTtC5M3+z+UNXisnnl9oWvOZ\nXSgxbxNYcdRodPbm+emNcP9/bRDyxxjbQbvqE9s0VcvBMfmlH7fNpdMfsE1kBRW6Th6277f7qHP7\nBH2p1RTum2P71rqN9J+GmEftZ2LJu3DtS+e+tmkWHN8FQ19x9n5KUWAEgsS5UDPC/w05L1830IJ0\nusGO/vn1Teg4zN4Evevid7+94CYLrzaD7ciehLmlEwg2TIfUZDvCwRdv8Jp679ng5V1oLv9ch5II\nCrajS0pD3uB1yd323GcmCF4BIVUKP75ZH1siS5zrOxAs/8DWArvfAT3utP0Wn98C93zjuwax9Uc4\nuNF2hBY08a7/OJg07PzgVZoS59oJfde9ZifQlcSZ4DXBE7w8AwZysmwQbd4PmvUqeZrrtrY1g4+v\n8wSDebZ0XZiFr9kbaMzjcM2L/r9TBanXBr77ne2/uuFfvs9T1M7aOi3tjxO1mtoRSKsnweW/O1vz\nMsYOsa3fwbYQlLGLvo8gKCfj3EXm3BAcYr84ySvPLi3tXRe/sGYhryo1oNXl9ktd0ok33pJqw86F\n39TzBi9jqHZ6r2ehuVJoFnKDN3gd2WZrWmA7ttP2F94s5BUcYicMbv7v+aOZ1k+DuU/bWsMN/7TB\n+NZP7OiPKXfam0J+i960tb3IWwq+ZstLocklNngVdWkCJ4yxhYfWg0oeBLz6j4OTh2zw8to4y3bm\nl2a7dVHmnqz4EBb8FbqNssuLl+R73OdhuPz3Bfdf5e2sLW4TmD/9nrD3hrx9XtsX2L6y/mOdzegv\nZRd9IKhzdN3ZVT/dFHXnubNKvevit/TTZOHVcSgcTbJzDkpi6w92Ibt+Ywv/wnjHNnuCV63j8XZ7\nUSaSlTVv8FpkgxeJ+RaZ86fD0POfA7HlB5j5sG0CvOWjs80FHa61oz+SfrajQfLcyGukbvHMrH3s\n/KVK8vIVvErTgY22KaE0P9v5g1fembXtri6964CzuScbpsOcp2wQH/6v0rlJDvyDfZ7GordsQSiv\nsuisDe9i83LZe3Y1ZDh3vkI5cDUQiMh4EdkoIhtEZLKIVM3z2tsi4vpjKuulLC/aDbm4KodC74dt\nf8SBTfZfJ00WXmdmwJZwZMuit2wzmJM24ag7IbQ+LHrLBgInC82VpzPBa5VtG0/8zt7A83dsFuTM\nInSePN69HL4abZcXuX3y+XMnom63o0Div7Fj4D21tWa7Z9phhZc4WMSv0/W238UbvEpT4lxASjcQ\nnAle2+0Q4G0/wYH1tmDhRkm1/TV2NJOvuSdbf4AZD9vO01s/sXN5SoMIXPuq/Y788KztfIay7azt\nP87WwOO+IOzENjukNuZR5/eLUuZaIBCRCGAsEG2MiQSCgVGe16KBOm5d+4zcXOqlrLAPKimLDO79\nkF0SYebDdqGpwiav5VezsS2JlWQYqXcNmBg/JVUv76zSzfNswHS60Fx58gavec/Ymk9Bk8h8yfsc\niAOb7IqsNRrZOSJVa/k+pu9jdjTI6knw4/OQso0Gh5YUPKwwv/zBqzQlzLFj80ujcz8vb/D69U1P\nE5jLJdXuo+yopoTZdkFHY+xCiV+OtjURX0G6pIKCYMR7dh7Qt+Mg/tuznbVlMXSzRX87UGLxP2m+\na7pdETn/fIUy5Pa3PgSoJiIhQCiwV0SCgVeB37l8bUheRZXMo0W7WZREaF07Cmf/uqI1WXh1HGqb\nagobZVMYh2vAnKPXg1AplMpZqc4XmitP3uC1f539u6ilYe9zID6+1p5r9Cz/N9LBf7JPsvv1Dfhi\nJEaCirYGTNQdZ2pepeZ4sp3r4kaTpzd47fUxs9YtMY/akUprPoWvH/cs6RJuh/EWtCRMSYVUhpGf\n2hvytPvhh+fKrrPWW/M6mmRXaY2+r+DCSBlwbdSQMSZZRF4DdgGngfnGmPkiMg74xhizTwppwxaR\nMcAYgPDwcGJjY4uchlbbP6UZQSw+EEp2MY4vjqrSkz4EcaxWZ9YuK9pzkKunNaAXkDT9L+xsWciY\nbx9qHo+nx6Zv2NX8JpKWFG2yTtuGg2maPJs1KVU5Xkb5VBIhWR3pG1SF09UasXLdTmCn42MrZ9Sk\nH5CVnU1c5B84uTYJSPJ/YNj1dG6wmYaHFrGn/kC2r0oAnPfntGh4Da22fE72C00K3Cc5YihJre9y\ndL4myd/RHlie2oBTLvyfBeU0JaZSLYJys1hyui05xbhGWlpa0b630p92TdYTEfc5GZXrsKb9H0hf\nFQ/EF/naRRHSYhw9jvyR6sd3kdDhCfYvdLAeUGkwYfSu1piq6QdZmtudzHL87olxaXlYEakDTAdG\nAseAqcAM7M19oDEmW0TSjDFh/s4VHR1tVq5cWfRExH/LziVf0+J+P88YKG0bptvVBpsUYbgq2Crx\ntPvs+ucj3it4hmJ+BzbZEm5oXXjwR+dt5l6njrB1+gu0vfO1cyfEVWSJ39kSlL95Hr6sn2b7BcK7\nFO247AxY+TGLUhvT/+rhRTs24wT88nrBS5HsXW1ndo/f4Kyp59Ob7JpYT6xybzTc9ljIzoT2xesk\njo2NZeDAgUU7KDfHjhJqM9i9UTu+nNgPm76xJfPS6otwYvcKNi6ZT5fb/teV04vIKmOM37Hwbs4j\nuBJIMsYc8iRoBvAcUA3Y6qkNhIrIVmNMW1dS0Ol6kg7UoIX/PUuXk45aX0Tgxgl2Nc2vH7dVYn9V\n/6M77FhsbzNHUYMAQGhd9jQbTtsLJQhAyZpEuhYy5LMwIVUg5hGyilNyq1IDrvxLwa8f3gL/6mWH\nLg7+U+HnSk+1TTZ9HnYvCIB9qE9ZCwq276us1WgEfcaU/XWb9eLQtvJ/rKebfQS7gBgRCRV7178C\neMMY08gY09IY0xI45VoQuFCFVIFRn9sVQKfeCzsWFbxv2kEbBLLTbYdn/rX41YWjfjvPMhgf+F+J\ndtuPkJtVtMEIShXCtUBgjFkGTANWA+s913rfretdVLwLWtVuDpNH2VUj80s/Dp/dZKu0d06F8M5l\nn05Vuvo/aec5rPm08P0S5kK1uiVfHFApD1dHDRljnjXGdDTGRBpjRhtjMvK97rd/IGBVr2cf0FKl\npr3h511ULOs0fDEKDibYUQ9lvECVckmzXnYZhyXv2GUdfMnJsgsUth9y4fTnqAqvgg8aD3C1mtoF\nukyuff5p6l57I5h6n50de9OEgh+7qS5M/cfZZRc2zvT9+q4ltjboZOkSpRzSQFDR1W9nx1KfPmJH\nisx8xD7j+LrXit8prSqudlfbSVQFPd82Ya6dHd16UNmnTV20NBBcCJr0sLMrj2yzj0Ac9Cc7EUxd\nfLwPRjqw4fyn1nnXV2o90M6SVqqUaCC4ULS6zHYgD33N3QedqPLX9Va7rEP+mcgHN9lHSWqzkCpl\nGgguJK0vt+sZuTl2XJW/kMp2WYekhfYB6l7edajaO3iQj1JFoIFAqYqo5712xNjiPM+3TZwDEdH+\nn5qlVBFpIFCqIqpa0z7sfNPXdkno1L32QTzaLKRcoIFAqYqqzyP2AepL3rFrK0HZraSrAkpgPLNY\nqQtRzcb2gehrPoPwSPuMgAYdyztV6iKkNQKlKrJ+Y+1aUskrbW1ABwooF2ggUKoia9AeOngWl9P+\nAeUSbRpSqqK76nmo39Y+S1cpF2ggUKqiq9/WBgOlXKJNQ0opFeA0ECilVIDTQKCUUgFOA4FSSgU4\nVwOBiIwXkY0iskFEJotIVRGZKCJrRWSdiEwTEV1PVymlypFrgUBEIoCxQLQxJhIIBkYB440x3Y0x\n3bAPuP+NW2lQSinln9tNQyFANREJAUKBvcaYVAAREaAa4OMxTEoppcqKa4HAGJMMvIYt9e8Djhtj\n5gOIyMfAfqAj8E+30qCUUso/Mb6ei1oaJxapA0wHRgLHgKnANGPMZ57Xg7FBYIUx5mMfx48Bxnj+\n7AAkFjMp9YHDxTw2kGg+Oad55YzmkzNu5lMLY0wDfzu5GQhuBYYYYx7w/H03EGOMeSzPPpcBvzPG\nDHMlEfYaK40x0W6d/2Kh+eSc5pUzmk/OVIR8crOPYBcQIyKhnv6AK4B4EWkLZ/oIbgASXEyDUkop\nP1xba8gYs0xEpgGrgWxgDfA+8JOI1AQEWAs86lYalFJK+efqonPGmGeBZ/Nt7u/mNX14v4yvd6HS\nfHJO88oZzSdnyj2fXOsjUEopdWHQJSaUUirAXdSBQESGiEiiiGwVkWfKOz0VhYh8JCIHRWRDnm11\nReR7Edni+bdOeaaxIhCRZiKyQEQ2eZZKGefZrnmVh2fpmOWepWM2ishznu2tRGSZ5/v3pYhULu+0\nVgQiEiwia0Rktufvcs+nizYQeOYpvANcC3QGbheRzuWbqgrjE2BIvm3PAD8aY9oBP3r+DnTZwP8Y\nYzoDMcDjns+Q5tW5MoDBxpjuQBQwRERigJeBfxhj2gJHgQfKMY0VyTggPs/f5Z5PF20gAHoDW40x\n240xmcAUYHg5p6lCMMYsBI7k2zwcmOT5fRIwokwTVQEZY/YZY1Z7fj+B/fJGoHl1DmOlef6s5Pkx\nwGBgmmd7wOcTgIg0Ba4DPvT8LVSAfLqYA0EEsDvP33s825Rv4caYfZ7f9wPh5ZmYikZEWgI9gGVo\nXp3H09wRBxwEvge2AceMMdmeXfT7Z70J/A7I9fxdjwqQTxdzIFDFZOxQMh1O5uFZKn068KR30UQv\nzSvLGJNjjIkCmmJr4x3LOUkVjogMAw4aY1aVd1ryu5gfXp8MNMvzd1PPNuXbARFpbIzZJyKNsSW7\ngCcilbBB4HNjzAzPZs2rAhhjjonIAqAvUFtEQjylXf3+2TlUN4jIUKAqUBN4iwqQTxdzjWAF0M7T\nI18Z+yyEb8o5TRXZN8A9nt/vAb4ux7RUCJ7224lAvDHmjTwvaV7lISINRKS25/dqwFXY/pQFwC2e\n3QI+n4wxfzDGNDXGtMTej34yxtxJBcini3pCmSfyvol9KM5HxpgXyzlJFYKITAYGYlc9PICd/T0L\n+ApoDuwEbjPG5O9QDigicinwC7Ces226f8T2E2heeYhIN2wnZzC2cPmVMeZ5EWmNHaRRF7vEzF3G\nmIzyS2nFISIDgaeMMcMqQj5d1IFAKaWUfxdz05BSSikHNBAopVSA00CglFIBTgOBUkoFOA0ESikV\n4DQQKKVUgNNAoJRSAU4DgVJKBbj/BwoQHogoW9VFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u3UFxL_bUb3B",
        "colab_type": "code",
        "outputId": "fa06f906-06d7-4fa6-98ef-69fd761d89b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.max(ValidAccuracy_Track))\n",
        "print(np.argmax(ValidAccuracy_Track))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.8\n",
            "41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LG0RQz3FI1vV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qw9Rb1WxH91p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### weights are 6,6,1"
      ]
    },
    {
      "metadata": {
        "id": "SNa5wb-fNgdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shuffling_indices_validation_data = np.random.permutation(validation_data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wo0Ckop2O-zr",
        "colab_type": "code",
        "outputId": "f4954661-976c-472f-e0e4-a5fd5fe839b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "shuffling_indices_validation_data.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "ffB0tBLCLyxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shuffled_validation_data = validation_data[shuffling_indices_validation_data,:]\n",
        "shuffled_validation_label = validation_label_one_hot[shuffling_indices_validation_data,:]\n",
        "train_valid_combined_shuffled = np.concatenate((train_data, shuffled_validation_data))\n",
        "train_valid_combined_shuffled_label = np.concatenate((train_label_one_hot, shuffled_validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5ENx3_HSDoW",
        "colab_type": "code",
        "outputId": "70a1bd1f-b8bf-4076-a048-4c1a73674e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(validation_label_one_hot,axis = 1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([291.,   0.,  95.,   0., 163.,   0., 109.,   0., 176., 497.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lun1902_I2aP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # keep aside \n",
        "# aside_examples= 300\n",
        "# aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "# aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "# combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "# combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFcQiksEQNKy",
        "colab_type": "code",
        "outputId": "2c42391e-0272-4728-87c2-66747aed7dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffled.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "H4ELGdrQQD6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 400\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0QFZESfMJErm",
        "colab_type": "code",
        "outputId": "e032f58f-18cc-4e14-a168-ebec5e867826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(aside_valid_test_label,axis = 1))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 82.,   0.,  29.,   0.,  52.,   0.,  25.,   0.,  57., 155.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP0PvHyeeq9JAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tMF1ajQrJWRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Determine how many epochs are required"
      ]
    },
    {
      "metadata": {
        "id": "PiTBKrflH9K7",
        "colab_type": "code",
        "outputId": "e0d93244-344b-4a20-e5ae-e518705ccd17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 20000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 20000\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 6\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<5000:\n",
        "        learn = .1\n",
        "      elif ep >=5000 and ep <= 8000:\n",
        "        learn = .1\n",
        "      else:\n",
        "        learn = .01\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "              saver.save(sess, './statlog_letterReducedSGD')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 2.5011463, training acc total= 88.77323269844055%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 1000, training loss Total= 0.10494255, training acc total= 95.46468257904053%\n",
            "ValidTest acc= 90.25 %\n",
            "epoch 2000, training loss Total= 0.08661257, training acc total= 95.93556523323059%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 3000, training loss Total= 0.07774317, training acc total= 96.2081789970398%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 4000, training loss Total= 0.0705792, training acc total= 96.28252983093262%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 5000, training loss Total= 0.059275158, training acc total= 96.57992720603943%\n",
            "ValidTest acc= 91.75 %\n",
            "epoch 6000, training loss Total= 0.055875786, training acc total= 96.82775735855103%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 7000, training loss Total= 0.051685873, training acc total= 96.90210819244385%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8000, training loss Total= 0.04950832, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9000, training loss Total= 0.049083073, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 10000, training loss Total= 0.04870185, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 11000, training loss Total= 0.04835611, training acc total= 97.14993834495544%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 12000, training loss Total= 0.04802695, training acc total= 97.14993834495544%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 13000, training loss Total= 0.047707215, training acc total= 97.14993834495544%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 14000, training loss Total= 0.04739852, training acc total= 97.17472195625305%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 15000, training loss Total= 0.04709679, training acc total= 97.17472195625305%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 16000, training loss Total= 0.046804935, training acc total= 97.17472195625305%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 17000, training loss Total= 0.046523027, training acc total= 97.22428917884827%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 18000, training loss Total= 0.04624805, training acc total= 97.24907279014587%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 19000, training loss Total= 0.045982897, training acc total= 97.22428917884827%\n",
            "ValidTest acc= 92.25 %\n",
            "ValidValid acc= 94.214874 %\n",
            "ValidTest acc= 92.25 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "6\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoIsmarzTPqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### fine tune for higher precision for no. epochs"
      ]
    },
    {
      "metadata": {
        "id": "isv5BHBYI-JI",
        "colab_type": "code",
        "outputId": "455957f6-8606-4d2e-bc33-65e78ff28aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 10000\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 6\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<5000:\n",
        "        learn = .1\n",
        "      elif ep >=5000 and ep <= 8000:\n",
        "        learn = .1\n",
        "      else:\n",
        "        learn = .01\n",
        "      if ep>8000:\n",
        "        plot_every = 100\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "              saver.save(sess, './statlog_letterReducedSGD')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 2.5011463, training acc total= 88.77323269844055%\n",
            "ValidTest acc= 89.25 %\n",
            "epoch 1000, training loss Total= 0.10494255, training acc total= 95.46468257904053%\n",
            "ValidTest acc= 90.25 %\n",
            "epoch 2000, training loss Total= 0.08661257, training acc total= 95.93556523323059%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 3000, training loss Total= 0.07774317, training acc total= 96.2081789970398%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 4000, training loss Total= 0.0705792, training acc total= 96.28252983093262%\n",
            "ValidTest acc= 91.5 %\n",
            "epoch 5000, training loss Total= 0.059275158, training acc total= 96.57992720603943%\n",
            "ValidTest acc= 91.75 %\n",
            "epoch 6000, training loss Total= 0.055875786, training acc total= 96.82775735855103%\n",
            "ValidTest acc= 92.0 %\n",
            "epoch 7000, training loss Total= 0.051685873, training acc total= 96.90210819244385%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8000, training loss Total= 0.04950832, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8100, training loss Total= 0.049448416, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8200, training loss Total= 0.04940507, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8300, training loss Total= 0.049362734, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8400, training loss Total= 0.04932107, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8500, training loss Total= 0.049280137, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8600, training loss Total= 0.04923975, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8700, training loss Total= 0.049199987, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8800, training loss Total= 0.049160615, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 8900, training loss Total= 0.049121644, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9000, training loss Total= 0.049083073, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9100, training loss Total= 0.049044397, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9200, training loss Total= 0.04900051, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9300, training loss Total= 0.04896068, training acc total= 97.07558751106262%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9400, training loss Total= 0.04892218, training acc total= 97.07558751106262%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9500, training loss Total= 0.048884343, training acc total= 97.07558751106262%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9600, training loss Total= 0.048847128, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9700, training loss Total= 0.04881035, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9800, training loss Total= 0.048773885, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 92.25 %\n",
            "epoch 9900, training loss Total= 0.048737694, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 92.25 %\n",
            "ValidValid acc= 93.98948 %\n",
            "ValidTest acc= 92.25 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "6\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lZ5IPzM1aO3S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train entire data till 10000 epochs"
      ]
    },
    {
      "metadata": {
        "id": "Z6C75YaCI-Fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBmylidkbByd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_valid_combined_shuffled.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6zM5JVcI-Bv",
        "colab_type": "code",
        "outputId": "b60d9e04-3733-47d9-d72a-716e5f8de85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 9500\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "# learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 6\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<5000:\n",
        "        learn = .1\n",
        "      elif ep >=5000 and ep <= 8000:\n",
        "        learn = .1\n",
        "      else:\n",
        "        learn = .01\n",
        "      if ep>8000:\n",
        "        plot_every = 100\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "#           print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "#           if ep%plot_every == 0:\n",
        "#             if (validationTest_accuracy >= best_accuracy_valid):\n",
        "#               best_accuracy_valid = validationTest_accuracy\n",
        "#               saver.save(sess, './statlog_letterReducedSGD')\n",
        "#               G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "#     validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "#     print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "#     validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "#     print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "    print(\"Train acc=\",str(train_acc_total), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './statlog_satimFullSGDFinal')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 1.6421824, training acc total= 89.24221992492676%\n",
            "epoch 1000, training loss Total= 0.1167705, training acc total= 95.24131417274475%\n",
            "epoch 2000, training loss Total= 0.10244689, training acc total= 95.82769274711609%\n",
            "epoch 3000, training loss Total= 0.091625914, training acc total= 95.94045877456665%\n",
            "epoch 4000, training loss Total= 0.08408962, training acc total= 96.23364806175232%\n",
            "epoch 5000, training loss Total= 0.073307745, training acc total= 96.32385969161987%\n",
            "epoch 6000, training loss Total= 0.066499114, training acc total= 96.52683734893799%\n",
            "epoch 7000, training loss Total= 0.060303714, training acc total= 96.68470621109009%\n",
            "epoch 8000, training loss Total= 0.05692737, training acc total= 96.68470621109009%\n",
            "epoch 8100, training loss Total= 0.056117997, training acc total= 96.68470621109009%\n",
            "epoch 8200, training loss Total= 0.055982567, training acc total= 96.66215777397156%\n",
            "epoch 8300, training loss Total= 0.0558603, training acc total= 96.66215777397156%\n",
            "epoch 8400, training loss Total= 0.055742033, training acc total= 96.68470621109009%\n",
            "epoch 8500, training loss Total= 0.055630244, training acc total= 96.66215777397156%\n",
            "epoch 8600, training loss Total= 0.055525698, training acc total= 96.68470621109009%\n",
            "epoch 8700, training loss Total= 0.05542909, training acc total= 96.66215777397156%\n",
            "epoch 8800, training loss Total= 0.05533664, training acc total= 96.7072606086731%\n",
            "epoch 8900, training loss Total= 0.05524673, training acc total= 96.7298150062561%\n",
            "epoch 9000, training loss Total= 0.055158224, training acc total= 96.7072606086731%\n",
            "epoch 9100, training loss Total= 0.055071894, training acc total= 96.7072606086731%\n",
            "epoch 9200, training loss Total= 0.054983452, training acc total= 96.7072606086731%\n",
            "epoch 9300, training loss Total= 0.054898534, training acc total= 96.7072606086731%\n",
            "epoch 9400, training loss Total= 0.05481777, training acc total= 96.7298150062561%\n",
            "Train acc= 0.96729815 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "6\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tPpj4B9bzVQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HhHoRGntavcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check on test set!"
      ]
    },
    {
      "metadata": {
        "id": "ZjG059nKb0B7",
        "colab_type": "code",
        "outputId": "e26d8400-e39b-471c-ba22-c03427110bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, './statlog_satimFullSGDFinal')\n",
        "    train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "    print(\"Train acc=\",str(train_acc_total), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_satimFullSGDFinal\n",
            "Train acc= 0.96729815 %\n",
            "Test acc= 90.15 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QlzkjrMfavOm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "uYTrY2rwI9-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLSesmCEI96T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
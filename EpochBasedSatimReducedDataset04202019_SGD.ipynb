{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EpochBasedSatimReducedDataset04202019_SGD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/EpochBasedSatimReducedDataset04202019_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "cf0a4926-b2ce-48e2-9f6e-57994fa7589d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.601267</td>\n",
              "      <td>-1.288475</td>\n",
              "      <td>-0.051051</td>\n",
              "      <td>-0.409032</td>\n",
              "      <td>0.260482</td>\n",
              "      <td>-0.277124</td>\n",
              "      <td>0.102922</td>\n",
              "      <td>-0.210252</td>\n",
              "      <td>-0.037423</td>\n",
              "      <td>0.029499</td>\n",
              "      <td>0.104416</td>\n",
              "      <td>0.165190</td>\n",
              "      <td>-0.154018</td>\n",
              "      <td>-0.061375</td>\n",
              "      <td>0.052261</td>\n",
              "      <td>0.129714</td>\n",
              "      <td>-0.016616</td>\n",
              "      <td>-0.022097</td>\n",
              "      <td>0.105699</td>\n",
              "      <td>-0.111762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.895830</td>\n",
              "      <td>-1.888285</td>\n",
              "      <td>-0.036854</td>\n",
              "      <td>-0.006050</td>\n",
              "      <td>0.119070</td>\n",
              "      <td>-0.008976</td>\n",
              "      <td>0.108056</td>\n",
              "      <td>-0.022527</td>\n",
              "      <td>-0.028848</td>\n",
              "      <td>0.170903</td>\n",
              "      <td>-0.083485</td>\n",
              "      <td>-0.051184</td>\n",
              "      <td>0.041117</td>\n",
              "      <td>-0.055565</td>\n",
              "      <td>0.047334</td>\n",
              "      <td>-0.059557</td>\n",
              "      <td>-0.045411</td>\n",
              "      <td>0.093592</td>\n",
              "      <td>0.036876</td>\n",
              "      <td>-0.028558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.996519</td>\n",
              "      <td>-0.587328</td>\n",
              "      <td>-0.309866</td>\n",
              "      <td>-0.343356</td>\n",
              "      <td>0.891381</td>\n",
              "      <td>0.339134</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.052494</td>\n",
              "      <td>-0.160554</td>\n",
              "      <td>0.038198</td>\n",
              "      <td>0.066820</td>\n",
              "      <td>-0.026711</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.016461</td>\n",
              "      <td>0.058724</td>\n",
              "      <td>-0.003362</td>\n",
              "      <td>-0.075539</td>\n",
              "      <td>0.138385</td>\n",
              "      <td>-0.012593</td>\n",
              "      <td>-0.001673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.647370</td>\n",
              "      <td>-1.245622</td>\n",
              "      <td>-0.166432</td>\n",
              "      <td>0.515280</td>\n",
              "      <td>0.105636</td>\n",
              "      <td>0.183723</td>\n",
              "      <td>0.182418</td>\n",
              "      <td>-0.132266</td>\n",
              "      <td>-0.315006</td>\n",
              "      <td>0.097930</td>\n",
              "      <td>0.056246</td>\n",
              "      <td>0.337317</td>\n",
              "      <td>0.024939</td>\n",
              "      <td>-0.048987</td>\n",
              "      <td>-0.013325</td>\n",
              "      <td>-0.015493</td>\n",
              "      <td>-0.031741</td>\n",
              "      <td>-0.270518</td>\n",
              "      <td>-0.104466</td>\n",
              "      <td>0.078826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.077101</td>\n",
              "      <td>-1.052330</td>\n",
              "      <td>-0.259343</td>\n",
              "      <td>0.584375</td>\n",
              "      <td>0.466714</td>\n",
              "      <td>0.471585</td>\n",
              "      <td>-0.144931</td>\n",
              "      <td>0.281123</td>\n",
              "      <td>-0.052295</td>\n",
              "      <td>0.255867</td>\n",
              "      <td>-0.050871</td>\n",
              "      <td>-0.083271</td>\n",
              "      <td>-0.078085</td>\n",
              "      <td>0.001341</td>\n",
              "      <td>-0.195125</td>\n",
              "      <td>-0.020316</td>\n",
              "      <td>0.041219</td>\n",
              "      <td>0.029217</td>\n",
              "      <td>0.142422</td>\n",
              "      <td>-0.079658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.601267 -1.288475 -0.051051 -0.409032  0.260482 -0.277124  0.102922   \n",
              "1  0.895830 -1.888285 -0.036854 -0.006050  0.119070 -0.008976  0.108056   \n",
              "2 -0.996519 -0.587328 -0.309866 -0.343356  0.891381  0.339134 -0.161639   \n",
              "3  0.647370 -1.245622 -0.166432  0.515280  0.105636  0.183723  0.182418   \n",
              "4  0.077101 -1.052330 -0.259343  0.584375  0.466714  0.471585 -0.144931   \n",
              "\n",
              "         7         8         9         10        11        12        13  \\\n",
              "0 -0.210252 -0.037423  0.029499  0.104416  0.165190 -0.154018 -0.061375   \n",
              "1 -0.022527 -0.028848  0.170903 -0.083485 -0.051184  0.041117 -0.055565   \n",
              "2  0.052494 -0.160554  0.038198  0.066820 -0.026711  0.028572  0.016461   \n",
              "3 -0.132266 -0.315006  0.097930  0.056246  0.337317  0.024939 -0.048987   \n",
              "4  0.281123 -0.052295  0.255867 -0.050871 -0.083271 -0.078085  0.001341   \n",
              "\n",
              "         14        15        16        17        18        19  \n",
              "0  0.052261  0.129714 -0.016616 -0.022097  0.105699 -0.111762  \n",
              "1  0.047334 -0.059557 -0.045411  0.093592  0.036876 -0.028558  \n",
              "2  0.058724 -0.003362 -0.075539  0.138385 -0.012593 -0.001673  \n",
              "3 -0.013325 -0.015493 -0.031741 -0.270518 -0.104466  0.078826  \n",
              "4 -0.195125 -0.020316  0.041219  0.029217  0.142422 -0.079658  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "478383bf-afc0-4282-c1e6-924317a3b50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  5\n",
              "1  5\n",
              "2  5\n",
              "3  5\n",
              "4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "d50a954b-6dd8-4ee6-d15f-8dcab4e12e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "1702c919-fb76-41a7-ea8d-e5664dd9581a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "744514cb-7fd4-4316-8258-dbad538d3df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XnBnT6NdTqyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2d3b110-271c-44cd-8ad4-8dc25124cb6a"
      },
      "cell_type": "code",
      "source": [
        "20*90/36"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "352cfa1f-888c-4e35-f65b-fa0e8b6be971",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(50, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.95074262\n",
            "Iteration 2, loss = 0.40768669\n",
            "Iteration 3, loss = 0.36785070\n",
            "Iteration 4, loss = 0.34458895\n",
            "Iteration 5, loss = 0.33250029\n",
            "Iteration 6, loss = 0.32492560\n",
            "Iteration 7, loss = 0.31602461\n",
            "Iteration 8, loss = 0.31022870\n",
            "Iteration 9, loss = 0.30321219\n",
            "Iteration 10, loss = 0.29668668\n",
            "Iteration 11, loss = 0.29259674\n",
            "Iteration 12, loss = 0.28981648\n",
            "Iteration 13, loss = 0.28237008\n",
            "Iteration 14, loss = 0.27676422\n",
            "Iteration 15, loss = 0.27355262\n",
            "Iteration 16, loss = 0.26758509\n",
            "Iteration 17, loss = 0.26467467\n",
            "Iteration 18, loss = 0.25851363\n",
            "Iteration 19, loss = 0.25696537\n",
            "Iteration 20, loss = 0.25395678\n",
            "Iteration 21, loss = 0.24893087\n",
            "Iteration 22, loss = 0.24532578\n",
            "Iteration 23, loss = 0.24379364\n",
            "Iteration 24, loss = 0.24156889\n",
            "Iteration 25, loss = 0.23882958\n",
            "Iteration 26, loss = 0.23914027\n",
            "Iteration 27, loss = 0.23457658\n",
            "Iteration 28, loss = 0.23173433\n",
            "Iteration 29, loss = 0.23054574\n",
            "Iteration 30, loss = 0.22734081\n",
            "Iteration 31, loss = 0.22742927\n",
            "Iteration 32, loss = 0.22428501\n",
            "Iteration 33, loss = 0.22645777\n",
            "Iteration 34, loss = 0.21922461\n",
            "Iteration 35, loss = 0.21810316\n",
            "Iteration 36, loss = 0.21672321\n",
            "Iteration 37, loss = 0.21417549\n",
            "Iteration 38, loss = 0.21490680\n",
            "Iteration 39, loss = 0.21151040\n",
            "Iteration 40, loss = 0.21006523\n",
            "Iteration 41, loss = 0.21035758\n",
            "Iteration 42, loss = 0.20832934\n",
            "Iteration 43, loss = 0.20600904\n",
            "Iteration 44, loss = 0.20454652\n",
            "Iteration 45, loss = 0.20521039\n",
            "Iteration 46, loss = 0.20503524\n",
            "Iteration 47, loss = 0.20138200\n",
            "Iteration 48, loss = 0.20141667\n",
            "Iteration 49, loss = 0.19987018\n",
            "Iteration 50, loss = 0.19747397\n",
            "Iteration 51, loss = 0.19666531\n",
            "Iteration 52, loss = 0.19596888\n",
            "Iteration 53, loss = 0.19709708\n",
            "Iteration 54, loss = 0.19431888\n",
            "Iteration 55, loss = 0.19416356\n",
            "Iteration 56, loss = 0.19275202\n",
            "Iteration 57, loss = 0.19295534\n",
            "Iteration 58, loss = 0.19004691\n",
            "Iteration 59, loss = 0.19010823\n",
            "Iteration 60, loss = 0.19162169\n",
            "Iteration 61, loss = 0.18730362\n",
            "Iteration 62, loss = 0.18493162\n",
            "Iteration 63, loss = 0.18526362\n",
            "Iteration 64, loss = 0.18524466\n",
            "Iteration 65, loss = 0.18244430\n",
            "Iteration 66, loss = 0.18345577\n",
            "Iteration 67, loss = 0.18381467\n",
            "Iteration 68, loss = 0.18085034\n",
            "Iteration 69, loss = 0.18128665\n",
            "Iteration 70, loss = 0.17971048\n",
            "Iteration 71, loss = 0.17944994\n",
            "Iteration 72, loss = 0.17787072\n",
            "Iteration 73, loss = 0.17641098\n",
            "Iteration 74, loss = 0.17612699\n",
            "Iteration 75, loss = 0.17530516\n",
            "Iteration 76, loss = 0.17583348\n",
            "Iteration 77, loss = 0.17480372\n",
            "Iteration 78, loss = 0.17394294\n",
            "Iteration 79, loss = 0.17068555\n",
            "Iteration 80, loss = 0.17161057\n",
            "Iteration 81, loss = 0.17015480\n",
            "Iteration 82, loss = 0.17131631\n",
            "Iteration 83, loss = 0.16896311\n",
            "Iteration 84, loss = 0.17061081\n",
            "Iteration 85, loss = 0.16816616\n",
            "Iteration 86, loss = 0.16641030\n",
            "Iteration 87, loss = 0.16835225\n",
            "Iteration 88, loss = 0.16684512\n",
            "Iteration 89, loss = 0.16440606\n",
            "Iteration 90, loss = 0.16578737\n",
            "Iteration 91, loss = 0.16221365\n",
            "Iteration 92, loss = 0.16378680\n",
            "Iteration 93, loss = 0.16192391\n",
            "Iteration 94, loss = 0.16388635\n",
            "Iteration 95, loss = 0.16114762\n",
            "Iteration 96, loss = 0.16367723\n",
            "Iteration 97, loss = 0.16101316\n",
            "Iteration 98, loss = 0.15933302\n",
            "Iteration 99, loss = 0.16045387\n",
            "Iteration 100, loss = 0.15951001\n",
            "Iteration 101, loss = 0.15691568\n",
            "Iteration 102, loss = 0.15818791\n",
            "Iteration 103, loss = 0.15837329\n",
            "Iteration 104, loss = 0.15584391\n",
            "Iteration 105, loss = 0.15583827\n",
            "Iteration 106, loss = 0.15599273\n",
            "Iteration 107, loss = 0.15319245\n",
            "Iteration 108, loss = 0.15562912\n",
            "Iteration 109, loss = 0.15512648\n",
            "Iteration 110, loss = 0.15232538\n",
            "Iteration 111, loss = 0.15296338\n",
            "Iteration 112, loss = 0.15145067\n",
            "Iteration 113, loss = 0.15098276\n",
            "Iteration 114, loss = 0.15031846\n",
            "Iteration 115, loss = 0.15027724\n",
            "Iteration 116, loss = 0.14935966\n",
            "Iteration 117, loss = 0.15015494\n",
            "Iteration 118, loss = 0.14984951\n",
            "Iteration 119, loss = 0.14834641\n",
            "Iteration 120, loss = 0.14841561\n",
            "Iteration 121, loss = 0.14871887\n",
            "Iteration 122, loss = 0.15027818\n",
            "Iteration 123, loss = 0.14475348\n",
            "Iteration 124, loss = 0.14854944\n",
            "Iteration 125, loss = 0.14336146\n",
            "Iteration 126, loss = 0.14462108\n",
            "Iteration 127, loss = 0.14434297\n",
            "Iteration 128, loss = 0.14356984\n",
            "Iteration 129, loss = 0.14154698\n",
            "Iteration 130, loss = 0.14273714\n",
            "Iteration 131, loss = 0.14178325\n",
            "Iteration 132, loss = 0.14399314\n",
            "Iteration 133, loss = 0.14456158\n",
            "Iteration 134, loss = 0.14087202\n",
            "Iteration 135, loss = 0.14034021\n",
            "Iteration 136, loss = 0.14056923\n",
            "Iteration 137, loss = 0.13947551\n",
            "Iteration 138, loss = 0.13820539\n",
            "Iteration 139, loss = 0.13862573\n",
            "Iteration 140, loss = 0.13675965\n",
            "Iteration 141, loss = 0.13634741\n",
            "Iteration 142, loss = 0.13758536\n",
            "Iteration 143, loss = 0.13656693\n",
            "Iteration 144, loss = 0.13617684\n",
            "Iteration 145, loss = 0.13668260\n",
            "Iteration 146, loss = 0.13407951\n",
            "Iteration 147, loss = 0.13524165\n",
            "Iteration 148, loss = 0.13269198\n",
            "Iteration 149, loss = 0.13319225\n",
            "Iteration 150, loss = 0.13297231\n",
            "Iteration 151, loss = 0.13461861\n",
            "Iteration 152, loss = 0.13270776\n",
            "Iteration 153, loss = 0.13331697\n",
            "Iteration 154, loss = 0.13484333\n",
            "Iteration 155, loss = 0.13042394\n",
            "Iteration 156, loss = 0.12956801\n",
            "Iteration 157, loss = 0.13188497\n",
            "Iteration 158, loss = 0.12823179\n",
            "Iteration 159, loss = 0.12833942\n",
            "Iteration 160, loss = 0.12958848\n",
            "Iteration 161, loss = 0.13066224\n",
            "Iteration 162, loss = 0.12597281\n",
            "Iteration 163, loss = 0.12552055\n",
            "Iteration 164, loss = 0.12672183\n",
            "Iteration 165, loss = 0.12584478\n",
            "Iteration 166, loss = 0.12604925\n",
            "Iteration 167, loss = 0.12353436\n",
            "Iteration 168, loss = 0.12807580\n",
            "Iteration 169, loss = 0.12233480\n",
            "Iteration 170, loss = 0.12391715\n",
            "Iteration 171, loss = 0.12343118\n",
            "Iteration 172, loss = 0.12162751\n",
            "Iteration 173, loss = 0.12236546\n",
            "Iteration 174, loss = 0.12448056\n",
            "Iteration 175, loss = 0.12086769\n",
            "Iteration 176, loss = 0.11980328\n",
            "Iteration 177, loss = 0.12051658\n",
            "Iteration 178, loss = 0.11831469\n",
            "Iteration 179, loss = 0.11833034\n",
            "Iteration 180, loss = 0.11806005\n",
            "Iteration 181, loss = 0.12028357\n",
            "Iteration 182, loss = 0.11900392\n",
            "Iteration 183, loss = 0.11885993\n",
            "Iteration 184, loss = 0.11994181\n",
            "Iteration 185, loss = 0.11720171\n",
            "Iteration 186, loss = 0.11505591\n",
            "Iteration 187, loss = 0.11379610\n",
            "Iteration 188, loss = 0.11443438\n",
            "Iteration 189, loss = 0.11537570\n",
            "Iteration 190, loss = 0.11728507\n",
            "Iteration 191, loss = 0.11493212\n",
            "Iteration 192, loss = 0.11455919\n",
            "Iteration 193, loss = 0.11469774\n",
            "Iteration 194, loss = 0.11389851\n",
            "Iteration 195, loss = 0.11142616\n",
            "Iteration 196, loss = 0.11165826\n",
            "Iteration 197, loss = 0.11095011\n",
            "Iteration 198, loss = 0.11164786\n",
            "Iteration 199, loss = 0.11068664\n",
            "Iteration 200, loss = 0.11190760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "6ef0c89a-7adc-4b37-a1c8-767aba0c833a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.958118556701031"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "0cfff49a-d89b-49b5-a5ed-38684818f50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8812922614575507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "9da23e6e-7748-4206-82f0-c6b252b386da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "10d39fac-ce73-4e7e-b875-c50516f9ceee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 36 -> 90 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "47d29297-4e0d-4d11-c58f-a38c5520badf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "f897237b-83f0-4d7f-9850-e3d839623133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.train.GradientDescentOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "caa0ef5d-3d2f-498d-d21b-6623a8423fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "hid_neuron = [374]\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-4106bc23d37b>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.09654394, training acc= 96.49999737739563%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1000, training loss= 0.074345045, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2000, training loss= 0.0795926, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 3000, training loss= 0.09808998, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 4000, training loss= 0.07493803, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 5000, training loss= 0.095866315, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 6000, training loss= 0.07703011, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 7000, training loss= 0.074125834, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 8000, training loss= 0.099417955, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 9000, training loss= 0.09222789, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 10000, training loss= 0.08109907, training acc= 96.49999737739563%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 11000, training loss= 0.11149396, training acc= 95.49999833106995%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 12000, training loss= 0.06741232, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 13000, training loss= 0.109245956, training acc= 95.99999785423279%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 14000, training loss= 0.07493451, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 15000, training loss= 0.090577155, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 16000, training loss= 0.13477787, training acc= 94.49999928474426%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 17000, training loss= 0.07381674, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 18000, training loss= 0.07977779, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 19000, training loss= 0.102517195, training acc= 95.99999785423279%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "Test acc= 89.450005 %\n",
            "Valid acc= 88.805405 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5A_PHV3bS7ui"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G5BxkTLzUAok"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-testÂ¶"
      ]
    },
    {
      "metadata": {
        "id": "mejHTwMYhEzu",
        "colab_type": "code",
        "outputId": "3c9dce5f-d9f2-4e0b-ffc1-0742cf485d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(validation_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1331, 20)\n",
            "(3104, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 50\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xguK-SPLUrkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgzAMkJCXVq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc954b0b-b6de-4577-c1bd-9da9c6fda00d"
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "qT_XdektXjmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plt.scatter(np.argmax(valid_validation_data_label,axis = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RS8J8lVeXGoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "830921be-9bb0-4664-91bc-ec21f7fb7557"
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(valid_validation_data_label,axis = 1))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([262.,   0.,  89.,   0., 152.,   0., 103.,   0., 165., 229.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CWpuf8GKxxT4b3UCxMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AJtaOCHUc8Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6357ac95-1c50-46bd-f491-cd82ec9f8ff7"
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "KrEu6ndlUZh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "id": "Q5TyGgw4Ub9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219929
        },
        "outputId": "4e43875f-a65d-4a4e-ad53-8c41d329c985"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "# hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 2056\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "number_of_epoch = 10000\n",
        "# learning_rate = 0.001\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "number_of_ex = train_data.shape[0]\n",
        "\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,7):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for ep in range(0,number_of_epoch):\n",
        "              if ep<5000:\n",
        "                learn = .1\n",
        "              elif ep >=5000 and ep <= 8000:\n",
        "                learn = .01\n",
        "              else:\n",
        "                learn = .001\n",
        "              for step in range(0, total_steps_for_one_pass):\n",
        "\n",
        "                if step>=number_of_ex//batch_size:\n",
        "                  batch_x, batch_y = train_data[step*batch_size:,:],train_label_one_hot[step*batch_size:,:]\n",
        "        #           print(step,'Finishing',step*batch_size )\n",
        "                  step = 0\n",
        "\n",
        "                else:\n",
        "\n",
        "                  start = step*batch_size\n",
        "                  finish = (step+1)*batch_size\n",
        "        #           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "                  batch_x, batch_y = train_data[step:finish,:],train_label_one_hot[step:finish,:]\n",
        "        #         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})              \n",
        "\n",
        "\n",
        "\n",
        "  #                 batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "  #                 sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "              if ep % plot_every == 0:\n",
        "                  train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                  print(\"epoch \" + str(ep) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                  train_losses.append(train_loss)\n",
        "                  validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                  if ep%plot_every == 0:\n",
        "                    print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                    print()\n",
        "                    if (validation_accuracy >= best_accuracy_valid):\n",
        "                      best_accuracy_valid = validation_accuracy\n",
        "                      saver.save(sess, './statimgTrack')\n",
        "                      G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.9150815, training acc= 95.03816962242126%\n",
            "Validation Accuracy valid 88.5999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.12016836, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.118887745, training acc= 96.66030406951904%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.09064041, training acc= 96.37404680252075%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.09162044, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 500, training loss= 0.09455323, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 600, training loss= 0.08354485, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 700, training loss= 0.07257748, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.07828987, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.0790963, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.075024165, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07240203, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07234976, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1300, training loss= 0.07008555, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.065668546, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06594175, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1600, training loss= 0.07262583, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06806636, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05773904, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.07106125, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05929519, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05889862, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.061417338, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.063680395, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05360244, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.06705624, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.06199862, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2700, training loss= 0.055146687, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.05775627, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.06507853, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3000, training loss= 0.057983246, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.050059438, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04675559, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050930023, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04672075, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.057329148, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.07568937, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.049789604, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0954627, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 3900, training loss= 0.048054732, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05983208, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04238107, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04574001, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04248075, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04490391, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.047794055, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04695217, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.043566104, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.051227883, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.049482197, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.037813045, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.035874918, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.035634037, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03547001, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.035335053, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03525114, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.035061296, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.034900777, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.034762874, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03463647, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.0345174, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03440325, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03429325, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03418932, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.034092065, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.033998564, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.0339075, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.033820882, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03373704, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.033653997, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03356785, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.033466578, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033362243, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.033267844, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033180255, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03309781, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.03301402, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03293759, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03285597, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03278219, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.032709613, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.0327076, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.032701436, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.032695025, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.032688223, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03268104, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.032673948, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.032666966, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03265971, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03265236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.032645144, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03263817, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.032631308, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03262425, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03261755, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.032610964, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.032603987, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.032597154, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03259062, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.032583993, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.29057947, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.10349335, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.083668254, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.07876873, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07510009, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07251558, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07058575, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.069096506, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06778329, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.066618405, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.066023424, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06458697, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06364812, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06729769, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06197762, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.061475717, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.060674638, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.060071822, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06750201, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.05855816, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.058127236, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05746735, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.056692954, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.056120045, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.055508014, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05496381, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.054528236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.053728234, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.053269487, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.052816726, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05212746, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05168911, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.052264743, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050591554, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05019, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049909886, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048928976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04861131, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04824906, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04918903, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.047335416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04676672, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.047585063, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.045897808, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.045512944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04510819, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.044890642, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04473425, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.043976422, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04372362, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.043338194, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043416947, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.043401077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.043375976, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.043348994, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.043320872, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04329239, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.043263435, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04323496, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.043205902, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.043176122, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04314615, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04311704, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04308718, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.043057542, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.043028243, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.0429992, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042970177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042940304, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042911403, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04288143, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042851955, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042821795, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042792123, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04275985, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042729482, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04270045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04267198, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.042643003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04261358, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04258507, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.042588796, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.042588204, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.042586114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04258378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.042581316, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.042578608, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04257576, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.042572886, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.042570047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.04256729, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04256442, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.042561546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.042558752, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.042555943, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.042553093, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04255031, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.042547535, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.042544745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04254201, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.5222546, training acc= 95.61068415641785%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.118043736, training acc= 96.56488299369812%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.10341528, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.09091846, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.08816008, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.07878174, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.0808832, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.07490067, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.07613469, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.07219856, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07136464, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06746526, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06953283, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.07336679, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.05994135, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06070858, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06397424, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06433098, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061861277, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1900, training loss= 0.071441054, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.07380435, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.06380777, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.056412637, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.054762796, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.053822596, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.055236273, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.051456258, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.0673295, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.06442732, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.07414694, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05015446, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 3100, training loss= 0.06211905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.05416292, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04656893, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.047249883, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049369834, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.051475927, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04795309, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04540816, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.094655186, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.044802804, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04453785, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04860235, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 4300, training loss= 0.042509254, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.041909296, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04488206, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0416757, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.05747696, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.040805697, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.040412683, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03974082, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.039573975, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5200, training loss= 0.039522585, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03946669, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5400, training loss= 0.039405387, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5500, training loss= 0.039341193, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5600, training loss= 0.039277904, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03921651, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5800, training loss= 0.039157115, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5900, training loss= 0.039097514, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 6000, training loss= 0.039036926, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 6100, training loss= 0.038977653, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03891594, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.038848523, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03877805, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.038712922, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.038645044, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03857889, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.038513906, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.038444564, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.038366493, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03827401, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03816081, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.038055528, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.037955593, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.037862085, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.037770346, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03768351, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.037601177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.037521876, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03743924, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.037435018, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.037428655, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.037421685, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.037414458, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03740698, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.037399318, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03739155, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.037383653, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.0373758, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.037367955, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03736029, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03735253, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.037344623, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.037336722, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.037328783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.037321027, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.037313204, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.037305344, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.037297565, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "Valid acc= 89.9 %\n",
            "Validation Accuracy Test 82.77945709228516 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.54311776, training acc= 95.41984796524048%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.11521304, training acc= 96.46946787834167%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 200, training loss= 0.09610859, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.103076436, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 400, training loss= 0.09305864, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.09981238, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.081584044, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.074774764, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 800, training loss= 0.076553695, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.071986616, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07141673, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.0694324, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06911296, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06688972, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.065516815, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.07051554, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06138834, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05624954, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05505816, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06333246, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05747323, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.060234975, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.0549418, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05694003, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.060289975, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 2500, training loss= 0.050314534, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05450357, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.048221257, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2800, training loss= 0.056497674, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 2900, training loss= 0.055628993, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.047430974, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05735595, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.05078357, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05912713, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.060169227, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 3500, training loss= 0.058898468, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.051484823, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043840267, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.048059184, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.041509707, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.041647658, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.042318147, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04033817, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.05325092, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.040590163, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03780536, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.037592947, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4700, training loss= 0.046274897, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037138052, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.047020327, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03585083, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5100, training loss= 0.035533078, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.035373468, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03523984, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.035128992, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.035034865, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.0349491, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03487212, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.034799587, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.034728315, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.034657042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.034589317, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03452893, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03446905, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03441074, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.034354508, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.034297828, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03424197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03418774, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.034137517, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.034089357, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.034041595, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033992764, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.033945665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033899646, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.033853024, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.0338055, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.033754487, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03370497, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033655725, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.033606913, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033609048, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.033606414, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033602323, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03359805, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.033593565, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033589084, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.033584457, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.033579815, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.033575173, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.033570513, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033565808, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.033561114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.033556532, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.033551957, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.033547536, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.033543125, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.033538662, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.033534165, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.033529684, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.2441052, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.093770824, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.08563927, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.0808557, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.078114934, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.07555672, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.07385984, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.072494105, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.07131848, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.07029215, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06925931, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06819333, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.0672485, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.066455826, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06573725, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06504591, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06449709, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.063686006, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.0630862, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06233403, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.066238984, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.061165407, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.060929623, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.060191706, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.059781324, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.059199426, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.06094254, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.058125503, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.057627067, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05730509, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.056470554, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05607514, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.055624656, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.055336162, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.054627586, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.053889517, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.053368192, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05365575, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.052333754, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.053390216, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05150371, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.051421143, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.050716244, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.05031413, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.049889185, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.05073482, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.049280237, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.049520083, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.048212975, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.048412193, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.047499098, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.047443546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.047419976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.047391854, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.047362708, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.047330942, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.047296446, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04726118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.047226053, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.047191445, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.047154635, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.047119807, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.047084957, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04704946, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.047015272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.046981458, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.046947315, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.046912618, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.0468783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.046844047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.046809286, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.046775628, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04674049, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.046705272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04667175, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.046637915, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04660396, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04657035, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.0465357, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.046501245, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04646707, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.046469003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.046467416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.046465386, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.046463143, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.04646084, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.046458334, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04645548, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.046452597, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04644957, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.046446487, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04644354, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.046440516, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.046437424, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.046434138, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.046431117, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.046428077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.046424877, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.046421647, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.046418488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.4221513, training acc= 95.99236845970154%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.12249136, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.10208938, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.09074896, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.087219596, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.081811205, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.077516146, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.07536497, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.07429996, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.07820909, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06916004, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06804775, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07085543, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06580289, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06663633, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.07295916, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06389346, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06314434, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.063159905, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06029315, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06000365, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.07507173, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.057674, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.058299888, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.058167692, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.057692945, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05617372, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2700, training loss= 0.056021716, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2800, training loss= 0.053848427, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.062075622, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.055235565, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.051837068, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.05174767, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05313937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.054793157, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.05164633, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.049922407, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.051852267, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.050743867, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.05011445, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.049204767, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.047483213, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.047772296, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.047772363, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.046154402, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04648416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.045618523, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04554407, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.045716226, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.045227922, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.044192057, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043753654, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04357507, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.043450754, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.043358777, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.043284528, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.043216687, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04315951, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.043107457, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.043058824, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.04301199, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04296625, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.0429206, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.042877685, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.042833354, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.042789467, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.042749107, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042707942, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042667508, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042626895, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.042586498, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042544797, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042503517, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042461384, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04241981, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.04237889, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.042338002, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.042297795, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.04225764, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.042218175, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.042179503, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04218034, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04217769, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.042174466, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.042170975, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.042167347, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.042163696, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.042160217, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.042156648, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.042153075, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.04214928, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.0421456, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.042141866, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.042138215, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.04213453, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.042130876, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04212714, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.042123426, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.042119753, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.042116057, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3213906, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.09204254, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.08140594, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.076844595, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07252051, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.07024521, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.068379484, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.066895686, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06551955, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.06438416, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06331889, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.062311716, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06119581, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06016621, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.059179902, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05859953, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.058358144, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.056920268, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.056996018, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.055652793, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.09430905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05506758, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.054024108, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.053493947, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.07466127, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.055315662, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.052142005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.051659435, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.051186174, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05121621, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.050600436, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.074883536, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.050571557, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.049352862, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04876898, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04829197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.047706746, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.047819536, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04712637, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04640622, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.046217173, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04570648, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04591527, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.057347607, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.044430032, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.044626255, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.045634758, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04524895, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04403489, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04352062, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.042322207, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04233479, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.042304937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04227454, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.042243626, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04220648, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.042171504, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04213699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04210284, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.042070784, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.042037096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04200424, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.041969728, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.041936465, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04190309, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.041870743, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04183739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.04180419, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.041772686, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.041740905, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.041710027, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04167626, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04164384, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.041612756, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.041581932, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.041549888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.041518208, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.041487522, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.041455757, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.041425046, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.041394696, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04140176, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.041402318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04140037, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04139782, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.041395217, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.041392516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.041389752, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.041387003, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.041384242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.041381504, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.041378643, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.041375782, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04137295, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.04136998, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04136717, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04136417, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.041361257, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.041358296, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04135532, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.45476198, training acc= 95.61068415641785%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.15655866, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.09385951, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.08564599, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.08176576, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07638708, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07279435, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.07326196, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.07005473, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.07170398, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.0719941, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06368231, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07512518, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1300, training loss= 0.061884712, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.058617454, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05810561, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.060907256, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05865808, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.059248265, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.068798386, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.056781095, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.058536794, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.053926304, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2300, training loss= 0.052814968, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05127193, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.052377906, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.049904417, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05509484, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.057884373, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2900, training loss= 0.049236163, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.051581338, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.051316693, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.050236315, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04628104, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.051830586, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.046342995, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.058094874, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3700, training loss= 0.09567814, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.046587184, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.047463045, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043503366, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.05439218, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4200, training loss= 0.041929252, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.044414014, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.047240242, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.043468624, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04361087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4700, training loss= 0.046574276, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04036051, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04231353, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.039137743, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.039018847, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.038933173, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.0388554, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.038778458, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03871213, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.038644545, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.038582213, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03852018, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03845843, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03840081, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.038345776, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.038291365, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.038234994, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.038181923, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.038131297, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.03807969, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.038030006, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.037979975, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.037931133, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.037884064, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.037836783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.037790455, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03774441, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.037699807, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03765635, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.037612326, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03756897, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.037527204, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.037484758, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.037442856, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03744583, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03744428, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.037441432, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03743836, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.037434936, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.037431605, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.037428074, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.037424363, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03742061, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.03741686, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.037413016, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03740926, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.037405465, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.037401628, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03739782, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.037394032, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.037390105, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.037386272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.037382297, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.4596848, training acc= 95.61068415641785%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.1182061, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.09144482, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.11965976, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07992923, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.08109244, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.0734877, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 700, training loss= 0.07279587, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.07096236, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.067533135, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07225134, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.066778615, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.08669479, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06613244, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.05707468, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1500, training loss= 0.056809317, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.058743894, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05766614, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061553232, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.054104865, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.051488254, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.056245625, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.06063314, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04975105, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.04896972, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.051835038, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.0465117, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.045357056, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.045840032, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.06531952, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044217307, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.04372923, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.043210436, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.059804663, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.043382924, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.061923668, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 3600, training loss= 0.04058916, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04198202, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.044580292, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.07845871, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.038852867, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.12612659, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03911658, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.037531205, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.036977656, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.03689925, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.036308527, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.040876742, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.041193474, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.035818975, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03515756, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 5100, training loss= 0.035147358, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.035081778, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.035021048, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.034951, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.034838315, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.034734778, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.034646403, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.034570273, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.034501087, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03443775, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.034375563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.034316678, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.034259938, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.034203794, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.034148715, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.034094527, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.034043945, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03399591, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.033949003, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.033903725, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.033860255, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.033820964, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03378242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.033743337, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.033702552, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.033660647, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03362023, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.033580158, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.033540197, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03350139, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.033502784, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.033500593, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.033497524, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03349408, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03349052, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.033486728, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03348301, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.033479363, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.033475734, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.033472043, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.033468287, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03346451, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03346075, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.033456847, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.0334529, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.0334491, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.0334453, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.033441424, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03343759, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.21693626, training acc= 96.27862572669983%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 100, training loss= 0.09238733, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.085592546, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.0806169, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.078001395, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.07627325, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07442304, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.07294352, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.0717822, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07066724, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.069794126, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06896039, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.068019524, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06733727, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06662965, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06587456, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06526453, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06454897, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06414734, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06362013, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.062875934, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.06227693, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.06175793, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.0611809, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.060624134, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2500, training loss= 0.06006081, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.059589364, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.059144814, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.058611352, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05808728, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.0575907, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05713439, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.056688227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.056231547, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.055752706, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.05533097, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.05485489, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.054470915, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.054042745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.053614344, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05318156, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.052757006, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.052360423, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.051944952, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.051559668, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.051167298, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.05077771, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.050424904, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.05008484, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.049715254, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04927361, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.049322993, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.049304392, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.049280938, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04925325, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.049222466, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04919016, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.049156856, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.049122427, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.04908768, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.049053427, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.049016643, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.048979178, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.048941962, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.048905578, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.04887018, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.048834037, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.048798334, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.048763197, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.048728693, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.048694205, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04865975, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04862574, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.04859112, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.048557464, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.048524242, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04849026, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04845528, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.048420448, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04838594, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.048351135, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.048354637, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.048353896, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04835213, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.048349544, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.048346877, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.048344214, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04834139, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.0483384, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04833519, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.048331946, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04832859, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.048325278, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.048321906, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.048318606, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04831523, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.048311885, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.048308406, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.048305, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.048301693, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3575446, training acc= 95.99236845970154%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.11715017, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.12209351, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.09653197, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.08688208, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.082664736, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07912777, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.079006076, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.07521101, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.07353484, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.0711872, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06952988, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07283454, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06926199, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06511129, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06460504, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.063074976, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06302683, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061461918, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.062070526, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.059906673, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.061815705, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2200, training loss= 0.058941603, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05806614, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05738707, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.06333522, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.056587126, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05732733, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.05754193, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.06231351, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.054312415, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05592775, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.053261362, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.055670723, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.052413337, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.081105195, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.05448073, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.051022418, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.050885692, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.051939584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04971116, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.049331166, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.048866384, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04917052, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.048011117, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04763361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04726165, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.0468869, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04672502, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.046249386, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.046121605, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.046102405, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04602813, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.045972478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04591657, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04586885, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.0458214, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.045772087, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.045688134, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.045511585, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.045446783, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04538972, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.045338668, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.045291387, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.045247808, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.04520545, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.045164242, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.045122564, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.045081608, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.045042243, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04500238, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04496146, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04492144, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.044883564, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.044843458, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.04480447, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.044766918, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.044730157, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.044692688, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.044657584, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.044620782, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.044629555, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04463076, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04462893, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.044626366, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.044622958, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.04461935, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.044615604, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.044612035, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04460838, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.044604745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.044601075, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.044597488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04459391, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.044590246, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04458663, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.044583045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.044579547, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.044575937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.044572234, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.29057947, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.10349335, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.083668254, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.07876873, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07510009, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07251558, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07058575, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.069096506, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06778329, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.066618405, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.066023424, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06458697, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06364812, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06729769, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06197762, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.061475717, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.060674638, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.060071822, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06750201, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.05855816, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.058127236, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05746735, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.056692954, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.056120045, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.055508014, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05496381, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.054528236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.053728234, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.053269487, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.052816726, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05212746, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05168911, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.052264743, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050591554, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05019, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049909886, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048928976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04861131, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04824906, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04918903, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.047335416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04676672, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.047585063, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.045897808, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.045512944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04510819, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.044890642, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04473425, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.043976422, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04372362, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.043338194, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043416947, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.043401077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.043375976, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.043348994, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.043320872, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04329239, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.043263435, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04323496, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.043205902, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.043176122, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04314615, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04311704, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04308718, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.043057542, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.043028243, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.0429992, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042970177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042940304, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042911403, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04288143, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042851955, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042821795, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042792123, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04275985, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042729482, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04270045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04267198, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.042643003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04261358, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04258507, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.042588796, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.042588204, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.042586114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04258378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.042581316, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.042578608, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04257576, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.042572886, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.042570047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.04256729, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04256442, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.042561546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.042558752, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.042555943, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.042553093, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04255031, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.042547535, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.042544745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04254201, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.39237782, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.114809655, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.096038915, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.0960032, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.089585416, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.07935611, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07415055, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.084594086, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.07156071, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.075134315, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06761743, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.0664275, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.072623156, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.070117384, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06456705, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06989213, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06658271, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.060658403, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061537363, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.0717649, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.057849955, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.065125674, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.059853066, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.057605408, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.056301244, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05438047, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.055055916, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.062307306, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.055636086, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.059076894, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.054338776, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.052958444, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.054703776, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050734624, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05158166, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.051210847, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.0583902, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.050796885, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.047835097, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.048091043, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.051745262, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.047698725, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.06776992, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4300, training loss= 0.055159885, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04624252, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.045169607, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.044658765, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.044049345, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04541885, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.043952886, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.043820683, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04302797, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.042804502, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.042687602, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.042608727, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.042517796, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.042398445, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04228313, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.042175185, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.042079758, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.041983858, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.041893546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04181448, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.041743305, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.041675676, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.041611575, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04155151, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.041495074, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.041442066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.04139089, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.041340757, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.041292053, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.041244905, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.041197233, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.041149776, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.0410906, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04104154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.040994003, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.040949553, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.040905446, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04086405, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04086688, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.040864646, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.040861268, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.040857702, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.04085402, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.040850278, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04084655, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04084282, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.040839043, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.04083535, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.040831674, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04082799, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04082435, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.040820695, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04081698, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.040813524, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.040810026, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.040806558, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04080301, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3328747, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.10083821, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.08066272, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.074984774, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.071649335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.069351144, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.06763187, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.06596762, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.064813614, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.063737765, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06217225, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06102118, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.059850454, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.059141032, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057901196, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.057462227, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.056434937, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.0562021, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05541783, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.07042962, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.0632589, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.053195756, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.052613053, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.052382387, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.051641393, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05240695, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05098287, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050068535, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04951735, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.048974283, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04850286, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.048088126, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.04759024, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.047298845, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.046812, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.046500765, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.046198394, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04699184, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.05594648, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.045216497, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.044459675, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.044282787, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.049470495, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.043665595, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.043269616, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.042980917, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4600, training loss= 0.042481788, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.042300235, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04231752, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.042314038, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04133165, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.041305467, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04129039, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.041260116, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.041228335, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.041197505, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.041168056, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.041140534, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04111333, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.041086424, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.041059446, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.041035265, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.041010063, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04098608, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.0409609, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.040936567, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.040913433, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.040887445, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.040860027, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.04082882, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.040798463, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04076633, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.040735323, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.040703252, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.040669944, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.0406387, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.040605485, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.040573806, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.04054092, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.0405074, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.040475298, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.040481746, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04048105, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.040479045, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.040476825, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.040474296, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.04047139, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.040468466, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04046564, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04046267, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.040459543, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04045663, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.040453542, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.040450484, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.040447306, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04044433, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.0404412, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.040438045, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.04043486, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04043185, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.41838962, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.1077401, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.0903072, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.0911858, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07817919, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.07804516, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 600, training loss= 0.07389604, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.07814892, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.07499411, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.07149152, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.12744474, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.065631725, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07716484, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.059575427, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.094425984, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.060344327, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.059875067, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.056984697, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.056710068, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06879221, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.053193882, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05247909, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2200, training loss= 0.052361477, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05331679, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.061516084, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.052839223, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.056201123, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.06620609, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.06337766, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.047880534, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.047639422, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.04973967, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.050269235, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04585715, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.07144378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04800279, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.044506095, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04528719, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.044007756, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04842861, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04326542, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.042336073, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04360807, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.059112154, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04275086, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.040661074, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.040930804, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.044600125, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.039662603, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.039410464, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.039246302, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.039060302, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.038979284, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.038930085, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.038882103, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.038841628, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.038805265, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.038764548, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.038724925, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.038683597, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.038642276, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.038601182, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03856191, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.0385238, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03848519, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.038447313, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.038410865, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.038372926, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.038335014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.038298246, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03826223, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.038226616, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03819055, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.038154714, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.0381189, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.038083993, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.038048673, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.038012795, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03797713, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03794215, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03790698, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.037908062, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.037906308, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.037903845, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.037901014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.037898034, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03789497, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.037891615, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.037888255, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.03788486, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.03788146, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.037878007, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.037874486, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03787105, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.037867635, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.037864204, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.037860896, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.0378576, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.037854236, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03785091, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.43850502, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.1068455, training acc= 96.94656729698181%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.08975268, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.08128909, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.077165164, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.070894554, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.06742377, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.067855805, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.09683136, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.06268761, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.11546576, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.060883947, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.05863085, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.0638318, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.15527362, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.054224517, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.054057498, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05319175, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.051894534, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.053624794, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.051118974, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.06009235, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2200, training loss= 0.060385037, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.04757717, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.050111532, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.04592772, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04627602, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.04487159, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04603215, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.044663377, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044401027, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.045240737, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.054178156, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04362974, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.046578623, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.06057047, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.04860533, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04216959, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0418153, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04400443, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.042001467, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.046932448, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.042823777, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04141154, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.03878666, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04024588, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.03834212, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.03816195, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037709534, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037230264, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.037233308, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036968935, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036895294, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036828298, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036768474, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.036715288, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.036668915, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.0366236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.036580972, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03653966, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036499336, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646134, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036423136, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03638694, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.036350634, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03631581, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036280543, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.036247063, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036213174, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.036180425, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03614746, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03611516, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03608351, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03605111, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03601972, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03598668, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.035955112, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.035923332, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.035890542, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.035858348, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03582574, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.035824977, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035822414, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03581953, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035816547, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035813402, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035810314, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03580715, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03580412, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035800952, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.0357978, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035794754, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035791624, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035788465, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.035785187, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.035781976, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03577895, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035775974, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03577284, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035769783, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.20099318, training acc= 96.37404680252075%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.09267157, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 200, training loss= 0.08616876, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 300, training loss= 0.08201096, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 400, training loss= 0.07909545, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 500, training loss= 0.07722579, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07588711, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.07447218, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.07329413, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07223427, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.071297765, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07041703, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06954881, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06876553, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06802715, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06731744, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.066655055, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06604873, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06545686, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06486031, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06426968, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.063705884, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.0631649, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.062620245, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.062095135, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.061595127, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.061099634, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.060638495, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.060204368, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.059754502, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05930076, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.058824837, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.058361974, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05792971, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05750264, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.05706626, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.05661743, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.056192532, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.055749282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.055328533, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.054898914, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.05447745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.054045796, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.05362962, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.05320641, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.052812755, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.052418582, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.052048087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.051709056, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.05134156, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.05097373, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.05100101, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.05097293, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.050942875, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.05090825, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.050873064, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.050836585, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.05079995, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.050764572, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.05072943, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.050694287, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.05065944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.050625086, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.050590973, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.0505574, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.050523188, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.05048972, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.050455358, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.050422072, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.050388493, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.05035476, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.050320722, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.050286617, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.05025388, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.050219696, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.050186228, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.050154056, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.050120495, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.050088238, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.050054558, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.05002082, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.050024778, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.050023686, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.050021585, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.050019037, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.0500163, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.050013416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.050010465, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.050007414, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.050004374, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.050001413, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04999822, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04999514, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.049992055, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.049988937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.049985714, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.049982555, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.04997932, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.049976088, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04997293, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3227419, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.12553386, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.12219666, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.08937545, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.08740448, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.08524411, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.08052223, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 700, training loss= 0.078431524, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.07582734, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07412074, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.072763555, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07147255, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07037021, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06939065, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06902835, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06843861, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06660643, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06546803, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06457804, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.064084485, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06323772, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.062534645, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.061863977, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.06603572, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.060789302, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.06011147, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05960211, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.064714864, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.059616312, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.058305215, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05777045, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05708649, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.059616342, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05762592, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.056226354, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.057386443, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.055268556, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.054677475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.054194648, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.054291196, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.059577633, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.052970544, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.05269481, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.052175805, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.051652275, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.051444154, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.05642858, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.051019706, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.050440032, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.049243636, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04983196, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04881949, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.048742708, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04866741, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.048598383, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04853096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.048469562, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.048407357, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04835031, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.048294257, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.048240013, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.048185844, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04813159, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.048076298, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04802125, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.047966845, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04791293, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.047858942, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.047806673, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.047754053, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.047703497, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.047651634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.047600035, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.04754859, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04749562, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.047442865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04738839, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.047333155, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.04727609, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.047216024, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04715596, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.047159694, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.047153454, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.047147408, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.047141638, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.047135852, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.047129933, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.047123946, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.047117744, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04711158, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.047105324, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.047099028, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04709265, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04708626, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.047079686, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.0470732, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.047066703, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.047060076, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.047053736, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.047047213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.26471397, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.09805687, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.08476842, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.08000073, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.07669948, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.07420372, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07232421, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.07084738, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.069619216, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.068468854, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06751526, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06654578, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.065692075, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06483778, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.064051375, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06334534, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06428523, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.061966836, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.061300978, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06069418, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2000, training loss= 0.060210757, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.059522454, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.058934405, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05841747, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.057881135, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.057290196, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.056745272, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05628306, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.055638894, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05512492, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.054715414, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05431313, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.05375694, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.054309163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.053869475, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.05374316, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.053398464, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05207391, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.050769303, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.050201103, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.050309535, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.049303755, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.048844382, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.048433956, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04808186, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.047687743, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04748831, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04695489, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.046504732, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.046167158, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04574945, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.045824755, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04579798, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04576765, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04573761, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5500, training loss= 0.045706067, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5600, training loss= 0.045674272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5700, training loss= 0.045641378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04561009, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 5900, training loss= 0.04557883, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6000, training loss= 0.045548182, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04551687, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.045484915, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.045452006, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04541966, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6500, training loss= 0.04538818, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6600, training loss= 0.045355607, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6700, training loss= 0.045323867, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6800, training loss= 0.045292087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 6900, training loss= 0.04525997, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04522923, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7100, training loss= 0.045197733, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7200, training loss= 0.045165755, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7300, training loss= 0.045132946, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7400, training loss= 0.045099653, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7500, training loss= 0.04506621, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04503395, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.045001347, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.044968482, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.044936754, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.044904154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.044908293, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04490689, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.0449042, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.044901565, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.044898894, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.04489595, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.044892956, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.044889934, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.044886865, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.044883795, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.044880714, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.044877525, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.044874404, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.044871226, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.044868194, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04486518, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.04486213, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.044859085, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.044855926, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.35972834, training acc= 95.99236845970154%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.15455264, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.09761023, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.084698334, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.09501436, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.077955015, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.07552617, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.0727719, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.071005754, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.074265055, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06819139, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06691815, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.065808564, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.07572085, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06428121, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.0637411, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06303372, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06254122, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.0601085, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.062198795, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05982983, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.058812756, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.07166574, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.056667898, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.057354793, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05929965, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05552511, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.054431286, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.055804934, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.0533634, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.059504412, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.11731495, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.051761422, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.059677996, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050897554, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049419034, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3600, training loss= 0.04941104, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05730171, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.05586023, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3900, training loss= 0.056863472, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05335726, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04695767, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04901186, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.051955063, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04629572, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4500, training loss= 0.046988923, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4600, training loss= 0.05284543, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.044417914, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.049135353, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.043602347, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.044422686, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043815743, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.043622002, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04350114, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04340035, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04330897, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04322283, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.043137845, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.043058917, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.042987198, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.04292316, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6100, training loss= 0.042863496, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6200, training loss= 0.042797573, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 6300, training loss= 0.042738806, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04268589, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.0426381, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04259138, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042544562, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042497367, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042451132, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.042402193, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042355545, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042309657, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042263832, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04221874, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042172506, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.042126514, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.042082194, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.042036325, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.041991185, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.041948587, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.041953057, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.041952316, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04194979, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.041946072, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.04194234, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.04193859, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.041934762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.041931037, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04192719, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.041923486, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.041919723, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.041915953, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.041912228, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.041908532, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.041904736, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04190091, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.04189714, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.04189332, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04188949, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.31029546, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.09313533, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.08191647, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.076746546, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07334638, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.071427464, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.06971479, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.06819052, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06673715, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.065218024, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06406838, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06308834, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.062131967, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.061215453, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.060432184, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.060284756, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.058980525, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.058238097, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.057557642, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.056842882, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.0577407, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.055637643, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.054937467, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05460002, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.0592925, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.053452566, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05645066, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.052759327, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.052199993, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.051430672, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.051160485, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.0508249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.0501184, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.049717765, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.049447894, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.048788037, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.04797113, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.050010726, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.0480178, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.047325395, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.046493556, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.046663538, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.045710713, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04592998, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.05058507, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.05229225, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0448175, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04414302, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.043545984, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04359198, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.042831413, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.042859856, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04283397, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04279754, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.042763125, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.042729937, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04269719, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04266583, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.042633712, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.042599127, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.042563546, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.042530853, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.042498, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04246512, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.042432517, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.04239983, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.042367484, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.04233464, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042300485, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.04226868, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.042235684, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042202044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042168885, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042135768, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.042101786, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042068854, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.042036377, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04200312, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.041970626, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04193772, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04190552, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04191291, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04191093, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.041907698, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04190465, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.041901417, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.041898154, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04189509, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.041891932, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.041888725, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.04188555, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.041882377, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.041879244, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.041875944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.041872773, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.041869443, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04186622, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.04186297, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.041859794, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.041856438, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3818928, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.10800212, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.09342453, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.08877895, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.08062526, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 500, training loss= 0.08659048, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.0754026, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.07924371, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.06956604, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.06826375, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06711205, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06661435, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.064574085, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06546135, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06482451, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.061204996, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.09629502, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06061535, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.060813997, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.0581994, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.059299488, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.057590656, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.055868495, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.057010982, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05473167, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.054942254, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.056305367, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05312832, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.05272629, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.054600727, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05300306, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.051327463, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.050482854, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050316542, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050094675, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049368795, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.049245775, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04894698, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.05008642, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.047772806, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04767509, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.053460445, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.048104685, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.05035157, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.059738252, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.047439698, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.045517966, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.045597788, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04865419, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04572293, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.043600578, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043505955, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.043460228, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04340803, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.043355722, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.043302916, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04325097, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.043200515, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.043147895, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.04309544, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.043044973, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04299546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04294237, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.042889927, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04283797, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.042783964, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.042727716, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042671926, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.04261679, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042564068, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.042510964, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.042461257, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04241316, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042365983, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.042319696, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.04227335, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.042228892, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.042184375, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.04214109, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.042097855, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.042054888, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04205562, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.042051975, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.042048104, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.042044036, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.04203966, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.042035297, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.042031035, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04202672, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.042022444, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.042018197, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.042013947, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04200969, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04200537, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.042001165, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.041996803, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04199248, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.0419882, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.041983932, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.041979708, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.33919305, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.090142466, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.0797738, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.07667169, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07161822, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.07002563, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.06861131, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.065772034, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.065571465, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.06280502, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.08544692, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06035923, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.0594815, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.05812288, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.05773877, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.057867043, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.055948, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.056371458, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05529153, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.057192497, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.055995643, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052325733, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.0518355, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.053852253, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05103643, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.050329093, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05075949, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.048676934, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04944738, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.052915353, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.04893973, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.053024095, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.046838578, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.050795317, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.045379795, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04559087, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.0447986, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.046789814, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04383742, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.044300184, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04340454, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04291271, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04494815, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.045391046, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.0414259, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.041971803, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04101901, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.041000858, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04515149, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04106862, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.039722152, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.039565373, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.039545946, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.039515454, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03948287, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.039451268, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.039422717, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03939228, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.039361928, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.039330006, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.039295316, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03925935, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03922051, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.039182674, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03914283, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03910382, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.039066967, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.039029915, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.038992476, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03895596, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03892039, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.038886197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03885204, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03881787, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.038785294, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.038751993, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.038718134, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.038686592, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.038654514, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.038622364, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03858899, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.038590267, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.038588583, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.038585957, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03858308, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03858023, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03857732, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03857431, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03857132, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.038568307, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.038565293, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03856227, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.038559243, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.038556468, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.038553566, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.038550675, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.038547654, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.038544673, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03854168, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.038538445, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.40187135, training acc= 95.61068415641785%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.104562595, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 200, training loss= 0.09593973, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08141753, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.0766857, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.07265839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 600, training loss= 0.0796798, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.068319656, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06914159, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07353552, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06659889, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06306971, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06837796, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06037904, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.07425512, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.059012413, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.07060697, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06091965, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.060145814, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.059290685, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.054425236, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.054334547, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2200, training loss= 0.057353772, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.059321225, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.053562492, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.052816868, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.054536637, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05106779, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.05069194, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.0528139, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.0506848, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05127081, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.049227055, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04666337, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04653434, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.047946926, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3600, training loss= 0.045823563, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.044609994, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.044798434, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.045261502, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04337374, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.043595344, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4200, training loss= 0.042221908, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.048130386, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.050910242, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.041024875, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4600, training loss= 0.039784897, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.054460317, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.03894573, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.043380342, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.038016357, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03799763, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03793904, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.037882563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.037828326, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.037776604, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03772315, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.037671946, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.037622005, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03757517, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.037534095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03749421, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03745031, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.037398633, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.037349787, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03730226, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.03725684, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.037211724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.037166245, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.037122328, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.037078798, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.037035443, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03699299, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.036949154, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03690921, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036868654, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.03682915, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.036787465, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036746763, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.036706455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.036667895, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.036669698, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.036666658, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03666349, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.036659956, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.036656287, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.036652494, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.036648862, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.036645193, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.036641505, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.036637705, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.036634035, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03663027, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.036626603, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.0366229, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.036619227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.036615435, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03661172, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.036607843, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03660415, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.416936, training acc= 95.80152630805969%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.10935728, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.08825371, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 300, training loss= 0.08444645, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.079253115, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07440323, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.071329236, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.065874524, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.0766184, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.06145955, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.060505837, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07256681, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.059307843, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06522447, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.055848163, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05830521, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.055555247, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.058354627, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.057999548, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1900, training loss= 0.058278672, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2000, training loss= 0.050984222, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.049209997, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.056363188, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05334594, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.1668537, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.047571134, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.049978357, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2700, training loss= 0.045331407, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.048615813, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045334756, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044088762, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.04583486, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044165473, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.042635094, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.042608093, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04162325, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.041181806, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3700, training loss= 0.041163582, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.05365845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.03996258, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.045397736, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.043179493, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4200, training loss= 0.039085373, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.0387502, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04121757, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04468904, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4600, training loss= 0.05897914, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.054475885, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4800, training loss= 0.039001662, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03685434, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.036524825, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036458977, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036426734, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036392886, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036356475, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.036311448, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.036258876, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03620465, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.036149155, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036101073, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03605926, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.036019087, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03597988, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.035940968, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.035903085, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.035866994, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.035829797, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.035794318, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.035758913, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.035725463, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.035690773, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03565692, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.0356235, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03559093, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.035557486, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.035524342, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.035491504, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.035459872, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.03542843, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.035397768, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03536694, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03537131, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.03537041, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.03536834, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03536599, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035363488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.0353607, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03535787, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035354998, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035352133, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035349447, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035346724, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03534394, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035341233, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03533836, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03533565, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03533284, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035330176, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03532757, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035324853, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.38368225097656 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.19067518, training acc= 96.37404680252075%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.09206466, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 200, training loss= 0.08652042, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.082917064, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "epoch 400, training loss= 0.07988756, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 500, training loss= 0.07800513, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 600, training loss= 0.076552905, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.07542738, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.07422456, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.073184446, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07229395, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07148515, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07070364, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06993511, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1400, training loss= 0.0691966, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06847789, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.067790195, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06713423, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.066494636, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06589076, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06531286, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2100, training loss= 0.064732485, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.06417342, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.06362555, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.063067965, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.062546425, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.06205577, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.06154825, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.061080985, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.060651846, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.060182154, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.059726283, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.059265107, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.0588432, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05840618, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.057946455, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.057521723, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05707563, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.056661516, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.056245007, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.055841092, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.05541856, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.055019725, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.054616667, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.054222632, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.05386766, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.053478714, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.05314524, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.05273391, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.052373964, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.05194742, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.051982418, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.051950857, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.05191544, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.051878843, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.05184316, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.051807735, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.051773097, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.05173879, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.051704787, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.05167059, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.051637065, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.0516022, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.051568665, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.05153455, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.051499598, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.051456843, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.05141724, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.051380407, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.051345028, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.051310055, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.05127516, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.051239446, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.051202968, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.05116672, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7500, training loss= 0.05113045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7600, training loss= 0.051093075, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7700, training loss= 0.05105673, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7800, training loss= 0.051021792, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7900, training loss= 0.050987713, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8000, training loss= 0.050952923, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8100, training loss= 0.050957587, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8200, training loss= 0.050955817, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8300, training loss= 0.050953485, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8400, training loss= 0.050950687, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8500, training loss= 0.05094777, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8600, training loss= 0.050944723, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8700, training loss= 0.050941635, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8800, training loss= 0.05093849, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 8900, training loss= 0.050935425, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9000, training loss= 0.050932147, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9100, training loss= 0.05092888, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9200, training loss= 0.05092562, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9300, training loss= 0.050922196, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9400, training loss= 0.050918963, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9500, training loss= 0.050915673, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9600, training loss= 0.050912395, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9700, training loss= 0.050909188, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9800, training loss= 0.050905757, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 9900, training loss= 0.050902445, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 84.29002380371094 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.29639214, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.1251042, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.116742596, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 300, training loss= 0.09483391, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.09214059, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.093049265, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.09458539, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.08371161, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.075713314, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 900, training loss= 0.073781006, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07465058, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07170506, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.07031143, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.069197066, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1400, training loss= 0.067047276, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06669557, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.0665326, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06533418, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06473827, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.063379586, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.062237665, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.062483903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.06156386, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.06033691, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05979561, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.059519827, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05848527, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05816761, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.05796143, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.057047993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05883045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.069161214, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.057237912, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.055174507, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05489996, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.054334823, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.05405775, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.053693496, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.05390063, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.052876197, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05233218, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.051823802, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.06116964, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.051089454, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.052590348, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.065765895, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.050122645, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04979335, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.049623866, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4900, training loss= 0.049068376, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5000, training loss= 0.048813768, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.048721477, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04870322, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.048679847, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04865598, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.048627406, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.0485977, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04856579, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.048534557, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.048504114, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.048472166, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.048441082, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04840885, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04837702, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.048345473, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.048314553, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04828361, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.04825266, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.048220348, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.048188385, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04815784, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.048126176, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04809429, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.048062395, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04803154, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.048001144, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.047970746, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.047940176, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.047909435, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.047878888, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04784753, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04785068, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.04784921, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04784682, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.047844317, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.047841392, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.047838736, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04783594, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04783309, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04783022, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.047827337, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04782447, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04782146, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04781855, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.04781561, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.047812685, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.047809653, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.047806654, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.04780361, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04780047, training acc= 98.47328066825867%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.2441052, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.093770824, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.08563927, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 300, training loss= 0.0808557, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.078114934, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.07555672, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.07385984, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.072494105, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 800, training loss= 0.07131848, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.07029215, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06925931, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06819333, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.0672485, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.066455826, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06573725, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06504591, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06449709, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.063686006, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.0630862, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06233403, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.066238984, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.061165407, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.060929623, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.060191706, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.059781324, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.059199426, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2600, training loss= 0.06094254, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.058125503, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2800, training loss= 0.057627067, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05730509, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.056470554, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05607514, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3200, training loss= 0.055624656, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3300, training loss= 0.055336162, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3400, training loss= 0.054627586, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.053889517, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.053368192, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05365575, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.052333754, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.053390216, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05150371, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4100, training loss= 0.051421143, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.050716244, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.05031413, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.049889185, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.05073482, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.049280237, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4700, training loss= 0.049520083, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.048212975, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.048412193, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.047499098, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.047443546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.047419976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.047391854, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.047362708, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.047330942, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.047296446, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04726118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.047226053, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.047191445, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.047154635, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.047119807, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.047084957, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04704946, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.047015272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.046981458, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.046947315, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.046912618, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.0468783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.046844047, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.046809286, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.046775628, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04674049, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.046705272, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.04667175, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.046637915, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04660396, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04657035, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.0465357, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.046501245, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04646707, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.046469003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.046467416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.046465386, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.046463143, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.04646084, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.046458334, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04645548, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.046452597, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.04644957, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.046446487, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04644354, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.046440516, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.046437424, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.046434138, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.046431117, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.046428077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.046424877, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.046421647, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.046418488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3330886, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 100, training loss= 0.106995106, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.09144483, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.086817056, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 400, training loss= 0.0806749, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07775382, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07377163, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.071894266, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.070652984, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07225175, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06848095, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06694707, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06735573, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06502771, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06404885, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.062489644, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.062411144, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.0627848, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.060716834, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.061677285, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06002306, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05928196, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.059233923, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.057152525, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05727811, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.056447975, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.057183657, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.056033254, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.054594647, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.054196596, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05618435, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.058210686, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.052753516, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05241739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05285089, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.052587677, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.051059593, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05726611, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.051213987, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3900, training loss= 0.050838888, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4000, training loss= 0.05372548, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.12027291, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04903791, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4300, training loss= 0.048345577, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.048401214, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.054005735, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04736427, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.049874455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4800, training loss= 0.046604227, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.053763766, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04575985, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04581581, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04579257, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04575409, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.045712348, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04567298, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.045636307, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.045599945, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.045561094, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.04552141, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.045483667, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.045442734, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.045405127, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.04536567, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.045323815, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.0452841, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04524399, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.045203425, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.04516197, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.045122094, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04508404, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04504317, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04500654, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.04496843, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.044930417, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.044891734, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.0448549, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7700, training loss= 0.044815272, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7800, training loss= 0.044776, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04473966, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8000, training loss= 0.044701044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8100, training loss= 0.044707827, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8200, training loss= 0.044707514, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8300, training loss= 0.0447038, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8400, training loss= 0.044700217, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8500, training loss= 0.044696327, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8600, training loss= 0.044692576, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8700, training loss= 0.044688854, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04468498, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 8900, training loss= 0.0446813, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9000, training loss= 0.044677317, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9100, training loss= 0.04467361, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9200, training loss= 0.04466977, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9300, training loss= 0.044666033, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9400, training loss= 0.044661924, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9500, training loss= 0.044658322, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9600, training loss= 0.044654597, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9700, training loss= 0.044650543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9800, training loss= 0.044646908, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 9900, training loss= 0.0446429, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.29057947, training acc= 96.1832046508789%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.10349335, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.08366825, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 300, training loss= 0.07876873, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07510009, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.07251558, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07058576, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 700, training loss= 0.0690965, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06778328, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.066618405, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06602342, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1100, training loss= 0.064586975, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06364812, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06729768, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.061977617, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.061475713, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06067464, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06007182, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.067502, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 1900, training loss= 0.05855816, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.058127232, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05746735, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05669295, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2300, training loss= 0.056120045, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2400, training loss= 0.055508014, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05496381, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.054528236, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05372823, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.053269483, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.052816723, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.052127462, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 3100, training loss= 0.051689107, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.05226474, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05059155, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050189998, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3500, training loss= 0.049909882, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048928976, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04861131, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.048249055, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04918903, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4000, training loss= 0.047335416, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.046766717, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04758506, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.045897804, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.045512944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.045108188, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.044890646, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04473425, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04397642, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.043723617, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.043338194, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04341695, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04340108, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.043375973, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04334899, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04332087, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5600, training loss= 0.04329239, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04326344, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.043234963, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.043205902, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.04317612, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04314615, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.043117035, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.043087177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.043057542, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.043028243, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.0429992, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.042970173, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042940307, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.0429114, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04288143, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04285195, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.042821795, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.042792123, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.042759854, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042729486, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.04270045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.04267198, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.042643003, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.042613585, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.04258507, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.042588793, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.0425882, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04258611, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04258378, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.042581312, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.042578604, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.04257576, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.04257289, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.042570043, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.042567287, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.042564414, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.042561546, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04255875, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.042555947, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04255309, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.042550314, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.04254753, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.04254474, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04254201, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.35932833, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.11716634, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.09266604, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.08788606, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.08439204, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.08229499, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07862941, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.07635904, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.072804905, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 900, training loss= 0.079385154, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1000, training loss= 0.07263151, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1100, training loss= 0.07036243, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06770451, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1300, training loss= 0.065276645, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1400, training loss= 0.066371016, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06329826, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.065643124, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06344014, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1800, training loss= 0.06275112, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.06498433, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.06096515, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.058781065, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.056934442, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2300, training loss= 0.056581605, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2400, training loss= 0.057982087, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.055144757, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2600, training loss= 0.058467377, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.054565128, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.059954405, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2900, training loss= 0.059293617, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3000, training loss= 0.052883387, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.055056125, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.057362434, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.06127112, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.05105716, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3500, training loss= 0.05171789, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.049938545, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.05035725, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.049598586, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.049201753, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.049220152, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4100, training loss= 0.078766584, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.050001826, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.048064552, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04713482, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.045369547, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.050593227, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04626052, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04532966, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.05059108, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04356045, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.043247066, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.04317872, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.043118685, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04306243, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.043007713, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5600, training loss= 0.042954914, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04290333, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5800, training loss= 0.042852756, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5900, training loss= 0.04280051, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6000, training loss= 0.042750746, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6100, training loss= 0.042703565, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6200, training loss= 0.042658374, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.042614616, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.042568948, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.042525705, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.042483207, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.04244071, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.042399667, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.042359192, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.04231957, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04227958, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04224139, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.04220354, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.042164423, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.042127598, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.042089146, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.042051025, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.042012744, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.04197562, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.041937646, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04194025, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.041937884, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04193494, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04193169, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.0419283, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.041924845, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.041921355, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.041917723, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.041914113, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.041910496, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.041906852, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.041903228, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.041899525, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.04189589, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.041892167, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04188843, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.041884717, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.041880965, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.041877218, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3213906, training acc= 96.08778357505798%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.09204254, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 200, training loss= 0.08140594, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.076844595, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 400, training loss= 0.07252051, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.07024521, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 600, training loss= 0.068379484, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.066895686, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06551955, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.06438416, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06331889, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1100, training loss= 0.062311716, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06119581, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06016621, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.059179902, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05859953, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.058358144, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.056920268, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.056996018, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.055652793, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.09430905, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2100, training loss= 0.05506758, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.054024108, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.053493947, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.07466127, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.055315662, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.052142005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2700, training loss= 0.051659435, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2800, training loss= 0.051186174, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.05121621, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.050600436, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3100, training loss= 0.074883536, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.050571557, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3300, training loss= 0.049352862, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04876898, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04829197, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3600, training loss= 0.047706746, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.047819536, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04712637, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04640622, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.046217173, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04570648, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4200, training loss= 0.04591527, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.057347607, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4400, training loss= 0.044430032, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4500, training loss= 0.044626255, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.045634758, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04524895, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04403489, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4900, training loss= 0.04352062, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.042322207, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.04233479, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.042304937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.04227454, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.042243626, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.04220648, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.042171504, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.04213699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.04210284, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.042070784, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.042037096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.04200424, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.041969728, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.041936465, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.04190309, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.041870743, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.04183739, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.04180419, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.041772686, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.041740905, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.041710027, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.04167626, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.04164384, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.041612756, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.041581932, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.041549888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.041518208, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.041487522, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.041455757, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.041425046, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.041394696, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.04140176, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.041402318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.04140037, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.04139782, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.041395217, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.041392516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.041389752, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.041387003, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.041384242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.041381504, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.041378643, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.041375782, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.04137295, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.04136998, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.04136717, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.04136417, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.041361257, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.041358296, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.04135532, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3769674, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "epoch 100, training loss= 0.110599585, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.0896441, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08463802, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 400, training loss= 0.110469565, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 500, training loss= 0.082838856, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.073283456, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 700, training loss= 0.07497261, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 800, training loss= 0.071877636, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.07284333, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1000, training loss= 0.090812825, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06571555, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 1200, training loss= 0.06516163, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06434945, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.064695604, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.06462741, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.06141413, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.06055225, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.060988948, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1900, training loss= 0.057978664, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2000, training loss= 0.0625578, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.059787862, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.062340446, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05896238, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05351278, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2500, training loss= 0.059303474, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.052366924, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05118646, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.06304526, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.049342882, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3000, training loss= 0.07991604, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3100, training loss= 0.048158474, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3200, training loss= 0.049363542, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.047392093, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04677164, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.048952706, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.059247386, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.050601322, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04707969, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3900, training loss= 0.046952162, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04874943, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.046608374, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.045479715, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4300, training loss= 0.04347111, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.042825215, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.05290534, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.04375506, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4700, training loss= 0.041733462, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.04178642, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4900, training loss= 0.041335106, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5000, training loss= 0.04557693, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5100, training loss= 0.040812165, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5200, training loss= 0.040646818, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5300, training loss= 0.040558, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5400, training loss= 0.04048888, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.040429436, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.040375967, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.040327698, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5800, training loss= 0.040281277, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 5900, training loss= 0.040238556, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6000, training loss= 0.040196944, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6100, training loss= 0.040155783, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6200, training loss= 0.04011572, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6300, training loss= 0.040075976, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6400, training loss= 0.040037323, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6500, training loss= 0.0399982, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6600, training loss= 0.039959483, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6700, training loss= 0.039922852, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6800, training loss= 0.03988567, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03984841, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03981152, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7100, training loss= 0.039776273, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7200, training loss= 0.039740384, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7300, training loss= 0.039704908, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03967032, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7500, training loss= 0.039636493, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7600, training loss= 0.039602764, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03956918, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7800, training loss= 0.039536197, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03950332, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8000, training loss= 0.039470084, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8100, training loss= 0.039471764, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8200, training loss= 0.039469942, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8300, training loss= 0.039467443, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8400, training loss= 0.039464787, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8500, training loss= 0.039462, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03945909, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8700, training loss= 0.039456055, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8800, training loss= 0.03945308, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 8900, training loss= 0.039450157, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9000, training loss= 0.039447077, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9100, training loss= 0.039444126, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9200, training loss= 0.039441023, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9300, training loss= 0.039437998, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03943475, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03943177, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9600, training loss= 0.0394286, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9700, training loss= 0.0394255, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03942243, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 9900, training loss= 0.03941929, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.34333947, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "epoch 100, training loss= 0.08967794, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 200, training loss= 0.07961196, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.07474218, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07143688, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 500, training loss= 0.071885146, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06764839, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 700, training loss= 0.06710287, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.06502786, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 900, training loss= 0.06252988, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1000, training loss= 0.0619077, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.06011177, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1200, training loss= 0.059742015, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.058419257, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057539314, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1500, training loss= 0.057203423, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1600, training loss= 0.057957575, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1700, training loss= 0.05586345, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1800, training loss= 0.05507122, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.053036265, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.055089865, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052721135, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.054899782, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.05128631, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05118173, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05087492, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05078758, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2700, training loss= 0.048668128, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2800, training loss= 0.04905115, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 2900, training loss= 0.048320413, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3000, training loss= 0.05105339, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05144003, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.046945807, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.047016162, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04888652, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3500, training loss= 0.046218257, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.04497731, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3700, training loss= 0.045450866, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04386573, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3900, training loss= 0.044787586, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04280182, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4100, training loss= 0.050796498, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.044003233, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4300, training loss= 0.0465073, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4400, training loss= 0.04399403, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.04530411, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.05070301, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 4700, training loss= 0.044903886, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.040438257, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.039411444, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5000, training loss= 0.039086353, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.039142687, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.039093647, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.039047595, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03900269, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5500, training loss= 0.038964927, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.038925916, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.03888682, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03884962, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.038812634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03877578, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.038738687, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03870632, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03867376, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03864157, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.038608782, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.038575996, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.038544096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.038512766, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.038480133, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.038448054, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.038417228, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.03838712, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.038355753, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.038324837, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03829453, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.038264655, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.038233854, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.038204223, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03817456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03814544, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.038148027, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.038146228, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.038143627, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.03814096, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.038138248, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03813541, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.038132478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.0381296, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.038126744, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.038123783, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.0381209, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03811809, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.03811525, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.038112327, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03810949, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.038106628, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03810386, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.038100947, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.038098108, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.200005 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.39394712, training acc= 95.61068415641785%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.11142428, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 200, training loss= 0.0862456, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.08008273, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 400, training loss= 0.077687055, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.07588425, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 600, training loss= 0.07697084, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.07097573, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 800, training loss= 0.066965364, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 900, training loss= 0.065311626, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.063452944, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1100, training loss= 0.062358584, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1200, training loss= 0.061722465, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.06947743, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1400, training loss= 0.06025392, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1500, training loss= 0.058147438, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.059907056, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1700, training loss= 0.056628507, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 1800, training loss= 0.055988964, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 1900, training loss= 0.09110095, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 2000, training loss= 0.055428274, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.053809173, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2200, training loss= 0.063903734, training acc= 97.2328245639801%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2300, training loss= 0.07732242, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05412513, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2500, training loss= 0.05251741, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.05299195, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2700, training loss= 0.05181215, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2800, training loss= 0.050695546, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.07456301, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.050609585, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.05122648, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3200, training loss= 0.048335746, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3300, training loss= 0.06698802, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.048851408, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04647949, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3600, training loss= 0.10712962, training acc= 98.37786555290222%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.046048112, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3800, training loss= 0.04402633, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.043458648, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.04324477, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04255756, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.065511994, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4300, training loss= 0.044093147, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4400, training loss= 0.043681987, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4500, training loss= 0.040599354, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4600, training loss= 0.040240042, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4700, training loss= 0.040031932, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4800, training loss= 0.039530583, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4900, training loss= 0.040302195, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5000, training loss= 0.038957633, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.03905029, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5200, training loss= 0.03900323, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03895717, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5400, training loss= 0.038914386, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03887345, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03883317, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5700, training loss= 0.038795527, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5800, training loss= 0.038756043, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 5900, training loss= 0.038716435, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6000, training loss= 0.038676273, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6100, training loss= 0.038638283, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03859943, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6300, training loss= 0.038562626, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6400, training loss= 0.038524896, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6500, training loss= 0.038488537, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6600, training loss= 0.038452346, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03841692, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6800, training loss= 0.038382627, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 6900, training loss= 0.038346015, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7000, training loss= 0.038311046, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7100, training loss= 0.03827493, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7200, training loss= 0.038240425, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7300, training loss= 0.038205907, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7400, training loss= 0.038171045, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7500, training loss= 0.038137715, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7600, training loss= 0.038102575, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7700, training loss= 0.038069088, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7800, training loss= 0.038035408, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03800262, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8000, training loss= 0.03796824, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8100, training loss= 0.037975475, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8200, training loss= 0.037976477, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8300, training loss= 0.037975296, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8400, training loss= 0.037972875, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8500, training loss= 0.037970148, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8600, training loss= 0.037967198, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8700, training loss= 0.037964325, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8800, training loss= 0.037961263, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 8900, training loss= 0.037958138, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9000, training loss= 0.0379551, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03795197, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9200, training loss= 0.0379488, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9300, training loss= 0.037945673, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03794247, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9500, training loss= 0.037939228, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9600, training loss= 0.0379361, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9700, training loss= 0.037932813, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03792958, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 9900, training loss= 0.037926286, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.3633597, training acc= 95.89694738388062%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "epoch 100, training loss= 0.08856406, training acc= 96.75572514533997%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 200, training loss= 0.077823445, training acc= 97.04198241233826%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 300, training loss= 0.08166845, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.07075303, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 500, training loss= 0.0693713, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.06659801, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06445522, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 800, training loss= 0.062185064, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 900, training loss= 0.06090839, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06022232, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.058350787, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1200, training loss= 0.058128316, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1300, training loss= 0.055726003, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1400, training loss= 0.057366613, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1500, training loss= 0.05412933, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1600, training loss= 0.05407799, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1700, training loss= 0.052717194, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1800, training loss= 0.052905016, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.052804668, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05104184, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2100, training loss= 0.052168615, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2200, training loss= 0.05230715, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "epoch 2300, training loss= 0.050681528, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2400, training loss= 0.05685335, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049340755, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2600, training loss= 0.04819366, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2700, training loss= 0.050086018, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.046199266, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2900, training loss= 0.045285508, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3000, training loss= 0.044832163, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3100, training loss= 0.044685956, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3200, training loss= 0.044850014, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3300, training loss= 0.04318314, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3400, training loss= 0.050740935, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 3500, training loss= 0.042311803, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3600, training loss= 0.048587676, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3700, training loss= 0.043094456, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3800, training loss= 0.09564005, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3900, training loss= 0.040568158, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4000, training loss= 0.043570533, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 4100, training loss= 0.04199952, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4200, training loss= 0.03991144, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 4300, training loss= 0.039449546, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4400, training loss= 0.038706042, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4500, training loss= 0.038377993, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4600, training loss= 0.0379249, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.037647482, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4800, training loss= 0.037362162, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.037635475, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.0367649, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 5100, training loss= 0.036760267, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5200, training loss= 0.036731724, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5300, training loss= 0.036700044, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.036668822, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03663903, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.03660935, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.036580242, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.03654992, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.036521196, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.036491442, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.03646318, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.036434613, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.036407232, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.03638058, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03635519, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036329634, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6700, training loss= 0.03630356, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6800, training loss= 0.036277656, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03625455, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7000, training loss= 0.03623114, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036206543, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036183335, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03615888, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7400, training loss= 0.03613563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.036111865, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036089882, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03606665, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036042213, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.03601906, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.035993274, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.03599699, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.035997428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.035995282, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.035993174, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.035991002, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.035988774, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.03598651, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.035984095, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.035981797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.035979513, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.035977118, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.035974797, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.035972428, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.03597011, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.03596762, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.03596516, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.035962563, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.03596008, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.035957478, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.100006 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 6 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "epoch 0, training loss= 0.41300243, training acc= 95.70610523223877%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "epoch 100, training loss= 0.11208114, training acc= 97.13740348815918%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 200, training loss= 0.08790648, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 300, training loss= 0.08549884, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 400, training loss= 0.085974716, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 500, training loss= 0.074201755, training acc= 97.32824563980103%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 600, training loss= 0.07174307, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "epoch 700, training loss= 0.06924241, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 800, training loss= 0.06766483, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 900, training loss= 0.06696865, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1000, training loss= 0.06261893, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 1100, training loss= 0.0625668, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "epoch 1200, training loss= 0.060233623, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1300, training loss= 0.10042077, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "epoch 1400, training loss= 0.05873867, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 1500, training loss= 0.060331777, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1600, training loss= 0.066161714, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "epoch 1700, training loss= 0.055122387, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 1800, training loss= 0.053337295, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 1900, training loss= 0.0862491, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "epoch 2000, training loss= 0.05755011, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 2100, training loss= 0.054331, training acc= 97.61450290679932%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 2200, training loss= 0.052496184, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 2300, training loss= 0.049457874, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2400, training loss= 0.049201787, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2500, training loss= 0.049106147, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2600, training loss= 0.050935697, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 2700, training loss= 0.048264734, training acc= 97.80534505844116%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2800, training loss= 0.052767713, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 2900, training loss= 0.046577368, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3000, training loss= 0.0473223, training acc= 97.90076613426208%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 3100, training loss= 0.04507418, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 3200, training loss= 0.045792557, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3300, training loss= 0.05868811, training acc= 97.5190818309784%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 3400, training loss= 0.04336301, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3500, training loss= 0.04371301, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3600, training loss= 0.045927577, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "epoch 3700, training loss= 0.04357159, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 3800, training loss= 0.06163347, training acc= 97.42366671562195%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 3900, training loss= 0.04294408, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4000, training loss= 0.049284626, training acc= 97.70992398262024%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "epoch 4100, training loss= 0.043873485, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4200, training loss= 0.040042978, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4300, training loss= 0.041003022, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4400, training loss= 0.040707782, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4500, training loss= 0.040768363, training acc= 98.2824444770813%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 4600, training loss= 0.040119857, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4700, training loss= 0.04127872, training acc= 98.09160232543945%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "epoch 4800, training loss= 0.039405182, training acc= 97.99618124961853%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 4900, training loss= 0.03809604, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5000, training loss= 0.03771777, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5100, training loss= 0.037581652, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5200, training loss= 0.037527066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "epoch 5300, training loss= 0.03747583, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5400, training loss= 0.03742909, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5500, training loss= 0.03738451, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5600, training loss= 0.037340987, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5700, training loss= 0.037295446, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5800, training loss= 0.037250124, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 5900, training loss= 0.03720429, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6000, training loss= 0.03716382, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6100, training loss= 0.037125066, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6200, training loss= 0.03708727, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6300, training loss= 0.03704958, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6400, training loss= 0.037013814, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6500, training loss= 0.03697937, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6600, training loss= 0.036944967, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6700, training loss= 0.036909938, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6800, training loss= 0.0368733, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 6900, training loss= 0.03683827, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7000, training loss= 0.036802962, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7100, training loss= 0.036769386, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7200, training loss= 0.036734562, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7300, training loss= 0.03669953, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "epoch 7400, training loss= 0.036663745, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7500, training loss= 0.03662873, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7600, training loss= 0.036593556, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7700, training loss= 0.03656121, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7800, training loss= 0.036528442, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 7900, training loss= 0.036495518, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8000, training loss= 0.036464337, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8100, training loss= 0.036464788, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8200, training loss= 0.036462996, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8300, training loss= 0.036460638, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8400, training loss= 0.036458008, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8500, training loss= 0.03645524, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8600, training loss= 0.03645251, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8700, training loss= 0.036449786, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8800, training loss= 0.036447037, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 8900, training loss= 0.036444213, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9000, training loss= 0.0364415, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9100, training loss= 0.03643858, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9200, training loss= 0.03643561, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9300, training loss= 0.0364325, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9400, training loss= 0.036429543, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9500, training loss= 0.036426544, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9600, training loss= 0.036423426, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9700, training loss= 0.03642046, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9800, training loss= 0.036417402, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "epoch 9900, training loss= 0.036414444, training acc= 98.18702340126038%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 83.68580627441406 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 6 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrkZIJvoUb6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "ccd74383-7883-4014-acdb-818b1cbe2f64"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD9CAYAAACx+XApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u3UFxL_bUb3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "19311282-3525-4524-80ea-4f1c80bc9c35"
      },
      "cell_type": "code",
      "source": [
        "print(np.max(ValidAccuracy_Track))\n",
        "print(np.argmax(ValidAccuracy_Track))\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.6\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LG0RQz3FI1vV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qw9Rb1WxH91p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### weights are 3,3,1"
      ]
    },
    {
      "metadata": {
        "id": "SNa5wb-fNgdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shuffling_indices_validation_data = np.random.permutation(validation_data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wo0Ckop2O-zr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5da5666f-98a1-4428-fabe-111e61b1e3d4"
      },
      "cell_type": "code",
      "source": [
        "shuffling_indices_validation_data.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "ffB0tBLCLyxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shuffled_validation_data = validation_data[shuffling_indices_validation_data,:]\n",
        "shuffled_validation_label = validation_label_one_hot[shuffling_indices_validation_data,:]\n",
        "train_valid_combined_shuffled = np.concatenate((train_data, shuffled_validation_data))\n",
        "train_valid_combined_shuffled_label = np.concatenate((train_label_one_hot, shuffled_validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5ENx3_HSDoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "5d633f3f-c893-4195-d249-ec02ba56bd84"
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(validation_label_one_hot,axis = 1))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([291.,   0.,  95.,   0., 163.,   0., 109.,   0., 176., 497.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADdlJREFUeJzt3W+IXfWdx/H3Z422xXabqrMhJGFH\naOgihaoM1sWy7Cot/qPJAyvKrs1KljxRsLjQTffJUtgH9kltC4sQqmzc7ValVgwq3Uq0FKH+mfi3\nmnY7KxETopn6rxXpLrbffTA/2alNnDuZe+c6v3m/YJhzfufce34H8Z3Dybk3qSokSf36o3FPQJI0\nWoZekjpn6CWpc4Zekjpn6CWpc4Zekjpn6CWpc4Zekjpn6CWpc2vGPQGA0047rSYnJ8c9DUlaUfbt\n2/fLqppYaL/3RegnJyeZnp4e9zQkaUVJ8sIg+3nrRpI6Z+glqXOGXpI6Z+glqXMDhT7JgSTPJHky\nyXQbOyXJ/Ul+0X5/rI0nybeSzCR5OsnZozwBSdJ7W8wV/V9V1ZlVNdXWdwJ7q2ozsLetA1wEbG4/\nO4CbhjVZSdLiLeXWzRZgd1veDWydN35rzXkYWJtk/RKOI0lagkFDX8APk+xLsqONrauqw235JWBd\nW94AvDjvtQfb2O9JsiPJdJLp2dnZ45i6JGkQg35g6jNVdSjJnwD3J/nZ/I1VVUkW9Y/PVtUuYBfA\n1NSU/3CtJI3IQKGvqkPt95EkdwHnAC8nWV9Vh9utmSNt90PApnkv39jGJOl9aXLnvWM79oEbLhn5\nMRa8dZPk5CQfeWcZ+BzwU2APsK3ttg24uy3vAb7Ynr45F3hj3i0eSdIyG+SKfh1wV5J39v+PqvpB\nkseAO5JsB14ALm/73wdcDMwAbwFXD33WkqSBLRj6qnoe+NRRxl8BLjjKeAHXDGV2kqQl85OxktQ5\nQy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9J\nnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnTP0\nktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5Qy9JnRs49ElOSPJEknva+ulJHkkyk+T2JCe18Q+09Zm2fXI0\nU5ckDWIxV/TXAfvnrX8NuLGqPg68Bmxv49uB19r4jW0/SdKYDBT6JBuBS4Bvt/UA5wPfa7vsBra2\n5S1tnbb9gra/JGkMBr2i/wbwZeB3bf1U4PWqerutHwQ2tOUNwIsAbfsbbX9J0hgsGPoklwJHqmrf\nMA+cZEeS6STTs7Ozw3xrSdI8g1zRnwd8PskB4Dbmbtl8E1ibZE3bZyNwqC0fAjYBtO0fBV5595tW\n1a6qmqqqqYmJiSWdhCTp2BYMfVV9pao2VtUkcAXwQFX9NfAgcFnbbRtwd1ve09Zp2x+oqhrqrCVJ\nA1vKc/T/AFyfZIa5e/A3t/GbgVPb+PXAzqVNUZK0FGsW3uX/VdWPgB+15eeBc46yz2+ALwxhbpKk\nIfCTsZLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z\n9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLU\nOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUuQVDn+SDSR5N8lSSZ5N8tY2fnuSR\nJDNJbk9yUhv/QFufadsnR3sKkqT3MsgV/f8A51fVp4AzgQuTnAt8Dbixqj4OvAZsb/tvB15r4ze2\n/SRJY7Jg6GvOm231xPZTwPnA99r4bmBrW97S1mnbL0iSoc1YkrQoA92jT3JCkieBI8D9wH8Dr1fV\n222Xg8CGtrwBeBGgbX8DOHWYk5YkDW6g0FfVb6vqTGAjcA7wZ0s9cJIdSaaTTM/Ozi717SRJx7Co\np26q6nXgQeDPgbVJ1rRNG4FDbfkQsAmgbf8o8MpR3mtXVU1V1dTExMRxTl+StJBBnrqZSLK2LX8I\n+Cywn7ngX9Z22wbc3Zb3tHXa9geqqoY5aUnS4NYsvAvrgd1JTmDuD4Y7quqeJM8BtyX5Z+AJ4Oa2\n/83AvyWZAV4FrhjBvCVJA1ow9FX1NHDWUcafZ+5+/bvHfwN8YSizG8DkznuX61B/4MANl4zt2JI0\nKD8ZK0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlD\nL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0md\nM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdM/SS1DlDL0mdWzD0STYleTDJc0meTXJdGz8lyf1J\nftF+f6yNJ8m3kswkeTrJ2aM+CUnSsQ1yRf828PdVdQZwLnBNkjOAncDeqtoM7G3rABcBm9vPDuCm\noc9akjSwBUNfVYer6vG2/GtgP7AB2ALsbrvtBra25S3ArTXnYWBtkvVDn7kkaSCLukefZBI4C3gE\nWFdVh9uml4B1bXkD8OK8lx1sY+9+rx1JppNMz87OLnLakqRBDRz6JB8G7gS+VFW/mr+tqgqoxRy4\nqnZV1VRVTU1MTCzmpZKkRRgo9ElOZC7y36mq77fhl9+5JdN+H2njh4BN816+sY1JksZgkKduAtwM\n7K+qr8/btAfY1pa3AXfPG/9ie/rmXOCNebd4JEnLbM0A+5wHXAU8k+TJNvaPwA3AHUm2Ay8Al7dt\n9wEXAzPAW8DVQ52xJGlRFgx9VT0E5BibLzjK/gVcs8R5SZKGxE/GSlLnDL0kdc7QS1LnDL0kdW6Q\np24kaVlM7rx33FPoklf0ktQ5Qy9JnTP0ktQ5Qy9JnTP0ktQ5n7rRijCupzEO3HDJWI4rDZNX9JLU\nOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMv\nSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUOUMvSZ0z9JLUuTUL7ZDkFuBS4EhVfbKNnQLcDkwCB4DL\nq+q1JAG+CVwMvAX8bVU9PpqpS32b3HnvWI574IZLxnJcjc4gV/T/Clz4rrGdwN6q2gzsbesAFwGb\n288O4KbhTFOSdLwWDH1V/Rh49V3DW4DdbXk3sHXe+K0152FgbZL1w5qsJGnxjvce/bqqOtyWXwLW\nteUNwIvz9jvYxiRJY7Lkv4ytqgJqsa9LsiPJdJLp2dnZpU5DknQMxxv6l9+5JdN+H2njh4BN8/bb\n2Mb+QFXtqqqpqpqamJg4zmlIkhay4FM3x7AH2Abc0H7fPW/82iS3AZ8G3ph3i0dDMq6nMcAnMqSV\naJDHK78L/CVwWpKDwD8xF/g7kmwHXgAub7vfx9yjlTPMPV559QjmLElahAVDX1VXHmPTBUfZt4Br\nljopSdLw+MlYSeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6Seqc\noZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZek\nzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SeqcoZekzhl6SercSEKf5MIkP08yk2TnKI4h\nSRrM0EOf5ATgX4CLgDOAK5OcMezjSJIGM4or+nOAmap6vqr+F7gN2DKC40iSBjCK0G8AXpy3frCN\nSZLGIFU13DdMLgMurKq/a+tXAZ+uqmvftd8OYEdb/QTw8+M85GnAL4/ztSuV57w6eM6rw1LO+U+r\namKhndYc55u/l0PApnnrG9vY76mqXcCupR4syXRVTS31fVYSz3l18JxXh+U451HcunkM2Jzk9CQn\nAVcAe0ZwHEnSAIZ+RV9Vbye5FvhP4ATglqp6dtjHkSQNZhS3bqiq+4D7RvHeR7Hk2z8rkOe8OnjO\nq8PIz3nofxkrSXp/8SsQJKlzKzr0q+2rFpLckuRIkp+Oey7LJcmmJA8meS7Js0muG/ecRi3JB5M8\nmuSpds5fHfeclkOSE5I8keSecc9lOSQ5kOSZJE8mmR7psVbqrZv2VQv/BXyWuQ9lPQZcWVXPjXVi\nI5TkL4A3gVur6pPjns9ySLIeWF9Vjyf5CLAP2Nr5f+cAJ1fVm0lOBB4Crquqh8c8tZFKcj0wBfxx\nVV067vmMWpIDwFRVjfxzAyv5in7VfdVCVf0YeHXc81hOVXW4qh5vy78G9tP5J61rzptt9cT2szKv\nyAaUZCNwCfDtcc+lRys59H7VwiqTZBI4C3hkvDMZvXYb40ngCHB/VfV+zt8Avgz8btwTWUYF/DDJ\nvvZNASOzkkOvVSTJh4E7gS9V1a/GPZ9Rq6rfVtWZzH2y/Jwk3d6qS3IpcKSq9o17LsvsM1V1NnPf\n9HtNuzU7Eis59AN91YJWvnaf+k7gO1X1/XHPZzlV1evAg8CF457LCJ0HfL7ds74NOD/Jv493SqNX\nVYfa7yPAXczdjh6JlRx6v2phFWh/MXkzsL+qvj7u+SyHJBNJ1rblDzH3wMHPxjur0amqr1TVxqqa\nZO7/4weq6m/GPK2RSnJye7iAJCcDnwNG9jTdig19Vb0NvPNVC/uBO3r/qoUk3wV+AnwiycEk28c9\np2VwHnAVc1d5T7afi8c9qRFbDzyY5GnmLmjur6pV8cjhKrIOeCjJU8CjwL1V9YNRHWzFPl4pSRrM\nir2ilyQNxtBLUucMvSR1ztBLUucMvSR1ztBLUucMvSR1ztBLUuf+D4LedMkwtAvoAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Lun1902_I2aP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 300\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFcQiksEQNKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec0d7858-e59f-4a8f-c667-af2234ec0379"
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffled.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "H4ELGdrQQD6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 400\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0QFZESfMJErm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "cb849ac4-90aa-46ad-d5b8-4283c180612a"
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(aside_valid_test_label,axis = 1))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 64.,   0.,  15.,   0.,  31.,   0.,  30.,   0.,  42., 118.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tMF1ajQrJWRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Determine how many epochs are required"
      ]
    },
    {
      "metadata": {
        "id": "PiTBKrflH9K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "819a1f5a-50b1-4156-818f-c73bc5b6d20c"
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 20000\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 3\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<3000:\n",
        "        learn = .1\n",
        "      elif ep >=8000 and ep <= 17000:\n",
        "        learn = .001\n",
        "      else:\n",
        "        learn = .0001\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "              saver.save(sess, './statlog_letterReducedSGD')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 3.8707163, training acc total= 77.48488783836365%\n",
            "ValidTest acc= 62.333332 %\n",
            "epoch 1000, training loss Total= 0.16600206, training acc total= 93.83313059806824%\n",
            "ValidTest acc= 90.33333 %\n",
            "epoch 2000, training loss Total= 0.13964918, training acc total= 94.36517357826233%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 3000, training loss Total= 0.13757339, training acc total= 94.31681036949158%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 4000, training loss Total= 0.12622702, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5000, training loss Total= 0.12598847, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 6000, training loss Total= 0.12583676, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7000, training loss Total= 0.12571886, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8000, training loss Total= 0.1256192, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 9000, training loss Total= 0.12494656, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10000, training loss Total= 0.1244622, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11000, training loss Total= 0.12397973, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12000, training loss Total= 0.12354119, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 13000, training loss Total= 0.1231531, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14000, training loss Total= 0.12279087, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15000, training loss Total= 0.122435674, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16000, training loss Total= 0.12208364, training acc total= 94.46191191673279%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17000, training loss Total= 0.12175739, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18000, training loss Total= 0.12172691, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19000, training loss Total= 0.1216953, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "ValidValid acc= 90.38317 %\n",
            "ValidTest acc= 91.0 %\n",
            "==================================================\n",
            "W1\n",
            "3\n",
            "W2\n",
            "3\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoIsmarzTPqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### fine tune for higher precision for no. epochs"
      ]
    },
    {
      "metadata": {
        "id": "isv5BHBYI-JI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6970
        },
        "outputId": "3222772d-6f04-4d22-fbcb-2c7c75d148f3"
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 20000\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 100\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 3\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<3000:\n",
        "        learn = .1\n",
        "      elif ep >=8000 and ep <= 17000:\n",
        "        learn = .001\n",
        "      else:\n",
        "        learn = .0001\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "          print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "          if ep%plot_every == 0:\n",
        "            if (validationTest_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validationTest_accuracy\n",
        "              saver.save(sess, './statlog_letterReducedSGD')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 3.8707163, training acc total= 77.48488783836365%\n",
            "ValidTest acc= 62.333332 %\n",
            "epoch 100, training loss Total= 0.27612352, training acc total= 92.26118326187134%\n",
            "ValidTest acc= 89.0 %\n",
            "epoch 200, training loss Total= 0.23594344, training acc total= 92.84159541130066%\n",
            "ValidTest acc= 89.33333 %\n",
            "epoch 300, training loss Total= 0.21810143, training acc total= 93.13180446624756%\n",
            "ValidTest acc= 89.33333 %\n",
            "epoch 400, training loss Total= 0.20574985, training acc total= 93.25271844863892%\n",
            "ValidTest acc= 89.33333 %\n",
            "epoch 500, training loss Total= 0.19726034, training acc total= 93.42200756072998%\n",
            "ValidTest acc= 90.0 %\n",
            "epoch 600, training loss Total= 0.19069761, training acc total= 93.54292750358582%\n",
            "ValidTest acc= 90.0 %\n",
            "epoch 700, training loss Total= 0.18196669, training acc total= 93.66384744644165%\n",
            "ValidTest acc= 89.666664 %\n",
            "epoch 800, training loss Total= 0.17548576, training acc total= 93.76057982444763%\n",
            "ValidTest acc= 89.666664 %\n",
            "epoch 900, training loss Total= 0.17026874, training acc total= 93.78476142883301%\n",
            "ValidTest acc= 89.666664 %\n",
            "epoch 1000, training loss Total= 0.16600206, training acc total= 93.83313059806824%\n",
            "ValidTest acc= 90.33333 %\n",
            "epoch 1100, training loss Total= 0.16468592, training acc total= 93.9298689365387%\n",
            "ValidTest acc= 90.33333 %\n",
            "epoch 1200, training loss Total= 0.15705304, training acc total= 94.12333965301514%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 1300, training loss Total= 0.15775739, training acc total= 94.22007203102112%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 1400, training loss Total= 0.15472756, training acc total= 94.29262280464172%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 1500, training loss Total= 0.15375386, training acc total= 94.29262280464172%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 1600, training loss Total= 0.15150245, training acc total= 94.31681036949158%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 1700, training loss Total= 0.14245366, training acc total= 94.26844120025635%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 1800, training loss Total= 0.14483891, training acc total= 94.36517357826233%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 1900, training loss Total= 0.13701086, training acc total= 94.34099197387695%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 2000, training loss Total= 0.13964918, training acc total= 94.36517357826233%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 2100, training loss Total= 0.14054243, training acc total= 94.38936114311218%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 2200, training loss Total= 0.157911, training acc total= 94.26844120025635%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 2300, training loss Total= 0.13464344, training acc total= 94.43772435188293%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 2400, training loss Total= 0.1336898, training acc total= 94.38936114311218%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 2500, training loss Total= 0.1899767, training acc total= 93.76057982444763%\n",
            "ValidTest acc= 90.0 %\n",
            "epoch 2600, training loss Total= 0.13150373, training acc total= 94.34099197387695%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 2700, training loss Total= 0.14956865, training acc total= 94.41354274749756%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 2800, training loss Total= 0.14991815, training acc total= 94.36517357826233%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 2900, training loss Total= 0.1450613, training acc total= 94.38936114311218%\n",
            "ValidTest acc= 90.33333 %\n",
            "epoch 3000, training loss Total= 0.13757339, training acc total= 94.31681036949158%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 3100, training loss Total= 0.13096501, training acc total= 94.43772435188293%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 3200, training loss Total= 0.12852463, training acc total= 94.55864429473877%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 3300, training loss Total= 0.12746775, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 3400, training loss Total= 0.12694786, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 90.66667 %\n",
            "epoch 3500, training loss Total= 0.12666988, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 3600, training loss Total= 0.12650564, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 3700, training loss Total= 0.12639879, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 3800, training loss Total= 0.12632416, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 3900, training loss Total= 0.12626973, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4000, training loss Total= 0.12622702, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4100, training loss Total= 0.1261919, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4200, training loss Total= 0.12616216, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4300, training loss Total= 0.12613425, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4400, training loss Total= 0.12610883, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4500, training loss Total= 0.12608568, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4600, training loss Total= 0.12606429, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4700, training loss Total= 0.12604427, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4800, training loss Total= 0.12602498, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 4900, training loss Total= 0.12600644, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5000, training loss Total= 0.12598847, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5100, training loss Total= 0.12597114, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5200, training loss Total= 0.12595434, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5300, training loss Total= 0.12593785, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5400, training loss Total= 0.1259217, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5500, training loss Total= 0.12590624, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5600, training loss Total= 0.12589139, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5700, training loss Total= 0.12587702, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5800, training loss Total= 0.12586331, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 5900, training loss Total= 0.12584978, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6000, training loss Total= 0.12583676, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6100, training loss Total= 0.12582396, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6200, training loss Total= 0.12581125, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6300, training loss Total= 0.1257987, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6400, training loss Total= 0.1257867, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6500, training loss Total= 0.1257747, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6600, training loss Total= 0.12576288, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6700, training loss Total= 0.12575138, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6800, training loss Total= 0.12574019, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 6900, training loss Total= 0.12572949, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7000, training loss Total= 0.12571886, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7100, training loss Total= 0.12570846, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7200, training loss Total= 0.12569815, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7300, training loss Total= 0.12568769, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7400, training loss Total= 0.1256777, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7500, training loss Total= 0.12566774, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7600, training loss Total= 0.12565784, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7700, training loss Total= 0.12564825, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7800, training loss Total= 0.12563878, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 7900, training loss Total= 0.12562895, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8000, training loss Total= 0.1256192, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8100, training loss Total= 0.12553291, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8200, training loss Total= 0.12545164, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8300, training loss Total= 0.1253771, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8400, training loss Total= 0.1253066, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 8500, training loss Total= 0.12523985, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 8600, training loss Total= 0.12517646, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 8700, training loss Total= 0.12511568, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 8800, training loss Total= 0.12505792, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 8900, training loss Total= 0.12500182, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9000, training loss Total= 0.12494656, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9100, training loss Total= 0.12489276, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9200, training loss Total= 0.1248409, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9300, training loss Total= 0.12479082, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9400, training loss Total= 0.124741234, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9500, training loss Total= 0.12469326, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9600, training loss Total= 0.124646075, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9700, training loss Total= 0.12459977, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9800, training loss Total= 0.124553904, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 9900, training loss Total= 0.124508, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10000, training loss Total= 0.1244622, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10100, training loss Total= 0.12441479, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10200, training loss Total= 0.12436757, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10300, training loss Total= 0.124319814, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10400, training loss Total= 0.124270834, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10500, training loss Total= 0.124221034, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10600, training loss Total= 0.124171585, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10700, training loss Total= 0.12412346, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10800, training loss Total= 0.12407529, training acc total= 94.65538263320923%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 10900, training loss Total= 0.12402747, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11000, training loss Total= 0.12397973, training acc total= 94.63119506835938%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11100, training loss Total= 0.123932466, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11200, training loss Total= 0.12388563, training acc total= 94.607013463974%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11300, training loss Total= 0.12384037, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11400, training loss Total= 0.12379555, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11500, training loss Total= 0.12375138, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11600, training loss Total= 0.12370733, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11700, training loss Total= 0.12366493, training acc total= 94.58283185958862%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11800, training loss Total= 0.12362325, training acc total= 94.55864429473877%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 11900, training loss Total= 0.123581976, training acc total= 94.55864429473877%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12000, training loss Total= 0.12354119, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12100, training loss Total= 0.12350151, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12200, training loss Total= 0.12346163, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12300, training loss Total= 0.12342156, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12400, training loss Total= 0.123382464, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.333336 %\n",
            "epoch 12500, training loss Total= 0.12334384, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 12600, training loss Total= 0.123304665, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 12700, training loss Total= 0.12326602, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 12800, training loss Total= 0.12322787, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 12900, training loss Total= 0.12319035, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13000, training loss Total= 0.1231531, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13100, training loss Total= 0.12311746, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13200, training loss Total= 0.12308124, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13300, training loss Total= 0.12304416, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13400, training loss Total= 0.12300754, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13500, training loss Total= 0.122971006, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13600, training loss Total= 0.12293473, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13700, training loss Total= 0.12289939, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13800, training loss Total= 0.12286282, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 13900, training loss Total= 0.122826874, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14000, training loss Total= 0.12279087, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14100, training loss Total= 0.1227549, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14200, training loss Total= 0.122719035, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14300, training loss Total= 0.12268349, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14400, training loss Total= 0.122647405, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14500, training loss Total= 0.122612156, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14600, training loss Total= 0.122577585, training acc total= 94.5344626903534%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14700, training loss Total= 0.12254179, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14800, training loss Total= 0.12250611, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 14900, training loss Total= 0.12247132, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15000, training loss Total= 0.122435674, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15100, training loss Total= 0.12240054, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15200, training loss Total= 0.122364864, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15300, training loss Total= 0.12232867, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15400, training loss Total= 0.12229298, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15500, training loss Total= 0.12225739, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15600, training loss Total= 0.12222228, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15700, training loss Total= 0.12218763, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15800, training loss Total= 0.122153044, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 15900, training loss Total= 0.12211827, training acc total= 94.46191191673279%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16000, training loss Total= 0.12208364, training acc total= 94.46191191673279%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16100, training loss Total= 0.122049585, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16200, training loss Total= 0.12201661, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16300, training loss Total= 0.121983185, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16400, training loss Total= 0.12195043, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16500, training loss Total= 0.12191787, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16600, training loss Total= 0.12188549, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16700, training loss Total= 0.12185318, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16800, training loss Total= 0.12182136, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 16900, training loss Total= 0.12178966, training acc total= 94.48609352111816%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17000, training loss Total= 0.12175739, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17100, training loss Total= 0.12175441, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17200, training loss Total= 0.121751435, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17300, training loss Total= 0.121748425, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17400, training loss Total= 0.121745385, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17500, training loss Total= 0.12174233, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17600, training loss Total= 0.12173923, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17700, training loss Total= 0.121736184, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17800, training loss Total= 0.12173311, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 17900, training loss Total= 0.12173, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18000, training loss Total= 0.12172691, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18100, training loss Total= 0.121723756, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18200, training loss Total= 0.12172058, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18300, training loss Total= 0.121717356, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18400, training loss Total= 0.12171424, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18500, training loss Total= 0.12171111, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18600, training loss Total= 0.12170793, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18700, training loss Total= 0.12170479, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18800, training loss Total= 0.121701606, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 18900, training loss Total= 0.12169844, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19000, training loss Total= 0.1216953, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19100, training loss Total= 0.12169215, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19200, training loss Total= 0.12168899, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19300, training loss Total= 0.12168585, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19400, training loss Total= 0.12168272, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19500, training loss Total= 0.12167957, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19600, training loss Total= 0.12167642, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19700, training loss Total= 0.121673316, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19800, training loss Total= 0.12167027, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "epoch 19900, training loss Total= 0.121667214, training acc total= 94.51028108596802%\n",
            "ValidTest acc= 91.0 %\n",
            "ValidValid acc= 90.38317 %\n",
            "ValidTest acc= 91.0 %\n",
            "==================================================\n",
            "W1\n",
            "3\n",
            "W2\n",
            "3\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lZ5IPzM1aO3S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train entire data till 10000 epochs"
      ]
    },
    {
      "metadata": {
        "id": "Z6C75YaCI-Fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = train_valid_combined_shuffled_label[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = train_valid_combined_shuffled_label[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBmylidkbByd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_valid_combined_shuffled.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6zM5JVcI-Bv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "275ece79-5108-49bb-f2ea-450f24969897"
      },
      "cell_type": "code",
      "source": [
        "## 123 Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "hid_neuron = [104]\n",
        "num_steps = 150000\n",
        "# num_steps = 20000\n",
        "number_of_epoch = 10000\n",
        "batch_size = 2056\n",
        "# batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 1000\n",
        "best_accuracy_valid = 0\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "tracked_valid_accuracy = []\n",
        "total_steps_for_one_pass = number_of_ex//batch_size + 1\n",
        "step = 0\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "lr = tf.placeholder(tf.float32, shape = [])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 3\n",
        "wLoss2 = 3\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for ep in range(0,number_of_epoch):\n",
        "      if ep<3000:\n",
        "        learn = .1\n",
        "      elif ep >=8000 and ep <= 17000:\n",
        "        learn = .001\n",
        "      else:\n",
        "        learn = .0001\n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "#         print(step)\n",
        "#         if (step>5000):\n",
        "#           plot_every = 10\n",
        "        \n",
        "        if step>=number_of_ex//batch_size:\n",
        "          batch_x, batch_y = combined_train_valid[step*batch_size:,:],combined_train_valid_label[step*batch_size:,:]\n",
        "#           print(step,'Finishing',step*batch_size )\n",
        "          step = 0\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          start = step*batch_size\n",
        "          finish = (step+1)*batch_size\n",
        "#           print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "          batch_x, batch_y = combined_train_valid[step:finish,:],combined_train_valid_label[step:finish,:]\n",
        "#         batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "      if ep % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          track_step.append(step)\n",
        "          train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "          train_accuracy.append(train_acc_total)\n",
        "          train_losses.append(train_loss_total)\n",
        "          print(\"epoch \" + str(ep) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "          validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "#           print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "          tracked_valid_accuracy.append(validationTest_accuracy)\n",
        "#           if ep%plot_every == 0:\n",
        "#             if (validationTest_accuracy >= best_accuracy_valid):\n",
        "#               best_accuracy_valid = validationTest_accuracy\n",
        "#               saver.save(sess, './statlog_letterReducedSGD')\n",
        "#               G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "  #         if(train_loss_total<0.033881765):\n",
        "  #           break\n",
        "                                         \n",
        "#     validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "#     print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "#     validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "#     print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "    print(\"Train acc=\",str(train_acc_total), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './statlog_letterReducedSGDFinal')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, training loss Total= 0.7279103, training acc total= 91.94858074188232%\n",
            "epoch 1000, training loss Total= 0.14714189, training acc total= 93.73026490211487%\n",
            "epoch 2000, training loss Total= 0.11703745, training acc total= 94.24898624420166%\n",
            "epoch 3000, training loss Total= 0.12543412, training acc total= 94.27154064178467%\n",
            "epoch 4000, training loss Total= 0.11386755, training acc total= 94.33919787406921%\n",
            "epoch 5000, training loss Total= 0.11287211, training acc total= 94.33919787406921%\n",
            "epoch 6000, training loss Total= 0.112070836, training acc total= 94.33919787406921%\n",
            "epoch 7000, training loss Total= 0.11137527, training acc total= 94.33919787406921%\n",
            "epoch 8000, training loss Total= 0.11089559, training acc total= 94.33919787406921%\n",
            "epoch 9000, training loss Total= 0.107166156, training acc total= 94.42940950393677%\n",
            "Train acc= 0.9451962 %\n",
            "==================================================\n",
            "W1\n",
            "3\n",
            "W2\n",
            "3\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tPpj4B9bzVQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HhHoRGntavcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check on test set!"
      ]
    },
    {
      "metadata": {
        "id": "ZjG059nKb0B7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "66b08775-1d34-4642-d16d-7edcaefcaa82"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, './statlog_letterReducedSGDFinal')\n",
        "    train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "    print(\"Train acc=\",str(train_acc_total), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_letterReducedSGDFinal\n",
            "Train acc= 0.9451962 %\n",
            "Test acc= 90.8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QlzkjrMfavOm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "uYTrY2rwI9-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLSesmCEI96T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}